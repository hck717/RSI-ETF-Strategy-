{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hck717/RSI-ETF-Strategy-/blob/main/QRT_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6qz2CtYLmVj"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.15.0 catboost==1.2.5 lightgbm==4.3.0 imbalanced-learn==0.12.4 statsmodels==0.14.1 pandas==2.0.3 numpy==1.26.4 scikit-learn==1.4.2 matplotlib==3.8.4 seaborn==0.13.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHeJUbtCrEZa"
      },
      "source": [
        "Best up-to-date, 13-jul, 73%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "3fiRLkpImgdd",
        "outputId": "d11da8d8-9a6e-4c6b-e322-84fb468fc2bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost version: 2.1.4\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "Dataset not found: [Errno 2] No such file or directory: '/content/X_train_itDkypA.csv'. Please ensure files are uploaded to /content.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-3312324152.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X_train_itDkypA.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_train_3LeeT2g.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/X_train_itDkypA.csv'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-3312324152.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0msupplementary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supplementary_data_Vkoyn8z.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset not found: {e}. Please ensure files are uploaded to {DATA_DIR}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Custom weighted accuracy metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Dataset not found: [Errno 2] No such file or directory: '/content/X_train_itDkypA.csv'. Please ensure files are uploaded to /content."
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from joblib import Parallel, delayed\n",
        "import json\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import xgboost\n",
        "\n",
        "# Check xgboost version for compatibility\n",
        "print(f\"XGBoost version: {xgboost.__version__}\")\n",
        "if int(xgboost.__version__.split('.')[0]) < 1:\n",
        "    print(\"Warning: XGBoost version < 1.0.0 detected. Ensure compatibility with eval_metric in constructor.\")\n",
        "\n",
        "# Set up data directory\n",
        "DATA_DIR = '/content'\n",
        "\n",
        "# Load datasets\n",
        "try:\n",
        "    X_train = pd.read_csv(os.path.join(DATA_DIR, 'X_train_itDkypA.csv'), index_col='ID', dtype=np.float32)\n",
        "    y_train = pd.read_csv(os.path.join(DATA_DIR, 'y_train_3LeeT2g.csv'), index_col='ID', dtype=np.float32)\n",
        "    X_test = pd.read_csv(os.path.join(DATA_DIR, 'X_test_Beg4ey3.csv'), index_col='ID', dtype=np.float32)\n",
        "    supplementary = pd.read_csv(os.path.join(DATA_DIR, 'supplementary_data_Vkoyn8z.csv'))\n",
        "except FileNotFoundError as e:\n",
        "    raise FileNotFoundError(f\"Dataset not found: {e}. Please ensure files are uploaded to {DATA_DIR}.\")\n",
        "\n",
        "# Custom weighted accuracy metric\n",
        "def weighted_accuracy(y_true, y_pred, weights):\n",
        "    y_pred_mapped = np.where(y_pred == 1, 1, -1)\n",
        "    correct = (y_pred_mapped == np.sign(y_true)).astype(float)\n",
        "    return np.sum(np.abs(y_true) * correct) / np.sum(np.abs(y_true))\n",
        "\n",
        "# Preprocess data with enhanced feature selection\n",
        "def preprocess_data(X, y=None, supplementary=None, is_train=True, top_cols=None):\n",
        "    ret_cols = [col for col in X.columns if col.startswith('RET_')]\n",
        "\n",
        "    # Dynamic feature selection with minimum variance threshold\n",
        "    if is_train and top_cols is None:\n",
        "        if len(ret_cols) > 15:\n",
        "            variances = X[ret_cols].var()\n",
        "            corr_sum = X[ret_cols].corr().abs().sum()\n",
        "            combined_score = variances * corr_sum\n",
        "            # Filter out low-variance features (threshold = 1e-5)\n",
        "            valid_cols = variances[variances > 1e-5].index\n",
        "            if len(valid_cols) < 15:\n",
        "                top_cols = valid_cols.tolist()\n",
        "            else:\n",
        "                top_cols = combined_score.loc[valid_cols].sort_values(ascending=False).head(15).index.tolist()\n",
        "        else:\n",
        "            top_cols = ret_cols\n",
        "        print(f\"Selected top return columns: {top_cols}\")\n",
        "    elif top_cols is not None:\n",
        "        ret_cols = [col for col in ret_cols if col in top_cols]\n",
        "        if not ret_cols:\n",
        "            raise ValueError(\"No return columns selected. Check top_cols consistency.\")\n",
        "\n",
        "    # Cache sector-based medians\n",
        "    sector_medians = {}\n",
        "    if supplementary is not None:\n",
        "        sector_map = supplementary.set_index('ID_asset')['CLASS_LEVEL_1']\n",
        "        for col in ret_cols:\n",
        "            asset_id = int(col.replace('RET_', ''))\n",
        "            sector = sector_map.get(asset_id, np.nan)\n",
        "            if pd.notna(sector):\n",
        "                sector_assets = supplementary[supplementary['CLASS_LEVEL_1'] == sector]['ID_asset']\n",
        "                sector_cols = [f'RET_{a}' for a in sector_assets if f'RET_{a}' in X.columns]\n",
        "                if sector_cols:\n",
        "                    sector_medians[col] = X[sector_cols].median(axis=1)\n",
        "            if col in sector_medians:\n",
        "                X[col] = X[col].fillna(sector_medians[col])\n",
        "            else:\n",
        "                X[col] = X[col].fillna(X[col].median())\n",
        "\n",
        "    # Sector-based features\n",
        "    new_cols = {}\n",
        "    if supplementary is not None:\n",
        "        level = 'CLASS_LEVEL_1'\n",
        "        sector_groups = supplementary.groupby(level)['ID_asset'].apply(list).to_dict()\n",
        "        for sector, assets in sector_groups.items():\n",
        "            asset_cols = [f'RET_{asset}' for asset in assets if f'RET_{asset}' in ret_cols]\n",
        "            if asset_cols:\n",
        "                new_cols[f'SECTOR_AVG_{level}_{sector}'] = X[asset_cols].mean(axis=1).replace([np.inf, -np.inf], 0).fillna(0)\n",
        "        X = X.merge(supplementary[['ID_asset', level]].rename(columns={'ID_asset': 'ID_TARGET', level: f'TARGET_{level}'}),\n",
        "                    on='ID_TARGET', how='left')\n",
        "        X = pd.concat([X, pd.get_dummies(X[f'TARGET_{level}'], prefix=f'TARGET_{level}', dummy_na=True)], axis=1)\n",
        "        X = X.drop(f'TARGET_{level}', axis=1)\n",
        "\n",
        "    # Cross-sectional features\n",
        "    new_cols['MEAN_RET'] = X[ret_cols].mean(axis=1)\n",
        "    new_cols['STD_RET'] = X[ret_cols].std(axis=1)\n",
        "    new_cols.update({f'CS_RANK_{col}': X.groupby('ID_DAY')[col].rank(pct=True).replace([np.inf, -np.inf], 0).fillna(0) for col in ret_cols})\n",
        "\n",
        "    # Correlation-based features (top 5 pairs)\n",
        "    if is_train:\n",
        "        corr_matrix = X[ret_cols].corr()\n",
        "        corr_pairs = corr_matrix.unstack().sort_values(ascending=False)\n",
        "        top_pairs = [(i, j) for i, j in corr_pairs.index if i < j][:5]\n",
        "        for i, j in top_pairs:\n",
        "            new_cols[f'CORR_{i}_{j}'] = X[i] * X[j]\n",
        "\n",
        "    # PCA features (2 components)\n",
        "    if ret_cols:\n",
        "        pca = PCA(n_components=min(2, len(ret_cols)), random_state=42)\n",
        "        pca_features = pca.fit_transform(X[ret_cols].fillna(0))\n",
        "        for i in range(pca_features.shape[1]):\n",
        "            new_cols[f'PCA_{i}'] = pca_features[:, i]\n",
        "\n",
        "    # Add new features to DataFrame\n",
        "    new_cols_df = pd.DataFrame(new_cols, index=X.index, dtype=np.float32)\n",
        "    X = pd.concat([X, new_cols_df], axis=1)\n",
        "\n",
        "    # Standardize numerical features\n",
        "    feature_cols = [col for col in X.columns if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "    scaler = StandardScaler()\n",
        "    X[feature_cols] = scaler.fit_transform(X[feature_cols].replace([np.inf, -np.inf], 0).fillna(0))\n",
        "\n",
        "    if is_train:\n",
        "        y['SIGN_TARGET'] = np.where(y['RET_TARGET'] > 0, 1, 0).astype(np.int32)\n",
        "        return X, y, feature_cols, top_cols\n",
        "    return X, None, feature_cols, top_cols\n",
        "\n",
        "# Preprocess data\n",
        "try:\n",
        "    X_train, y_train, feature_cols, top_cols = preprocess_data(X_train, y_train, supplementary, is_train=True)\n",
        "    X_test, _, test_feature_cols, _ = preprocess_data(X_test, supplementary=supplementary, is_train=False, top_cols=top_cols)\n",
        "except ValueError as e:\n",
        "    print(f\"Preprocessing error: {e}\")\n",
        "    raise\n",
        "\n",
        "# Align columns\n",
        "common_cols = X_train.columns.intersection(X_test.columns)\n",
        "X_train = X_train[common_cols]\n",
        "X_test = X_test[common_cols]\n",
        "feature_cols = [col for col in common_cols if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "\n",
        "# Align y_train\n",
        "y_train = y_train.loc[X_train.index]\n",
        "\n",
        "# Define models with lightweight grid search\n",
        "models = {\n",
        "    'LightGBM': {\n",
        "        'model': LGBMClassifier(n_estimators=100, num_leaves=25, min_child_samples=20,\n",
        "                                lambda_l1=0.5, lambda_l2=0.5, subsample=0.7, colsample_bytree=0.7,\n",
        "                                random_state=42, n_jobs=-1, verbosity=-1, class_weight='balanced'),\n",
        "        'param_grid': [{'learning_rate': [0.02, 0.05]}],\n",
        "        'callbacks': [lightgbm.early_stopping(stopping_rounds=10, verbose=False)]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'model': XGBClassifier(n_estimators=100, max_depth=4, subsample=0.7, colsample_bytree=0.7,\n",
        "                               random_state=42, n_jobs=-1, verbosity=0, eval_metric='logloss',\n",
        "                               scale_pos_weight=len(y_train[y_train['SIGN_TARGET'] == 0]) / len(y_train[y_train['SIGN_TARGET'] == 1])),\n",
        "        'param_grid': [{'learning_rate': [0.05, 0.1]}],\n",
        "        'callbacks': [None]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to train and predict for a single target\n",
        "def train_target(target, X_train, y_train, X_test, feature_cols, model, model_name, kf, param_grid, callbacks):\n",
        "    X_target = X_train[X_train['ID_TARGET'] == target][feature_cols]\n",
        "    y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "    weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "    groups = X_train[X_train['ID_TARGET'] == target]['ID_DAY']\n",
        "    X_test_target = X_test[X_test['ID_TARGET'] == target][feature_cols]\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "    # Check for sufficient data\n",
        "    if len(X_target) < 10 or len(X_test_target) == 0:\n",
        "        print(f\"Warning: Insufficient data for ID_TARGET {target} (train: {len(X_target)}, test: {len(X_test_target)}). Skipping.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids)), []\n",
        "\n",
        "    param_results = []\n",
        "    best_params = None\n",
        "    best_score = 0\n",
        "    best_model = None\n",
        "\n",
        "    # Lightweight grid search\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        model.set_params(**params)\n",
        "        fold_accuracies = []\n",
        "        for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "            X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "            y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "            w_val = weights.iloc[val_idx]\n",
        "\n",
        "            if model_name == 'LightGBM' and callbacks:\n",
        "                model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=callbacks)\n",
        "            else:\n",
        "                model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "            y_pred = model.predict(X_val)\n",
        "            acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "            fold_accuracies.append(acc)\n",
        "\n",
        "        mean_acc = np.mean(fold_accuracies)\n",
        "        print(f\"{model_name} | ID_TARGET: {target} | Params: {params} | Mean Accuracy: {mean_acc:.4f} | Fold Accuracies: {fold_accuracies} | Train Samples: {len(X_target)}\", flush=True)\n",
        "        param_results.append({\n",
        "            'params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': fold_accuracies\n",
        "        })\n",
        "        if mean_acc > best_score:\n",
        "            best_score = mean_acc\n",
        "            best_params = params\n",
        "            best_model = type(model)(**model.get_params())\n",
        "\n",
        "    # Train with best parameters\n",
        "    best_model.set_params(**best_params)\n",
        "    if model_name == 'LightGBM' and callbacks:\n",
        "        best_model.fit(X_target, y_target, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=callbacks)\n",
        "    else:\n",
        "        best_model.fit(X_target, y_target, eval_set=[(X_target, y_target)], verbose=False)\n",
        "\n",
        "    # Predict\n",
        "    preds = best_model.predict_proba(X_test_target)[:, 1]\n",
        "\n",
        "    # Feature importance\n",
        "    importance = best_model.feature_importances_\n",
        "    feature_importance = dict(zip(feature_cols, importance))\n",
        "    top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:30]\n",
        "\n",
        "    # Clean up memory\n",
        "    gc.collect()\n",
        "\n",
        "    return str(target), best_params, best_score, param_results, test_ids, preds, top_features\n",
        "\n",
        "# Cross-validation and training\n",
        "kf = GroupKFold(n_splits=2)  # Reduced folds for faster training\n",
        "results = {}\n",
        "predictions = {}\n",
        "ensemble_weights = {'LightGBM': 0.7, 'XGBoost': 0.3}\n",
        "param_log = {}\n",
        "top_features_all = {}\n",
        "param_summary = []\n",
        "\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\", flush=True)\n",
        "    param_log[model_name] = {}\n",
        "    top_features_all[model_name] = {}\n",
        "\n",
        "    # Parallelize training across targets\n",
        "    results_parallel = Parallel(n_jobs=-1)(\n",
        "        delayed(train_target)(target, X_train, y_train, X_test, feature_cols, model_info['model'], model_name, kf,\n",
        "                             model_info['param_grid'], model_info['callbacks'])\n",
        "        for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\")\n",
        "    )\n",
        "\n",
        "    # Collect results\n",
        "    accuracies = []\n",
        "    for target, params, mean_acc, param_results, test_ids, preds, top_features in results_parallel:\n",
        "        param_log[model_name][target] = {\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'all_params': param_results\n",
        "        }\n",
        "        top_features_all[model_name][target] = top_features\n",
        "        accuracies.append(mean_acc)\n",
        "        predictions.setdefault(target, {})[model_name] = dict(zip(test_ids, preds))\n",
        "        param_summary.append({\n",
        "            'model': model_name,\n",
        "            'ID_TARGET': target,\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': param_results[-1]['fold_accuracies'] if param_results else []\n",
        "        })\n",
        "\n",
        "    results[model_name] = np.mean([acc for acc in accuracies if acc > 0])  # Exclude skipped targets\n",
        "    print(f\"{model_name} Weighted Accuracy: {results[model_name]:.4f}\", flush=True)\n",
        "\n",
        "    # Print parameter summary\n",
        "    print(f\"\\n{model_name} Parameter Summary:\", flush=True)\n",
        "    for summary in param_summary:\n",
        "        if summary['model'] == model_name:\n",
        "            print(f\"ID_TARGET: {summary['ID_TARGET']} | Best Params: {summary['best_params']} | Mean Accuracy: {summary['mean_accuracy']:.4f} | Fold Accuracies: {summary['fold_accuracies']}\", flush=True)\n",
        "\n",
        "# Save parameter log\n",
        "param_log_path = os.path.join(DATA_DIR, 'hyperparameters.json')\n",
        "with open(param_log_path, 'w') as f:\n",
        "    json.dump(param_log, f, indent=4)\n",
        "print(f\"Saved hyperparameter log to: {param_log_path}\", flush=True)\n",
        "files.download(param_log_path)\n",
        "\n",
        "# Second-pass training with top 30 features\n",
        "print(\"\\nPerforming second-pass training with top 30 features...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nSecond-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\"):\n",
        "        target_str = str(target)\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "        if len(X_target) < 10:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        model = model_info['model']\n",
        "        model.set_params(**param_log[model_name][target_str]['best_params'])\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        else:\n",
        "            model.fit(X_target, y_target, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1]\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Ensemble predictions\n",
        "final_predictions = {}\n",
        "for target in X_test['ID_TARGET'].unique():\n",
        "    target_str = str(target)\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "    lgbm_preds = np.array(list(predictions[target_str].get('LightGBM', {idx: 0 for idx in test_ids}).values()))\n",
        "    xgb_preds = np.array(list(predictions[target_str].get('XGBoost', {idx: 0 for idx in test_ids}).values()))\n",
        "    ensemble_preds = ensemble_weights['LightGBM'] * lgbm_preds + ensemble_weights['XGBoost'] * xgb_preds\n",
        "    final_predictions.update({idx: 1 if p >= 0.5 else -1 for idx, p in zip(test_ids, ensemble_preds)})\n",
        "\n",
        "# Create output CSV\n",
        "output_df = pd.DataFrame.from_dict(final_predictions, orient='index', columns=['RET_TARGET']).reset_index()\n",
        "output_df.columns = ['ID', 'RET_TARGET']\n",
        "output_df = output_df.sort_values('ID')\n",
        "output_path = os.path.join(DATA_DIR, 'predictions_ensemble.csv')\n",
        "output_df.to_csv(output_path, index=False)\n",
        "print(f\"Saved predictions to: {output_path}\", flush=True)\n",
        "\n",
        "# Validate output\n",
        "test_csv = pd.read_csv(output_path)\n",
        "print(f\"Output CSV shape: {test_csv.shape}\", flush=True)\n",
        "print(f\"Output CSV ID range: {test_csv['ID'].min()} to {test_csv['ID'].max()}\", flush=True)\n",
        "print(f\"Unique RET_TARGET values: {test_csv['RET_TARGET'].unique()}\", flush=True)\n",
        "print(f\"Missing values: {test_csv.isna().sum().sum()}\", flush=True)\n",
        "\n",
        "# Download the file\n",
        "files.download(output_path)\n",
        "\n",
        "# Print final results\n",
        "print(\"\\nValidation Results:\", flush=True)\n",
        "for model_name, acc in results.items():\n",
        "    print(f\"{model_name}: {acc:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCizJVAGvBgX"
      },
      "source": [
        "less complex than 74.22%- 74.15\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "cW7QyqGwvDeQ",
        "outputId": "763461c7-10ea-4c8d-f83a-1d61249c2dc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting preprocessing at 03:15:27\n",
            "Selected top return columns: ['RET_262', 'RET_121', 'RET_88', 'RET_172', 'RET_261', 'RET_118', 'RET_150', 'RET_238']\n",
            "Preprocessing completed in 45.61 seconds\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'ID_DAY'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'ID_DAY'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-4049866068.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m# Create holdout set (20% of training data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0mouter_kf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGroupKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mholdout_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouter_kf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID_DAY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0mX_train_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_holdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mholdout_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0my_train_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_holdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mholdout_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'ID_DAY'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost\n",
        "from sklearn.decomposition import PCA\n",
        "from joblib import Parallel, delayed\n",
        "import json\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# Check xgboost version for compatibility\n",
        "print(f\"XGBoost version: {xgboost.__version__}\")\n",
        "if int(xgboost.__version__.split('.')[0]) < 1:\n",
        "    print(\"Warning: XGBoost version < 1.0.0 detected. Ensure compatibility with eval_metric in constructor.\")\n",
        "\n",
        "# Set up data directory\n",
        "DATA_DIR = '/content'\n",
        "\n",
        "# Load datasets\n",
        "try:\n",
        "    X_train = pd.read_csv(os.path.join(DATA_DIR, 'X_train_itDkypA.csv'), index_col='ID', dtype=np.float32)\n",
        "    y_train = pd.read_csv(os.path.join(DATA_DIR, 'y_train_3LeeT2g.csv'), index_col='ID', dtype=np.float32)\n",
        "    X_test = pd.read_csv(os.path.join(DATA_DIR, 'X_test_Beg4ey3.csv'), index_col='ID', dtype=np.float32)\n",
        "    supplementary = pd.read_csv(os.path.join(DATA_DIR, 'supplementary_data_Vkoyn8z.csv'))\n",
        "except FileNotFoundError as e:\n",
        "    raise FileNotFoundError(f\"Dataset not found: {e}. Please ensure files are uploaded to {DATA_DIR}.\")\n",
        "\n",
        "# Custom weighted accuracy metric\n",
        "def weighted_accuracy(y_true, y_pred, weights):\n",
        "    y_pred_mapped = np.where(y_pred == 1, 1, -1)\n",
        "    correct = (y_pred_mapped == np.sign(y_true)).astype(float)\n",
        "    return np.sum(np.abs(y_true) * correct) / np.sum(np.abs(y_true))\n",
        "\n",
        "# Preprocess data with enhanced feature selection and momentum feature\n",
        "def preprocess_data(X, y=None, supplementary=None, is_train=True, top_cols=None):\n",
        "    ret_cols = [col for col in X.columns if col.startswith('RET_')]\n",
        "    if is_train and top_cols is None:\n",
        "        if len(ret_cols) > 15:\n",
        "            variances = X[ret_cols].var()\n",
        "            corr_sum = X[ret_cols].corr().abs().sum()\n",
        "            combined_score = variances * corr_sum\n",
        "            valid_cols = variances[variances > 1e-5].index\n",
        "            if len(valid_cols) < 15:\n",
        "                top_cols = valid_cols.tolist()\n",
        "            else:\n",
        "                top_cols = combined_score.loc[valid_cols].sort_values(ascending=False).head(15).index.tolist()\n",
        "        else:\n",
        "            top_cols = ret_cols\n",
        "        print(f\"Selected top return columns: {top_cols}\")\n",
        "    elif top_cols is not None:\n",
        "        ret_cols = [col for col in ret_cols if col in top_cols]\n",
        "        if not ret_cols:\n",
        "            raise ValueError(\"No return columns selected. Check top_cols consistency.\")\n",
        "\n",
        "    sector_medians = {}\n",
        "    if supplementary is not None:\n",
        "        sector_map = supplementary.set_index('ID_asset')['CLASS_LEVEL_1']\n",
        "        for col in ret_cols:\n",
        "            asset_id = int(col.replace('RET_', ''))\n",
        "            sector = sector_map.get(asset_id, np.nan)\n",
        "            if pd.notna(sector):\n",
        "                sector_assets = supplementary[supplementary['CLASS_LEVEL_1'] == sector]['ID_asset']\n",
        "                sector_cols = [f'RET_{a}' for a in sector_assets if f'RET_{a}' in X.columns]\n",
        "                if sector_cols:\n",
        "                    sector_medians[col] = X[sector_cols].median(axis=1)\n",
        "            if col in sector_medians:\n",
        "                X[col] = X[col].fillna(sector_medians[col])\n",
        "            else:\n",
        "                X[col] = X[col].fillna(X[col].median())\n",
        "\n",
        "    new_cols = {}\n",
        "    if supplementary is not None:\n",
        "        level = 'CLASS_LEVEL_1'\n",
        "        sector_groups = supplementary.groupby(level)['ID_asset'].apply(list).to_dict()\n",
        "        for sector, assets in sector_groups.items():\n",
        "            asset_cols = [f'RET_{asset}' for asset in assets if f'RET_{asset}' in ret_cols]\n",
        "            if asset_cols:\n",
        "                new_cols[f'SECTOR_AVG_{level}_{sector}'] = X[asset_cols].mean(axis=1).replace([np.inf, -np.inf], 0).fillna(0)\n",
        "        X = X.merge(supplementary[['ID_asset', level]].rename(columns={'ID_asset': 'ID_TARGET', level: f'TARGET_{level}'}),\n",
        "                    on='ID_TARGET', how='left')\n",
        "        X = pd.concat([X, pd.get_dummies(X[f'TARGET_{level}'], prefix=f'TARGET_{level}', dummy_na=True)], axis=1)\n",
        "        X = X.drop(f'TARGET_{level}', axis=1)\n",
        "\n",
        "    new_cols['MEAN_RET'] = X[ret_cols].mean(axis=1)\n",
        "    new_cols['STD_RET'] = X[ret_cols].std(axis=1)\n",
        "    new_cols['MOMENTUM_7D'] = X[ret_cols].rolling(window=7, min_periods=1).mean().mean(axis=1).replace([np.inf, -np.inf], 0).fillna(0)\n",
        "    new_cols.update({f'CS_RANK_{col}': X.groupby('ID_DAY')[col].rank(pct=True).replace([np.inf, -np.inf], 0).fillna(0) for col in ret_cols})\n",
        "\n",
        "    if is_train:\n",
        "        corr_matrix = X[ret_cols].corr()\n",
        "        corr_pairs = corr_matrix.unstack().sort_values(ascending=False)\n",
        "        top_pairs = [(i, j) for i, j in corr_pairs.index if i < j][:5]\n",
        "        for i, j in top_pairs:\n",
        "            new_cols[f'CORR_{i}_{j}'] = X[i] * X[j]\n",
        "\n",
        "    if ret_cols:\n",
        "        pca = PCA(n_components=min(2, len(ret_cols)), random_state=42)\n",
        "        pca_features = pca.fit_transform(X[ret_cols].fillna(0))\n",
        "        for i in range(pca_features.shape[1]):\n",
        "            new_cols[f'PCA_{i}'] = pca_features[:, i]\n",
        "\n",
        "    new_cols_df = pd.DataFrame(new_cols, index=X.index, dtype=np.float32)\n",
        "    X = pd.concat([X, new_cols_df], axis=1)\n",
        "\n",
        "    feature_cols = [col for col in X.columns if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "    scaler = StandardScaler()\n",
        "    X[feature_cols] = scaler.fit_transform(X[feature_cols].replace([np.inf, -np.inf], 0).fillna(0))\n",
        "\n",
        "    if is_train:\n",
        "        y['SIGN_TARGET'] = np.where(y['RET_TARGET'] > 0, 1, 0).astype(np.int32)\n",
        "        return X, y, feature_cols, top_cols\n",
        "    return X, None, feature_cols, top_cols\n",
        "\n",
        "# Preprocess data\n",
        "try:\n",
        "    X_train, y_train, feature_cols, top_cols = preprocess_data(X_train, y_train, supplementary, is_train=True)\n",
        "    X_test, _, test_feature_cols, _ = preprocess_data(X_test, supplementary=supplementary, is_train=False, top_cols=top_cols)\n",
        "except ValueError as e:\n",
        "    print(f\"Preprocessing error: {e}\")\n",
        "    raise\n",
        "\n",
        "# Align columns\n",
        "common_cols = X_train.columns.intersection(X_test.columns)\n",
        "X_train = X_train[common_cols]\n",
        "X_test = X_test[common_cols]\n",
        "feature_cols = [col for col in common_cols if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "\n",
        "# Align y_train\n",
        "y_train = y_train.loc[X_train.index]\n",
        "\n",
        "# Define models with reduced hyperparameter grids\n",
        "models = {\n",
        "    'LightGBM': {\n",
        "        'model': LGBMClassifier(num_leaves=31, min_child_samples=15, lambda_l1=0.3, lambda_l2=0.3,\n",
        "                                subsample=0.7, colsample_bytree=0.8, bagging_freq=5, bagging_fraction=0.7,\n",
        "                                random_state=42, n_jobs=1, verbosity=-1, class_weight='balanced', force_row_wise=True),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.02], 'num_leaves': [15], 'min_child_samples': [20], 'bagging_fraction': [0.6], 'reg_alpha': [0.1], 'reg_lambda': [0.1]},\n",
        "            {'learning_rate': [0.05], 'num_leaves': [31], 'min_child_samples': [10], 'bagging_fraction': [0.7], 'reg_alpha': [0.2], 'reg_lambda': [0.2]}\n",
        "        ],\n",
        "        'callbacks': [lightgbm.early_stopping(stopping_rounds=10, verbose=False)]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'model': XGBClassifier(max_depth=4, min_child_weight=2, subsample=0.8, colsample_bytree=0.8,\n",
        "                               random_state=42, n_jobs=1, eval_metric='logloss', verbosity=0,\n",
        "                               scale_pos_weight=len(y_train[y_train['SIGN_TARGET'] == 0]) / len(y_train[y_train['SIGN_TARGET'] == 1])),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.03], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [150], 'reg_alpha': [0.1], 'reg_lambda': [1.0]},\n",
        "            {'learning_rate': [0.05], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [200], 'reg_alpha': [0.2], 'reg_lambda': [1.5]}\n",
        "        ],\n",
        "        'callbacks': [xgboost.callback.EarlyStopping(rounds=10, metric_name='logloss', save_best=True)]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to train and predict for a single target\n",
        "def train_target(target, X_train, y_train, X_test, feature_cols, model, model_name, kf, param_grid, callbacks):\n",
        "    X_target = X_train[X_train['ID_TARGET'] == target][feature_cols]\n",
        "    y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "    weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "    low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "    weight_scale = 1.5 if target in low_performing_targets else 1.0\n",
        "    weights = weights * weight_scale\n",
        "    groups = X_train[X_train['ID_TARGET'] == target]['ID_DAY']\n",
        "    X_test_target = X_test[X_test['ID_TARGET'] == target][feature_cols]\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "    if len(X_target) < 100 or len(X_test_target) == 0:\n",
        "        print(f\"Warning: Insufficient data for ID_TARGET {target} (train: {len(X_target)}, test: {len(X_test_target)}). Skipping.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    param_results = []\n",
        "    best_params = None\n",
        "    best_score = 0\n",
        "    best_model = None\n",
        "\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        print(f\"Testing params for {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "        try:\n",
        "            model.set_params(**params)\n",
        "        except ValueError as e:\n",
        "            print(f\"Invalid params for {model_name} ID_TARGET {target}: {e}\")\n",
        "            continue\n",
        "        fold_accuracies = []\n",
        "        for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "            X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "            y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "            w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "            if model_name == 'LightGBM' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=callbacks)\n",
        "            elif model_name == 'XGBoost' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "            else:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "            y_pred = model.predict(X_val)\n",
        "            acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "            fold_accuracies.append(acc)\n",
        "        mean_acc = np.mean(fold_accuracies)\n",
        "        print(f\"{model_name} | ID_TARGET: {target} | Params: {params} | Mean Accuracy: {mean_acc:.4f} | Fold Accuracies: {fold_accuracies}\", flush=True)\n",
        "        param_results.append({\n",
        "            'params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': fold_accuracies\n",
        "        })\n",
        "        if mean_acc > best_score:\n",
        "            best_score = mean_acc\n",
        "            best_params = params\n",
        "            best_model = type(model)(**model.get_params())\n",
        "\n",
        "    if best_model is None:\n",
        "        print(f\"No valid model for {model_name} ID_TARGET {target}. Using default.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    best_model.set_params(**best_params)\n",
        "    if model_name == 'LightGBM' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=callbacks)\n",
        "    elif model_name == 'XGBoost' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "    else:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights)\n",
        "    preds = best_model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "    importance = best_model.feature_importances_\n",
        "    feature_importance = dict(zip(feature_cols, importance))\n",
        "    top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:30]\n",
        "    gc.collect()\n",
        "    return str(target), best_params, best_score, param_results, test_ids, preds, top_features\n",
        "\n",
        "# Cross-validation and training\n",
        "kf = GroupKFold(n_splits=5)\n",
        "results = {}\n",
        "predictions = {}\n",
        "param_log = {}\n",
        "top_features_all = {}\n",
        "param_summary = []\n",
        "low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\", flush=True)\n",
        "    param_log[model_name] = {}\n",
        "    top_features_all[model_name] = {}\n",
        "    results_parallel = Parallel(n_jobs=-1)(\n",
        "        delayed(train_target)(target, X_train, y_train, X_test, feature_cols, model_info['model'], model_name, kf,\n",
        "                             model_info['param_grid'], model_info['callbacks'])\n",
        "        for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\")\n",
        "    )\n",
        "    accuracies = []\n",
        "    for target, params, mean_acc, param_results, test_ids, preds, top_features in results_parallel:\n",
        "        param_log[model_name][target] = {\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'all_params': param_results\n",
        "        }\n",
        "        top_features_all[model_name][target] = top_features\n",
        "        accuracies.append(mean_acc)\n",
        "        predictions.setdefault(target, {})[model_name] = dict(zip(test_ids, preds))\n",
        "        param_summary.append({\n",
        "            'model': model_name,\n",
        "            'ID_TARGET': target,\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': param_results[-1]['fold_accuracies'] if param_results else []\n",
        "        })\n",
        "    results[model_name] = np.mean([acc for acc in accuracies if acc > 0])\n",
        "    print(f\"{model_name} Weighted Accuracy: {results[model_name]:.4f}\", flush=True)\n",
        "    print(f\"\\n{model_name} Parameter Summary:\", flush=True)\n",
        "    for summary in param_summary:\n",
        "        if summary['model'] == model_name:\n",
        "            print(f\"ID_TARGET: {summary['ID_TARGET']} | Best Params: {summary['best_params']} | Mean Accuracy: {summary['mean_accuracy']:.4f} | Fold Accuracies: {summary['fold_accuracies']}\", flush=True)\n",
        "\n",
        "# Second-pass training with top 30 features\n",
        "print(\"\\nPerforming second-pass training with top 30 features...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nSecond-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\"):\n",
        "        target_str = str(target)\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "        weight_scale = 1.5 if target in low_performing_targets else 1.0\n",
        "        weights = weights * weight_scale\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        best_params['n_estimators'] = 200\n",
        "        model.set_params(**best_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Third-pass training for low-performing targets\n",
        "print(\"\\nPerforming third-pass training for low-performing targets...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nThird-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(low_performing_targets, desc=f\"{model_name} Low-Performing Targets\"):\n",
        "        target_str = str(target)\n",
        "        if target_str not in param_log[model_name] or param_log[model_name][target_str]['mean_accuracy'] >= 0.75:\n",
        "            continue\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs() * 1.5\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        fine_tune_grid = [\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.8, 'n_estimators': 200, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.2, 'n_estimators': 200, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1}\n",
        "        ]\n",
        "        best_score = param_log[model_name][target_str]['mean_accuracy']\n",
        "        best_fine_params = best_params\n",
        "        for params in ParameterGrid(fine_tune_grid):\n",
        "            print(f\"Fine-tuning {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "            model.set_params(**params)\n",
        "            fold_accuracies = []\n",
        "            for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "                X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "                y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "                w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "                if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "                elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "                else:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "                y_pred = model.predict(X_val)\n",
        "                acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "                fold_accuracies.append(acc)\n",
        "            mean_acc = np.mean(fold_accuracies)\n",
        "            print(f\"{model_name} | ID_TARGET: {target} | Fine-tune Params: {params} | Mean Accuracy: {mean_acc:.4f}\", flush=True)\n",
        "            if mean_acc > best_score:\n",
        "                best_score = mean_acc\n",
        "                best_fine_params = params\n",
        "                param_log[model_name][target_str]['best_params'] = best_fine_params\n",
        "                param_log[model_name][target_str]['mean_accuracy'] = best_score\n",
        "                param_summary.append({\n",
        "                    'model': model_name,\n",
        "                    'ID_TARGET': target_str,\n",
        "                    'best_params': best_fine_params,\n",
        "                    'mean_accuracy': best_score,\n",
        "                    'fold_accuracies': fold_accuracies\n",
        "                })\n",
        "        model.set_params(**best_fine_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Save parameter log\n",
        "param_log_path = os.path.join(DATA_DIR, 'hyperparameters.json')\n",
        "with open(param_log_path, 'w') as f:\n",
        "    json.dump(param_log, f, indent=4)\n",
        "print(f\"Saved hyperparameter log to: {param_log_path}\", flush=True)\n",
        "files.download(param_log_path)\n",
        "\n",
        "# Ensemble predictions with dynamic weights\n",
        "final_predictions = {}\n",
        "missing_day_targets = []\n",
        "for target in X_test['ID_TARGET'].unique():\n",
        "    target_str = str(target)\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "    lgbm_acc = param_log.get('LightGBM', {}).get(target_str, {}).get('mean_accuracy', 0.5)\n",
        "    xgb_acc = param_log.get('XGBoost', {}).get(target_str, {}).get('mean_accuracy', 0.5)\n",
        "    total_acc = lgbm_acc + xgb_acc\n",
        "    ensemble_weights = {\n",
        "        'LightGBM': lgbm_acc / total_acc if total_acc > 0 else 0.5,\n",
        "        'XGBoost': xgb_acc / total_acc if total_acc > 0 else 0.5\n",
        "    }\n",
        "    for day in X_test[X_test['ID_TARGET'] == target]['ID_DAY'].unique():\n",
        "        day_idx = (X_test['ID_TARGET'] == target) & (X_test['ID_DAY'] == day)\n",
        "        day_test_ids = X_test[day_idx].index\n",
        "        if len(day_test_ids) == 0:\n",
        "            print(f\"Warning: No test samples for ID_TARGET {target} on ID_DAY {day}. Using default prediction.\")\n",
        "            missing_day_targets.append((target, day))\n",
        "            for idx in test_ids:\n",
        "                final_predictions[idx] = -1\n",
        "            continue\n",
        "        lgbm_preds = np.array([predictions[target_str].get('LightGBM', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        xgb_preds = np.array([predictions[target_str].get('XGBoost', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        ensemble_preds = ensemble_weights['LightGBM'] * lgbm_preds + ensemble_weights['XGBoost'] * xgb_preds\n",
        "        smoothed_preds = pd.Series(ensemble_preds).ewm(span=3).mean().values[-1] if len(ensemble_preds) > 0 else 0.5\n",
        "        for idx in day_test_ids:\n",
        "            final_predictions[idx] = 1 if smoothed_preds >= 0.5 else -1\n",
        "\n",
        "if missing_day_targets:\n",
        "    print(f\"Missing day-target pairs: {missing_day_targets}\")\n",
        "\n",
        "# Create output CSV\n",
        "output_df = pd.DataFrame.from_dict(final_predictions, orient='index', columns=['RET_TARGET']).reset_index()\n",
        "output_df.columns = ['ID', 'RET_TARGET']\n",
        "output_df = output_df.sort_values('ID')\n",
        "expected_ids = set(X_test.index)\n",
        "submission_ids = set(output_df['ID'])\n",
        "if expected_ids != submission_ids:\n",
        "    missing_ids = expected_ids - submission_ids\n",
        "    print(f\"Warning: Submission missing {len(missing_ids)} IDs: {missing_ids}\")\n",
        "    missing_df = pd.DataFrame({'ID': list(missing_ids), 'RET_TARGET': -1})\n",
        "    output_df = pd.concat([output_df, missing_df], ignore_index=True).sort_values('ID')\n",
        "output_path = os.path.join(DATA_DIR, 'predictions_ensemble.csv')\n",
        "output_df.to_csv(output_path, index=False)\n",
        "print(f\"Saved predictions to: {output_path}\", flush=True)\n",
        "\n",
        "# Validate output\n",
        "test_csv = pd.read_csv(output_path)\n",
        "print(f\"Output CSV shape: {test_csv.shape}\", flush=True)\n",
        "print(f\"Output CSV ID range: {test_csv['ID'].min()} to {test_csv['ID'].max()}\", flush=True)\n",
        "print(f\"Unique RET_TARGET values: {test_csv['RET_TARGET'].unique()}\", flush=True)\n",
        "print(f\"Missing values: {test_csv.isna().sum().sum()}\", flush=True)\n",
        "\n",
        "# Download the file\n",
        "files.download(output_path)\n",
        "\n",
        "# Print final results\n",
        "print(\"\\nValidation Results:\", flush=True)\n",
        "for model_name, acc in results.items():\n",
        "    print(f\"{model_name}: {acc:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtO7gXPsIlSe"
      },
      "source": [
        "less complex than 74% -- 74.22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v1KkmiV_InWn",
        "outputId": "72d7738e-2251-4700-a8ec-ee75a1d23779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost version: 2.1.4\n",
            "Selected top return columns: ['RET_262', 'RET_88', 'RET_172', 'RET_259', 'RET_150', 'RET_118', 'RET_216', 'RET_268', 'RET_115', 'RET_261', 'RET_59', 'RET_238', 'RET_121', 'RET_97', 'RET_30']\n",
            "\n",
            "Training LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LightGBM Targets: 100%|| 100/100 [10:45<00:00,  6.46s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightGBM Weighted Accuracy: 0.7327\n",
            "\n",
            "LightGBM Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.9173 | Fold Accuracies: [np.float64(0.7531914893617021), np.float64(0.83203125), np.float64(0.7330677290836654), np.float64(0.8255813953488372), np.float64(0.8112449799196787)]\n",
            "ID_TARGET: 129.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6481 | Fold Accuracies: [np.float64(0.5959183673469388), np.float64(0.6504065040650406), np.float64(0.6363636363636364), np.float64(0.6118143459915611), np.float64(0.7090909090909091)]\n",
            "ID_TARGET: 136.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.6080 | Fold Accuracies: [np.float64(0.6138996138996139), np.float64(0.6060606060606061), np.float64(0.610909090909091), np.float64(0.59765625), np.float64(0.611336032388664)]\n",
            "ID_TARGET: 161.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6911 | Fold Accuracies: [np.float64(0.6532258064516129), np.float64(0.6704545454545454), np.float64(0.6908396946564885), np.float64(0.7258687258687259), np.float64(0.6704980842911877)]\n",
            "ID_TARGET: 217.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6876 | Fold Accuracies: [np.float64(0.6795366795366795), np.float64(0.6844106463878327), np.float64(0.671280276816609), np.float64(0.6666666666666666), np.float64(0.6808510638297872)]\n",
            "ID_TARGET: 91.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6982 | Fold Accuracies: [np.float64(0.6603053435114504), np.float64(0.6788617886178862), np.float64(0.6920152091254753), np.float64(0.6900826446280992), np.float64(0.7191011235955056)]\n",
            "ID_TARGET: 137.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6451 | Fold Accuracies: [np.float64(0.5909090909090909), np.float64(0.6200873362445415), np.float64(0.6282051282051282), np.float64(0.71484375), np.float64(0.6185185185185185)]\n",
            "ID_TARGET: 8.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7665 | Fold Accuracies: [np.float64(0.7042801556420234), np.float64(0.6506024096385542), np.float64(0.6693227091633466), np.float64(0.68), np.float64(0.9015748031496063)]\n",
            "ID_TARGET: 3.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7112 | Fold Accuracies: [np.float64(0.6818181818181818), np.float64(0.6598360655737705), np.float64(0.6932270916334662), np.float64(0.7330508474576272), np.float64(0.6593886462882096)]\n",
            "ID_TARGET: 9.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6752 | Fold Accuracies: [np.float64(0.6553191489361702), np.float64(0.708), np.float64(0.65), np.float64(0.6776859504132231), np.float64(0.6627906976744186)]\n",
            "ID_TARGET: 131.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6581 | Fold Accuracies: [np.float64(0.6889763779527559), np.float64(0.6692307692307692), np.float64(0.6733870967741935), np.float64(0.5822784810126582), np.float64(0.6307692307692307)]\n",
            "ID_TARGET: 21.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6770 | Fold Accuracies: [np.float64(0.7323943661971831), np.float64(0.6755725190839694), np.float64(0.663003663003663), np.float64(0.63671875), np.float64(0.6264591439688716)]\n",
            "ID_TARGET: 54.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7675 | Fold Accuracies: [np.float64(0.7829457364341085), np.float64(0.7640449438202247), np.float64(0.7577092511013216), np.float64(0.6834532374100719), np.float64(0.788235294117647)]\n",
            "ID_TARGET: 130.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7486 | Fold Accuracies: [np.float64(0.7012987012987013), np.float64(0.7453874538745388), np.float64(0.6738351254480287), np.float64(0.6958174904942965), np.float64(0.6715328467153284)]\n",
            "ID_TARGET: 269.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6907 | Fold Accuracies: [np.float64(0.708), np.float64(0.6899563318777293), np.float64(0.7044534412955465), np.float64(0.5957446808510638), np.float64(0.658008658008658)]\n",
            "ID_TARGET: 157.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7842 | Fold Accuracies: [np.float64(0.7652173913043478), np.float64(0.8361344537815126), np.float64(0.7620967741935484), np.float64(0.76), np.float64(0.7827868852459017)]\n",
            "ID_TARGET: 249.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7234 | Fold Accuracies: [np.float64(0.7558139534883721), np.float64(0.6806083650190115), np.float64(0.7654320987654321), np.float64(0.673469387755102), np.float64(0.6870229007633588)]\n",
            "ID_TARGET: 22.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6774 | Fold Accuracies: [np.float64(0.6666666666666666), np.float64(0.650375939849624), np.float64(0.6732283464566929), np.float64(0.6513409961685823), np.float64(0.688715953307393)]\n",
            "ID_TARGET: 202.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.6716 | Fold Accuracies: [np.float64(0.6235294117647059), np.float64(0.7089552238805971), np.float64(0.6283524904214559), np.float64(0.7003610108303249), np.float64(0.696969696969697)]\n",
            "ID_TARGET: 132.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7474 | Fold Accuracies: [np.float64(0.7586206896551724), np.float64(0.714859437751004), np.float64(0.7362204724409449), np.float64(0.7219917012448133), np.float64(0.7862903225806451)]\n",
            "ID_TARGET: 96.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7597 | Fold Accuracies: [np.float64(0.6926406926406926), np.float64(0.6566523605150214), np.float64(0.6423076923076924), np.float64(0.7397260273972602), np.float64(0.8034188034188035)]\n",
            "ID_TARGET: 7.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7348 | Fold Accuracies: [np.float64(0.71484375), np.float64(0.694980694980695), np.float64(0.7153284671532847), np.float64(0.7312252964426877), np.float64(0.8178294573643411)]\n",
            "ID_TARGET: 178.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7171 | Fold Accuracies: [np.float64(0.7154471544715447), np.float64(0.7110266159695817), np.float64(0.7272727272727273), np.float64(0.6612244897959184), np.float64(0.71875)]\n",
            "ID_TARGET: 68.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7697 | Fold Accuracies: [np.float64(0.7394636015325671), np.float64(0.7651821862348178), np.float64(0.7692307692307693), np.float64(0.7755102040816326), np.float64(0.75)]\n",
            "ID_TARGET: 44.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7190 | Fold Accuracies: [np.float64(0.7433962264150943), np.float64(0.7165354330708661), np.float64(0.7050359712230215), np.float64(0.7008547008547008), np.float64(0.7074074074074074)]\n",
            "ID_TARGET: 196.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7216 | Fold Accuracies: [np.float64(0.6933333333333334), np.float64(0.7364864864864865), np.float64(0.7282608695652174), np.float64(0.73046875), np.float64(0.7127659574468085)]\n",
            "ID_TARGET: 292.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7064 | Fold Accuracies: [np.float64(0.6425992779783394), np.float64(0.6349206349206349), np.float64(0.7058823529411765), np.float64(0.671875), np.float64(0.7394636015325671)]\n",
            "ID_TARGET: 239.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7517 | Fold Accuracies: [np.float64(0.7076923076923077), np.float64(0.7096774193548387), np.float64(0.711864406779661), np.float64(0.7936507936507936), np.float64(0.7678571428571429)]\n",
            "ID_TARGET: 279.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6957 | Fold Accuracies: [np.float64(0.6943396226415094), np.float64(0.7007874015748031), np.float64(0.6498054474708171), np.float64(0.6833333333333333), np.float64(0.6456692913385826)]\n",
            "ID_TARGET: 38.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7154 | Fold Accuracies: [np.float64(0.6641221374045801), np.float64(0.6837944664031621), np.float64(0.6626016260162602), np.float64(0.7049808429118773), np.float64(0.6828193832599119)]\n",
            "ID_TARGET: 209.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7241 | Fold Accuracies: [np.float64(0.7725490196078432), np.float64(0.6821705426356589), np.float64(0.7003891050583657), np.float64(0.6851851851851852), np.float64(0.6809338521400778)]\n",
            "ID_TARGET: 207.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6671 | Fold Accuracies: [np.float64(0.6653696498054474), np.float64(0.6313725490196078), np.float64(0.7108433734939759), np.float64(0.6377358490566037), np.float64(0.6550387596899225)]\n",
            "ID_TARGET: 98.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7187 | Fold Accuracies: [np.float64(0.6486486486486487), np.float64(0.7428571428571429), np.float64(0.7654320987654321), np.float64(0.7416666666666667), np.float64(0.6387832699619772)]\n",
            "ID_TARGET: 65.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7317 | Fold Accuracies: [np.float64(0.7443609022556391), np.float64(0.7227272727272728), np.float64(0.7142857142857143), np.float64(0.7222222222222222), np.float64(0.7350427350427351)]\n",
            "ID_TARGET: 51.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7547 | Fold Accuracies: [np.float64(0.7541666666666667), np.float64(0.757085020242915), np.float64(0.7586206896551724), np.float64(0.7439024390243902), np.float64(0.7598425196850394)]\n",
            "ID_TARGET: 78.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7117 | Fold Accuracies: [np.float64(0.7322175732217573), np.float64(0.732), np.float64(0.7), np.float64(0.6540084388185654), np.float64(0.6956521739130435)]\n",
            "ID_TARGET: 177.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7318 | Fold Accuracies: [np.float64(0.7418181818181818), np.float64(0.7211895910780669), np.float64(0.7269503546099291), np.float64(0.7342657342657343), np.float64(0.7181467181467182)]\n",
            "ID_TARGET: 231.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7775 | Fold Accuracies: [np.float64(0.7680608365019012), np.float64(0.7388059701492538), np.float64(0.756), np.float64(0.8081632653061225), np.float64(0.752851711026616)]\n",
            "ID_TARGET: 119.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7598 | Fold Accuracies: [np.float64(0.7159533073929961), np.float64(0.7569721115537849), np.float64(0.7790697674418605), np.float64(0.7172995780590717), np.float64(0.7622950819672131)]\n",
            "ID_TARGET: 158.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7916 | Fold Accuracies: [np.float64(0.7842323651452282), np.float64(0.8306451612903226), np.float64(0.7748091603053435), np.float64(0.8023715415019763), np.float64(0.7620817843866171)]\n",
            "ID_TARGET: 80.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6956 | Fold Accuracies: [np.float64(0.672), np.float64(0.7075098814229249), np.float64(0.668), np.float64(0.6938775510204082), np.float64(0.7123893805309734)]\n",
            "ID_TARGET: 25.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7211 | Fold Accuracies: [np.float64(0.7195121951219512), np.float64(0.6864406779661016), np.float64(0.6985294117647058), np.float64(0.7276119402985075), np.float64(0.73046875)]\n",
            "ID_TARGET: 175.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7280 | Fold Accuracies: [np.float64(0.71484375), np.float64(0.68), np.float64(0.6814516129032258), np.float64(0.7729083665338645), np.float64(0.6964980544747081)]\n",
            "ID_TARGET: 151.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7705 | Fold Accuracies: [np.float64(0.7749077490774908), np.float64(0.7647058823529411), np.float64(0.7692307692307693), np.float64(0.7304347826086957), np.float64(0.7892561983471075)]\n",
            "ID_TARGET: 257.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7166 | Fold Accuracies: [np.float64(0.691699604743083), np.float64(0.720754716981132), np.float64(0.7116788321167883), np.float64(0.6974169741697417), np.float64(0.7345454545454545)]\n",
            "ID_TARGET: 75.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7677 | Fold Accuracies: [np.float64(0.7704918032786885), np.float64(0.7327935222672065), np.float64(0.7649253731343284), np.float64(0.7517241379310344), np.float64(0.7827715355805244)]\n",
            "ID_TARGET: 244.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6957 | Fold Accuracies: [np.float64(0.6816479400749064), np.float64(0.7333333333333333), np.float64(0.6867924528301886), np.float64(0.6857142857142857), np.float64(0.6236162361623616)]\n",
            "ID_TARGET: 149.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7443 | Fold Accuracies: [np.float64(0.6917293233082706), np.float64(0.7294117647058823), np.float64(0.7461538461538462), np.float64(0.7322834645669292), np.float64(0.7165354330708661)]\n",
            "ID_TARGET: 85.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7712 | Fold Accuracies: [np.float64(0.8089430894308943), np.float64(0.7540983606557377), np.float64(0.78), np.float64(0.7563025210084033), np.float64(0.7318007662835249)]\n",
            "ID_TARGET: 190.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7397 | Fold Accuracies: [np.float64(0.7481203007518797), np.float64(0.7265917602996255), np.float64(0.7408906882591093), np.float64(0.7213740458015268), np.float64(0.7582417582417582)]\n",
            "ID_TARGET: 13.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7416 | Fold Accuracies: [np.float64(0.7354085603112841), np.float64(0.7364620938628159), np.float64(0.7195571955719557), np.float64(0.7148760330578512), np.float64(0.7519685039370079)]\n",
            "ID_TARGET: 228.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6944 | Fold Accuracies: [np.float64(0.7142857142857143), np.float64(0.7209302325581395), np.float64(0.6933797909407665), np.float64(0.6829268292682927), np.float64(0.644927536231884)]\n",
            "ID_TARGET: 144.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7785 | Fold Accuracies: [np.float64(0.7669491525423728), np.float64(0.8235294117647058), np.float64(0.7963636363636364), np.float64(0.7103174603174603), np.float64(0.7415254237288136)]\n",
            "ID_TARGET: 290.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7138 | Fold Accuracies: [np.float64(0.7312252964426877), np.float64(0.6652892561983471), np.float64(0.7310606060606061), np.float64(0.6747967479674797), np.float64(0.6706349206349206)]\n",
            "ID_TARGET: 114.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.6967 | Fold Accuracies: [np.float64(0.6743295019157088), np.float64(0.7182539682539683), np.float64(0.7121212121212122), np.float64(0.6812749003984063), np.float64(0.6977611940298507)]\n",
            "ID_TARGET: 166.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7523 | Fold Accuracies: [np.float64(0.7642276422764228), np.float64(0.7619047619047619), np.float64(0.7827868852459017), np.float64(0.7340823970037453), np.float64(0.7131147540983607)]\n",
            "ID_TARGET: 234.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7609 | Fold Accuracies: [np.float64(0.7459016393442623), np.float64(0.7701612903225806), np.float64(0.7521008403361344), np.float64(0.7662337662337663), np.float64(0.7237354085603113)]\n",
            "ID_TARGET: 34.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7563 | Fold Accuracies: [np.float64(0.7116104868913857), np.float64(0.7480916030534351), np.float64(0.764), np.float64(0.7520325203252033), np.float64(0.7471264367816092)]\n",
            "ID_TARGET: 154.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7532 | Fold Accuracies: [np.float64(0.7795275590551181), np.float64(0.7669172932330827), np.float64(0.696969696969697), np.float64(0.700374531835206), np.float64(0.7800829875518672)]\n",
            "ID_TARGET: 225.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7136 | Fold Accuracies: [np.float64(0.6549295774647887), np.float64(0.7142857142857143), np.float64(0.7021276595744681), np.float64(0.7131782945736435), np.float64(0.7355072463768116)]\n",
            "ID_TARGET: 185.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.8007 | Fold Accuracies: [np.float64(0.7828054298642534), np.float64(0.7903930131004366), np.float64(0.7186147186147186), np.float64(0.7292576419213974), np.float64(0.8389830508474576)]\n",
            "ID_TARGET: 39.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7360 | Fold Accuracies: [np.float64(0.7073170731707317), np.float64(0.6862745098039216), np.float64(0.7431906614785992), np.float64(0.7211155378486056), np.float64(0.7154150197628458)]\n",
            "ID_TARGET: 272.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7528 | Fold Accuracies: [np.float64(0.7447698744769874), np.float64(0.7958333333333333), np.float64(0.7198443579766537), np.float64(0.789272030651341), np.float64(0.704225352112676)]\n",
            "ID_TARGET: 282.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7332 | Fold Accuracies: [np.float64(0.71484375), np.float64(0.7181467181467182), np.float64(0.7), np.float64(0.7519083969465649), np.float64(0.7219917012448133)]\n",
            "ID_TARGET: 90.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7507 | Fold Accuracies: [np.float64(0.7421875), np.float64(0.7509578544061303), np.float64(0.712), np.float64(0.7634854771784232), np.float64(0.7619047619047619)]\n",
            "ID_TARGET: 52.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7405 | Fold Accuracies: [np.float64(0.75), np.float64(0.7309417040358744), np.float64(0.7322175732217573), np.float64(0.7261904761904762), np.float64(0.6991869918699187)]\n",
            "ID_TARGET: 258.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7202 | Fold Accuracies: [np.float64(0.7319148936170212), np.float64(0.717391304347826), np.float64(0.7154150197628458), np.float64(0.77734375), np.float64(0.6589147286821705)]\n",
            "ID_TARGET: 291.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7525 | Fold Accuracies: [np.float64(0.7639484978540773), np.float64(0.7374517374517374), np.float64(0.7289377289377289), np.float64(0.7610294117647058), np.float64(0.7341269841269841)]\n",
            "ID_TARGET: 152.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7570 | Fold Accuracies: [np.float64(0.7666666666666667), np.float64(0.772), np.float64(0.7386363636363636), np.float64(0.7608695652173914), np.float64(0.7385892116182573)]\n",
            "ID_TARGET: 133.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7649 | Fold Accuracies: [np.float64(0.79182156133829), np.float64(0.7370517928286853), np.float64(0.7747035573122529), np.float64(0.7310606060606061), np.float64(0.7829457364341085)]\n",
            "ID_TARGET: 29.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7151 | Fold Accuracies: [np.float64(0.6812749003984063), np.float64(0.7092511013215859), np.float64(0.7011494252873564), np.float64(0.7480916030534351), np.float64(0.7241379310344828)]\n",
            "ID_TARGET: 274.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7397 | Fold Accuracies: [np.float64(0.762962962962963), np.float64(0.7661870503597122), np.float64(0.749034749034749), np.float64(0.7096774193548387), np.float64(0.7106227106227107)]\n",
            "ID_TARGET: 106.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7634 | Fold Accuracies: [np.float64(0.7705627705627706), np.float64(0.755656108597285), np.float64(0.7255813953488373), np.float64(0.7373271889400922), np.float64(0.7875)]\n",
            "ID_TARGET: 173.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7719 | Fold Accuracies: [np.float64(0.7765567765567766), np.float64(0.752), np.float64(0.7336065573770492), np.float64(0.8148148148148148), np.float64(0.7362204724409449)]\n",
            "ID_TARGET: 33.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7343 | Fold Accuracies: [np.float64(0.7219917012448133), np.float64(0.7065637065637066), np.float64(0.6980392156862745), np.float64(0.7431906614785992), np.float64(0.7360594795539034)]\n",
            "ID_TARGET: 69.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7188 | Fold Accuracies: [np.float64(0.7130434782608696), np.float64(0.729957805907173), np.float64(0.6692307692307692), np.float64(0.7018867924528301), np.float64(0.7072072072072072)]\n",
            "ID_TARGET: 17.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6870 | Fold Accuracies: [np.float64(0.7286821705426356), np.float64(0.706766917293233), np.float64(0.66796875), np.float64(0.64453125), np.float64(0.6525096525096525)]\n",
            "ID_TARGET: 189.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7351 | Fold Accuracies: [np.float64(0.7628458498023716), np.float64(0.6872586872586872), np.float64(0.6776859504132231), np.float64(0.758893280632411), np.float64(0.75)]\n",
            "ID_TARGET: 284.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7283 | Fold Accuracies: [np.float64(0.6981818181818182), np.float64(0.7104247104247104), np.float64(0.7581967213114754), np.float64(0.7100371747211895), np.float64(0.7416666666666667)]\n",
            "ID_TARGET: 218.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6929 | Fold Accuracies: [np.float64(0.6806083650190115), np.float64(0.6745098039215687), np.float64(0.6518518518518519), np.float64(0.757085020242915), np.float64(0.697841726618705)]\n",
            "ID_TARGET: 183.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7584 | Fold Accuracies: [np.float64(0.75), np.float64(0.756198347107438), np.float64(0.7355371900826446), np.float64(0.6908396946564885), np.float64(0.7954545454545454)]\n",
            "ID_TARGET: 206.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7564 | Fold Accuracies: [np.float64(0.6932270916334662), np.float64(0.7624521072796935), np.float64(0.7549407114624506), np.float64(0.7510729613733905), np.float64(0.7938931297709924)]\n",
            "ID_TARGET: 93.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7229 | Fold Accuracies: [np.float64(0.7615062761506276), np.float64(0.7416974169741697), np.float64(0.6794871794871795), np.float64(0.7228464419475655), np.float64(0.7088122605363985)]\n",
            "ID_TARGET: 16.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7182 | Fold Accuracies: [np.float64(0.7201492537313433), np.float64(0.6935483870967742), np.float64(0.6891385767790262), np.float64(0.706766917293233), np.float64(0.7184873949579832)]\n",
            "ID_TARGET: 246.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7500 | Fold Accuracies: [np.float64(0.7049808429118773), np.float64(0.7386363636363636), np.float64(0.7376425855513308), np.float64(0.769811320754717), np.float64(0.7764705882352941)]\n",
            "ID_TARGET: 167.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7443 | Fold Accuracies: [np.float64(0.7171314741035857), np.float64(0.7644787644787645), np.float64(0.7076271186440678), np.float64(0.7090163934426229), np.float64(0.7786885245901639)]\n",
            "ID_TARGET: 1.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7424 | Fold Accuracies: [np.float64(0.7412280701754386), np.float64(0.7649572649572649), np.float64(0.7165991902834008), np.float64(0.7182539682539683), np.float64(0.7593360995850622)]\n",
            "ID_TARGET: 289.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7311 | Fold Accuracies: [np.float64(0.7136752136752137), np.float64(0.746268656716418), np.float64(0.7421875), np.float64(0.7238805970149254), np.float64(0.7293233082706767)]\n",
            "ID_TARGET: 141.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7909 | Fold Accuracies: [np.float64(0.7375), np.float64(0.7705627705627706), np.float64(0.789272030651341), np.float64(0.8015267175572519), np.float64(0.7235772357723578)]\n",
            "ID_TARGET: 109.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6993 | Fold Accuracies: [np.float64(0.6933333333333334), np.float64(0.708502024291498), np.float64(0.6707818930041153), np.float64(0.6679841897233202), np.float64(0.697841726618705)]\n",
            "ID_TARGET: 19.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7570 | Fold Accuracies: [np.float64(0.7651515151515151), np.float64(0.7377049180327869), np.float64(0.72265625), np.float64(0.7924528301886793), np.float64(0.767175572519084)]\n",
            "ID_TARGET: 28.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.6971 | Fold Accuracies: [np.float64(0.7196969696969697), np.float64(0.6317991631799164), np.float64(0.7091633466135459), np.float64(0.7343173431734318), np.float64(0.690677966101695)]\n",
            "ID_TARGET: 251.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7211 | Fold Accuracies: [np.float64(0.6653225806451613), np.float64(0.7014925373134329), np.float64(0.7185185185185186), np.float64(0.7804878048780488), np.float64(0.7083333333333334)]\n",
            "ID_TARGET: 278.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7686 | Fold Accuracies: [np.float64(0.7142857142857143), np.float64(0.7626459143968871), np.float64(0.7593360995850622), np.float64(0.8268398268398268), np.float64(0.7553648068669528)]\n",
            "ID_TARGET: 76.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7339 | Fold Accuracies: [np.float64(0.7335907335907336), np.float64(0.6940298507462687), np.float64(0.7470817120622568), np.float64(0.7158273381294964), np.float64(0.766798418972332)]\n",
            "ID_TARGET: 241.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7443 | Fold Accuracies: [np.float64(0.7649402390438247), np.float64(0.7342342342342343), np.float64(0.7154811715481172), np.float64(0.7736625514403292), np.float64(0.7333333333333333)]\n",
            "ID_TARGET: 214.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7762 | Fold Accuracies: [np.float64(0.7584905660377359), np.float64(0.7058823529411765), np.float64(0.8307086614173228), np.float64(0.8185185185185185), np.float64(0.7674418604651163)]\n",
            "ID_TARGET: 102.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7796 | Fold Accuracies: [np.float64(0.767175572519084), np.float64(0.7130434782608696), np.float64(0.7892561983471075), np.float64(0.8103448275862069), np.float64(0.7423076923076923)]\n",
            "ID_TARGET: 145.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7225 | Fold Accuracies: [np.float64(0.7413127413127413), np.float64(0.6555555555555556), np.float64(0.6775510204081633), np.float64(0.6958174904942965), np.float64(0.7530864197530864)]\n",
            "ID_TARGET: 155.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7905 | Fold Accuracies: [np.float64(0.7638888888888888), np.float64(0.8014705882352942), np.float64(0.7942386831275721), np.float64(0.7470817120622568), np.float64(0.7757352941176471)]\n",
            "\n",
            "Training XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "XGBoost Targets: 100%|| 100/100 [18:40<00:00, 11.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Weighted Accuracy: 0.7645\n",
            "\n",
            "XGBoost Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7133 | Fold Accuracies: [np.float64(0.7574468085106383), np.float64(0.67578125), np.float64(0.7729083665338645), np.float64(0.6937984496124031), np.float64(0.6666666666666666)]\n",
            "ID_TARGET: 129.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6275 | Fold Accuracies: [np.float64(0.6040816326530613), np.float64(0.6869918699186992), np.float64(0.6060606060606061), np.float64(0.6075949367088608), np.float64(0.6327272727272727)]\n",
            "ID_TARGET: 136.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 161.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.6710 | Fold Accuracies: [np.float64(0.5887096774193549), np.float64(0.6742424242424242), np.float64(0.6183206106870229), np.float64(0.667953667953668), np.float64(0.6743295019157088)]\n",
            "ID_TARGET: 217.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 91.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7799 | Fold Accuracies: [np.float64(0.8282442748091603), np.float64(0.8089430894308943), np.float64(0.6996197718631179), np.float64(0.8099173553719008), np.float64(0.7528089887640449)]\n",
            "ID_TARGET: 137.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0)]\n",
            "ID_TARGET: 8.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6083 | Fold Accuracies: [np.float64(0.5797665369649806), np.float64(0.5582329317269076), np.float64(0.6374501992031872), np.float64(0.616), np.float64(0.6181102362204725)]\n",
            "ID_TARGET: 3.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6825 | Fold Accuracies: [np.float64(0.678030303030303), np.float64(0.6639344262295082), np.float64(0.7131474103585658), np.float64(0.7330508474576272), np.float64(0.6244541484716157)]\n",
            "ID_TARGET: 9.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8953 | Fold Accuracies: [np.float64(1.0), np.float64(0.828), np.float64(0.8384615384615385), np.float64(1.0), np.float64(0.810077519379845)]\n",
            "ID_TARGET: 131.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6427 | Fold Accuracies: [np.float64(0.6968503937007874), np.float64(0.6538461538461539), np.float64(0.6532258064516129), np.float64(0.5864978902953587), np.float64(0.6230769230769231)]\n",
            "ID_TARGET: 21.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6880 | Fold Accuracies: [np.float64(0.7183098591549296), np.float64(0.6679389312977099), np.float64(0.6886446886446886), np.float64(0.66015625), np.float64(0.5914396887159533)]\n",
            "ID_TARGET: 54.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7428 | Fold Accuracies: [np.float64(0.7403100775193798), np.float64(0.7116104868913857), np.float64(0.775330396475771), np.float64(0.6474820143884892), np.float64(0.7686274509803922)]\n",
            "ID_TARGET: 130.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7001 | Fold Accuracies: [np.float64(0.7229437229437229), np.float64(0.6900369003690037), np.float64(0.7204301075268817), np.float64(0.6768060836501901), np.float64(0.635036496350365)]\n",
            "ID_TARGET: 269.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6456 | Fold Accuracies: [np.float64(0.676), np.float64(0.6812227074235808), np.float64(0.6639676113360324), np.float64(0.5531914893617021), np.float64(0.6536796536796536)]\n",
            "ID_TARGET: 157.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7185 | Fold Accuracies: [np.float64(0.7130434782608696), np.float64(0.7689075630252101), np.float64(0.7137096774193549), np.float64(0.708), np.float64(0.6762295081967213)]\n",
            "ID_TARGET: 249.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6977 | Fold Accuracies: [np.float64(0.686046511627907), np.float64(0.6730038022813688), np.float64(0.7325102880658436), np.float64(0.6693877551020408), np.float64(0.6412213740458015)]\n",
            "ID_TARGET: 22.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.6951 | Fold Accuracies: [np.float64(0.6847826086956522), np.float64(0.650375939849624), np.float64(0.7086614173228346), np.float64(0.685823754789272), np.float64(0.7042801556420234)]\n",
            "ID_TARGET: 202.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6943 | Fold Accuracies: [np.float64(0.6588235294117647), np.float64(0.7164179104477612), np.float64(0.6666666666666666), np.float64(0.7111913357400722), np.float64(0.6818181818181818)]\n",
            "ID_TARGET: 132.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7437 | Fold Accuracies: [np.float64(0.7543103448275862), np.float64(0.7068273092369478), np.float64(0.7244094488188977), np.float64(0.7427385892116183), np.float64(0.7903225806451613)]\n",
            "ID_TARGET: 96.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.9823 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(0.9115384615384615), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 7.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7419 | Fold Accuracies: [np.float64(0.7109375), np.float64(0.694980694980695), np.float64(0.6970802919708029), np.float64(0.7233201581027668), np.float64(0.7906976744186046)]\n",
            "ID_TARGET: 178.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7174 | Fold Accuracies: [np.float64(0.7357723577235772), np.float64(0.7110266159695817), np.float64(0.758893280632411), np.float64(0.689795918367347), np.float64(0.69140625)]\n",
            "ID_TARGET: 68.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7428 | Fold Accuracies: [np.float64(0.6973180076628352), np.float64(0.7489878542510121), np.float64(0.7521367521367521), np.float64(0.7755102040816326), np.float64(0.7090163934426229)]\n",
            "ID_TARGET: 44.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7481 | Fold Accuracies: [np.float64(0.7924528301886793), np.float64(0.7677165354330708), np.float64(0.7517985611510791), np.float64(0.7136752136752137), np.float64(0.7148148148148148)]\n",
            "ID_TARGET: 196.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7447 | Fold Accuracies: [np.float64(0.69), np.float64(0.7972972972972973), np.float64(0.7789855072463768), np.float64(0.69140625), np.float64(0.7659574468085106)]\n",
            "ID_TARGET: 292.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7031 | Fold Accuracies: [np.float64(0.6642599277978339), np.float64(0.7023809523809523), np.float64(0.6801470588235294), np.float64(0.67578125), np.float64(0.7126436781609196)]\n",
            "ID_TARGET: 239.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7428 | Fold Accuracies: [np.float64(0.6730769230769231), np.float64(0.6854838709677419), np.float64(0.7330508474576272), np.float64(0.753968253968254), np.float64(0.7366071428571429)]\n",
            "ID_TARGET: 279.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6781 | Fold Accuracies: [np.float64(0.6075471698113207), np.float64(0.7322834645669292), np.float64(0.6809338521400778), np.float64(0.7083333333333334), np.float64(0.6614173228346457)]\n",
            "ID_TARGET: 38.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7325 | Fold Accuracies: [np.float64(0.6870229007633588), np.float64(0.7233201581027668), np.float64(0.7601626016260162), np.float64(0.7164750957854407), np.float64(0.775330396475771)]\n",
            "ID_TARGET: 209.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 207.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6802 | Fold Accuracies: [np.float64(0.6809338521400778), np.float64(0.6666666666666666), np.float64(0.7188755020080321), np.float64(0.6792452830188679), np.float64(0.6550387596899225)]\n",
            "ID_TARGET: 98.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7322 | Fold Accuracies: [np.float64(0.6872586872586872), np.float64(0.7795918367346939), np.float64(0.7860082304526749), np.float64(0.7541666666666667), np.float64(0.6539923954372624)]\n",
            "ID_TARGET: 65.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8022 | Fold Accuracies: [np.float64(0.7443609022556391), np.float64(0.740909090909091), np.float64(1.0), np.float64(0.7777777777777778), np.float64(0.7478632478632479)]\n",
            "ID_TARGET: 51.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7318 | Fold Accuracies: [np.float64(0.7291666666666666), np.float64(0.708502024291498), np.float64(0.7241379310344828), np.float64(0.7235772357723578), np.float64(0.6929133858267716)]\n",
            "ID_TARGET: 78.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7317 | Fold Accuracies: [np.float64(0.7196652719665272), np.float64(0.78), np.float64(0.6958333333333333), np.float64(0.6962025316455697), np.float64(0.766798418972332)]\n",
            "ID_TARGET: 177.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7548 | Fold Accuracies: [np.float64(0.7454545454545455), np.float64(0.7695167286245354), np.float64(0.723404255319149), np.float64(0.7622377622377622), np.float64(0.7142857142857143)]\n",
            "ID_TARGET: 231.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 119.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7668 | Fold Accuracies: [np.float64(0.7159533073929961), np.float64(0.7370517928286853), np.float64(0.8372093023255814), np.float64(0.7172995780590717), np.float64(0.7622950819672131)]\n",
            "ID_TARGET: 158.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7908 | Fold Accuracies: [np.float64(0.7634854771784232), np.float64(0.8225806451612904), np.float64(0.7709923664122137), np.float64(0.7984189723320159), np.float64(0.7397769516728625)]\n",
            "ID_TARGET: 80.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7180 | Fold Accuracies: [np.float64(0.672), np.float64(0.7114624505928854), np.float64(0.668), np.float64(0.7061224489795919), np.float64(0.7433628318584071)]\n",
            "ID_TARGET: 25.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7408 | Fold Accuracies: [np.float64(0.7723577235772358), np.float64(0.7457627118644068), np.float64(0.7095588235294118), np.float64(0.7574626865671642), np.float64(0.71875)]\n",
            "ID_TARGET: 175.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 151.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7736 | Fold Accuracies: [np.float64(0.7601476014760148), np.float64(0.7536764705882353), np.float64(0.7649572649572649), np.float64(0.7347826086956522), np.float64(0.7975206611570248)]\n",
            "ID_TARGET: 257.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7382 | Fold Accuracies: [np.float64(0.7154150197628458), np.float64(0.6867924528301886), np.float64(0.7408759124087592), np.float64(0.7084870848708487), np.float64(0.7018181818181818)]\n",
            "ID_TARGET: 75.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7849 | Fold Accuracies: [np.float64(0.8032786885245902), np.float64(0.7530364372469636), np.float64(0.7873134328358209), np.float64(0.7551724137931034), np.float64(0.797752808988764)]\n",
            "ID_TARGET: 244.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.6760 | Fold Accuracies: [np.float64(0.704119850187266), np.float64(0.6823529411764706), np.float64(0.6754716981132075), np.float64(0.673469387755102), np.float64(0.6088560885608856)]\n",
            "ID_TARGET: 149.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7248 | Fold Accuracies: [np.float64(0.6353383458646616), np.float64(0.7176470588235294), np.float64(0.7307692307692307), np.float64(0.7283464566929134), np.float64(0.7007874015748031)]\n",
            "ID_TARGET: 85.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8157 | Fold Accuracies: [np.float64(0.8414634146341463), np.float64(0.8114754098360656), np.float64(0.816), np.float64(0.8739495798319328), np.float64(0.735632183908046)]\n",
            "ID_TARGET: 190.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7512 | Fold Accuracies: [np.float64(0.7631578947368421), np.float64(0.7228464419475655), np.float64(0.7692307692307693), np.float64(0.7213740458015268), np.float64(0.7655677655677655)]\n",
            "ID_TARGET: 13.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 228.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7756 | Fold Accuracies: [np.float64(0.7969924812030075), np.float64(0.7868217054263565), np.float64(0.735191637630662), np.float64(0.8414634146341463), np.float64(0.717391304347826)]\n",
            "ID_TARGET: 144.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7567 | Fold Accuracies: [np.float64(0.7457627118644068), np.float64(0.8277310924369747), np.float64(0.7672727272727272), np.float64(0.6785714285714286), np.float64(0.7161016949152542)]\n",
            "ID_TARGET: 290.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 114.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7208 | Fold Accuracies: [np.float64(0.6628352490421456), np.float64(0.7420634920634921), np.float64(0.7234848484848485), np.float64(0.7370517928286853), np.float64(0.7052238805970149)]\n",
            "ID_TARGET: 166.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7561 | Fold Accuracies: [np.float64(0.7439024390243902), np.float64(0.7435897435897436), np.float64(0.7459016393442623), np.float64(0.7340823970037453), np.float64(0.6967213114754098)]\n",
            "ID_TARGET: 234.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7604 | Fold Accuracies: [np.float64(0.7540983606557377), np.float64(0.7943548387096774), np.float64(0.7605042016806722), np.float64(0.7965367965367965), np.float64(0.6964980544747081)]\n",
            "ID_TARGET: 34.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7765 | Fold Accuracies: [np.float64(0.7415730337078652), np.float64(0.8053435114503816), np.float64(0.796), np.float64(0.7845528455284553), np.float64(0.7547892720306514)]\n",
            "ID_TARGET: 154.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7678 | Fold Accuracies: [np.float64(0.7677165354330708), np.float64(0.7857142857142857), np.float64(0.6893939393939394), np.float64(0.7078651685393258), np.float64(0.8008298755186722)]\n",
            "ID_TARGET: 225.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7313 | Fold Accuracies: [np.float64(0.6936619718309859), np.float64(0.7218045112781954), np.float64(0.7269503546099291), np.float64(0.7248062015503876), np.float64(0.7318840579710145)]\n",
            "ID_TARGET: 185.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7310 | Fold Accuracies: [np.float64(0.7013574660633484), np.float64(0.7074235807860262), np.float64(0.683982683982684), np.float64(0.7117903930131004), np.float64(0.7033898305084746)]\n",
            "ID_TARGET: 39.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 272.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7795 | Fold Accuracies: [np.float64(0.7615062761506276), np.float64(0.8416666666666667), np.float64(0.7120622568093385), np.float64(0.7701149425287356), np.float64(0.7852112676056338)]\n",
            "ID_TARGET: 282.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7396 | Fold Accuracies: [np.float64(0.70703125), np.float64(0.7451737451737451), np.float64(0.72), np.float64(0.7595419847328244), np.float64(0.7385892116182573)]\n",
            "ID_TARGET: 90.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7747 | Fold Accuracies: [np.float64(0.75), np.float64(0.7701149425287356), np.float64(0.724), np.float64(0.7800829875518672), np.float64(0.7936507936507936)]\n",
            "ID_TARGET: 52.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7410 | Fold Accuracies: [np.float64(0.717391304347826), np.float64(0.7713004484304933), np.float64(0.6694560669456067), np.float64(0.7142857142857143), np.float64(0.7154471544715447)]\n",
            "ID_TARGET: 258.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7263 | Fold Accuracies: [np.float64(0.6978723404255319), np.float64(0.7521739130434782), np.float64(0.7193675889328063), np.float64(0.75390625), np.float64(0.6589147286821705)]\n",
            "ID_TARGET: 291.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7596 | Fold Accuracies: [np.float64(0.7553648068669528), np.float64(0.7683397683397684), np.float64(0.73992673992674), np.float64(0.7683823529411765), np.float64(0.7658730158730159)]\n",
            "ID_TARGET: 152.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7523 | Fold Accuracies: [np.float64(0.6958333333333333), np.float64(0.744), np.float64(0.7310606060606061), np.float64(0.6884057971014492), np.float64(0.7593360995850622)]\n",
            "ID_TARGET: 133.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7715 | Fold Accuracies: [np.float64(0.7732342007434945), np.float64(0.7410358565737052), np.float64(0.7944664031620553), np.float64(0.7083333333333334), np.float64(0.8023255813953488)]\n",
            "ID_TARGET: 29.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7074 | Fold Accuracies: [np.float64(0.6613545816733067), np.float64(0.7665198237885462), np.float64(0.6781609195402298), np.float64(0.7022900763358778), np.float64(0.6973180076628352)]\n",
            "ID_TARGET: 274.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7475 | Fold Accuracies: [np.float64(0.7407407407407407), np.float64(0.7697841726618705), np.float64(0.7335907335907336), np.float64(0.7275985663082437), np.float64(0.6923076923076923)]\n",
            "ID_TARGET: 106.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.9610 | Fold Accuracies: [np.float64(0.8051948051948052), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 173.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7626 | Fold Accuracies: [np.float64(0.7875457875457875), np.float64(0.752), np.float64(0.75), np.float64(0.7777777777777778), np.float64(0.7086614173228346)]\n",
            "ID_TARGET: 33.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7340 | Fold Accuracies: [np.float64(0.7676348547717843), np.float64(0.722007722007722), np.float64(0.6941176470588235), np.float64(0.7354085603112841), np.float64(0.7509293680297398)]\n",
            "ID_TARGET: 69.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7338 | Fold Accuracies: [np.float64(0.7434782608695653), np.float64(0.7257383966244726), np.float64(0.6846153846153846), np.float64(0.7358490566037735), np.float64(0.7477477477477478)]\n",
            "ID_TARGET: 17.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7002 | Fold Accuracies: [np.float64(0.7170542635658915), np.float64(0.7180451127819549), np.float64(0.6953125), np.float64(0.6796875), np.float64(0.667953667953668)]\n",
            "ID_TARGET: 189.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7320 | Fold Accuracies: [np.float64(0.7272727272727273), np.float64(0.6833976833976834), np.float64(0.7851239669421488), np.float64(0.7391304347826086), np.float64(0.725)]\n",
            "ID_TARGET: 284.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7287 | Fold Accuracies: [np.float64(0.6618181818181819), np.float64(0.7065637065637066), np.float64(0.7581967213114754), np.float64(0.7211895910780669), np.float64(0.7333333333333333)]\n",
            "ID_TARGET: 218.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7126 | Fold Accuracies: [np.float64(0.6844106463878327), np.float64(0.7019607843137254), np.float64(0.6703703703703704), np.float64(0.8016194331983806), np.float64(0.6798561151079137)]\n",
            "ID_TARGET: 183.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7483 | Fold Accuracies: [np.float64(0.7246376811594203), np.float64(0.7644628099173554), np.float64(0.7396694214876033), np.float64(0.6946564885496184), np.float64(0.8181818181818182)]\n",
            "ID_TARGET: 206.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7602 | Fold Accuracies: [np.float64(0.7091633466135459), np.float64(0.7279693486590039), np.float64(0.782608695652174), np.float64(0.7510729613733905), np.float64(0.767175572519084)]\n",
            "ID_TARGET: 93.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7047 | Fold Accuracies: [np.float64(0.6694560669456067), np.float64(0.6383763837638377), np.float64(0.7136752136752137), np.float64(0.6966292134831461), np.float64(0.7011494252873564)]\n",
            "ID_TARGET: 16.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7130 | Fold Accuracies: [np.float64(0.6902985074626866), np.float64(0.6774193548387096), np.float64(0.6779026217228464), np.float64(0.7330827067669173), np.float64(0.6974789915966386)]\n",
            "ID_TARGET: 246.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7454 | Fold Accuracies: [np.float64(0.6628352490421456), np.float64(0.7121212121212122), np.float64(0.7338403041825095), np.float64(0.7132075471698113), np.float64(0.7137254901960784)]\n",
            "ID_TARGET: 167.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.9602 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(0.8008474576271186), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 1.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7377 | Fold Accuracies: [np.float64(0.7719298245614035), np.float64(0.7478632478632479), np.float64(0.7246963562753036), np.float64(0.6944444444444444), np.float64(0.7261410788381742)]\n",
            "ID_TARGET: 289.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7539 | Fold Accuracies: [np.float64(0.7521367521367521), np.float64(0.7761194029850746), np.float64(0.765625), np.float64(0.7649253731343284), np.float64(0.7105263157894737)]\n",
            "ID_TARGET: 141.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7918 | Fold Accuracies: [np.float64(0.7916666666666666), np.float64(0.8051948051948052), np.float64(0.7931034482758621), np.float64(0.816793893129771), np.float64(0.7520325203252033)]\n",
            "ID_TARGET: 109.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7265 | Fold Accuracies: [np.float64(0.7), np.float64(0.7530364372469636), np.float64(0.6995884773662552), np.float64(0.6679841897233202), np.float64(0.7446043165467626)]\n",
            "ID_TARGET: 19.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7719 | Fold Accuracies: [np.float64(0.7765151515151515), np.float64(0.7704918032786885), np.float64(0.73046875), np.float64(0.8150943396226416), np.float64(0.767175572519084)]\n",
            "ID_TARGET: 28.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7113 | Fold Accuracies: [np.float64(0.696969696969697), np.float64(0.6778242677824268), np.float64(0.7091633466135459), np.float64(0.7343173431734318), np.float64(0.690677966101695)]\n",
            "ID_TARGET: 251.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7186 | Fold Accuracies: [np.float64(0.6612903225806451), np.float64(0.6791044776119403), np.float64(0.725925925925926), np.float64(0.7073170731707317), np.float64(0.725)]\n",
            "ID_TARGET: 278.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7499 | Fold Accuracies: [np.float64(0.6587301587301587), np.float64(0.7509727626459144), np.float64(0.7219917012448133), np.float64(0.8095238095238095), np.float64(0.7467811158798283)]\n",
            "ID_TARGET: 76.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7491 | Fold Accuracies: [np.float64(0.6911196911196911), np.float64(0.7238805970149254), np.float64(0.7042801556420234), np.float64(0.7302158273381295), np.float64(0.7312252964426877)]\n",
            "ID_TARGET: 241.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7444 | Fold Accuracies: [np.float64(0.7051792828685259), np.float64(0.7522522522522522), np.float64(0.6652719665271967), np.float64(0.7860082304526749), np.float64(0.7166666666666667)]\n",
            "ID_TARGET: 214.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7816 | Fold Accuracies: [np.float64(0.7320754716981132), np.float64(0.6823529411764706), np.float64(0.7755905511811023), np.float64(0.7888888888888889), np.float64(0.7248062015503876)]\n",
            "ID_TARGET: 102.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7621 | Fold Accuracies: [np.float64(0.7862595419847328), np.float64(0.717391304347826), np.float64(0.7396694214876033), np.float64(0.8103448275862069), np.float64(0.7153846153846154)]\n",
            "ID_TARGET: 145.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6891 | Fold Accuracies: [np.float64(0.6640926640926641), np.float64(0.6370370370370371), np.float64(0.6816326530612244), np.float64(0.6539923954372624), np.float64(0.6954732510288066)]\n",
            "ID_TARGET: 155.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7950 | Fold Accuracies: [np.float64(0.7777777777777778), np.float64(0.8382352941176471), np.float64(0.7901234567901234), np.float64(0.7704280155642024), np.float64(0.7830882352941176)]\n",
            "\n",
            "Performing second-pass training with top 30 features...\n",
            "\n",
            "Second-pass LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rLightGBM Targets:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   1%|          | 1/100 [00:00<01:03,  1.57it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   2%|         | 2/100 [00:01<00:56,  1.73it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   3%|         | 3/100 [00:01<00:53,  1.81it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   4%|         | 4/100 [00:02<00:54,  1.78it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   5%|         | 5/100 [00:02<00:52,  1.82it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   6%|         | 6/100 [00:03<00:48,  1.93it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   7%|         | 7/100 [00:03<00:45,  2.06it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   8%|         | 8/100 [00:04<00:49,  1.85it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   9%|         | 9/100 [00:04<00:49,  1.84it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  10%|         | 10/100 [00:05<00:47,  1.89it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  11%|         | 11/100 [00:06<00:51,  1.74it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  12%|        | 12/100 [00:06<00:55,  1.59it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  13%|        | 13/100 [00:07<00:59,  1.46it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  14%|        | 14/100 [00:08<01:03,  1.36it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  15%|        | 15/100 [00:09<01:03,  1.33it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  16%|        | 16/100 [00:09<01:00,  1.39it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  17%|        | 17/100 [00:10<01:00,  1.38it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  18%|        | 18/100 [00:11<00:53,  1.54it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  19%|        | 19/100 [00:11<00:49,  1.62it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  20%|        | 20/100 [00:12<00:46,  1.73it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  21%|        | 21/100 [00:12<00:43,  1.81it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  22%|       | 22/100 [00:13<00:42,  1.84it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  23%|       | 23/100 [00:13<00:41,  1.87it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  24%|       | 24/100 [00:14<00:40,  1.90it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  25%|       | 25/100 [00:14<00:38,  1.93it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  26%|       | 26/100 [00:15<00:38,  1.94it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  27%|       | 27/100 [00:15<00:38,  1.91it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  28%|       | 28/100 [00:16<00:36,  1.98it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  29%|       | 29/100 [00:16<00:35,  1.98it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  30%|       | 30/100 [00:17<00:35,  1.97it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  31%|       | 31/100 [00:17<00:33,  2.04it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  32%|      | 32/100 [00:18<00:34,  1.99it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  33%|      | 33/100 [00:18<00:32,  2.03it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  34%|      | 34/100 [00:19<00:31,  2.09it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  35%|      | 35/100 [00:19<00:31,  2.08it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  36%|      | 36/100 [00:20<00:35,  1.82it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  37%|      | 37/100 [00:21<00:38,  1.64it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  38%|      | 38/100 [00:21<00:38,  1.59it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  39%|      | 39/100 [00:22<00:41,  1.48it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  40%|      | 40/100 [00:23<00:41,  1.43it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  41%|      | 41/100 [00:23<00:39,  1.51it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  42%|     | 42/100 [00:24<00:35,  1.65it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  43%|     | 43/100 [00:24<00:32,  1.77it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  44%|     | 44/100 [00:25<00:30,  1.85it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  45%|     | 45/100 [00:25<00:28,  1.90it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  46%|     | 46/100 [00:26<00:28,  1.91it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  47%|     | 47/100 [00:26<00:27,  1.91it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  48%|     | 48/100 [00:27<00:27,  1.91it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  49%|     | 49/100 [00:27<00:25,  1.98it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  50%|     | 50/100 [00:28<00:26,  1.88it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  51%|     | 51/100 [00:28<00:25,  1.95it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  52%|    | 52/100 [00:29<00:24,  1.94it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  53%|    | 53/100 [00:29<00:23,  1.98it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  54%|    | 54/100 [00:30<00:23,  1.96it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  55%|    | 55/100 [00:30<00:22,  2.01it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  56%|    | 56/100 [00:31<00:21,  2.02it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  57%|    | 57/100 [00:31<00:21,  2.04it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  58%|    | 58/100 [00:32<00:20,  2.02it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  59%|    | 59/100 [00:32<00:20,  2.02it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  60%|    | 60/100 [00:33<00:22,  1.80it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  61%|    | 61/100 [00:34<00:23,  1.65it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  62%|   | 62/100 [00:34<00:23,  1.60it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  63%|   | 63/100 [00:35<00:23,  1.56it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  64%|   | 64/100 [00:36<00:24,  1.47it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  65%|   | 65/100 [00:36<00:22,  1.55it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  66%|   | 66/100 [00:37<00:20,  1.70it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  67%|   | 67/100 [00:37<00:18,  1.74it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  68%|   | 68/100 [00:38<00:17,  1.82it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  69%|   | 69/100 [00:38<00:16,  1.88it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  70%|   | 70/100 [00:39<00:15,  1.95it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  71%|   | 71/100 [00:39<00:14,  1.98it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  72%|  | 72/100 [00:40<00:14,  1.94it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  73%|  | 73/100 [00:40<00:13,  1.99it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  74%|  | 74/100 [00:41<00:12,  2.03it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  75%|  | 75/100 [00:41<00:12,  1.98it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  76%|  | 76/100 [00:42<00:12,  1.99it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  77%|  | 77/100 [00:42<00:12,  1.88it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  78%|  | 78/100 [00:43<00:11,  1.93it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  79%|  | 79/100 [00:44<00:11,  1.88it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  80%|  | 80/100 [00:44<00:11,  1.81it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  81%|  | 81/100 [00:45<00:10,  1.85it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  82%| | 82/100 [00:45<00:09,  1.89it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  83%| | 83/100 [00:46<00:09,  1.87it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  84%| | 84/100 [00:46<00:09,  1.75it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  85%| | 85/100 [00:47<00:09,  1.56it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  86%| | 86/100 [00:48<00:09,  1.49it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  87%| | 87/100 [00:49<00:09,  1.33it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  88%| | 88/100 [00:50<00:08,  1.35it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  89%| | 89/100 [00:50<00:07,  1.48it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  90%| | 90/100 [00:51<00:06,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  91%| | 91/100 [00:51<00:05,  1.70it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  92%|| 92/100 [00:52<00:04,  1.76it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  93%|| 93/100 [00:52<00:03,  1.85it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  94%|| 94/100 [00:53<00:03,  1.93it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  95%|| 95/100 [00:53<00:02,  1.93it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  96%|| 96/100 [00:54<00:01,  2.02it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  97%|| 97/100 [00:54<00:01,  1.98it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  98%|| 98/100 [00:55<00:00,  2.04it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  99%|| 99/100 [00:55<00:00,  1.97it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets: 100%|| 100/100 [00:56<00:00,  1.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Second-pass XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Targets: 100%|| 100/100 [01:08<00:00,  1.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Performing third-pass training for low-performing targets...\n",
            "\n",
            "Third-pass LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "LightGBM Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 41304.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Third-pass XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 55856.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved hyperparameter log to: /content/hyperparameters.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_ef3a361b-d268-46d7-85b4-b133d0a62223\", \"hyperparameters.json\", 515267)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved predictions to: /content/predictions_ensemble.csv\n",
            "Output CSV shape: (114468, 2)\n",
            "Output CSV ID range: 0 to 114467\n",
            "Unique RET_TARGET values: [ 1 -1]\n",
            "Missing values: 0\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_b3eed89f-4f27-4823-9899-3dedf865a235\", \"predictions_ensemble.csv\", 970600)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Results:\n",
            "LightGBM: 0.7327\n",
            "XGBoost: 0.7645\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost\n",
        "from sklearn.decomposition import PCA\n",
        "from joblib import Parallel, delayed\n",
        "import json\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# Check xgboost version for compatibility\n",
        "print(f\"XGBoost version: {xgboost.__version__}\")\n",
        "if int(xgboost.__version__.split('.')[0]) < 1:\n",
        "    print(\"Warning: XGBoost version < 1.0.0 detected. Ensure compatibility with eval_metric in constructor.\")\n",
        "\n",
        "# Set up data directory\n",
        "DATA_DIR = '/content'\n",
        "\n",
        "# Load datasets\n",
        "try:\n",
        "    X_train = pd.read_csv(os.path.join(DATA_DIR, 'X_train_itDkypA.csv'), index_col='ID', dtype=np.float32)\n",
        "    y_train = pd.read_csv(os.path.join(DATA_DIR, 'y_train_3LeeT2g.csv'), index_col='ID', dtype=np.float32)\n",
        "    X_test = pd.read_csv(os.path.join(DATA_DIR, 'X_test_Beg4ey3.csv'), index_col='ID', dtype=np.float32)\n",
        "    supplementary = pd.read_csv(os.path.join(DATA_DIR, 'supplementary_data_Vkoyn8z.csv'))\n",
        "except FileNotFoundError as e:\n",
        "    raise FileNotFoundError(f\"Dataset not found: {e}. Please ensure files are uploaded to {DATA_DIR}.\")\n",
        "\n",
        "# Custom weighted accuracy metric\n",
        "def weighted_accuracy(y_true, y_pred, weights):\n",
        "    y_pred_mapped = np.where(y_pred == 1, 1, -1)\n",
        "    correct = (y_pred_mapped == np.sign(y_true)).astype(float)\n",
        "    return np.sum(np.abs(y_true) * correct) / np.sum(np.abs(y_true))\n",
        "\n",
        "# Preprocess data with enhanced feature selection\n",
        "def preprocess_data(X, y=None, supplementary=None, is_train=True, top_cols=None):\n",
        "    ret_cols = [col for col in X.columns if col.startswith('RET_')]\n",
        "    if is_train and top_cols is None:\n",
        "        if len(ret_cols) > 15:\n",
        "            variances = X[ret_cols].var()\n",
        "            corr_sum = X[ret_cols].corr().abs().sum()\n",
        "            combined_score = variances * corr_sum\n",
        "            valid_cols = variances[variances > 1e-5].index\n",
        "            if len(valid_cols) < 15:\n",
        "                top_cols = valid_cols.tolist()\n",
        "            else:\n",
        "                top_cols = combined_score.loc[valid_cols].sort_values(ascending=False).head(15).index.tolist()\n",
        "        else:\n",
        "            top_cols = ret_cols\n",
        "        print(f\"Selected top return columns: {top_cols}\")\n",
        "    elif top_cols is not None:\n",
        "        ret_cols = [col for col in ret_cols if col in top_cols]\n",
        "        if not ret_cols:\n",
        "            raise ValueError(\"No return columns selected. Check top_cols consistency.\")\n",
        "\n",
        "    sector_medians = {}\n",
        "    if supplementary is not None:\n",
        "        sector_map = supplementary.set_index('ID_asset')['CLASS_LEVEL_1']\n",
        "        for col in ret_cols:\n",
        "            asset_id = int(col.replace('RET_', ''))\n",
        "            sector = sector_map.get(asset_id, np.nan)\n",
        "            if pd.notna(sector):\n",
        "                sector_assets = supplementary[supplementary['CLASS_LEVEL_1'] == sector]['ID_asset']\n",
        "                sector_cols = [f'RET_{a}' for a in sector_assets if f'RET_{a}' in X.columns]\n",
        "                if sector_cols:\n",
        "                    sector_medians[col] = X[sector_cols].median(axis=1)\n",
        "            if col in sector_medians:\n",
        "                X[col] = X[col].fillna(sector_medians[col])\n",
        "            else:\n",
        "                X[col] = X[col].fillna(X[col].median())\n",
        "\n",
        "    new_cols = {}\n",
        "    if supplementary is not None:\n",
        "        level = 'CLASS_LEVEL_1'\n",
        "        sector_groups = supplementary.groupby(level)['ID_asset'].apply(list).to_dict()\n",
        "        for sector, assets in sector_groups.items():\n",
        "            asset_cols = [f'RET_{asset}' for asset in assets if f'RET_{asset}' in ret_cols]\n",
        "            if asset_cols:\n",
        "                new_cols[f'SECTOR_AVG_{level}_{sector}'] = X[asset_cols].mean(axis=1).replace([np.inf, -np.inf], 0).fillna(0)\n",
        "        X = X.merge(supplementary[['ID_asset', level]].rename(columns={'ID_asset': 'ID_TARGET', level: f'TARGET_{level}'}),\n",
        "                    on='ID_TARGET', how='left')\n",
        "        X = pd.concat([X, pd.get_dummies(X[f'TARGET_{level}'], prefix=f'TARGET_{level}', dummy_na=True)], axis=1)\n",
        "        X = X.drop(f'TARGET_{level}', axis=1)\n",
        "\n",
        "    new_cols['MEAN_RET'] = X[ret_cols].mean(axis=1)\n",
        "    new_cols['STD_RET'] = X[ret_cols].std(axis=1)\n",
        "    new_cols.update({f'CS_RANK_{col}': X.groupby('ID_DAY')[col].rank(pct=True).replace([np.inf, -np.inf], 0).fillna(0) for col in ret_cols})\n",
        "\n",
        "    if is_train:\n",
        "        corr_matrix = X[ret_cols].corr()\n",
        "        corr_pairs = corr_matrix.unstack().sort_values(ascending=False)\n",
        "        top_pairs = [(i, j) for i, j in corr_pairs.index if i < j][:5]\n",
        "        for i, j in top_pairs:\n",
        "            new_cols[f'CORR_{i}_{j}'] = X[i] * X[j]\n",
        "\n",
        "    if ret_cols:\n",
        "        pca = PCA(n_components=min(2, len(ret_cols)), random_state=42)\n",
        "        pca_features = pca.fit_transform(X[ret_cols].fillna(0))\n",
        "        for i in range(pca_features.shape[1]):\n",
        "            new_cols[f'PCA_{i}'] = pca_features[:, i]\n",
        "\n",
        "    new_cols_df = pd.DataFrame(new_cols, index=X.index, dtype=np.float32)\n",
        "    X = pd.concat([X, new_cols_df], axis=1)\n",
        "\n",
        "    feature_cols = [col for col in X.columns if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "    scaler = StandardScaler()\n",
        "    X[feature_cols] = scaler.fit_transform(X[feature_cols].replace([np.inf, -np.inf], 0).fillna(0))\n",
        "\n",
        "    if is_train:\n",
        "        y['SIGN_TARGET'] = np.where(y['RET_TARGET'] > 0, 1, 0).astype(np.int32)\n",
        "        return X, y, feature_cols, top_cols\n",
        "    return X, None, feature_cols, top_cols\n",
        "\n",
        "# Preprocess data\n",
        "try:\n",
        "    X_train, y_train, feature_cols, top_cols = preprocess_data(X_train, y_train, supplementary, is_train=True)\n",
        "    X_test, _, test_feature_cols, _ = preprocess_data(X_test, supplementary=supplementary, is_train=False, top_cols=top_cols)\n",
        "except ValueError as e:\n",
        "    print(f\"Preprocessing error: {e}\")\n",
        "    raise\n",
        "\n",
        "# Align columns\n",
        "common_cols = X_train.columns.intersection(X_test.columns)\n",
        "X_train = X_train[common_cols]\n",
        "X_test = X_test[common_cols]\n",
        "feature_cols = [col for col in common_cols if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "\n",
        "# Align y_train\n",
        "y_train = y_train.loc[X_train.index]\n",
        "\n",
        "# Define models with reduced hyperparameter grids including regularization\n",
        "models = {\n",
        "    'LightGBM': {\n",
        "        'model': LGBMClassifier(num_leaves=31, min_child_samples=15, lambda_l1=0.3, lambda_l2=0.3,\n",
        "                                subsample=0.7, colsample_bytree=0.8, bagging_freq=5, bagging_fraction=0.7,\n",
        "                                random_state=42, n_jobs=1, verbosity=-1, class_weight='balanced', force_row_wise=True),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.02], 'num_leaves': [15], 'min_child_samples': [20], 'bagging_fraction': [0.6], 'reg_alpha': [0.1], 'reg_lambda': [0.1]},\n",
        "            {'learning_rate': [0.05], 'num_leaves': [31], 'min_child_samples': [10], 'bagging_fraction': [0.7], 'reg_alpha': [0.2], 'reg_lambda': [0.2]},\n",
        "            {'learning_rate': [0.07], 'num_leaves': [47], 'min_child_samples': [15], 'bagging_fraction': [0.8], 'reg_alpha': [0.3], 'reg_lambda': [0.3]}\n",
        "        ],\n",
        "        'callbacks': [lightgbm.early_stopping(stopping_rounds=10, verbose=False)]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'model': XGBClassifier(max_depth=4, min_child_weight=2, subsample=0.8, colsample_bytree=0.8,\n",
        "                               random_state=42, n_jobs=1, eval_metric='logloss', verbosity=0,\n",
        "                               scale_pos_weight=len(y_train[y_train['SIGN_TARGET'] == 0]) / len(y_train[y_train['SIGN_TARGET'] == 1])),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.03], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [150], 'reg_alpha': [0.1], 'reg_lambda': [1.0]},\n",
        "            {'learning_rate': [0.05], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [200], 'reg_alpha': [0.2], 'reg_lambda': [1.5]},\n",
        "            {'learning_rate': [0.07], 'max_depth': [5], 'min_child_weight': [3], 'subsample': [0.8], 'n_estimators': [150], 'reg_alpha': [0.3], 'reg_lambda': [1.0]}\n",
        "        ],\n",
        "        'callbacks': [xgboost.callback.EarlyStopping(rounds=10, metric_name='logloss', save_best=True)]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to train and predict for a single target\n",
        "def train_target(target, X_train, y_train, X_test, feature_cols, model, model_name, kf, param_grid, callbacks):\n",
        "    X_target = X_train[X_train['ID_TARGET'] == target][feature_cols]\n",
        "    y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "    weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "    low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "    weight_scale = 1.5 if target in low_performing_targets else 1.0\n",
        "    if len(X_target) < 500:\n",
        "        weight_scale *= 1.5\n",
        "    weights = weights * weight_scale\n",
        "    groups = X_train[X_train['ID_TARGET'] == target]['ID_DAY']\n",
        "    X_test_target = X_test[X_test['ID_TARGET'] == target][feature_cols]\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "    if len(X_target) < 100 or len(X_test_target) == 0:\n",
        "        print(f\"Warning: Insufficient data for ID_TARGET {target} (train: {len(X_target)}, test: {len(X_test_target)}). Skipping.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    param_results = []\n",
        "    best_params = None\n",
        "    best_score = 0\n",
        "    best_model = None\n",
        "\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        print(f\"Testing params for {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "        try:\n",
        "            model.set_params(**params)\n",
        "        except ValueError as e:\n",
        "            print(f\"Invalid params for {model_name} ID_TARGET {target}: {e}\")\n",
        "            continue\n",
        "        fold_accuracies = []\n",
        "        for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "            X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "            y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "            w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "            if model_name == 'LightGBM' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=callbacks)\n",
        "            elif model_name == 'XGBoost' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "            else:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "            y_pred = model.predict(X_val)\n",
        "            acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "            fold_accuracies.append(acc)\n",
        "        mean_acc = np.mean(fold_accuracies)\n",
        "        print(f\"{model_name} | ID_TARGET: {target} | Params: {params} | Mean Accuracy: {mean_acc:.4f} | Fold Accuracies: {fold_accuracies}\", flush=True)\n",
        "        param_results.append({\n",
        "            'params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': fold_accuracies\n",
        "        })\n",
        "        if mean_acc > best_score:\n",
        "            best_score = mean_acc\n",
        "            best_params = params\n",
        "            best_model = type(model)(**model.get_params())\n",
        "\n",
        "    if best_model is None:\n",
        "        print(f\"No valid model for {model_name} ID_TARGET {target}. Using default.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    best_model.set_params(**best_params)\n",
        "    if model_name == 'LightGBM' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=callbacks)\n",
        "    elif model_name == 'XGBoost' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "    else:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights)\n",
        "    preds = best_model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "    importance = best_model.feature_importances_\n",
        "    feature_importance = dict(zip(feature_cols, importance))\n",
        "    top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:30]\n",
        "    gc.collect()\n",
        "    return str(target), best_params, best_score, param_results, test_ids, preds, top_features\n",
        "\n",
        "# Cross-validation and training\n",
        "kf = GroupKFold(n_splits=5)\n",
        "results = {}\n",
        "predictions = {}\n",
        "ensemble_weights = {'LightGBM': 0.7, 'XGBoost': 0.3}\n",
        "param_log = {}\n",
        "top_features_all = {}\n",
        "param_summary = []\n",
        "low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\", flush=True)\n",
        "    param_log[model_name] = {}\n",
        "    top_features_all[model_name] = {}\n",
        "    results_parallel = Parallel(n_jobs=-1)(\n",
        "        delayed(train_target)(target, X_train, y_train, X_test, feature_cols, model_info['model'], model_name, kf,\n",
        "                             model_info['param_grid'], model_info['callbacks'])\n",
        "        for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\")\n",
        "    )\n",
        "    accuracies = []\n",
        "    for target, params, mean_acc, param_results, test_ids, preds, top_features in results_parallel:\n",
        "        param_log[model_name][target] = {\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'all_params': param_results\n",
        "        }\n",
        "        top_features_all[model_name][target] = top_features\n",
        "        accuracies.append(mean_acc)\n",
        "        predictions.setdefault(target, {})[model_name] = dict(zip(test_ids, preds))\n",
        "        param_summary.append({\n",
        "            'model': model_name,\n",
        "            'ID_TARGET': target,\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': param_results[-1]['fold_accuracies'] if param_results else []\n",
        "        })\n",
        "    results[model_name] = np.mean([acc for acc in accuracies if acc > 0])\n",
        "    print(f\"{model_name} Weighted Accuracy: {results[model_name]:.4f}\", flush=True)\n",
        "    print(f\"\\n{model_name} Parameter Summary:\", flush=True)\n",
        "    for summary in param_summary:\n",
        "        if summary['model'] == model_name:\n",
        "            print(f\"ID_TARGET: {summary['ID_TARGET']} | Best Params: {summary['best_params']} | Mean Accuracy: {summary['mean_accuracy']:.4f} | Fold Accuracies: {summary['fold_accuracies']}\", flush=True)\n",
        "\n",
        "# Second-pass training with top 30 features\n",
        "print(\"\\nPerforming second-pass training with top 30 features...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nSecond-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\"):\n",
        "        target_str = str(target)\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "        weight_scale = 1.5 if target in low_performing_targets else 1.0\n",
        "        if len(X_target) < 500:\n",
        "            weight_scale *= 1.5\n",
        "        weights = weights * weight_scale\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        best_params['n_estimators'] = 200\n",
        "        model.set_params(**best_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Third-pass training for low-performing targets\n",
        "print(\"\\nPerforming third-pass training for low-performing targets...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nThird-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(low_performing_targets, desc=f\"{model_name} Low-Performing Targets\"):\n",
        "        target_str = str(target)\n",
        "        if target_str not in param_log[model_name] or param_log[model_name][target_str]['mean_accuracy'] >= 0.75:\n",
        "            continue\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs() * 1.5\n",
        "        if len(X_target) < 500:\n",
        "            weights = weights * 1.5\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        fine_tune_grid = [\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.8, 'n_estimators': 200, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.0, 'n_estimators': 250, 'reg_alpha': best_params['reg_alpha'][0], 'reg_lambda': best_params['reg_lambda'][0]},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.2, 'n_estimators': 200, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1}\n",
        "        ]\n",
        "        best_score = param_log[model_name][target_str]['mean_accuracy']\n",
        "        best_fine_params = best_params\n",
        "        for params in ParameterGrid(fine_tune_grid):\n",
        "            print(f\"Fine-tuning {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "            model.set_params(**params)\n",
        "            fold_accuracies = []\n",
        "            for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "                X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "                y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "                w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "                if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "                elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "                else:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "                y_pred = model.predict(X_val)\n",
        "                acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "                fold_accuracies.append(acc)\n",
        "            mean_acc = np.mean(fold_accuracies)\n",
        "            print(f\"{model_name} | ID_TARGET: {target} | Fine-tune Params: {params} | Mean Accuracy: {mean_acc:.4f}\", flush=True)\n",
        "            if mean_acc > best_score:\n",
        "                best_score = mean_acc\n",
        "                best_fine_params = params\n",
        "                param_log[model_name][target_str]['best_params'] = best_fine_params\n",
        "                param_log[model_name][target_str]['mean_accuracy'] = best_score\n",
        "                param_summary.append({\n",
        "                    'model': model_name,\n",
        "                    'ID_TARGET': target_str,\n",
        "                    'best_params': best_fine_params,\n",
        "                    'mean_accuracy': best_score,\n",
        "                    'fold_accuracies': fold_accuracies\n",
        "                })\n",
        "        model.set_params(**best_fine_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Save parameter log\n",
        "param_log_path = os.path.join(DATA_DIR, 'hyperparameters.json')\n",
        "with open(param_log_path, 'w') as f:\n",
        "    json.dump(param_log, f, indent=4)\n",
        "print(f\"Saved hyperparameter log to: {param_log_path}\", flush=True)\n",
        "files.download(param_log_path)\n",
        "\n",
        "# Ensemble predictions\n",
        "final_predictions = {}\n",
        "missing_day_targets = []\n",
        "for target in X_test['ID_TARGET'].unique():\n",
        "    target_str = str(target)\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "    for day in X_test[X_test['ID_TARGET'] == target]['ID_DAY'].unique():\n",
        "        day_idx = (X_test['ID_TARGET'] == target) & (X_test['ID_DAY'] == day)\n",
        "        day_test_ids = X_test[day_idx].index\n",
        "        if len(day_test_ids) == 0:\n",
        "            print(f\"Warning: No test samples for ID_TARGET {target} on ID_DAY {day}. Using default prediction.\")\n",
        "            missing_day_targets.append((target, day))\n",
        "            for idx in test_ids:\n",
        "                final_predictions[idx] = -1\n",
        "            continue\n",
        "        lgbm_preds = np.array([predictions[target_str].get('LightGBM', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        xgb_preds = np.array([predictions[target_str].get('XGBoost', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        ensemble_preds = ensemble_weights['LightGBM'] * lgbm_preds + ensemble_weights['XGBoost'] * xgb_preds\n",
        "        smoothed_preds = pd.Series(ensemble_preds).ewm(span=3).mean().values[-1] if len(ensemble_preds) > 0 else 0.5\n",
        "        for idx in day_test_ids:\n",
        "            final_predictions[idx] = 1 if smoothed_preds >= 0.5 else -1\n",
        "\n",
        "if missing_day_targets:\n",
        "    print(f\"Missing day-target pairs: {missing_day_targets}\")\n",
        "\n",
        "# Create output CSV\n",
        "output_df = pd.DataFrame.from_dict(final_predictions, orient='index', columns=['RET_TARGET']).reset_index()\n",
        "output_df.columns = ['ID', 'RET_TARGET']\n",
        "output_df = output_df.sort_values('ID')\n",
        "expected_ids = set(X_test.index)\n",
        "submission_ids = set(output_df['ID'])\n",
        "if expected_ids != submission_ids:\n",
        "    missing_ids = expected_ids - submission_ids\n",
        "    print(f\"Warning: Submission missing {len(missing_ids)} IDs: {missing_ids}\")\n",
        "    missing_df = pd.DataFrame({'ID': list(missing_ids), 'RET_TARGET': -1})\n",
        "    output_df = pd.concat([output_df, missing_df], ignore_index=True).sort_values('ID')\n",
        "output_path = os.path.join(DATA_DIR, 'predictions_ensemble.csv')\n",
        "output_df.to_csv(output_path, index=False)\n",
        "print(f\"Saved predictions to: {output_path}\", flush=True)\n",
        "\n",
        "# Validate output\n",
        "test_csv = pd.read_csv(output_path)\n",
        "print(f\"Output CSV shape: {test_csv.shape}\", flush=True)\n",
        "print(f\"Output CSV ID range: {test_csv['ID'].min()} to {test_csv['ID'].max()}\", flush=True)\n",
        "print(f\"Unique RET_TARGET values: {test_csv['RET_TARGET'].unique()}\", flush=True)\n",
        "print(f\"Missing values: {test_csv.isna().sum().sum()}\", flush=True)\n",
        "\n",
        "# Download the file\n",
        "files.download(output_path)\n",
        "\n",
        "# Print final results\n",
        "print(\"\\nValidation Results:\", flush=True)\n",
        "for model_name, acc in results.items():\n",
        "    print(f\"{model_name}: {acc:.4f}\", flush=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9lpNiBVf7-C"
      },
      "source": [
        "74%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9MgxaUqKkZWj",
        "outputId": "faeef477-c9e0-484b-88c8-fba82f512dd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost version: 2.1.4\n",
            "Selected top return columns: ['RET_262', 'RET_88', 'RET_172', 'RET_259', 'RET_150', 'RET_118', 'RET_216', 'RET_268', 'RET_115', 'RET_261', 'RET_59', 'RET_238', 'RET_121', 'RET_97', 'RET_30']\n",
            "\n",
            "Training LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LightGBM Targets: 100%|| 100/100 [12:35<00:00,  7.55s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightGBM Weighted Accuracy: 0.7336\n",
            "\n",
            "LightGBM Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.9173 | Fold Accuracies: [np.float64(0.7617021276595745), np.float64(1.0), np.float64(0.8406374501992032), np.float64(0.8604651162790697), np.float64(0.6867469879518072)]\n",
            "ID_TARGET: 129.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.6481 | Fold Accuracies: [np.float64(0.636734693877551), np.float64(0.6097560975609756), np.float64(0.6325757575757576), np.float64(0.6371308016877637), np.float64(0.6509090909090909)]\n",
            "ID_TARGET: 136.0 | Best Params: {'bagging_fraction': 0.65, 'learning_rate': 0.07, 'min_child_samples': 12, 'num_leaves': 47} | Mean Accuracy: 0.6070 | Fold Accuracies: [np.float64(0.6293436293436293), np.float64(0.6136363636363636), np.float64(0.6072727272727273), np.float64(0.58984375), np.float64(0.5951417004048583)]\n",
            "ID_TARGET: 161.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31} | Mean Accuracy: 0.6911 | Fold Accuracies: [np.float64(0.7016129032258065), np.float64(0.6363636363636364), np.float64(0.6946564885496184), np.float64(0.694980694980695), np.float64(0.6666666666666666)]\n",
            "ID_TARGET: 217.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31} | Mean Accuracy: 0.6876 | Fold Accuracies: [np.float64(0.6988416988416989), np.float64(0.6653992395437263), np.float64(0.6747404844290658), np.float64(0.6593406593406593), np.float64(0.6631205673758865)]\n",
            "ID_TARGET: 91.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.6982 | Fold Accuracies: [np.float64(0.6755725190839694), np.float64(0.6829268292682927), np.float64(0.6920152091254753), np.float64(0.6859504132231405), np.float64(0.7116104868913857)]\n",
            "ID_TARGET: 137.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.6451 | Fold Accuracies: [np.float64(0.5578512396694215), np.float64(0.6026200873362445), np.float64(0.6538461538461539), np.float64(0.70703125), np.float64(0.6444444444444445)]\n",
            "ID_TARGET: 8.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31} | Mean Accuracy: 0.7665 | Fold Accuracies: [np.float64(0.8832684824902723), np.float64(0.6465863453815262), np.float64(0.6175298804780877), np.float64(0.672), np.float64(0.8582677165354331)]\n",
            "ID_TARGET: 3.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7112 | Fold Accuracies: [np.float64(0.7121212121212122), np.float64(0.6598360655737705), np.float64(0.6972111553784861), np.float64(0.711864406779661), np.float64(0.6768558951965066)]\n",
            "ID_TARGET: 9.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.6752 | Fold Accuracies: [np.float64(0.6468085106382979), np.float64(0.7), np.float64(0.65), np.float64(0.6570247933884298), np.float64(0.6550387596899225)]\n",
            "ID_TARGET: 131.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31} | Mean Accuracy: 0.6581 | Fold Accuracies: [np.float64(0.6889763779527559), np.float64(0.7076923076923077), np.float64(0.6693548387096774), np.float64(0.6075949367088608), np.float64(0.6076923076923076)]\n",
            "ID_TARGET: 21.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.6770 | Fold Accuracies: [np.float64(0.7394366197183099), np.float64(0.6145038167938931), np.float64(0.6593406593406593), np.float64(0.65234375), np.float64(0.6653696498054474)]\n",
            "ID_TARGET: 54.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.1, 'min_child_samples': 15, 'num_leaves': 63} | Mean Accuracy: 0.7701 | Fold Accuracies: [np.float64(0.7248062015503876), np.float64(0.7902621722846442), np.float64(0.8193832599118943), np.float64(0.737410071942446), np.float64(0.7294117647058823)]\n",
            "ID_TARGET: 130.0 | Best Params: {'bagging_fraction': 0.65, 'learning_rate': 0.07, 'min_child_samples': 12, 'num_leaves': 47} | Mean Accuracy: 0.7842 | Fold Accuracies: [np.float64(0.8311688311688312), np.float64(0.8892988929889298), np.float64(0.6953405017921147), np.float64(0.6806083650190115), np.float64(0.8248175182481752)]\n",
            "ID_TARGET: 269.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.6907 | Fold Accuracies: [np.float64(0.704), np.float64(0.7117903930131004), np.float64(0.6963562753036437), np.float64(0.5787234042553191), np.float64(0.6623376623376623)]\n",
            "ID_TARGET: 157.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7842 | Fold Accuracies: [np.float64(0.7652173913043478), np.float64(0.819327731092437), np.float64(0.7258064516129032), np.float64(0.736), np.float64(0.7909836065573771)]\n",
            "ID_TARGET: 249.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31} | Mean Accuracy: 0.7234 | Fold Accuracies: [np.float64(0.7325581395348837), np.float64(0.688212927756654), np.float64(0.7448559670781894), np.float64(0.6653061224489796), np.float64(0.683206106870229)]\n",
            "ID_TARGET: 22.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.6774 | Fold Accuracies: [np.float64(0.6666666666666666), np.float64(0.6353383458646616), np.float64(0.6653543307086615), np.float64(0.6628352490421456), np.float64(0.7237354085603113)]\n",
            "ID_TARGET: 202.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.1, 'min_child_samples': 15, 'num_leaves': 63} | Mean Accuracy: 0.6786 | Fold Accuracies: [np.float64(0.6274509803921569), np.float64(0.7052238805970149), np.float64(0.6360153256704981), np.float64(0.6606498194945848), np.float64(0.696969696969697)]\n",
            "ID_TARGET: 132.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7474 | Fold Accuracies: [np.float64(0.7370689655172413), np.float64(0.7228915662650602), np.float64(0.7362204724409449), np.float64(0.7344398340248963), np.float64(0.7943548387096774)]\n",
            "ID_TARGET: 96.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7597 | Fold Accuracies: [np.float64(0.6277056277056277), np.float64(0.6223175965665236), np.float64(0.6538461538461539), np.float64(0.726027397260274), np.float64(0.9529914529914529)]\n",
            "ID_TARGET: 7.0 | Best Params: {'bagging_fraction': 0.65, 'learning_rate': 0.07, 'min_child_samples': 12, 'num_leaves': 47} | Mean Accuracy: 0.7357 | Fold Accuracies: [np.float64(0.70703125), np.float64(0.6988416988416989), np.float64(0.718978102189781), np.float64(0.758893280632411), np.float64(0.7945736434108527)]\n",
            "ID_TARGET: 178.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7171 | Fold Accuracies: [np.float64(0.7154471544715447), np.float64(0.6996197718631179), np.float64(0.7391304347826086), np.float64(0.6816326530612244), np.float64(0.71484375)]\n",
            "ID_TARGET: 68.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7697 | Fold Accuracies: [np.float64(0.7509578544061303), np.float64(0.7408906882591093), np.float64(0.7735042735042735), np.float64(0.7795918367346939), np.float64(0.7540983606557377)]\n",
            "ID_TARGET: 44.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7190 | Fold Accuracies: [np.float64(0.7245283018867924), np.float64(0.7283464566929134), np.float64(0.7122302158273381), np.float64(0.6923076923076923), np.float64(0.7074074074074074)]\n",
            "ID_TARGET: 196.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7216 | Fold Accuracies: [np.float64(0.66), np.float64(0.7635135135135135), np.float64(0.6630434782608695), np.float64(0.70703125), np.float64(0.7163120567375887)]\n",
            "ID_TARGET: 292.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7064 | Fold Accuracies: [np.float64(0.6498194945848376), np.float64(0.6746031746031746), np.float64(0.6911764705882353), np.float64(0.67578125), np.float64(0.7241379310344828)]\n",
            "ID_TARGET: 239.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7517 | Fold Accuracies: [np.float64(0.7153846153846154), np.float64(0.7258064516129032), np.float64(0.711864406779661), np.float64(0.7976190476190477), np.float64(0.7589285714285714)]\n",
            "ID_TARGET: 279.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.6957 | Fold Accuracies: [np.float64(0.6867924528301886), np.float64(0.7204724409448819), np.float64(0.6536964980544747), np.float64(0.6958333333333333), np.float64(0.6377952755905512)]\n",
            "ID_TARGET: 38.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7154 | Fold Accuracies: [np.float64(0.7061068702290076), np.float64(0.7075098814229249), np.float64(0.6829268292682927), np.float64(0.7049808429118773), np.float64(0.7136563876651982)]\n",
            "ID_TARGET: 209.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7241 | Fold Accuracies: [np.float64(0.7764705882352941), np.float64(0.7054263565891473), np.float64(0.7120622568093385), np.float64(0.6592592592592592), np.float64(0.6731517509727627)]\n",
            "ID_TARGET: 207.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.6671 | Fold Accuracies: [np.float64(0.6809338521400778), np.float64(0.6431372549019608), np.float64(0.6987951807228916), np.float64(0.6452830188679245), np.float64(0.6627906976744186)]\n",
            "ID_TARGET: 98.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7187 | Fold Accuracies: [np.float64(0.6563706563706564), np.float64(0.7306122448979592), np.float64(0.7530864197530864), np.float64(0.7541666666666667), np.float64(0.6577946768060836)]\n",
            "ID_TARGET: 65.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7317 | Fold Accuracies: [np.float64(0.7593984962406015), np.float64(0.7227272727272728), np.float64(0.6944444444444444), np.float64(0.753968253968254), np.float64(0.717948717948718)]\n",
            "ID_TARGET: 51.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31} | Mean Accuracy: 0.7492 | Fold Accuracies: [np.float64(0.7125), np.float64(0.7206477732793523), np.float64(0.75), np.float64(0.7439024390243902), np.float64(0.7716535433070866)]\n",
            "ID_TARGET: 78.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7117 | Fold Accuracies: [np.float64(0.7447698744769874), np.float64(0.736), np.float64(0.7083333333333334), np.float64(0.6413502109704642), np.float64(0.7035573122529645)]\n",
            "ID_TARGET: 177.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7318 | Fold Accuracies: [np.float64(0.7418181818181818), np.float64(0.7286245353159851), np.float64(0.7092198581560284), np.float64(0.7552447552447552), np.float64(0.7027027027027027)]\n",
            "ID_TARGET: 231.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7775 | Fold Accuracies: [np.float64(0.779467680608365), np.float64(0.7276119402985075), np.float64(0.736), np.float64(0.8), np.float64(0.7870722433460076)]\n",
            "ID_TARGET: 119.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7598 | Fold Accuracies: [np.float64(0.7159533073929961), np.float64(0.7450199203187251), np.float64(0.7829457364341085), np.float64(0.7172995780590717), np.float64(0.7622950819672131)]\n",
            "ID_TARGET: 158.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31} | Mean Accuracy: 0.7916 | Fold Accuracies: [np.float64(0.7634854771784232), np.float64(0.8306451612903226), np.float64(0.7862595419847328), np.float64(0.7905138339920948), np.float64(0.7843866171003717)]\n",
            "ID_TARGET: 80.0 | Best Params: {'bagging_fraction': 0.65, 'learning_rate': 0.07, 'min_child_samples': 12, 'num_leaves': 47} | Mean Accuracy: 0.7109 | Fold Accuracies: [np.float64(0.704), np.float64(0.7312252964426877), np.float64(0.692), np.float64(0.7061224489795919), np.float64(0.7212389380530974)]\n",
            "ID_TARGET: 25.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7211 | Fold Accuracies: [np.float64(0.6829268292682927), np.float64(0.7203389830508474), np.float64(0.7242647058823529), np.float64(0.7238805970149254), np.float64(0.7265625)]\n",
            "ID_TARGET: 175.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7280 | Fold Accuracies: [np.float64(0.69140625), np.float64(0.672), np.float64(0.6935483870967742), np.float64(0.7888446215139442), np.float64(0.7276264591439688)]\n",
            "ID_TARGET: 151.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7705 | Fold Accuracies: [np.float64(0.7675276752767528), np.float64(0.7683823529411765), np.float64(0.7692307692307693), np.float64(0.7391304347826086), np.float64(0.8057851239669421)]\n",
            "ID_TARGET: 257.0 | Best Params: {'bagging_fraction': 0.65, 'learning_rate': 0.07, 'min_child_samples': 12, 'num_leaves': 47} | Mean Accuracy: 0.7230 | Fold Accuracies: [np.float64(0.7035573122529645), np.float64(0.7132075471698113), np.float64(0.7445255474452555), np.float64(0.6900369003690037), np.float64(0.7636363636363637)]\n",
            "ID_TARGET: 75.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7677 | Fold Accuracies: [np.float64(0.7950819672131147), np.float64(0.7530364372469636), np.float64(0.746268656716418), np.float64(0.7206896551724138), np.float64(0.8014981273408239)]\n",
            "ID_TARGET: 244.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31} | Mean Accuracy: 0.6957 | Fold Accuracies: [np.float64(0.704119850187266), np.float64(0.6823529411764706), np.float64(0.6943396226415094), np.float64(0.6857142857142857), np.float64(0.6568265682656826)]\n",
            "ID_TARGET: 149.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7443 | Fold Accuracies: [np.float64(0.6954887218045113), np.float64(0.7137254901960784), np.float64(0.7615384615384615), np.float64(0.7480314960629921), np.float64(0.7283464566929134)]\n",
            "ID_TARGET: 85.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7712 | Fold Accuracies: [np.float64(0.8130081300813008), np.float64(0.7336065573770492), np.float64(0.78), np.float64(0.7352941176470589), np.float64(0.7241379310344828)]\n",
            "ID_TARGET: 190.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31} | Mean Accuracy: 0.7397 | Fold Accuracies: [np.float64(0.7556390977443609), np.float64(0.7528089887640449), np.float64(0.7125506072874493), np.float64(0.7290076335877863), np.float64(0.7435897435897436)]\n",
            "ID_TARGET: 13.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7416 | Fold Accuracies: [np.float64(0.6964980544747081), np.float64(0.7545126353790613), np.float64(0.7084870848708487), np.float64(0.71900826446281), np.float64(0.7559055118110236)]\n",
            "ID_TARGET: 228.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.6944 | Fold Accuracies: [np.float64(0.6954887218045113), np.float64(0.6937984496124031), np.float64(0.710801393728223), np.float64(0.6585365853658537), np.float64(0.6413043478260869)]\n",
            "ID_TARGET: 144.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7785 | Fold Accuracies: [np.float64(0.7923728813559322), np.float64(0.8235294117647058), np.float64(0.7963636363636364), np.float64(0.6865079365079365), np.float64(0.7288135593220338)]\n",
            "ID_TARGET: 290.0 | Best Params: {'bagging_fraction': 0.65, 'learning_rate': 0.07, 'min_child_samples': 12, 'num_leaves': 47} | Mean Accuracy: 0.7167 | Fold Accuracies: [np.float64(0.7312252964426877), np.float64(0.7479338842975206), np.float64(0.7348484848484849), np.float64(0.6869918699186992), np.float64(0.6825396825396826)]\n",
            "ID_TARGET: 114.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.1, 'min_child_samples': 15, 'num_leaves': 63} | Mean Accuracy: 0.6961 | Fold Accuracies: [np.float64(0.6475095785440613), np.float64(0.7063492063492064), np.float64(0.7121212121212122), np.float64(0.6772908366533864), np.float64(0.6902985074626866)]\n",
            "ID_TARGET: 166.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7523 | Fold Accuracies: [np.float64(0.7764227642276422), np.float64(0.7472527472527473), np.float64(0.7622950819672131), np.float64(0.7228464419475655), np.float64(0.7295081967213115)]\n",
            "ID_TARGET: 234.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7609 | Fold Accuracies: [np.float64(0.7295081967213115), np.float64(0.7741935483870968), np.float64(0.7647058823529411), np.float64(0.7705627705627706), np.float64(0.6926070038910506)]\n",
            "ID_TARGET: 34.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7563 | Fold Accuracies: [np.float64(0.7153558052434457), np.float64(0.7595419847328244), np.float64(0.768), np.float64(0.7682926829268293), np.float64(0.735632183908046)]\n",
            "ID_TARGET: 154.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7532 | Fold Accuracies: [np.float64(0.7795275590551181), np.float64(0.7706766917293233), np.float64(0.696969696969697), np.float64(0.7191011235955056), np.float64(0.7966804979253111)]\n",
            "ID_TARGET: 225.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7136 | Fold Accuracies: [np.float64(0.676056338028169), np.float64(0.7142857142857143), np.float64(0.6950354609929078), np.float64(0.7015503875968992), np.float64(0.7572463768115942)]\n",
            "ID_TARGET: 185.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.8007 | Fold Accuracies: [np.float64(0.755656108597285), np.float64(0.7860262008733624), np.float64(0.7575757575757576), np.float64(0.74235807860262), np.float64(0.826271186440678)]\n",
            "ID_TARGET: 39.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7360 | Fold Accuracies: [np.float64(0.7317073170731707), np.float64(0.7098039215686275), np.float64(0.7392996108949417), np.float64(0.7211155378486056), np.float64(0.7075098814229249)]\n",
            "ID_TARGET: 272.0 | Best Params: {'bagging_fraction': 0.65, 'learning_rate': 0.07, 'min_child_samples': 12, 'num_leaves': 47} | Mean Accuracy: 0.7600 | Fold Accuracies: [np.float64(0.7531380753138075), np.float64(0.8125), np.float64(0.7198443579766537), np.float64(0.789272030651341), np.float64(0.7253521126760564)]\n",
            "ID_TARGET: 282.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7332 | Fold Accuracies: [np.float64(0.70703125), np.float64(0.7258687258687259), np.float64(0.716), np.float64(0.7366412213740458), np.float64(0.7510373443983402)]\n",
            "ID_TARGET: 90.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7507 | Fold Accuracies: [np.float64(0.7578125), np.float64(0.7624521072796935), np.float64(0.712), np.float64(0.7551867219917012), np.float64(0.75)]\n",
            "ID_TARGET: 52.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7405 | Fold Accuracies: [np.float64(0.7210144927536232), np.float64(0.7488789237668162), np.float64(0.7489539748953975), np.float64(0.7261904761904762), np.float64(0.7032520325203252)]\n",
            "ID_TARGET: 258.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7177 | Fold Accuracies: [np.float64(0.7148936170212766), np.float64(0.7130434782608696), np.float64(0.6996047430830039), np.float64(0.75), np.float64(0.627906976744186)]\n",
            "ID_TARGET: 291.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7525 | Fold Accuracies: [np.float64(0.7467811158798283), np.float64(0.7335907335907336), np.float64(0.7252747252747253), np.float64(0.7536764705882353), np.float64(0.7301587301587301)]\n",
            "ID_TARGET: 152.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7570 | Fold Accuracies: [np.float64(0.7375), np.float64(0.76), np.float64(0.7234848484848485), np.float64(0.7608695652173914), np.float64(0.7551867219917012)]\n",
            "ID_TARGET: 133.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7649 | Fold Accuracies: [np.float64(0.79182156133829), np.float64(0.7410358565737052), np.float64(0.758893280632411), np.float64(0.7272727272727273), np.float64(0.7790697674418605)]\n",
            "ID_TARGET: 29.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7151 | Fold Accuracies: [np.float64(0.6772908366533864), np.float64(0.7268722466960352), np.float64(0.6973180076628352), np.float64(0.7366412213740458), np.float64(0.7241379310344828)]\n",
            "ID_TARGET: 274.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31} | Mean Accuracy: 0.7336 | Fold Accuracies: [np.float64(0.7666666666666667), np.float64(0.7482014388489209), np.float64(0.722007722007722), np.float64(0.7204301075268817), np.float64(0.6959706959706959)]\n",
            "ID_TARGET: 106.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7634 | Fold Accuracies: [np.float64(0.7705627705627706), np.float64(0.7239819004524887), np.float64(0.7534883720930232), np.float64(0.728110599078341), np.float64(0.7833333333333333)]\n",
            "ID_TARGET: 173.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7719 | Fold Accuracies: [np.float64(0.8021978021978022), np.float64(0.736), np.float64(0.7377049180327869), np.float64(0.8), np.float64(0.7086614173228346)]\n",
            "ID_TARGET: 33.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7343 | Fold Accuracies: [np.float64(0.7219917012448133), np.float64(0.7065637065637066), np.float64(0.7215686274509804), np.float64(0.7003891050583657), np.float64(0.7323420074349443)]\n",
            "ID_TARGET: 69.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7188 | Fold Accuracies: [np.float64(0.7260869565217392), np.float64(0.7215189873417721), np.float64(0.6576923076923077), np.float64(0.7094339622641509), np.float64(0.6981981981981982)]\n",
            "ID_TARGET: 17.0 | Best Params: {'bagging_fraction': 0.65, 'learning_rate': 0.07, 'min_child_samples': 12, 'num_leaves': 47} | Mean Accuracy: 0.6971 | Fold Accuracies: [np.float64(0.7286821705426356), np.float64(0.7255639097744361), np.float64(0.6640625), np.float64(0.68359375), np.float64(0.6833976833976834)]\n",
            "ID_TARGET: 189.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.1, 'min_child_samples': 15, 'num_leaves': 63} | Mean Accuracy: 0.7393 | Fold Accuracies: [np.float64(0.7430830039525692), np.float64(0.7027027027027027), np.float64(0.6652892561983471), np.float64(0.766798418972332), np.float64(0.7)]\n",
            "ID_TARGET: 284.0 | Best Params: {'bagging_fraction': 0.65, 'learning_rate': 0.07, 'min_child_samples': 12, 'num_leaves': 47} | Mean Accuracy: 0.7326 | Fold Accuracies: [np.float64(0.6981818181818182), np.float64(0.7374517374517374), np.float64(0.7663934426229508), np.float64(0.7026022304832714), np.float64(0.7583333333333333)]\n",
            "ID_TARGET: 218.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31} | Mean Accuracy: 0.6929 | Fold Accuracies: [np.float64(0.688212927756654), np.float64(0.6784313725490196), np.float64(0.6259259259259259), np.float64(0.7246963562753036), np.float64(0.7158273381294964)]\n",
            "ID_TARGET: 183.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7584 | Fold Accuracies: [np.float64(0.7717391304347826), np.float64(0.7892561983471075), np.float64(0.7520661157024794), np.float64(0.683206106870229), np.float64(0.7537878787878788)]\n",
            "ID_TARGET: 206.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7564 | Fold Accuracies: [np.float64(0.7131474103585658), np.float64(0.7471264367816092), np.float64(0.7707509881422925), np.float64(0.7553648068669528), np.float64(0.7595419847328244)]\n",
            "ID_TARGET: 93.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.1, 'min_child_samples': 15, 'num_leaves': 63} | Mean Accuracy: 0.7236 | Fold Accuracies: [np.float64(0.7112970711297071), np.float64(0.7195571955719557), np.float64(0.6623931623931624), np.float64(0.704119850187266), np.float64(0.7394636015325671)]\n",
            "ID_TARGET: 16.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7182 | Fold Accuracies: [np.float64(0.7052238805970149), np.float64(0.6612903225806451), np.float64(0.6891385767790262), np.float64(0.6992481203007519), np.float64(0.6974789915966386)]\n",
            "ID_TARGET: 246.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.1, 'min_child_samples': 15, 'num_leaves': 63} | Mean Accuracy: 0.7599 | Fold Accuracies: [np.float64(0.7088122605363985), np.float64(0.7196969696969697), np.float64(0.7642585551330798), np.float64(0.7735849056603774), np.float64(0.7529411764705882)]\n",
            "ID_TARGET: 167.0 | Best Params: {'bagging_fraction': 0.65, 'learning_rate': 0.07, 'min_child_samples': 12, 'num_leaves': 47} | Mean Accuracy: 0.7501 | Fold Accuracies: [np.float64(0.7569721115537849), np.float64(0.7644787644787645), np.float64(0.7415254237288136), np.float64(0.7131147540983607), np.float64(0.7745901639344263)]\n",
            "ID_TARGET: 1.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31} | Mean Accuracy: 0.7424 | Fold Accuracies: [np.float64(0.7456140350877193), np.float64(0.7435897435897436), np.float64(0.7165991902834008), np.float64(0.7142857142857143), np.float64(0.7219917012448133)]\n",
            "ID_TARGET: 289.0 | Best Params: {'bagging_fraction': 0.65, 'learning_rate': 0.07, 'min_child_samples': 12, 'num_leaves': 47} | Mean Accuracy: 0.7340 | Fold Accuracies: [np.float64(0.7435897435897436), np.float64(0.7350746268656716), np.float64(0.734375), np.float64(0.7350746268656716), np.float64(0.7218045112781954)]\n",
            "ID_TARGET: 141.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7909 | Fold Accuracies: [np.float64(0.7666666666666667), np.float64(0.8008658008658008), np.float64(0.7777777777777778), np.float64(0.7977099236641222), np.float64(0.7479674796747967)]\n",
            "ID_TARGET: 109.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.1, 'min_child_samples': 15, 'num_leaves': 63} | Mean Accuracy: 0.7003 | Fold Accuracies: [np.float64(0.69), np.float64(0.6842105263157895), np.float64(0.6995884773662552), np.float64(0.6521739130434783), np.float64(0.7194244604316546)]\n",
            "ID_TARGET: 19.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7529 | Fold Accuracies: [np.float64(0.7537878787878788), np.float64(0.7213114754098361), np.float64(0.7109375), np.float64(0.7886792452830189), np.float64(0.7480916030534351)]\n",
            "ID_TARGET: 28.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.1, 'min_child_samples': 15, 'num_leaves': 63} | Mean Accuracy: 0.7009 | Fold Accuracies: [np.float64(0.7272727272727273), np.float64(0.6234309623430963), np.float64(0.6772908366533864), np.float64(0.7453874538745388), np.float64(0.690677966101695)]\n",
            "ID_TARGET: 251.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31} | Mean Accuracy: 0.7211 | Fold Accuracies: [np.float64(0.7056451612903226), np.float64(0.6828358208955224), np.float64(0.7111111111111111), np.float64(0.7886178861788617), np.float64(0.7041666666666667)]\n",
            "ID_TARGET: 278.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7686 | Fold Accuracies: [np.float64(0.6746031746031746), np.float64(0.754863813229572), np.float64(0.7593360995850622), np.float64(0.8181818181818182), np.float64(0.7339055793991416)]\n",
            "ID_TARGET: 76.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7339 | Fold Accuracies: [np.float64(0.7297297297297297), np.float64(0.7388059701492538), np.float64(0.7354085603112841), np.float64(0.6906474820143885), np.float64(0.7707509881422925)]\n",
            "ID_TARGET: 241.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31} | Mean Accuracy: 0.7418 | Fold Accuracies: [np.float64(0.7649402390438247), np.float64(0.7387387387387387), np.float64(0.694560669456067), np.float64(0.7654320987654321), np.float64(0.7208333333333333)]\n",
            "ID_TARGET: 214.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.1, 'min_child_samples': 15, 'num_leaves': 63} | Mean Accuracy: 0.7724 | Fold Accuracies: [np.float64(0.7358490566037735), np.float64(0.6980392156862745), np.float64(0.8070866141732284), np.float64(0.8296296296296296), np.float64(0.7441860465116279)]\n",
            "ID_TARGET: 102.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7796 | Fold Accuracies: [np.float64(0.7633587786259542), np.float64(0.717391304347826), np.float64(0.7768595041322314), np.float64(0.8103448275862069), np.float64(0.7692307692307693)]\n",
            "ID_TARGET: 145.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7225 | Fold Accuracies: [np.float64(0.7142857142857143), np.float64(0.6518518518518519), np.float64(0.673469387755102), np.float64(0.7376425855513308), np.float64(0.7613168724279835)]\n",
            "ID_TARGET: 155.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15} | Mean Accuracy: 0.7905 | Fold Accuracies: [np.float64(0.7395833333333334), np.float64(0.8014705882352942), np.float64(0.7942386831275721), np.float64(0.7159533073929961), np.float64(0.7720588235294118)]\n",
            "\n",
            "Training XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "XGBoost Targets: 100%|| 100/100 [25:53<00:00, 15.53s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Weighted Accuracy: 0.7601\n",
            "\n",
            "XGBoost Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.6171 | Fold Accuracies: [np.float64(0.6425531914893617), np.float64(0.58203125), np.float64(0.6175298804780877), np.float64(0.5697674418604651), np.float64(0.5823293172690763)]\n",
            "ID_TARGET: 129.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.6229 | Fold Accuracies: [np.float64(0.6081632653061224), np.float64(0.6260162601626016), np.float64(0.5871212121212122), np.float64(0.5780590717299579), np.float64(0.5745454545454546)]\n",
            "ID_TARGET: 136.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6293436293436293), np.float64(0.5568181818181818), np.float64(0.5781818181818181), np.float64(0.59765625), np.float64(0.5748987854251012)]\n",
            "ID_TARGET: 161.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.6711 | Fold Accuracies: [np.float64(0.6209677419354839), np.float64(0.6818181818181818), np.float64(0.648854961832061), np.float64(0.694980694980695), np.float64(0.6704980842911877)]\n",
            "ID_TARGET: 217.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7335907335907336), np.float64(0.6920152091254753), np.float64(0.6885813148788927), np.float64(0.706959706959707), np.float64(0.7021276595744681)]\n",
            "ID_TARGET: 91.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7677 | Fold Accuracies: [np.float64(0.7290076335877863), np.float64(0.7439024390243902), np.float64(0.7224334600760456), np.float64(0.756198347107438), np.float64(0.7752808988764045)]\n",
            "ID_TARGET: 137.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.8000 | Fold Accuracies: [np.float64(0.6322314049586777), np.float64(0.5982532751091703), np.float64(0.6623931623931624), np.float64(0.70703125), np.float64(0.6407407407407407)]\n",
            "ID_TARGET: 8.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.5870 | Fold Accuracies: [np.float64(0.5447470817120622), np.float64(0.5301204819277109), np.float64(0.6254980079681275), np.float64(0.552), np.float64(0.6141732283464567)]\n",
            "ID_TARGET: 3.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.6664 | Fold Accuracies: [np.float64(0.6174242424242424), np.float64(0.6475409836065574), np.float64(0.6972111553784861), np.float64(0.6610169491525424), np.float64(0.6375545851528385)]\n",
            "ID_TARGET: 9.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.8598 | Fold Accuracies: [np.float64(0.6680851063829787), np.float64(0.684), np.float64(0.6538461538461539), np.float64(0.628099173553719), np.float64(0.6511627906976745)]\n",
            "ID_TARGET: 131.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.6334 | Fold Accuracies: [np.float64(0.6496062992125984), np.float64(0.6), np.float64(0.6048387096774194), np.float64(0.6118143459915611), np.float64(0.6)]\n",
            "ID_TARGET: 21.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.6820 | Fold Accuracies: [np.float64(0.7288732394366197), np.float64(0.6908396946564885), np.float64(0.6666666666666666), np.float64(0.66015625), np.float64(0.603112840466926)]\n",
            "ID_TARGET: 54.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7352 | Fold Accuracies: [np.float64(0.7054263565891473), np.float64(0.6741573033707865), np.float64(0.7709251101321586), np.float64(0.6258992805755396), np.float64(0.7098039215686275)]\n",
            "ID_TARGET: 130.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.6944 | Fold Accuracies: [np.float64(0.696969696969697), np.float64(0.6863468634686347), np.float64(0.6774193548387096), np.float64(0.6273764258555133), np.float64(0.6021897810218978)]\n",
            "ID_TARGET: 269.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.6472 | Fold Accuracies: [np.float64(0.68), np.float64(0.6986899563318777), np.float64(0.6518218623481782), np.float64(0.5446808510638298), np.float64(0.6147186147186147)]\n",
            "ID_TARGET: 157.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7127 | Fold Accuracies: [np.float64(0.6521739130434783), np.float64(0.6932773109243697), np.float64(0.6411290322580645), np.float64(0.64), np.float64(0.6639344262295082)]\n",
            "ID_TARGET: 249.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.6924 | Fold Accuracies: [np.float64(0.686046511627907), np.float64(0.6768060836501901), np.float64(0.7325102880658436), np.float64(0.6326530612244898), np.float64(0.6335877862595419)]\n",
            "ID_TARGET: 22.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.7018 | Fold Accuracies: [np.float64(0.6956521739130435), np.float64(0.6616541353383458), np.float64(0.7007874015748031), np.float64(0.7049808429118773), np.float64(0.7120622568093385)]\n",
            "ID_TARGET: 202.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.6981 | Fold Accuracies: [np.float64(0.6431372549019608), np.float64(0.7126865671641791), np.float64(0.6819923371647509), np.float64(0.7364620938628159), np.float64(0.678030303030303)]\n",
            "ID_TARGET: 132.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7515 | Fold Accuracies: [np.float64(0.7327586206896551), np.float64(0.714859437751004), np.float64(0.7244094488188977), np.float64(0.7219917012448133), np.float64(0.7782258064516129)]\n",
            "ID_TARGET: 96.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.9654 | Fold Accuracies: [np.float64(0.7142857142857143), np.float64(0.7167381974248928), np.float64(0.6423076923076924), np.float64(0.7351598173515982), np.float64(0.6923076923076923)]\n",
            "ID_TARGET: 7.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7298 | Fold Accuracies: [np.float64(0.6796875), np.float64(0.6911196911196911), np.float64(0.6824817518248175), np.float64(0.7233201581027668), np.float64(0.810077519379845)]\n",
            "ID_TARGET: 178.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7142 | Fold Accuracies: [np.float64(0.7439024390243902), np.float64(0.688212927756654), np.float64(0.7430830039525692), np.float64(0.689795918367347), np.float64(0.69140625)]\n",
            "ID_TARGET: 68.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.7390 | Fold Accuracies: [np.float64(0.7049808429118773), np.float64(0.7327935222672065), np.float64(0.7564102564102564), np.float64(0.7714285714285715), np.float64(0.7254098360655737)]\n",
            "ID_TARGET: 44.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7447 | Fold Accuracies: [np.float64(0.7584905660377359), np.float64(0.7322834645669292), np.float64(0.7302158273381295), np.float64(0.688034188034188), np.float64(0.7222222222222222)]\n",
            "ID_TARGET: 196.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7415 | Fold Accuracies: [np.float64(0.67), np.float64(0.7567567567567568), np.float64(0.7572463768115942), np.float64(0.671875), np.float64(0.7375886524822695)]\n",
            "ID_TARGET: 292.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.6981 | Fold Accuracies: [np.float64(0.6462093862815884), np.float64(0.6428571428571429), np.float64(0.6727941176470589), np.float64(0.703125), np.float64(0.685823754789272)]\n",
            "ID_TARGET: 239.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 6, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.7475 | Fold Accuracies: [np.float64(0.7), np.float64(0.7338709677419355), np.float64(0.7330508474576272), np.float64(0.7936507936507936), np.float64(0.7767857142857143)]\n",
            "ID_TARGET: 279.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.6802 | Fold Accuracies: [np.float64(0.5547169811320755), np.float64(0.7244094488188977), np.float64(0.6848249027237354), np.float64(0.6791666666666667), np.float64(0.6771653543307087)]\n",
            "ID_TARGET: 38.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7291 | Fold Accuracies: [np.float64(0.6374045801526718), np.float64(0.6798418972332015), np.float64(0.6707317073170732), np.float64(0.6819923371647509), np.float64(0.7092511013215859)]\n",
            "ID_TARGET: 209.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7098039215686275), np.float64(0.7054263565891473), np.float64(0.7159533073929961), np.float64(0.7296296296296296), np.float64(0.688715953307393)]\n",
            "ID_TARGET: 207.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.6794 | Fold Accuracies: [np.float64(0.6809338521400778), np.float64(0.6745098039215687), np.float64(0.7269076305220884), np.float64(0.6377358490566037), np.float64(0.6744186046511628)]\n",
            "ID_TARGET: 98.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7386 | Fold Accuracies: [np.float64(0.6525096525096525), np.float64(0.7428571428571429), np.float64(0.757201646090535), np.float64(0.7375), np.float64(0.6539923954372624)]\n",
            "ID_TARGET: 65.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7550 | Fold Accuracies: [np.float64(0.7142857142857143), np.float64(0.7318181818181818), np.float64(0.6944444444444444), np.float64(0.7619047619047619), np.float64(0.7222222222222222)]\n",
            "ID_TARGET: 51.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7303 | Fold Accuracies: [np.float64(0.7208333333333333), np.float64(0.7044534412955465), np.float64(0.7327586206896551), np.float64(0.6991869918699187), np.float64(0.7086614173228346)]\n",
            "ID_TARGET: 78.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7304 | Fold Accuracies: [np.float64(0.7238493723849372), np.float64(0.748), np.float64(0.7083333333333334), np.float64(0.679324894514768), np.float64(0.7114624505928854)]\n",
            "ID_TARGET: 177.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7526 | Fold Accuracies: [np.float64(0.7418181818181818), np.float64(0.7211895910780669), np.float64(0.7056737588652482), np.float64(0.7657342657342657), np.float64(0.7065637065637066)]\n",
            "ID_TARGET: 231.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7566539923954373), np.float64(0.7052238805970149), np.float64(0.74), np.float64(0.7918367346938775), np.float64(0.7642585551330798)]\n",
            "ID_TARGET: 119.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7597 | Fold Accuracies: [np.float64(0.7276264591439688), np.float64(0.7290836653386454), np.float64(0.8023255813953488), np.float64(0.7172995780590717), np.float64(0.7295081967213115)]\n",
            "ID_TARGET: 158.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7838 | Fold Accuracies: [np.float64(0.7468879668049793), np.float64(0.8225806451612904), np.float64(0.7557251908396947), np.float64(0.7984189723320159), np.float64(0.758364312267658)]\n",
            "ID_TARGET: 80.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7145 | Fold Accuracies: [np.float64(0.704), np.float64(0.7035573122529645), np.float64(0.672), np.float64(0.710204081632653), np.float64(0.7345132743362832)]\n",
            "ID_TARGET: 25.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7386 | Fold Accuracies: [np.float64(0.7398373983739838), np.float64(0.7161016949152542), np.float64(0.6948529411764706), np.float64(0.7201492537313433), np.float64(0.7265625)]\n",
            "ID_TARGET: 175.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.703125), np.float64(0.66), np.float64(0.6532258064516129), np.float64(0.7609561752988048), np.float64(0.7042801556420234)]\n",
            "ID_TARGET: 151.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7688 | Fold Accuracies: [np.float64(0.7490774907749077), np.float64(0.7573529411764706), np.float64(0.7692307692307693), np.float64(0.7478260869565218), np.float64(0.8016528925619835)]\n",
            "ID_TARGET: 257.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7370 | Fold Accuracies: [np.float64(0.7154150197628458), np.float64(0.6981132075471698), np.float64(0.7116788321167883), np.float64(0.6974169741697417), np.float64(0.7381818181818182)]\n",
            "ID_TARGET: 75.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7873 | Fold Accuracies: [np.float64(0.7991803278688525), np.float64(0.7611336032388664), np.float64(0.7761194029850746), np.float64(0.7448275862068966), np.float64(0.8127340823970037)]\n",
            "ID_TARGET: 244.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.6760 | Fold Accuracies: [np.float64(0.6741573033707865), np.float64(0.6745098039215687), np.float64(0.6867924528301886), np.float64(0.7061224489795919), np.float64(0.6162361623616236)]\n",
            "ID_TARGET: 149.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7194 | Fold Accuracies: [np.float64(0.6466165413533834), np.float64(0.7137254901960784), np.float64(0.7615384615384615), np.float64(0.7283464566929134), np.float64(0.7047244094488189)]\n",
            "ID_TARGET: 85.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.8028 | Fold Accuracies: [np.float64(0.8130081300813008), np.float64(0.7622950819672131), np.float64(0.78), np.float64(0.7478991596638656), np.float64(0.7011494252873564)]\n",
            "ID_TARGET: 190.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7444 | Fold Accuracies: [np.float64(0.7443609022556391), np.float64(0.7453183520599251), np.float64(0.7327935222672065), np.float64(0.7175572519083969), np.float64(0.7692307692307693)]\n",
            "ID_TARGET: 13.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6964980544747081), np.float64(0.7689530685920578), np.float64(0.7380073800738007), np.float64(0.768595041322314), np.float64(0.7519685039370079)]\n",
            "ID_TARGET: 228.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7631 | Fold Accuracies: [np.float64(0.7744360902255639), np.float64(0.7015503875968992), np.float64(0.7142857142857143), np.float64(0.6991869918699187), np.float64(0.6666666666666666)]\n",
            "ID_TARGET: 144.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7616 | Fold Accuracies: [np.float64(0.7245762711864406), np.float64(0.819327731092437), np.float64(0.7563636363636363), np.float64(0.6626984126984127), np.float64(0.7161016949152542)]\n",
            "ID_TARGET: 290.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7154150197628458), np.float64(0.6694214876033058), np.float64(0.7007575757575758), np.float64(0.6829268292682927), np.float64(0.6825396825396826)]\n",
            "ID_TARGET: 114.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7309 | Fold Accuracies: [np.float64(0.6743295019157088), np.float64(0.75), np.float64(0.7462121212121212), np.float64(0.7370517928286853), np.float64(0.7014925373134329)]\n",
            "ID_TARGET: 166.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.7665 | Fold Accuracies: [np.float64(0.7804878048780488), np.float64(0.7728937728937729), np.float64(0.7827868852459017), np.float64(0.7228464419475655), np.float64(0.7418032786885246)]\n",
            "ID_TARGET: 234.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7586 | Fold Accuracies: [np.float64(0.75), np.float64(0.7782258064516129), np.float64(0.7563025210084033), np.float64(0.7748917748917749), np.float64(0.708171206225681)]\n",
            "ID_TARGET: 34.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7680 | Fold Accuracies: [np.float64(0.7228464419475655), np.float64(0.7595419847328244), np.float64(0.78), np.float64(0.7439024390243902), np.float64(0.7394636015325671)]\n",
            "ID_TARGET: 154.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.7667 | Fold Accuracies: [np.float64(0.7795275590551181), np.float64(0.8120300751879699), np.float64(0.7159090909090909), np.float64(0.7303370786516854), np.float64(0.7800829875518672)]\n",
            "ID_TARGET: 225.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.7285 | Fold Accuracies: [np.float64(0.6795774647887324), np.float64(0.7368421052631579), np.float64(0.7127659574468085), np.float64(0.751937984496124), np.float64(0.7427536231884058)]\n",
            "ID_TARGET: 185.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7292 | Fold Accuracies: [np.float64(0.7058823529411765), np.float64(0.74235807860262), np.float64(0.6666666666666666), np.float64(0.7030567685589519), np.float64(0.7203389830508474)]\n",
            "ID_TARGET: 39.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7154471544715447), np.float64(0.7176470588235294), np.float64(0.7782101167315175), np.float64(0.7370517928286853), np.float64(0.7114624505928854)]\n",
            "ID_TARGET: 272.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.7762 | Fold Accuracies: [np.float64(0.7740585774058577), np.float64(0.8166666666666667), np.float64(0.7237354085603113), np.float64(0.8122605363984674), np.float64(0.7535211267605634)]\n",
            "ID_TARGET: 282.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 6, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.7381 | Fold Accuracies: [np.float64(0.71875), np.float64(0.7297297297297297), np.float64(0.732), np.float64(0.7633587786259542), np.float64(0.7468879668049793)]\n",
            "ID_TARGET: 90.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.7755 | Fold Accuracies: [np.float64(0.76171875), np.float64(0.7931034482758621), np.float64(0.752), np.float64(0.7759336099585062), np.float64(0.7896825396825397)]\n",
            "ID_TARGET: 52.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 6, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.7443 | Fold Accuracies: [np.float64(0.7246376811594203), np.float64(0.7668161434977578), np.float64(0.7322175732217573), np.float64(0.7658730158730159), np.float64(0.7317073170731707)]\n",
            "ID_TARGET: 258.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.7233 | Fold Accuracies: [np.float64(0.7148936170212766), np.float64(0.7521739130434782), np.float64(0.7035573122529645), np.float64(0.75), np.float64(0.6472868217054264)]\n",
            "ID_TARGET: 291.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7566 | Fold Accuracies: [np.float64(0.7467811158798283), np.float64(0.7451737451737451), np.float64(0.7435897435897436), np.float64(0.7573529411764706), np.float64(0.7420634920634921)]\n",
            "ID_TARGET: 152.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7504 | Fold Accuracies: [np.float64(0.75), np.float64(0.78), np.float64(0.7196969696969697), np.float64(0.7137681159420289), np.float64(0.7302904564315352)]\n",
            "ID_TARGET: 133.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 6, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.7713 | Fold Accuracies: [np.float64(0.7955390334572491), np.float64(0.7569721115537849), np.float64(0.7786561264822134), np.float64(0.7348484848484849), np.float64(0.7906976744186046)]\n",
            "ID_TARGET: 29.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7040 | Fold Accuracies: [np.float64(0.6334661354581673), np.float64(0.7224669603524229), np.float64(0.6934865900383141), np.float64(0.6946564885496184), np.float64(0.7203065134099617)]\n",
            "ID_TARGET: 274.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7425 | Fold Accuracies: [np.float64(0.7592592592592593), np.float64(0.762589928057554), np.float64(0.722007722007722), np.float64(0.7311827956989247), np.float64(0.7142857142857143)]\n",
            "ID_TARGET: 106.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.9303 | Fold Accuracies: [np.float64(0.7705627705627706), np.float64(0.746606334841629), np.float64(0.7255813953488373), np.float64(0.7511520737327189), np.float64(0.7541666666666667)]\n",
            "ID_TARGET: 173.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7687 | Fold Accuracies: [np.float64(0.7692307692307693), np.float64(0.748), np.float64(0.7622950819672131), np.float64(0.7925925925925926), np.float64(0.7165354330708661)]\n",
            "ID_TARGET: 33.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7310 | Fold Accuracies: [np.float64(0.7178423236514523), np.float64(0.6795366795366795), np.float64(0.6980392156862745), np.float64(0.7276264591439688), np.float64(0.7472118959107806)]\n",
            "ID_TARGET: 69.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7282 | Fold Accuracies: [np.float64(0.7391304347826086), np.float64(0.7341772151898734), np.float64(0.6730769230769231), np.float64(0.720754716981132), np.float64(0.7612612612612613)]\n",
            "ID_TARGET: 17.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.6995 | Fold Accuracies: [np.float64(0.7131782945736435), np.float64(0.7105263157894737), np.float64(0.703125), np.float64(0.66796875), np.float64(0.6525096525096525)]\n",
            "ID_TARGET: 189.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7168 | Fold Accuracies: [np.float64(0.7193675889328063), np.float64(0.6988416988416989), np.float64(0.6694214876033058), np.float64(0.758893280632411), np.float64(0.7)]\n",
            "ID_TARGET: 284.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7294 | Fold Accuracies: [np.float64(0.7018181818181818), np.float64(0.7027027027027027), np.float64(0.7663934426229508), np.float64(0.7026022304832714), np.float64(0.7458333333333333)]\n",
            "ID_TARGET: 218.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7025 | Fold Accuracies: [np.float64(0.688212927756654), np.float64(0.6941176470588235), np.float64(0.662962962962963), np.float64(0.7732793522267206), np.float64(0.6834532374100719)]\n",
            "ID_TARGET: 183.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7585 | Fold Accuracies: [np.float64(0.6992753623188406), np.float64(0.7644628099173554), np.float64(0.743801652892562), np.float64(0.6603053435114504), np.float64(0.7765151515151515)]\n",
            "ID_TARGET: 206.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 6, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.7578 | Fold Accuracies: [np.float64(0.7370517928286853), np.float64(0.7394636015325671), np.float64(0.7984189723320159), np.float64(0.7467811158798283), np.float64(0.767175572519084)]\n",
            "ID_TARGET: 93.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7133 | Fold Accuracies: [np.float64(0.7238493723849372), np.float64(0.6678966789667896), np.float64(0.7393162393162394), np.float64(0.7153558052434457), np.float64(0.7088122605363985)]\n",
            "ID_TARGET: 16.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7067 | Fold Accuracies: [np.float64(0.7201492537313433), np.float64(0.6814516129032258), np.float64(0.6666666666666666), np.float64(0.7330827067669173), np.float64(0.6890756302521008)]\n",
            "ID_TARGET: 246.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7415 | Fold Accuracies: [np.float64(0.6896551724137931), np.float64(0.7310606060606061), np.float64(0.7262357414448669), np.float64(0.7358490566037735), np.float64(0.7176470588235294)]\n",
            "ID_TARGET: 167.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.9479 | Fold Accuracies: [np.float64(0.7211155378486056), np.float64(0.749034749034749), np.float64(0.7245762711864406), np.float64(0.7213114754098361), np.float64(0.7868852459016393)]\n",
            "ID_TARGET: 1.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.7380 | Fold Accuracies: [np.float64(0.7675438596491229), np.float64(0.7478632478632479), np.float64(0.7246963562753036), np.float64(0.7023809523809523), np.float64(0.7427385892116183)]\n",
            "ID_TARGET: 289.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7512 | Fold Accuracies: [np.float64(0.7435897435897436), np.float64(0.7425373134328358), np.float64(0.734375), np.float64(0.7201492537313433), np.float64(0.6879699248120301)]\n",
            "ID_TARGET: 141.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7906 | Fold Accuracies: [np.float64(0.7916666666666666), np.float64(0.7878787878787878), np.float64(0.7701149425287356), np.float64(0.8206106870229007), np.float64(0.7317073170731707)]\n",
            "ID_TARGET: 109.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 6, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.7181 | Fold Accuracies: [np.float64(0.74), np.float64(0.7449392712550608), np.float64(0.6995884773662552), np.float64(0.6758893280632411), np.float64(0.7302158273381295)]\n",
            "ID_TARGET: 19.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7689 | Fold Accuracies: [np.float64(0.7689393939393939), np.float64(0.7622950819672131), np.float64(0.7265625), np.float64(0.7811320754716982), np.float64(0.7633587786259542)]\n",
            "ID_TARGET: 28.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.7103 | Fold Accuracies: [np.float64(0.7196969696969697), np.float64(0.6652719665271967), np.float64(0.701195219123506), np.float64(0.7306273062730627), np.float64(0.690677966101695)]\n",
            "ID_TARGET: 251.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 150} | Mean Accuracy: 0.7224 | Fold Accuracies: [np.float64(0.6895161290322581), np.float64(0.7201492537313433), np.float64(0.7074074074074074), np.float64(0.7764227642276422), np.float64(0.7166666666666667)]\n",
            "ID_TARGET: 278.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7513 | Fold Accuracies: [np.float64(0.6944444444444444), np.float64(0.7392996108949417), np.float64(0.7344398340248963), np.float64(0.8051948051948052), np.float64(0.7381974248927039)]\n",
            "ID_TARGET: 76.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7499 | Fold Accuracies: [np.float64(0.722007722007722), np.float64(0.7126865671641791), np.float64(0.7354085603112841), np.float64(0.6870503597122302), np.float64(0.8142292490118577)]\n",
            "ID_TARGET: 241.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7502 | Fold Accuracies: [np.float64(0.7529880478087649), np.float64(0.7342342342342343), np.float64(0.7154811715481172), np.float64(0.7777777777777778), np.float64(0.7208333333333333)]\n",
            "ID_TARGET: 214.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.7807 | Fold Accuracies: [np.float64(0.7358490566037735), np.float64(0.6980392156862745), np.float64(0.7992125984251969), np.float64(0.8222222222222222), np.float64(0.7635658914728682)]\n",
            "ID_TARGET: 102.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 6, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.7663 | Fold Accuracies: [np.float64(0.7824427480916031), np.float64(0.7304347826086957), np.float64(0.7768595041322314), np.float64(0.8146551724137931), np.float64(0.7269230769230769)]\n",
            "ID_TARGET: 145.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150} | Mean Accuracy: 0.6829 | Fold Accuracies: [np.float64(0.667953667953668), np.float64(0.6481481481481481), np.float64(0.6775510204081633), np.float64(0.6463878326996197), np.float64(0.6872427983539094)]\n",
            "ID_TARGET: 155.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 200} | Mean Accuracy: 0.7939 | Fold Accuracies: [np.float64(0.7916666666666666), np.float64(0.8014705882352942), np.float64(0.8106995884773662), np.float64(0.7587548638132295), np.float64(0.7904411764705882)]\n",
            "\n",
            "Performing second-pass training with top 30 features...\n",
            "\n",
            "Second-pass LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rLightGBM Targets:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   1%|          | 1/100 [00:00<01:05,  1.52it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   2%|         | 2/100 [00:01<00:57,  1.70it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   3%|         | 3/100 [00:01<00:52,  1.83it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   4%|         | 4/100 [00:02<00:54,  1.77it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   5%|         | 5/100 [00:02<00:52,  1.81it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   6%|         | 6/100 [00:03<00:49,  1.92it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   7%|         | 7/100 [00:03<00:45,  2.04it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   8%|         | 8/100 [00:04<00:50,  1.82it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   9%|         | 9/100 [00:04<00:50,  1.81it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  10%|         | 10/100 [00:05<00:48,  1.84it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  11%|         | 11/100 [00:06<00:52,  1.68it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  12%|        | 12/100 [00:06<00:51,  1.72it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  13%|        | 13/100 [00:07<00:50,  1.71it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  14%|        | 14/100 [00:07<00:51,  1.67it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  15%|        | 15/100 [00:08<00:48,  1.74it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  16%|        | 16/100 [00:09<00:47,  1.76it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  17%|        | 17/100 [00:10<00:57,  1.44it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  18%|        | 18/100 [00:10<00:56,  1.44it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  19%|        | 19/100 [00:11<00:56,  1.44it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  20%|        | 20/100 [00:12<00:56,  1.41it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  21%|        | 21/100 [00:12<00:54,  1.46it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  22%|       | 22/100 [00:13<00:48,  1.60it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  23%|       | 23/100 [00:13<00:45,  1.68it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  24%|       | 24/100 [00:14<00:43,  1.75it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  25%|       | 25/100 [00:14<00:41,  1.82it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  26%|       | 26/100 [00:15<00:39,  1.85it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  27%|       | 27/100 [00:15<00:39,  1.85it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  28%|       | 28/100 [00:16<00:37,  1.93it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  29%|       | 29/100 [00:16<00:36,  1.94it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  30%|       | 30/100 [00:17<00:36,  1.94it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  31%|       | 31/100 [00:17<00:34,  2.01it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  32%|      | 32/100 [00:18<00:33,  2.00it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  33%|      | 33/100 [00:18<00:32,  2.05it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  34%|      | 34/100 [00:19<00:31,  2.09it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  35%|      | 35/100 [00:19<00:32,  1.98it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  36%|      | 36/100 [00:20<00:32,  1.95it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  37%|      | 37/100 [00:20<00:32,  1.94it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  38%|      | 38/100 [00:21<00:30,  2.01it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  39%|      | 39/100 [00:21<00:30,  1.99it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  40%|      | 40/100 [00:22<00:30,  1.94it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  41%|      | 41/100 [00:23<00:34,  1.72it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  42%|     | 42/100 [00:23<00:35,  1.63it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  43%|     | 43/100 [00:24<00:36,  1.56it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  44%|     | 44/100 [00:25<00:37,  1.51it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  45%|     | 45/100 [00:25<00:37,  1.45it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  46%|     | 46/100 [00:26<00:34,  1.58it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  47%|     | 47/100 [00:26<00:32,  1.65it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  48%|     | 48/100 [00:27<00:30,  1.72it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  49%|     | 49/100 [00:27<00:27,  1.83it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  50%|     | 50/100 [00:28<00:28,  1.78it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  51%|     | 51/100 [00:29<00:26,  1.86it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  52%|    | 52/100 [00:29<00:25,  1.88it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  53%|    | 53/100 [00:30<00:24,  1.93it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  54%|    | 54/100 [00:30<00:23,  1.96it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  55%|    | 55/100 [00:30<00:21,  2.07it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  56%|    | 56/100 [00:31<00:21,  2.05it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  57%|    | 57/100 [00:31<00:20,  2.05it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  58%|    | 58/100 [00:32<00:20,  2.01it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  59%|    | 59/100 [00:32<00:20,  2.02it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  60%|    | 60/100 [00:33<00:20,  1.94it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  61%|    | 61/100 [00:34<00:19,  1.97it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  62%|   | 62/100 [00:34<00:19,  1.98it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  63%|   | 63/100 [00:34<00:17,  2.10it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  64%|   | 64/100 [00:35<00:17,  2.06it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  65%|   | 65/100 [00:36<00:17,  1.95it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  66%|   | 66/100 [00:36<00:19,  1.77it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  67%|   | 67/100 [00:37<00:20,  1.63it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  68%|   | 68/100 [00:38<00:21,  1.52it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  69%|   | 69/100 [00:38<00:21,  1.46it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  70%|   | 70/100 [00:39<00:19,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  71%|   | 71/100 [00:40<00:17,  1.65it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  72%|  | 72/100 [00:40<00:16,  1.69it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  73%|  | 73/100 [00:41<00:14,  1.81it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  74%|  | 74/100 [00:41<00:13,  1.87it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  75%|  | 75/100 [00:42<00:13,  1.88it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  76%|  | 76/100 [00:42<00:12,  1.91it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  77%|  | 77/100 [00:43<00:12,  1.90it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  78%|  | 78/100 [00:43<00:10,  2.02it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  79%|  | 79/100 [00:44<00:10,  2.01it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  80%|  | 80/100 [00:44<00:10,  1.87it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  81%|  | 81/100 [00:45<00:10,  1.87it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  82%| | 82/100 [00:45<00:09,  1.89it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  83%| | 83/100 [00:46<00:08,  1.95it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  84%| | 84/100 [00:46<00:08,  1.93it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  85%| | 85/100 [00:47<00:07,  1.99it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  86%| | 86/100 [00:47<00:06,  2.05it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  87%| | 87/100 [00:48<00:06,  1.87it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  88%| | 88/100 [00:48<00:06,  1.94it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  89%| | 89/100 [00:49<00:05,  1.90it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  90%| | 90/100 [00:49<00:05,  1.79it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  91%| | 91/100 [00:50<00:05,  1.65it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  92%|| 92/100 [00:51<00:05,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  93%|| 93/100 [00:52<00:04,  1.50it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  94%|| 94/100 [00:52<00:03,  1.51it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  95%|| 95/100 [00:53<00:03,  1.63it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  96%|| 96/100 [00:53<00:02,  1.71it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  97%|| 97/100 [00:54<00:01,  1.86it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  98%|| 98/100 [00:54<00:01,  1.91it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  99%|| 99/100 [00:55<00:00,  1.90it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets: 100%|| 100/100 [00:55<00:00,  1.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Second-pass XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Targets: 100%|| 100/100 [01:09<00:00,  1.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Performing third-pass training for low-performing targets...\n",
            "\n",
            "Third-pass LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "LightGBM Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 52488.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Third-pass XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 53399.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved hyperparameter log to: /content/hyperparameters.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_6ba2c5b5-e44b-42e0-a9bd-bbcb18a7c1c3\", \"hyperparameters.json\", 555766)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved predictions to: /content/predictions_ensemble.csv\n",
            "Output CSV shape: (114468, 2)\n",
            "Output CSV ID range: 0 to 114467\n",
            "Unique RET_TARGET values: [ 1 -1]\n",
            "Missing values: 0\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_52099940-f1c4-4c5e-8f0a-aad0bd6bdfa4\", \"predictions_ensemble.csv\", 970862)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Results:\n",
            "LightGBM: 0.7336\n",
            "XGBoost: 0.7601\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost\n",
        "from sklearn.decomposition import PCA\n",
        "from joblib import Parallel, delayed\n",
        "import json\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# Check xgboost version for compatibility\n",
        "print(f\"XGBoost version: {xgboost.__version__}\")\n",
        "if int(xgboost.__version__.split('.')[0]) < 1:\n",
        "    print(\"Warning: XGBoost version < 1.0.0 detected. Ensure compatibility with eval_metric in constructor.\")\n",
        "\n",
        "# Set up data directory\n",
        "DATA_DIR = '/content'\n",
        "\n",
        "# Load datasets\n",
        "try:\n",
        "    X_train = pd.read_csv(os.path.join(DATA_DIR, 'X_train_itDkypA.csv'), index_col='ID', dtype=np.float32)\n",
        "    y_train = pd.read_csv(os.path.join(DATA_DIR, 'y_train_3LeeT2g.csv'), index_col='ID', dtype=np.float32)\n",
        "    X_test = pd.read_csv(os.path.join(DATA_DIR, 'X_test_Beg4ey3.csv'), index_col='ID', dtype=np.float32)\n",
        "    supplementary = pd.read_csv(os.path.join(DATA_DIR, 'supplementary_data_Vkoyn8z.csv'))\n",
        "except FileNotFoundError as e:\n",
        "    raise FileNotFoundError(f\"Dataset not found: {e}. Please ensure files are uploaded to {DATA_DIR}.\")\n",
        "\n",
        "# Custom weighted accuracy metric\n",
        "def weighted_accuracy(y_true, y_pred, weights):\n",
        "    y_pred_mapped = np.where(y_pred == 1, 1, -1)\n",
        "    correct = (y_pred_mapped == np.sign(y_true)).astype(float)\n",
        "    return np.sum(np.abs(y_true) * correct) / np.sum(np.abs(y_true))\n",
        "\n",
        "# Preprocess data with enhanced feature selection\n",
        "def preprocess_data(X, y=None, supplementary=None, is_train=True, top_cols=None):\n",
        "    ret_cols = [col for col in X.columns if col.startswith('RET_')]\n",
        "\n",
        "    # Dynamic feature selection with minimum variance threshold\n",
        "    if is_train and top_cols is None:\n",
        "        if len(ret_cols) > 15:\n",
        "            variances = X[ret_cols].var()\n",
        "            corr_sum = X[ret_cols].corr().abs().sum()\n",
        "            combined_score = variances * corr_sum\n",
        "            # Filter out low-variance features (threshold = 1e-5)\n",
        "            valid_cols = variances[variances > 1e-5].index\n",
        "            if len(valid_cols) < 15:\n",
        "                top_cols = valid_cols.tolist()\n",
        "            else:\n",
        "                top_cols = combined_score.loc[valid_cols].sort_values(ascending=False).head(15).index.tolist()\n",
        "        else:\n",
        "            top_cols = ret_cols\n",
        "        print(f\"Selected top return columns: {top_cols}\")\n",
        "    elif top_cols is not None:\n",
        "        ret_cols = [col for col in ret_cols if col in top_cols]\n",
        "        if not ret_cols:\n",
        "            raise ValueError(\"No return columns selected. Check top_cols consistency.\")\n",
        "\n",
        "    # Cache sector-based medians\n",
        "    sector_medians = {}\n",
        "    if supplementary is not None:\n",
        "        sector_map = supplementary.set_index('ID_asset')['CLASS_LEVEL_1']\n",
        "        for col in ret_cols:\n",
        "            asset_id = int(col.replace('RET_', ''))\n",
        "            sector = sector_map.get(asset_id, np.nan)\n",
        "            if pd.notna(sector):\n",
        "                sector_assets = supplementary[supplementary['CLASS_LEVEL_1'] == sector]['ID_asset']\n",
        "                sector_cols = [f'RET_{a}' for a in sector_assets if f'RET_{a}' in X.columns]\n",
        "                if sector_cols:\n",
        "                    sector_medians[col] = X[sector_cols].median(axis=1)\n",
        "            if col in sector_medians:\n",
        "                X[col] = X[col].fillna(sector_medians[col])\n",
        "            else:\n",
        "                X[col] = X[col].fillna(X[col].median())\n",
        "\n",
        "    # Sector-based features\n",
        "    new_cols = {}\n",
        "    if supplementary is not None:\n",
        "        level = 'CLASS_LEVEL_1'\n",
        "        sector_groups = supplementary.groupby(level)['ID_asset'].apply(list).to_dict()\n",
        "        for sector, assets in sector_groups.items():\n",
        "            asset_cols = [f'RET_{asset}' for asset in assets if f'RET_{asset}' in ret_cols]\n",
        "            if asset_cols:\n",
        "                new_cols[f'SECTOR_AVG_{level}_{sector}'] = X[asset_cols].mean(axis=1).replace([np.inf, -np.inf], 0).fillna(0)\n",
        "        X = X.merge(supplementary[['ID_asset', level]].rename(columns={'ID_asset': 'ID_TARGET', level: f'TARGET_{level}'}),\n",
        "                    on='ID_TARGET', how='left')\n",
        "        X = pd.concat([X, pd.get_dummies(X[f'TARGET_{level}'], prefix=f'TARGET_{level}', dummy_na=True)], axis=1)\n",
        "        X = X.drop(f'TARGET_{level}', axis=1)\n",
        "\n",
        "    # Cross-sectional features\n",
        "    new_cols['MEAN_RET'] = X[ret_cols].mean(axis=1)\n",
        "    new_cols['STD_RET'] = X[ret_cols].std(axis=1)\n",
        "    new_cols.update({f'CS_RANK_{col}': X.groupby('ID_DAY')[col].rank(pct=True).replace([np.inf, -np.inf], 0).fillna(0) for col in ret_cols})\n",
        "\n",
        "    # Correlation-based features (top 5 pairs)\n",
        "    if is_train:\n",
        "        corr_matrix = X[ret_cols].corr()\n",
        "        corr_pairs = corr_matrix.unstack().sort_values(ascending=False)\n",
        "        top_pairs = [(i, j) for i, j in corr_pairs.index if i < j][:5]\n",
        "        for i, j in top_pairs:\n",
        "            new_cols[f'CORR_{i}_{j}'] = X[i] * X[j]\n",
        "\n",
        "    # PCA features (2 components)\n",
        "    if ret_cols:\n",
        "        pca = PCA(n_components=min(2, len(ret_cols)), random_state=42)\n",
        "        pca_features = pca.fit_transform(X[ret_cols].fillna(0))\n",
        "        for i in range(pca_features.shape[1]):\n",
        "            new_cols[f'PCA_{i}'] = pca_features[:, i]\n",
        "\n",
        "    # Add new features to DataFrame\n",
        "    new_cols_df = pd.DataFrame(new_cols, index=X.index, dtype=np.float32)\n",
        "    X = pd.concat([X, new_cols_df], axis=1)\n",
        "\n",
        "    # Standardize numerical features\n",
        "    feature_cols = [col for col in X.columns if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "    scaler = StandardScaler()\n",
        "    X[feature_cols] = scaler.fit_transform(X[feature_cols].replace([np.inf, -np.inf], 0).fillna(0))\n",
        "\n",
        "    if is_train:\n",
        "        y['SIGN_TARGET'] = np.where(y['RET_TARGET'] > 0, 1, 0).astype(np.int32)\n",
        "        return X, y, feature_cols, top_cols\n",
        "    return X, None, feature_cols, top_cols\n",
        "\n",
        "# Preprocess data\n",
        "try:\n",
        "    X_train, y_train, feature_cols, top_cols = preprocess_data(X_train, y_train, supplementary, is_train=True)\n",
        "    X_test, _, test_feature_cols, _ = preprocess_data(X_test, supplementary=supplementary, is_train=False, top_cols=top_cols)\n",
        "except ValueError as e:\n",
        "    print(f\"Preprocessing error: {e}\")\n",
        "    raise\n",
        "\n",
        "# Align columns\n",
        "common_cols = X_train.columns.intersection(X_test.columns)\n",
        "X_train = X_train[common_cols]\n",
        "X_test = X_test[common_cols]\n",
        "feature_cols = [col for col in common_cols if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "\n",
        "# Align y_train\n",
        "y_train = y_train.loc[X_train.index]\n",
        "\n",
        "# Define models with corrected hyperparameter grids\n",
        "models = {\n",
        "    'LightGBM': {\n",
        "        'model': LGBMClassifier(num_leaves=31, min_child_samples=15, lambda_l1=0.3, lambda_l2=0.3,\n",
        "                                subsample=0.7, colsample_bytree=0.8, bagging_freq=5, bagging_fraction=0.7,\n",
        "                                random_state=42, n_jobs=1, verbosity=-1, class_weight='balanced', force_row_wise=True),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.02], 'num_leaves': [15], 'min_child_samples': [20], 'bagging_fraction': [0.6]},\n",
        "            {'learning_rate': [0.05], 'num_leaves': [31], 'min_child_samples': [10], 'bagging_fraction': [0.7]},\n",
        "            {'learning_rate': [0.1], 'num_leaves': [63], 'min_child_samples': [15], 'bagging_fraction': [0.8]},\n",
        "            {'learning_rate': [0.07], 'num_leaves': [47], 'min_child_samples': [12], 'bagging_fraction': [0.65]}\n",
        "        ],\n",
        "        'callbacks': [lightgbm.early_stopping(stopping_rounds=10, verbose=False)]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'model': XGBClassifier(max_depth=4, min_child_weight=2, subsample=0.8, colsample_bytree=0.8,\n",
        "                               random_state=42, n_jobs=1, eval_metric='logloss', verbosity=0,\n",
        "                               scale_pos_weight=len(y_train[y_train['SIGN_TARGET'] == 0]) / len(y_train[y_train['SIGN_TARGET'] == 1])),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.03], 'max_depth': [3], 'min_child_weight': [1], 'n_estimators': [150]},\n",
        "            {'learning_rate': [0.05], 'max_depth': [5], 'min_child_weight': [2], 'n_estimators': [200]},\n",
        "            {'learning_rate': [0.1], 'max_depth': [4], 'min_child_weight': [3], 'n_estimators': [150]},\n",
        "            {'learning_rate': [0.07], 'max_depth': [6], 'min_child_weight': [2], 'n_estimators': [200]}\n",
        "        ],\n",
        "        'callbacks': [xgboost.callback.EarlyStopping(rounds=10, metric_name='logloss', save_best=True)]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to train and predict for a single target\n",
        "def train_target(target, X_train, y_train, X_test, feature_cols, model, model_name, kf, param_grid, callbacks):\n",
        "    X_target = X_train[X_train['ID_TARGET'] == target][feature_cols]\n",
        "    y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "    weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "    low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "    if target in low_performing_targets:\n",
        "        weights = weights * 1.5\n",
        "    groups = X_train[X_train['ID_TARGET'] == target]['ID_DAY']\n",
        "    X_test_target = X_test[X_test['ID_TARGET'] == target][feature_cols]\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "    # Check for sufficient data\n",
        "    if len(X_target) < 100 or len(X_test_target) == 0:\n",
        "        print(f\"Warning: Insufficient data for ID_TARGET {target} (train: {len(X_target)}, test: {len(X_test_target)}). Skipping.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    param_results = []\n",
        "    best_params = None\n",
        "    best_score = 0\n",
        "    best_model = None\n",
        "\n",
        "    # First-pass grid search with sample weights\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        print(f\"Testing params for {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "        try:\n",
        "            model.set_params(**params)\n",
        "        except ValueError as e:\n",
        "            print(f\"Invalid params for {model_name} ID_TARGET {target}: {e}\")\n",
        "            continue\n",
        "        fold_accuracies = []\n",
        "        for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "            X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "            y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "            w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "\n",
        "            if model_name == 'LightGBM' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=callbacks)\n",
        "            elif model_name == 'XGBoost' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "            else:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "            y_pred = model.predict(X_val)\n",
        "            acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "            fold_accuracies.append(acc)\n",
        "\n",
        "        mean_acc = np.mean(fold_accuracies)\n",
        "        print(f\"{model_name} | ID_TARGET: {target} | Params: {params} | Mean Accuracy: {mean_acc:.4f} | Fold Accuracies: {fold_accuracies}\", flush=True)\n",
        "        param_results.append({\n",
        "            'params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': fold_accuracies\n",
        "        })\n",
        "        if mean_acc > best_score:\n",
        "            best_score = mean_acc\n",
        "            best_params = params\n",
        "            best_model = type(model)(**model.get_params())\n",
        "\n",
        "    # Train with best parameters\n",
        "    if best_model is None:\n",
        "        print(f\"No valid model for {model_name} ID_TARGET {target}. Using default.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    best_model.set_params(**best_params)\n",
        "    if model_name == 'LightGBM' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=callbacks)\n",
        "    elif model_name == 'XGBoost' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "    else:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights)\n",
        "\n",
        "    # Predict\n",
        "    preds = best_model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "\n",
        "    # Feature importance\n",
        "    importance = best_model.feature_importances_\n",
        "    feature_importance = dict(zip(feature_cols, importance))\n",
        "    top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:30]\n",
        "\n",
        "    # Clean up memory\n",
        "    gc.collect()\n",
        "\n",
        "    return str(target), best_params, best_score, param_results, test_ids, preds, top_features\n",
        "\n",
        "# Cross-validation and training\n",
        "kf = GroupKFold(n_splits=5)  # Increased to 5 folds\n",
        "results = {}\n",
        "predictions = {}\n",
        "ensemble_weights = {'LightGBM': 0.7, 'XGBoost': 0.3}\n",
        "param_log = {}\n",
        "top_features_all = {}\n",
        "param_summary = []\n",
        "low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\", flush=True)\n",
        "    param_log[model_name] = {}\n",
        "    top_features_all[model_name] = {}\n",
        "\n",
        "    # First-pass training\n",
        "    results_parallel = Parallel(n_jobs=-1)(\n",
        "        delayed(train_target)(target, X_train, y_train, X_test, feature_cols, model_info['model'], model_name, kf,\n",
        "                             model_info['param_grid'], model_info['callbacks'])\n",
        "        for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\")\n",
        "    )\n",
        "\n",
        "    # Collect results\n",
        "    accuracies = []\n",
        "    for target, params, mean_acc, param_results, test_ids, preds, top_features in results_parallel:\n",
        "        param_log[model_name][target] = {\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'all_params': param_results\n",
        "        }\n",
        "        top_features_all[model_name][target] = top_features\n",
        "        accuracies.append(mean_acc)\n",
        "        predictions.setdefault(target, {})[model_name] = dict(zip(test_ids, preds))\n",
        "        param_summary.append({\n",
        "            'model': model_name,\n",
        "            'ID_TARGET': target,\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': param_results[-1]['fold_accuracies'] if param_results else []\n",
        "        })\n",
        "\n",
        "    results[model_name] = np.mean([acc for acc in accuracies if acc > 0])  # Exclude skipped targets\n",
        "    print(f\"{model_name} Weighted Accuracy: {results[model_name]:.4f}\", flush=True)\n",
        "\n",
        "    # Print parameter summary\n",
        "    print(f\"\\n{model_name} Parameter Summary:\", flush=True)\n",
        "    for summary in param_summary:\n",
        "        if summary['model'] == model_name:\n",
        "            print(f\"ID_TARGET: {summary['ID_TARGET']} | Best Params: {summary['best_params']} | Mean Accuracy: {summary['mean_accuracy']:.4f} | Fold Accuracies: {summary['fold_accuracies']}\", flush=True)\n",
        "\n",
        "# Second-pass training with top 30 features\n",
        "print(\"\\nPerforming second-pass training with top 30 features...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nSecond-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\"):\n",
        "        target_str = str(target)\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "        if target in low_performing_targets:\n",
        "            weights = weights * 1.5\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        best_params['n_estimators'] = 200  # Increase for better convergence\n",
        "        model.set_params(**best_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Third-pass training for low-performing targets\n",
        "print(\"\\nPerforming third-pass training for low-performing targets...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nThird-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(low_performing_targets, desc=f\"{model_name} Low-Performing Targets\"):\n",
        "        target_str = str(target)\n",
        "        if target_str not in param_log[model_name] or param_log[model_name][target_str]['mean_accuracy'] >= 0.75:\n",
        "            continue  # Skip if already performing well\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs() * 2.0  # Increase weight\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        # Fine-tune parameters for low-performing targets\n",
        "        fine_tune_grid = [\n",
        "            {'learning_rate': [best_params['learning_rate'][0] * 0.8], 'n_estimators': [250]},\n",
        "            {'learning_rate': [best_params['learning_rate'][0] * 1.2], 'n_estimators': [250]}\n",
        "        ]\n",
        "        best_score = param_log[model_name][target_str]['mean_accuracy']\n",
        "        best_fine_params = best_params\n",
        "\n",
        "        for params in ParameterGrid(fine_tune_grid):\n",
        "            print(f\"Fine-tuning {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "            model.set_params(**params)\n",
        "            fold_accuracies = []\n",
        "            for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "                X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "                y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "                w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "                if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "                elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "                else:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "                y_pred = model.predict(X_val)\n",
        "                acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "                fold_accuracies.append(acc)\n",
        "            mean_acc = np.mean(fold_accuracies)\n",
        "            print(f\"{model_name} | ID_TARGET: {target} | Fine-tune Params: {params} | Mean Accuracy: {mean_acc:.4f}\", flush=True)\n",
        "            if mean_acc > best_score:\n",
        "                best_score = mean_acc\n",
        "                best_fine_params = params\n",
        "                param_log[model_name][target_str]['best_params'] = best_fine_params\n",
        "                param_log[model_name][target_str]['mean_accuracy'] = best_score\n",
        "                param_summary.append({\n",
        "                    'model': model_name,\n",
        "                    'ID_TARGET': target_str,\n",
        "                    'best_params': best_fine_params,\n",
        "                    'mean_accuracy': best_score,\n",
        "                    'fold_accuracies': fold_accuracies\n",
        "                })\n",
        "\n",
        "        # Retrain with fine-tuned parameters\n",
        "        model.set_params(**best_fine_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Save parameter log\n",
        "param_log_path = os.path.join(DATA_DIR, 'hyperparameters.json')\n",
        "with open(param_log_path, 'w') as f:\n",
        "    json.dump(param_log, f, indent=4)\n",
        "print(f\"Saved hyperparameter log to: {param_log_path}\", flush=True)\n",
        "files.download(param_log_path)\n",
        "\n",
        "# Ensemble predictions\n",
        "final_predictions = {}\n",
        "missing_day_targets = []\n",
        "for target in X_test['ID_TARGET'].unique():\n",
        "    target_str = str(target)\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "    for day in X_test[X_test['ID_TARGET'] == target]['ID_DAY'].unique():\n",
        "        day_idx = (X_test['ID_TARGET'] == target) & (X_test['ID_DAY'] == day)\n",
        "        day_test_ids = X_test[day_idx].index\n",
        "        if len(day_test_ids) == 0:\n",
        "            print(f\"Warning: No test samples for ID_TARGET {target} on ID_DAY {day}. Using default prediction.\")\n",
        "            missing_day_targets.append((target, day))\n",
        "            for idx in test_ids:\n",
        "                final_predictions[idx] = -1\n",
        "            continue\n",
        "        lgbm_preds = np.array([predictions[target_str].get('LightGBM', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        xgb_preds = np.array([predictions[target_str].get('XGBoost', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        ensemble_preds = ensemble_weights['LightGBM'] * lgbm_preds + ensemble_weights['XGBoost'] * xgb_preds\n",
        "        # Apply exponential moving average for smoothing\n",
        "        smoothed_preds = pd.Series(ensemble_preds).ewm(span=3).mean().values[-1] if len(ensemble_preds) > 0 else 0.5\n",
        "        for idx in day_test_ids:\n",
        "            final_predictions[idx] = 1 if smoothed_preds >= 0.5 else -1\n",
        "\n",
        "if missing_day_targets:\n",
        "    print(f\"Missing day-target pairs: {missing_day_targets}\")\n",
        "\n",
        "# Create output CSV\n",
        "output_df = pd.DataFrame.from_dict(final_predictions, orient='index', columns=['RET_TARGET']).reset_index()\n",
        "output_df.columns = ['ID', 'RET_TARGET']\n",
        "output_df = output_df.sort_values('ID')\n",
        "expected_ids = set(X_test.index)\n",
        "submission_ids = set(output_df['ID'])\n",
        "if expected_ids != submission_ids:\n",
        "    missing_ids = expected_ids - submission_ids\n",
        "    print(f\"Warning: Submission missing {len(missing_ids)} IDs: {missing_ids}\")\n",
        "    missing_df = pd.DataFrame({'ID': list(missing_ids), 'RET_TARGET': -1})\n",
        "    output_df = pd.concat([output_df, missing_df], ignore_index=True).sort_values('ID')\n",
        "output_path = os.path.join(DATA_DIR, 'predictions_ensemble.csv')\n",
        "output_df.to_csv(output_path, index=False)\n",
        "print(f\"Saved predictions to: {output_path}\", flush=True)\n",
        "\n",
        "# Validate output\n",
        "test_csv = pd.read_csv(output_path)\n",
        "print(f\"Output CSV shape: {test_csv.shape}\", flush=True)\n",
        "print(f\"Output CSV ID range: {test_csv['ID'].min()} to {test_csv['ID'].max()}\", flush=True)\n",
        "print(f\"Unique RET_TARGET values: {test_csv['RET_TARGET'].unique()}\", flush=True)\n",
        "print(f\"Missing values: {test_csv.isna().sum().sum()}\", flush=True)\n",
        "\n",
        "# Download the file\n",
        "files.download(output_path)\n",
        "\n",
        "# Print final results\n",
        "print(\"\\nValidation Results:\", flush=True)\n",
        "for model_name, acc in results.items():\n",
        "    print(f\"{model_name}: {acc:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc0U9NlOb43A"
      },
      "source": [
        "new method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FOHs5Pa7b54b",
        "outputId": "51edbabc-a61a-4a30-ab0c-8078cddf4fe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost version: 2.1.4\n",
            "Selected top return columns: ['RET_262', 'RET_88', 'RET_172', 'RET_259', 'RET_150', 'RET_118', 'RET_216', 'RET_268', 'RET_115', 'RET_261', 'RET_59', 'RET_238', 'RET_121', 'RET_97', 'RET_30']\n",
            "\n",
            "Training LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LightGBM Targets: 100%|| 100/100 [13:03<00:00,  7.83s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightGBM Weighted Accuracy: 0.7317\n",
            "\n",
            "LightGBM Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.8608 | Fold Accuracies: [np.float64(0.7106382978723405), np.float64(0.8125), np.float64(0.7051792828685259), np.float64(0.8178294573643411), np.float64(0.7791164658634538)]\n",
            "ID_TARGET: 129.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6497 | Fold Accuracies: [np.float64(0.6122448979591837), np.float64(0.6260162601626016), np.float64(0.6628787878787878), np.float64(0.5738396624472574), np.float64(0.7054545454545454)]\n",
            "ID_TARGET: 136.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6136 | Fold Accuracies: [np.float64(0.61003861003861), np.float64(0.6098484848484849), np.float64(0.6), np.float64(0.59375), np.float64(0.6194331983805668)]\n",
            "ID_TARGET: 161.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6980 | Fold Accuracies: [np.float64(0.6935483870967742), np.float64(0.6628787878787878), np.float64(0.6793893129770993), np.float64(0.7335907335907336), np.float64(0.6743295019157088)]\n",
            "ID_TARGET: 217.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6888 | Fold Accuracies: [np.float64(0.6640926640926641), np.float64(0.7186311787072244), np.float64(0.6782006920415224), np.float64(0.6703296703296703), np.float64(0.6808510638297872)]\n",
            "ID_TARGET: 91.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7054 | Fold Accuracies: [np.float64(0.683206106870229), np.float64(0.7032520325203252), np.float64(0.6920152091254753), np.float64(0.6900826446280992), np.float64(0.7265917602996255)]\n",
            "ID_TARGET: 137.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6517 | Fold Accuracies: [np.float64(0.5991735537190083), np.float64(0.6331877729257642), np.float64(0.6410256410256411), np.float64(0.6953125), np.float64(0.6)]\n",
            "ID_TARGET: 8.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7232 | Fold Accuracies: [np.float64(0.688715953307393), np.float64(0.6987951807228916), np.float64(0.6932270916334662), np.float64(0.736), np.float64(0.7992125984251969)]\n",
            "ID_TARGET: 3.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7121 | Fold Accuracies: [np.float64(0.6666666666666666), np.float64(0.6598360655737705), np.float64(0.6812749003984063), np.float64(0.7076271186440678), np.float64(0.6681222707423581)]\n",
            "ID_TARGET: 9.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6840 | Fold Accuracies: [np.float64(0.6425531914893617), np.float64(0.708), np.float64(0.6461538461538462), np.float64(0.6818181818181818), np.float64(0.6744186046511628)]\n",
            "ID_TARGET: 131.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6558 | Fold Accuracies: [np.float64(0.6929133858267716), np.float64(0.676923076923077), np.float64(0.6612903225806451), np.float64(0.5991561181434599), np.float64(0.6192307692307693)]\n",
            "ID_TARGET: 21.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6740 | Fold Accuracies: [np.float64(0.7394366197183099), np.float64(0.6679389312977099), np.float64(0.6556776556776557), np.float64(0.62109375), np.float64(0.6809338521400778)]\n",
            "ID_TARGET: 54.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7717 | Fold Accuracies: [np.float64(0.7751937984496124), np.float64(0.7265917602996255), np.float64(0.8149779735682819), np.float64(0.6366906474820144), np.float64(0.7215686274509804)]\n",
            "ID_TARGET: 130.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7269 | Fold Accuracies: [np.float64(0.7142857142857143), np.float64(0.7047970479704797), np.float64(0.6917562724014337), np.float64(0.6653992395437263), np.float64(0.6642335766423357)]\n",
            "ID_TARGET: 269.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6805 | Fold Accuracies: [np.float64(0.676), np.float64(0.6593886462882096), np.float64(0.7165991902834008), np.float64(0.6), np.float64(0.6883116883116883)]\n",
            "ID_TARGET: 157.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7841 | Fold Accuracies: [np.float64(0.7434782608695653), np.float64(0.7941176470588235), np.float64(0.7620967741935484), np.float64(0.744), np.float64(0.7745901639344263)]\n",
            "ID_TARGET: 249.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7195 | Fold Accuracies: [np.float64(0.7054263565891473), np.float64(0.6958174904942965), np.float64(0.7777777777777778), np.float64(0.6979591836734694), np.float64(0.6717557251908397)]\n",
            "ID_TARGET: 22.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6721 | Fold Accuracies: [np.float64(0.6557971014492754), np.float64(0.6127819548872181), np.float64(0.6889763779527559), np.float64(0.6666666666666666), np.float64(0.6770428015564203)]\n",
            "ID_TARGET: 202.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6561 | Fold Accuracies: [np.float64(0.6274509803921569), np.float64(0.6753731343283582), np.float64(0.632183908045977), np.float64(0.6823104693140795), np.float64(0.6515151515151515)]\n",
            "ID_TARGET: 132.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7393 | Fold Accuracies: [np.float64(0.7370689655172413), np.float64(0.7188755020080321), np.float64(0.7283464566929134), np.float64(0.7261410788381742), np.float64(0.7862903225806451)]\n",
            "ID_TARGET: 96.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7732 | Fold Accuracies: [np.float64(0.6666666666666666), np.float64(0.6995708154506438), np.float64(0.6423076923076924), np.float64(0.730593607305936), np.float64(0.9743589743589743)]\n",
            "ID_TARGET: 7.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7419 | Fold Accuracies: [np.float64(0.68359375), np.float64(0.6872586872586872), np.float64(0.708029197080292), np.float64(0.7114624505928854), np.float64(0.7868217054263565)]\n",
            "ID_TARGET: 178.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7179 | Fold Accuracies: [np.float64(0.7113821138211383), np.float64(0.7072243346007605), np.float64(0.7430830039525692), np.float64(0.6653061224489796), np.float64(0.71875)]\n",
            "ID_TARGET: 68.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7661 | Fold Accuracies: [np.float64(0.7394636015325671), np.float64(0.7530364372469636), np.float64(0.7606837606837606), np.float64(0.7918367346938775), np.float64(0.7581967213114754)]\n",
            "ID_TARGET: 44.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7273 | Fold Accuracies: [np.float64(0.7245283018867924), np.float64(0.7401574803149606), np.float64(0.7122302158273381), np.float64(0.6923076923076923), np.float64(0.737037037037037)]\n",
            "ID_TARGET: 196.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7120 | Fold Accuracies: [np.float64(0.64), np.float64(0.7364864864864865), np.float64(0.6920289855072463), np.float64(0.71484375), np.float64(0.7127659574468085)]\n",
            "ID_TARGET: 292.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7111 | Fold Accuracies: [np.float64(0.631768953068592), np.float64(0.6865079365079365), np.float64(0.6985294117647058), np.float64(0.68359375), np.float64(0.7509578544061303)]\n",
            "ID_TARGET: 239.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7461 | Fold Accuracies: [np.float64(0.7038461538461539), np.float64(0.7217741935483871), np.float64(0.7245762711864406), np.float64(0.7896825396825397), np.float64(0.75)]\n",
            "ID_TARGET: 279.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6891 | Fold Accuracies: [np.float64(0.7132075471698113), np.float64(0.6771653543307087), np.float64(0.6536964980544747), np.float64(0.6708333333333333), np.float64(0.6535433070866141)]\n",
            "ID_TARGET: 38.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7124 | Fold Accuracies: [np.float64(0.648854961832061), np.float64(0.7035573122529645), np.float64(0.6585365853658537), np.float64(0.7011494252873564), np.float64(0.6872246696035242)]\n",
            "ID_TARGET: 209.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7128 | Fold Accuracies: [np.float64(0.7803921568627451), np.float64(0.6976744186046512), np.float64(0.7198443579766537), np.float64(0.6888888888888889), np.float64(0.6770428015564203)]\n",
            "ID_TARGET: 207.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6726 | Fold Accuracies: [np.float64(0.6731517509727627), np.float64(0.6470588235294118), np.float64(0.7228915662650602), np.float64(0.6415094339622641), np.float64(0.6705426356589147)]\n",
            "ID_TARGET: 98.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7185 | Fold Accuracies: [np.float64(0.6563706563706564), np.float64(0.7510204081632653), np.float64(0.7407407407407407), np.float64(0.7458333333333333), np.float64(0.6425855513307985)]\n",
            "ID_TARGET: 65.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7320 | Fold Accuracies: [np.float64(0.7443609022556391), np.float64(0.7272727272727273), np.float64(0.7182539682539683), np.float64(0.7380952380952381), np.float64(0.7264957264957265)]\n",
            "ID_TARGET: 51.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7481 | Fold Accuracies: [np.float64(0.7208333333333333), np.float64(0.7651821862348178), np.float64(0.7629310344827587), np.float64(0.7357723577235772), np.float64(0.7559055118110236)]\n",
            "ID_TARGET: 78.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7140 | Fold Accuracies: [np.float64(0.7238493723849372), np.float64(0.74), np.float64(0.7041666666666667), np.float64(0.6624472573839663), np.float64(0.6719367588932806)]\n",
            "ID_TARGET: 177.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7326 | Fold Accuracies: [np.float64(0.7418181818181818), np.float64(0.7323420074349443), np.float64(0.7340425531914894), np.float64(0.7167832167832168), np.float64(0.7104247104247104)]\n",
            "ID_TARGET: 231.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7754 | Fold Accuracies: [np.float64(0.7604562737642585), np.float64(0.7350746268656716), np.float64(0.752), np.float64(0.7959183673469388), np.float64(0.7756653992395437)]\n",
            "ID_TARGET: 119.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7646 | Fold Accuracies: [np.float64(0.7159533073929961), np.float64(0.7370517928286853), np.float64(0.7751937984496124), np.float64(0.7172995780590717), np.float64(0.7336065573770492)]\n",
            "ID_TARGET: 158.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7931 | Fold Accuracies: [np.float64(0.7925311203319502), np.float64(0.8306451612903226), np.float64(0.7709923664122137), np.float64(0.7944664031620553), np.float64(0.758364312267658)]\n",
            "ID_TARGET: 80.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6957 | Fold Accuracies: [np.float64(0.672), np.float64(0.7075098814229249), np.float64(0.668), np.float64(0.6775510204081633), np.float64(0.7123893805309734)]\n",
            "ID_TARGET: 25.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7205 | Fold Accuracies: [np.float64(0.7195121951219512), np.float64(0.7203389830508474), np.float64(0.6985294117647058), np.float64(0.7089552238805971), np.float64(0.734375)]\n",
            "ID_TARGET: 175.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7303 | Fold Accuracies: [np.float64(0.7265625), np.float64(0.692), np.float64(0.6733870967741935), np.float64(0.7689243027888446), np.float64(0.7237354085603113)]\n",
            "ID_TARGET: 151.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7741 | Fold Accuracies: [np.float64(0.7564575645756457), np.float64(0.7610294117647058), np.float64(0.7692307692307693), np.float64(0.717391304347826), np.float64(0.8140495867768595)]\n",
            "ID_TARGET: 257.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7261 | Fold Accuracies: [np.float64(0.7075098814229249), np.float64(0.7094339622641509), np.float64(0.7153284671532847), np.float64(0.7011070110701108), np.float64(0.7163636363636363)]\n",
            "ID_TARGET: 75.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7685 | Fold Accuracies: [np.float64(0.7868852459016393), np.float64(0.7246963562753036), np.float64(0.753731343283582), np.float64(0.7551724137931034), np.float64(0.7827715355805244)]\n",
            "ID_TARGET: 244.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6933 | Fold Accuracies: [np.float64(0.7116104868913857), np.float64(0.7058823529411765), np.float64(0.6830188679245283), np.float64(0.6857142857142857), np.float64(0.6383763837638377)]\n",
            "ID_TARGET: 149.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7388 | Fold Accuracies: [np.float64(0.6992481203007519), np.float64(0.7176470588235294), np.float64(0.7423076923076923), np.float64(0.7598425196850394), np.float64(0.6929133858267716)]\n",
            "ID_TARGET: 85.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7746 | Fold Accuracies: [np.float64(0.8048780487804879), np.float64(0.7540983606557377), np.float64(0.78), np.float64(0.7436974789915967), np.float64(0.7394636015325671)]\n",
            "ID_TARGET: 190.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7374 | Fold Accuracies: [np.float64(0.7368421052631579), np.float64(0.7191011235955056), np.float64(0.7449392712550608), np.float64(0.7175572519083969), np.float64(0.7545787545787546)]\n",
            "ID_TARGET: 13.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7425 | Fold Accuracies: [np.float64(0.7198443579766537), np.float64(0.7364620938628159), np.float64(0.7047970479704797), np.float64(0.7355371900826446), np.float64(0.7480314960629921)]\n",
            "ID_TARGET: 228.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7028 | Fold Accuracies: [np.float64(0.6992481203007519), np.float64(0.7286821705426356), np.float64(0.7177700348432056), np.float64(0.6585365853658537), np.float64(0.6630434782608695)]\n",
            "ID_TARGET: 144.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7824 | Fold Accuracies: [np.float64(0.7669491525423728), np.float64(0.8235294117647058), np.float64(0.7818181818181819), np.float64(0.6944444444444444), np.float64(0.7245762711864406)]\n",
            "ID_TARGET: 290.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7233 | Fold Accuracies: [np.float64(0.7193675889328063), np.float64(0.6570247933884298), np.float64(0.75), np.float64(0.6788617886178862), np.float64(0.6904761904761905)]\n",
            "ID_TARGET: 114.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.6991 | Fold Accuracies: [np.float64(0.6475095785440613), np.float64(0.7222222222222222), np.float64(0.7424242424242424), np.float64(0.6892430278884463), np.float64(0.6940298507462687)]\n",
            "ID_TARGET: 166.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7514 | Fold Accuracies: [np.float64(0.7642276422764228), np.float64(0.7435897435897436), np.float64(0.7663934426229508), np.float64(0.7340823970037453), np.float64(0.7295081967213115)]\n",
            "ID_TARGET: 234.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7577 | Fold Accuracies: [np.float64(0.7336065573770492), np.float64(0.7701612903225806), np.float64(0.7478991596638656), np.float64(0.7662337662337663), np.float64(0.7198443579766537)]\n",
            "ID_TARGET: 34.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7571 | Fold Accuracies: [np.float64(0.7153558052434457), np.float64(0.7404580152671756), np.float64(0.764), np.float64(0.7479674796747967), np.float64(0.7471264367816092)]\n",
            "ID_TARGET: 154.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7518 | Fold Accuracies: [np.float64(0.7716535433070866), np.float64(0.7669172932330827), np.float64(0.6931818181818182), np.float64(0.7153558052434457), np.float64(0.7842323651452282)]\n",
            "ID_TARGET: 225.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7120 | Fold Accuracies: [np.float64(0.6725352112676056), np.float64(0.6992481203007519), np.float64(0.6985815602836879), np.float64(0.7054263565891473), np.float64(0.7355072463768116)]\n",
            "ID_TARGET: 185.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.8050 | Fold Accuracies: [np.float64(0.7873303167420814), np.float64(0.7947598253275109), np.float64(0.7359307359307359), np.float64(0.74235807860262), np.float64(0.8220338983050848)]\n",
            "ID_TARGET: 39.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7345 | Fold Accuracies: [np.float64(0.7235772357723578), np.float64(0.7176470588235294), np.float64(0.7431906614785992), np.float64(0.7370517928286853), np.float64(0.7272727272727273)]\n",
            "ID_TARGET: 272.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7499 | Fold Accuracies: [np.float64(0.7238493723849372), np.float64(0.7958333333333333), np.float64(0.7120622568093385), np.float64(0.7816091954022989), np.float64(0.7112676056338029)]\n",
            "ID_TARGET: 282.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7355 | Fold Accuracies: [np.float64(0.703125), np.float64(0.722007722007722), np.float64(0.708), np.float64(0.7595419847328244), np.float64(0.7095435684647303)]\n",
            "ID_TARGET: 90.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7507 | Fold Accuracies: [np.float64(0.75390625), np.float64(0.7586206896551724), np.float64(0.716), np.float64(0.7593360995850622), np.float64(0.75)]\n",
            "ID_TARGET: 52.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7316 | Fold Accuracies: [np.float64(0.7427536231884058), np.float64(0.7130044843049327), np.float64(0.7364016736401674), np.float64(0.7142857142857143), np.float64(0.6951219512195121)]\n",
            "ID_TARGET: 258.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7180 | Fold Accuracies: [np.float64(0.7148936170212766), np.float64(0.6956521739130435), np.float64(0.6996047430830039), np.float64(0.78125), np.float64(0.6627906976744186)]\n",
            "ID_TARGET: 291.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7572 | Fold Accuracies: [np.float64(0.7381974248927039), np.float64(0.7451737451737451), np.float64(0.7289377289377289), np.float64(0.75), np.float64(0.7222222222222222)]\n",
            "ID_TARGET: 152.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7583 | Fold Accuracies: [np.float64(0.7625), np.float64(0.78), np.float64(0.7386363636363636), np.float64(0.75), np.float64(0.7302904564315352)]\n",
            "ID_TARGET: 133.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7626 | Fold Accuracies: [np.float64(0.7955390334572491), np.float64(0.7250996015936255), np.float64(0.758893280632411), np.float64(0.7310606060606061), np.float64(0.7751937984496124)]\n",
            "ID_TARGET: 29.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7138 | Fold Accuracies: [np.float64(0.6414342629482072), np.float64(0.73568281938326), np.float64(0.685823754789272), np.float64(0.7519083969465649), np.float64(0.7164750957854407)]\n",
            "ID_TARGET: 274.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7323 | Fold Accuracies: [np.float64(0.7407407407407407), np.float64(0.762589928057554), np.float64(0.749034749034749), np.float64(0.7168458781362007), np.float64(0.6923076923076923)]\n",
            "ID_TARGET: 106.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7644 | Fold Accuracies: [np.float64(0.7835497835497836), np.float64(0.7285067873303167), np.float64(0.7116279069767442), np.float64(0.7327188940092166), np.float64(0.7833333333333333)]\n",
            "ID_TARGET: 173.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7735 | Fold Accuracies: [np.float64(0.7912087912087912), np.float64(0.74), np.float64(0.7418032786885246), np.float64(0.8148148148148148), np.float64(0.7086614173228346)]\n",
            "ID_TARGET: 33.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7370 | Fold Accuracies: [np.float64(0.7012448132780082), np.float64(0.7181467181467182), np.float64(0.7019607843137254), np.float64(0.7159533073929961), np.float64(0.7323420074349443)]\n",
            "ID_TARGET: 69.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7133 | Fold Accuracies: [np.float64(0.717391304347826), np.float64(0.7215189873417721), np.float64(0.6846153846153846), np.float64(0.7132075471698113), np.float64(0.7207207207207207)]\n",
            "ID_TARGET: 17.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6963 | Fold Accuracies: [np.float64(0.6937984496124031), np.float64(0.7142857142857143), np.float64(0.6953125), np.float64(0.6640625), np.float64(0.6640926640926641)]\n",
            "ID_TARGET: 189.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7337 | Fold Accuracies: [np.float64(0.7312252964426877), np.float64(0.6911196911196911), np.float64(0.6652892561983471), np.float64(0.7707509881422925), np.float64(0.7375)]\n",
            "ID_TARGET: 284.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7316 | Fold Accuracies: [np.float64(0.7054545454545454), np.float64(0.7104247104247104), np.float64(0.7581967213114754), np.float64(0.6988847583643123), np.float64(0.725)]\n",
            "ID_TARGET: 218.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6933 | Fold Accuracies: [np.float64(0.6768060836501901), np.float64(0.6745098039215687), np.float64(0.662962962962963), np.float64(0.7327935222672065), np.float64(0.697841726618705)]\n",
            "ID_TARGET: 183.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7618 | Fold Accuracies: [np.float64(0.7644927536231884), np.float64(0.7768595041322314), np.float64(0.7520661157024794), np.float64(0.7251908396946565), np.float64(0.7727272727272727)]\n",
            "ID_TARGET: 206.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7560 | Fold Accuracies: [np.float64(0.701195219123506), np.float64(0.7624521072796935), np.float64(0.7707509881422925), np.float64(0.7553648068669528), np.float64(0.7900763358778626)]\n",
            "ID_TARGET: 93.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7322 | Fold Accuracies: [np.float64(0.7782426778242678), np.float64(0.7490774907749077), np.float64(0.6794871794871795), np.float64(0.7453183520599251), np.float64(0.7088122605363985)]\n",
            "ID_TARGET: 16.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7219 | Fold Accuracies: [np.float64(0.7089552238805971), np.float64(0.6895161290322581), np.float64(0.6816479400749064), np.float64(0.7142857142857143), np.float64(0.7310924369747899)]\n",
            "ID_TARGET: 246.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7547 | Fold Accuracies: [np.float64(0.7164750957854407), np.float64(0.7424242424242424), np.float64(0.752851711026616), np.float64(0.7773584905660378), np.float64(0.7843137254901961)]\n",
            "ID_TARGET: 167.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7469 | Fold Accuracies: [np.float64(0.7370517928286853), np.float64(0.7451737451737451), np.float64(0.7161016949152542), np.float64(0.680327868852459), np.float64(0.7827868852459017)]\n",
            "ID_TARGET: 1.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7433 | Fold Accuracies: [np.float64(0.7456140350877193), np.float64(0.7564102564102564), np.float64(0.7206477732793523), np.float64(0.7182539682539683), np.float64(0.7717842323651453)]\n",
            "ID_TARGET: 289.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7288 | Fold Accuracies: [np.float64(0.7222222222222222), np.float64(0.7350746268656716), np.float64(0.73046875), np.float64(0.7238805970149254), np.float64(0.7255639097744361)]\n",
            "ID_TARGET: 141.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7910 | Fold Accuracies: [np.float64(0.75), np.float64(0.7705627705627706), np.float64(0.789272030651341), np.float64(0.7862595419847328), np.float64(0.7317073170731707)]\n",
            "ID_TARGET: 109.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6974 | Fold Accuracies: [np.float64(0.69), np.float64(0.708502024291498), np.float64(0.6666666666666666), np.float64(0.6719367588932806), np.float64(0.7122302158273381)]\n",
            "ID_TARGET: 19.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7489 | Fold Accuracies: [np.float64(0.7575757575757576), np.float64(0.7377049180327869), np.float64(0.69921875), np.float64(0.7849056603773585), np.float64(0.7366412213740458)]\n",
            "ID_TARGET: 28.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6925 | Fold Accuracies: [np.float64(0.7196969696969697), np.float64(0.6234309623430963), np.float64(0.6772908366533864), np.float64(0.7564575645756457), np.float64(0.6779661016949152)]\n",
            "ID_TARGET: 251.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7225 | Fold Accuracies: [np.float64(0.6693548387096774), np.float64(0.7089552238805971), np.float64(0.7074074074074074), np.float64(0.7804878048780488), np.float64(0.7083333333333334)]\n",
            "ID_TARGET: 278.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7703 | Fold Accuracies: [np.float64(0.7222222222222222), np.float64(0.7704280155642024), np.float64(0.7551867219917012), np.float64(0.8398268398268398), np.float64(0.7510729613733905)]\n",
            "ID_TARGET: 76.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7338 | Fold Accuracies: [np.float64(0.7374517374517374), np.float64(0.7052238805970149), np.float64(0.7159533073929961), np.float64(0.7050359712230215), np.float64(0.758893280632411)]\n",
            "ID_TARGET: 241.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7432 | Fold Accuracies: [np.float64(0.7729083665338645), np.float64(0.7207207207207207), np.float64(0.7280334728033473), np.float64(0.7736625514403292), np.float64(0.7208333333333333)]\n",
            "ID_TARGET: 214.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7737 | Fold Accuracies: [np.float64(0.7509433962264151), np.float64(0.7137254901960784), np.float64(0.8267716535433071), np.float64(0.8111111111111111), np.float64(0.7635658914728682)]\n",
            "ID_TARGET: 102.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7810 | Fold Accuracies: [np.float64(0.7595419847328244), np.float64(0.7086956521739131), np.float64(0.78099173553719), np.float64(0.7974137931034483), np.float64(0.7538461538461538)]\n",
            "ID_TARGET: 145.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7201 | Fold Accuracies: [np.float64(0.722007722007722), np.float64(0.6703703703703704), np.float64(0.6857142857142857), np.float64(0.7110266159695817), np.float64(0.7160493827160493)]\n",
            "ID_TARGET: 155.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7884 | Fold Accuracies: [np.float64(0.7708333333333334), np.float64(0.8161764705882353), np.float64(0.8024691358024691), np.float64(0.7470817120622568), np.float64(0.7830882352941176)]\n",
            "\n",
            "Training XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "XGBoost Targets: 100%|| 100/100 [20:39<00:00, 12.40s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Weighted Accuracy: 0.7598\n",
            "\n",
            "XGBoost Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6562 | Fold Accuracies: [np.float64(0.7361702127659574), np.float64(0.60546875), np.float64(0.6812749003984063), np.float64(0.6317829457364341), np.float64(0.6265060240963856)]\n",
            "ID_TARGET: 129.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.6040 | Fold Accuracies: [np.float64(0.6122448979591837), np.float64(0.6300813008130082), np.float64(0.5795454545454546), np.float64(0.5822784810126582), np.float64(0.5636363636363636)]\n",
            "ID_TARGET: 136.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.5962 | Fold Accuracies: [np.float64(0.640926640926641), np.float64(0.553030303030303), np.float64(0.5745454545454546), np.float64(0.59765625), np.float64(0.5546558704453441)]\n",
            "ID_TARGET: 161.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.6680 | Fold Accuracies: [np.float64(0.5846774193548387), np.float64(0.678030303030303), np.float64(0.6183206106870229), np.float64(0.6640926640926641), np.float64(0.6781609195402298)]\n",
            "ID_TARGET: 217.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 91.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7994 | Fold Accuracies: [np.float64(0.8244274809160306), np.float64(0.8089430894308943), np.float64(0.7186311787072244), np.float64(0.8099173553719008), np.float64(0.8352059925093633)]\n",
            "ID_TARGET: 137.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0)]\n",
            "ID_TARGET: 8.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.5932 | Fold Accuracies: [np.float64(0.5525291828793775), np.float64(0.5502008032128514), np.float64(0.649402390438247), np.float64(0.58), np.float64(0.6338582677165354)]\n",
            "ID_TARGET: 3.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6683 | Fold Accuracies: [np.float64(0.6515151515151515), np.float64(0.6557377049180327), np.float64(0.6932270916334662), np.float64(0.6949152542372882), np.float64(0.6462882096069869)]\n",
            "ID_TARGET: 9.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8892 | Fold Accuracies: [np.float64(1.0), np.float64(0.828), np.float64(0.8), np.float64(1.0), np.float64(0.8178294573643411)]\n",
            "ID_TARGET: 131.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6209 | Fold Accuracies: [np.float64(0.6692913385826772), np.float64(0.6076923076923076), np.float64(0.6290322580645161), np.float64(0.5907172995780591), np.float64(0.6076923076923076)]\n",
            "ID_TARGET: 21.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.6886 | Fold Accuracies: [np.float64(0.721830985915493), np.float64(0.6717557251908397), np.float64(0.6776556776556777), np.float64(0.6640625), np.float64(0.5992217898832685)]\n",
            "ID_TARGET: 54.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7376 | Fold Accuracies: [np.float64(0.7325581395348837), np.float64(0.704119850187266), np.float64(0.7797356828193832), np.float64(0.6510791366906474), np.float64(0.7176470588235294)]\n",
            "ID_TARGET: 130.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6913 | Fold Accuracies: [np.float64(0.7056277056277056), np.float64(0.6715867158671587), np.float64(0.7132616487455197), np.float64(0.6615969581749049), np.float64(0.6021897810218978)]\n",
            "ID_TARGET: 269.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6447 | Fold Accuracies: [np.float64(0.688), np.float64(0.6899563318777293), np.float64(0.6558704453441295), np.float64(0.5574468085106383), np.float64(0.6320346320346321)]\n",
            "ID_TARGET: 157.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7161 | Fold Accuracies: [np.float64(0.6956521739130435), np.float64(0.7478991596638656), np.float64(0.6693548387096774), np.float64(0.66), np.float64(0.680327868852459)]\n",
            "ID_TARGET: 249.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7000 | Fold Accuracies: [np.float64(0.7131782945736435), np.float64(0.688212927756654), np.float64(0.720164609053498), np.float64(0.6448979591836734), np.float64(0.6374045801526718)]\n",
            "ID_TARGET: 22.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.6966 | Fold Accuracies: [np.float64(0.6739130434782609), np.float64(0.6578947368421053), np.float64(0.6968503937007874), np.float64(0.6781609195402298), np.float64(0.7120622568093385)]\n",
            "ID_TARGET: 202.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7026 | Fold Accuracies: [np.float64(0.6588235294117647), np.float64(0.7164179104477612), np.float64(0.6781609195402298), np.float64(0.7075812274368231), np.float64(0.6931818181818182)]\n",
            "ID_TARGET: 132.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7548 | Fold Accuracies: [np.float64(0.7543103448275862), np.float64(0.7309236947791165), np.float64(0.7519685039370079), np.float64(0.7302904564315352), np.float64(0.8064516129032258)]\n",
            "ID_TARGET: 96.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.9831 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(0.9153846153846154), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 7.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7420 | Fold Accuracies: [np.float64(0.70703125), np.float64(0.6988416988416989), np.float64(0.6824817518248175), np.float64(0.7312252964426877), np.float64(0.7945736434108527)]\n",
            "ID_TARGET: 178.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7214 | Fold Accuracies: [np.float64(0.7357723577235772), np.float64(0.7034220532319392), np.float64(0.7628458498023716), np.float64(0.6979591836734694), np.float64(0.70703125)]\n",
            "ID_TARGET: 68.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7421 | Fold Accuracies: [np.float64(0.7088122605363985), np.float64(0.7408906882591093), np.float64(0.7564102564102564), np.float64(0.7673469387755102), np.float64(0.7049180327868853)]\n",
            "ID_TARGET: 44.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7455 | Fold Accuracies: [np.float64(0.7849056603773585), np.float64(0.7716535433070866), np.float64(0.737410071942446), np.float64(0.7222222222222222), np.float64(0.7111111111111111)]\n",
            "ID_TARGET: 196.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7475 | Fold Accuracies: [np.float64(0.7033333333333334), np.float64(0.7905405405405406), np.float64(0.782608695652174), np.float64(0.69140625), np.float64(0.7695035460992907)]\n",
            "ID_TARGET: 292.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7045 | Fold Accuracies: [np.float64(0.6714801444043321), np.float64(0.6984126984126984), np.float64(0.6691176470588235), np.float64(0.671875), np.float64(0.7126436781609196)]\n",
            "ID_TARGET: 239.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7409 | Fold Accuracies: [np.float64(0.6730769230769231), np.float64(0.7016129032258065), np.float64(0.7330508474576272), np.float64(0.753968253968254), np.float64(0.7410714285714286)]\n",
            "ID_TARGET: 279.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6837 | Fold Accuracies: [np.float64(0.6037735849056604), np.float64(0.7401574803149606), np.float64(0.6848249027237354), np.float64(0.7166666666666667), np.float64(0.6732283464566929)]\n",
            "ID_TARGET: 38.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7365 | Fold Accuracies: [np.float64(0.6908396946564885), np.float64(0.7154150197628458), np.float64(0.7682926829268293), np.float64(0.7279693486590039), np.float64(0.7797356828193832)]\n",
            "ID_TARGET: 209.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 207.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6833 | Fold Accuracies: [np.float64(0.6848249027237354), np.float64(0.6705882352941176), np.float64(0.7269076305220884), np.float64(0.6754716981132075), np.float64(0.6589147286821705)]\n",
            "ID_TARGET: 98.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7351 | Fold Accuracies: [np.float64(0.694980694980695), np.float64(0.7836734693877551), np.float64(0.7860082304526749), np.float64(0.7833333333333333), np.float64(0.6273764258555133)]\n",
            "ID_TARGET: 65.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8331 | Fold Accuracies: [np.float64(0.8007518796992481), np.float64(0.7772727272727272), np.float64(1.0), np.float64(0.8095238095238095), np.float64(0.7777777777777778)]\n",
            "ID_TARGET: 51.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7310 | Fold Accuracies: [np.float64(0.7333333333333333), np.float64(0.7125506072874493), np.float64(0.7241379310344828), np.float64(0.7235772357723578), np.float64(0.7047244094488189)]\n",
            "ID_TARGET: 78.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7293 | Fold Accuracies: [np.float64(0.7280334728033473), np.float64(0.78), np.float64(0.6958333333333333), np.float64(0.6877637130801688), np.float64(0.7549407114624506)]\n",
            "ID_TARGET: 177.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7503 | Fold Accuracies: [np.float64(0.7454545454545455), np.float64(0.7657992565055762), np.float64(0.723404255319149), np.float64(0.7587412587412588), np.float64(0.7258687258687259)]\n",
            "ID_TARGET: 231.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 119.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7622 | Fold Accuracies: [np.float64(0.7159533073929961), np.float64(0.7370517928286853), np.float64(0.8333333333333334), np.float64(0.7172995780590717), np.float64(0.7581967213114754)]\n",
            "ID_TARGET: 158.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7906 | Fold Accuracies: [np.float64(0.7717842323651453), np.float64(0.8266129032258065), np.float64(0.7709923664122137), np.float64(0.7984189723320159), np.float64(0.7434944237918215)]\n",
            "ID_TARGET: 80.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7180 | Fold Accuracies: [np.float64(0.684), np.float64(0.7193675889328063), np.float64(0.668), np.float64(0.7020408163265306), np.float64(0.7522123893805309)]\n",
            "ID_TARGET: 25.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7293 | Fold Accuracies: [np.float64(0.7357723577235772), np.float64(0.7457627118644068), np.float64(0.7205882352941176), np.float64(0.7649253731343284), np.float64(0.6796875)]\n",
            "ID_TARGET: 175.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 151.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7720 | Fold Accuracies: [np.float64(0.7675276752767528), np.float64(0.7610294117647058), np.float64(0.7649572649572649), np.float64(0.7434782608695653), np.float64(0.7933884297520661)]\n",
            "ID_TARGET: 257.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7362 | Fold Accuracies: [np.float64(0.7154150197628458), np.float64(0.7094339622641509), np.float64(0.7408759124087592), np.float64(0.7084870848708487), np.float64(0.7090909090909091)]\n",
            "ID_TARGET: 75.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7833 | Fold Accuracies: [np.float64(0.8073770491803278), np.float64(0.757085020242915), np.float64(0.7873134328358209), np.float64(0.7586206896551724), np.float64(0.8014981273408239)]\n",
            "ID_TARGET: 244.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.6790 | Fold Accuracies: [np.float64(0.7078651685393258), np.float64(0.6588235294117647), np.float64(0.660377358490566), np.float64(0.6612244897959184), np.float64(0.6162361623616236)]\n",
            "ID_TARGET: 149.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7233 | Fold Accuracies: [np.float64(0.6428571428571429), np.float64(0.7254901960784313), np.float64(0.7346153846153847), np.float64(0.7125984251968503), np.float64(0.7086614173228346)]\n",
            "ID_TARGET: 85.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8095 | Fold Accuracies: [np.float64(0.8577235772357723), np.float64(0.8319672131147541), np.float64(0.832), np.float64(0.8361344537815126), np.float64(0.6896551724137931)]\n",
            "ID_TARGET: 190.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7473 | Fold Accuracies: [np.float64(0.7518796992481203), np.float64(0.7228464419475655), np.float64(0.7611336032388664), np.float64(0.7137404580152672), np.float64(0.7692307692307693)]\n",
            "ID_TARGET: 13.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 228.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7592 | Fold Accuracies: [np.float64(0.793233082706767), np.float64(0.7441860465116279), np.float64(0.7212543554006968), np.float64(0.8414634146341463), np.float64(0.6956521739130435)]\n",
            "ID_TARGET: 144.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7613 | Fold Accuracies: [np.float64(0.75), np.float64(0.8235294117647058), np.float64(0.7709090909090909), np.float64(0.6825396825396826), np.float64(0.7203389830508474)]\n",
            "ID_TARGET: 290.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 114.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7247 | Fold Accuracies: [np.float64(0.6666666666666666), np.float64(0.7420634920634921), np.float64(0.7159090909090909), np.float64(0.7290836653386454), np.float64(0.7089552238805971)]\n",
            "ID_TARGET: 166.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7592 | Fold Accuracies: [np.float64(0.7520325203252033), np.float64(0.7435897435897436), np.float64(0.7459016393442623), np.float64(0.7265917602996255), np.float64(0.6967213114754098)]\n",
            "ID_TARGET: 234.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7621 | Fold Accuracies: [np.float64(0.7459016393442623), np.float64(0.7943548387096774), np.float64(0.7563025210084033), np.float64(0.8095238095238095), np.float64(0.7042801556420234)]\n",
            "ID_TARGET: 34.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7780 | Fold Accuracies: [np.float64(0.7453183520599251), np.float64(0.8053435114503816), np.float64(0.796), np.float64(0.7845528455284553), np.float64(0.7586206896551724)]\n",
            "ID_TARGET: 154.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7687 | Fold Accuracies: [np.float64(0.7637795275590551), np.float64(0.7857142857142857), np.float64(0.696969696969697), np.float64(0.7191011235955056), np.float64(0.8049792531120332)]\n",
            "ID_TARGET: 225.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7319 | Fold Accuracies: [np.float64(0.6971830985915493), np.float64(0.7293233082706767), np.float64(0.7375886524822695), np.float64(0.7286821705426356), np.float64(0.7391304347826086)]\n",
            "ID_TARGET: 185.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7355 | Fold Accuracies: [np.float64(0.7013574660633484), np.float64(0.7117903930131004), np.float64(0.683982683982684), np.float64(0.7117903930131004), np.float64(0.7203389830508474)]\n",
            "ID_TARGET: 39.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 272.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8132 | Fold Accuracies: [np.float64(0.7907949790794979), np.float64(0.8791666666666667), np.float64(0.7198443579766537), np.float64(0.8275862068965517), np.float64(0.8485915492957746)]\n",
            "ID_TARGET: 282.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7404 | Fold Accuracies: [np.float64(0.69921875), np.float64(0.7451737451737451), np.float64(0.724), np.float64(0.7480916030534351), np.float64(0.7427385892116183)]\n",
            "ID_TARGET: 90.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7739 | Fold Accuracies: [np.float64(0.75), np.float64(0.7739463601532567), np.float64(0.736), np.float64(0.7842323651452282), np.float64(0.7976190476190477)]\n",
            "ID_TARGET: 52.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7377 | Fold Accuracies: [np.float64(0.644927536231884), np.float64(0.7354260089686099), np.float64(0.6903765690376569), np.float64(0.7103174603174603), np.float64(0.7195121951219512)]\n",
            "ID_TARGET: 258.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7223 | Fold Accuracies: [np.float64(0.6936170212765957), np.float64(0.7478260869565218), np.float64(0.7075098814229249), np.float64(0.75390625), np.float64(0.6550387596899225)]\n",
            "ID_TARGET: 291.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7604 | Fold Accuracies: [np.float64(0.759656652360515), np.float64(0.7683397683397684), np.float64(0.7362637362637363), np.float64(0.7720588235294118), np.float64(0.7658730158730159)]\n",
            "ID_TARGET: 152.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7529 | Fold Accuracies: [np.float64(0.6875), np.float64(0.768), np.float64(0.7045454545454546), np.float64(0.6920289855072463), np.float64(0.7510373443983402)]\n",
            "ID_TARGET: 133.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7707 | Fold Accuracies: [np.float64(0.7732342007434945), np.float64(0.7689243027888446), np.float64(0.7509881422924901), np.float64(0.7083333333333334), np.float64(0.7635658914728682)]\n",
            "ID_TARGET: 29.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7071 | Fold Accuracies: [np.float64(0.6573705179282868), np.float64(0.7533039647577092), np.float64(0.6743295019157088), np.float64(0.7251908396946565), np.float64(0.6934865900383141)]\n",
            "ID_TARGET: 274.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7477 | Fold Accuracies: [np.float64(0.737037037037037), np.float64(0.7661870503597122), np.float64(0.752895752895753), np.float64(0.7240143369175627), np.float64(0.7032967032967034)]\n",
            "ID_TARGET: 106.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.9706 | Fold Accuracies: [np.float64(0.8528138528138528), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 173.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7665 | Fold Accuracies: [np.float64(0.7912087912087912), np.float64(0.724), np.float64(0.7418032786885246), np.float64(0.7814814814814814), np.float64(0.7047244094488189)]\n",
            "ID_TARGET: 33.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7356 | Fold Accuracies: [np.float64(0.7676348547717843), np.float64(0.7142857142857143), np.float64(0.6980392156862745), np.float64(0.7470817120622568), np.float64(0.7509293680297398)]\n",
            "ID_TARGET: 69.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7392 | Fold Accuracies: [np.float64(0.7521739130434782), np.float64(0.7341772151898734), np.float64(0.6846153846153846), np.float64(0.7433962264150943), np.float64(0.7522522522522522)]\n",
            "ID_TARGET: 17.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.6948 | Fold Accuracies: [np.float64(0.7170542635658915), np.float64(0.706766917293233), np.float64(0.6953125), np.float64(0.68359375), np.float64(0.6602316602316602)]\n",
            "ID_TARGET: 189.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7239 | Fold Accuracies: [np.float64(0.7154150197628458), np.float64(0.6833976833976834), np.float64(0.78099173553719), np.float64(0.7312252964426877), np.float64(0.7083333333333334)]\n",
            "ID_TARGET: 284.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7286 | Fold Accuracies: [np.float64(0.6690909090909091), np.float64(0.7065637065637066), np.float64(0.7540983606557377), np.float64(0.7174721189591078), np.float64(0.7375)]\n",
            "ID_TARGET: 218.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7094 | Fold Accuracies: [np.float64(0.6844106463878327), np.float64(0.7058823529411765), np.float64(0.6703703703703704), np.float64(0.8016194331983806), np.float64(0.6834532374100719)]\n",
            "ID_TARGET: 183.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7479 | Fold Accuracies: [np.float64(0.717391304347826), np.float64(0.7768595041322314), np.float64(0.743801652892562), np.float64(0.6946564885496184), np.float64(0.8068181818181818)]\n",
            "ID_TARGET: 206.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7616 | Fold Accuracies: [np.float64(0.7051792828685259), np.float64(0.7318007662835249), np.float64(0.7905138339920948), np.float64(0.7510729613733905), np.float64(0.7633587786259542)]\n",
            "ID_TARGET: 93.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7072 | Fold Accuracies: [np.float64(0.6736401673640168), np.float64(0.6383763837638377), np.float64(0.7222222222222222), np.float64(0.6928838951310862), np.float64(0.7011494252873564)]\n",
            "ID_TARGET: 16.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7053 | Fold Accuracies: [np.float64(0.6977611940298507), np.float64(0.6814516129032258), np.float64(0.6891385767790262), np.float64(0.7368421052631579), np.float64(0.6974789915966386)]\n",
            "ID_TARGET: 246.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7461 | Fold Accuracies: [np.float64(0.6666666666666666), np.float64(0.7159090909090909), np.float64(0.7110266159695817), np.float64(0.7094339622641509), np.float64(0.7137254901960784)]\n",
            "ID_TARGET: 167.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.9602 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(0.8008474576271186), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 1.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7396 | Fold Accuracies: [np.float64(0.7631578947368421), np.float64(0.7478632478632479), np.float64(0.7206477732793523), np.float64(0.6984126984126984), np.float64(0.7261410788381742)]\n",
            "ID_TARGET: 289.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7542 | Fold Accuracies: [np.float64(0.7649572649572649), np.float64(0.7835820895522388), np.float64(0.7734375), np.float64(0.753731343283582), np.float64(0.6954887218045113)]\n",
            "ID_TARGET: 141.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7902 | Fold Accuracies: [np.float64(0.7916666666666666), np.float64(0.8051948051948052), np.float64(0.789272030651341), np.float64(0.8129770992366412), np.float64(0.7520325203252033)]\n",
            "ID_TARGET: 109.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7282 | Fold Accuracies: [np.float64(0.7166666666666667), np.float64(0.7530364372469636), np.float64(0.7037037037037037), np.float64(0.6679841897233202), np.float64(0.7446043165467626)]\n",
            "ID_TARGET: 19.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7713 | Fold Accuracies: [np.float64(0.7727272727272727), np.float64(0.7745901639344263), np.float64(0.73828125), np.float64(0.8037735849056604), np.float64(0.767175572519084)]\n",
            "ID_TARGET: 28.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7071 | Fold Accuracies: [np.float64(0.7007575757575758), np.float64(0.6736401673640168), np.float64(0.7051792828685259), np.float64(0.7195571955719557), np.float64(0.6949152542372882)]\n",
            "ID_TARGET: 251.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7170 | Fold Accuracies: [np.float64(0.6935483870967742), np.float64(0.6902985074626866), np.float64(0.7037037037037037), np.float64(0.7398373983739838), np.float64(0.7125)]\n",
            "ID_TARGET: 278.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7458 | Fold Accuracies: [np.float64(0.6428571428571429), np.float64(0.7470817120622568), np.float64(0.7510373443983402), np.float64(0.8138528138528138), np.float64(0.7553648068669528)]\n",
            "ID_TARGET: 76.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7514 | Fold Accuracies: [np.float64(0.7374517374517374), np.float64(0.7425373134328358), np.float64(0.7665369649805448), np.float64(0.737410071942446), np.float64(0.7470355731225297)]\n",
            "ID_TARGET: 241.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7478 | Fold Accuracies: [np.float64(0.7171314741035857), np.float64(0.7252252252252253), np.float64(0.6610878661087866), np.float64(0.7818930041152263), np.float64(0.7083333333333334)]\n",
            "ID_TARGET: 214.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7823 | Fold Accuracies: [np.float64(0.7320754716981132), np.float64(0.6745098039215687), np.float64(0.7834645669291339), np.float64(0.7888888888888889), np.float64(0.7209302325581395)]\n",
            "ID_TARGET: 102.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7680 | Fold Accuracies: [np.float64(0.7862595419847328), np.float64(0.7347826086956522), np.float64(0.7644628099173554), np.float64(0.8275862068965517), np.float64(0.7269230769230769)]\n",
            "ID_TARGET: 145.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6899 | Fold Accuracies: [np.float64(0.6602316602316602), np.float64(0.6370370370370371), np.float64(0.689795918367347), np.float64(0.6577946768060836), np.float64(0.7037037037037037)]\n",
            "ID_TARGET: 155.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7936 | Fold Accuracies: [np.float64(0.7638888888888888), np.float64(0.8345588235294118), np.float64(0.7818930041152263), np.float64(0.7626459143968871), np.float64(0.7830882352941176)]\n",
            "\n",
            "Performing second-pass training with top 30 features...\n",
            "\n",
            "Second-pass LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rLightGBM Targets:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   1%|          | 1/100 [00:01<02:25,  1.47s/it]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   2%|         | 2/100 [00:02<01:51,  1.14s/it]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   3%|         | 3/100 [00:03<01:45,  1.09s/it]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   4%|         | 4/100 [00:04<01:29,  1.08it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   5%|         | 5/100 [00:04<01:15,  1.26it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   6%|         | 6/100 [00:05<01:06,  1.42it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   7%|         | 7/100 [00:05<00:59,  1.56it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   8%|         | 8/100 [00:06<01:02,  1.48it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   9%|         | 9/100 [00:07<00:58,  1.55it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  10%|         | 10/100 [00:07<00:54,  1.65it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  11%|         | 11/100 [00:08<01:01,  1.45it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  12%|        | 12/100 [00:09<01:00,  1.46it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  13%|        | 13/100 [00:09<00:58,  1.50it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  14%|        | 14/100 [00:10<00:57,  1.50it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  15%|        | 15/100 [00:11<00:57,  1.47it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  16%|        | 16/100 [00:11<00:55,  1.50it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  17%|        | 17/100 [00:12<00:55,  1.51it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  18%|        | 18/100 [00:12<00:51,  1.58it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  19%|        | 19/100 [00:13<00:55,  1.46it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  20%|        | 20/100 [00:14<00:56,  1.41it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  21%|        | 21/100 [00:15<00:58,  1.34it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  22%|       | 22/100 [00:16<01:02,  1.26it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  23%|       | 23/100 [00:17<01:00,  1.28it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  24%|       | 24/100 [00:17<00:56,  1.34it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  25%|       | 25/100 [00:18<00:52,  1.44it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  26%|       | 26/100 [00:18<00:49,  1.49it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  27%|       | 27/100 [00:19<00:47,  1.54it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  28%|       | 28/100 [00:20<00:44,  1.60it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  29%|       | 29/100 [00:20<00:44,  1.60it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  30%|       | 30/100 [00:21<00:43,  1.62it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  31%|       | 31/100 [00:21<00:40,  1.72it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  32%|      | 32/100 [00:22<00:39,  1.71it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  33%|      | 33/100 [00:22<00:38,  1.75it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  34%|      | 34/100 [00:23<00:36,  1.79it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  35%|      | 35/100 [00:23<00:36,  1.79it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  36%|      | 36/100 [00:24<00:35,  1.79it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  37%|      | 37/100 [00:25<00:36,  1.74it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  38%|      | 38/100 [00:25<00:33,  1.82it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  39%|      | 39/100 [00:26<00:33,  1.84it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  40%|      | 40/100 [00:26<00:34,  1.75it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  41%|      | 41/100 [00:27<00:41,  1.43it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  42%|     | 42/100 [00:28<00:42,  1.36it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  43%|     | 43/100 [00:29<00:43,  1.31it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  44%|     | 44/100 [00:30<00:43,  1.28it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  45%|     | 45/100 [00:30<00:40,  1.35it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  46%|     | 46/100 [00:31<00:36,  1.47it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  47%|     | 47/100 [00:32<00:35,  1.50it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  48%|     | 48/100 [00:32<00:33,  1.54it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  49%|     | 49/100 [00:33<00:31,  1.62it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  50%|     | 50/100 [00:33<00:30,  1.63it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  51%|     | 51/100 [00:34<00:29,  1.68it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  52%|    | 52/100 [00:34<00:28,  1.68it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  53%|    | 53/100 [00:35<00:27,  1.71it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  54%|    | 54/100 [00:36<00:26,  1.72it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  55%|    | 55/100 [00:36<00:26,  1.70it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  56%|    | 56/100 [00:37<00:25,  1.72it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  57%|    | 57/100 [00:37<00:24,  1.72it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  58%|    | 58/100 [00:38<00:24,  1.72it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  59%|    | 59/100 [00:39<00:24,  1.66it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  60%|    | 60/100 [00:39<00:24,  1.64it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  61%|    | 61/100 [00:40<00:24,  1.62it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  62%|   | 62/100 [00:41<00:25,  1.48it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  63%|   | 63/100 [00:41<00:25,  1.43it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  64%|   | 64/100 [00:42<00:26,  1.35it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  65%|   | 65/100 [00:43<00:28,  1.24it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  66%|   | 66/100 [00:44<00:24,  1.37it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  67%|   | 67/100 [00:44<00:22,  1.46it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  68%|   | 68/100 [00:45<00:20,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  69%|   | 69/100 [00:45<00:19,  1.63it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  70%|   | 70/100 [00:46<00:17,  1.72it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  71%|   | 71/100 [00:47<00:16,  1.72it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  72%|  | 72/100 [00:47<00:16,  1.71it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  73%|  | 73/100 [00:48<00:15,  1.79it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  74%|  | 74/100 [00:48<00:13,  1.86it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  75%|  | 75/100 [00:49<00:13,  1.88it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  76%|  | 76/100 [00:49<00:12,  1.91it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  77%|  | 77/100 [00:50<00:13,  1.75it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  78%|  | 78/100 [00:50<00:12,  1.77it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  79%|  | 79/100 [00:51<00:12,  1.74it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  80%|  | 80/100 [00:52<00:11,  1.71it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  81%|  | 81/100 [00:52<00:10,  1.76it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  82%| | 82/100 [00:53<00:10,  1.76it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  83%| | 83/100 [00:53<00:10,  1.66it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  84%| | 84/100 [00:54<00:10,  1.47it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  85%| | 85/100 [00:55<00:11,  1.35it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  86%| | 86/100 [00:56<00:10,  1.31it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  87%| | 87/100 [00:57<00:10,  1.19it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  88%| | 88/100 [00:58<00:09,  1.29it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  89%| | 89/100 [00:58<00:07,  1.39it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  90%| | 90/100 [00:59<00:06,  1.45it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  91%| | 91/100 [00:59<00:05,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  92%|| 92/100 [01:00<00:05,  1.59it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  93%|| 93/100 [01:00<00:04,  1.65it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  94%|| 94/100 [01:01<00:03,  1.74it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  95%|| 95/100 [01:01<00:02,  1.80it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  96%|| 96/100 [01:02<00:02,  1.82it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  97%|| 97/100 [01:03<00:01,  1.79it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  98%|| 98/100 [01:03<00:01,  1.81it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  99%|| 99/100 [01:04<00:00,  1.76it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets: 100%|| 100/100 [01:04<00:00,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Second-pass XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Targets: 100%|| 100/100 [01:16<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Performing third-pass training for low-performing targets...\n",
            "\n",
            "Third-pass LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "LightGBM Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 47711.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Third-pass XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 115343.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved hyperparameter log to: /content/hyperparameters.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_685a549b-bd2d-4925-96e2-a30cd674a758\", \"hyperparameters.json\", 515130)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved predictions to: /content/predictions_ensemble.csv\n",
            "Output CSV shape: (114468, 2)\n",
            "Output CSV ID range: 0 to 114467\n",
            "Unique RET_TARGET values: [ 1 -1]\n",
            "Missing values: 0\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_4c79e2fd-5a15-4680-846f-7f39eedabb67\", \"predictions_ensemble.csv\", 970099)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Results:\n",
            "LightGBM: 0.7317\n",
            "XGBoost: 0.7598\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost\n",
        "from sklearn.decomposition import PCA\n",
        "from joblib import Parallel, delayed\n",
        "import json\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# Check xgboost version for compatibility\n",
        "print(f\"XGBoost version: {xgboost.__version__}\")\n",
        "if int(xgboost.__version__.split('.')[0]) < 1:\n",
        "    print(\"Warning: XGBoost version < 1.0.0 detected. Ensure compatibility with eval_metric in constructor.\")\n",
        "\n",
        "# Set up data directory\n",
        "DATA_DIR = '/content'\n",
        "\n",
        "# Load datasets\n",
        "try:\n",
        "    X_train = pd.read_csv(os.path.join(DATA_DIR, 'X_train_itDkypA.csv'), index_col='ID', dtype=np.float32)\n",
        "    y_train = pd.read_csv(os.path.join(DATA_DIR, 'y_train_3LeeT2g.csv'), index_col='ID', dtype=np.float32)\n",
        "    X_test = pd.read_csv(os.path.join(DATA_DIR, 'X_test_Beg4ey3.csv'), index_col='ID', dtype=np.float32)\n",
        "    supplementary = pd.read_csv(os.path.join(DATA_DIR, 'supplementary_data_Vkoyn8z.csv'))\n",
        "except FileNotFoundError as e:\n",
        "    raise FileNotFoundError(f\"Dataset not found: {e}. Please ensure files are uploaded to {DATA_DIR}.\")\n",
        "\n",
        "# Custom weighted accuracy metric\n",
        "def weighted_accuracy(y_true, y_pred, weights):\n",
        "    y_pred_mapped = np.where(y_pred == 1, 1, -1)\n",
        "    correct = (y_pred_mapped == np.sign(y_true)).astype(float)\n",
        "    return np.sum(np.abs(y_true) * correct) / np.sum(np.abs(y_true))\n",
        "\n",
        "# Preprocess data with enhanced feature selection, momentum, and volatility\n",
        "def preprocess_data(X, y=None, supplementary=None, is_train=True, top_cols=None):\n",
        "    ret_cols = [col for col in X.columns if col.startswith('RET_')]\n",
        "    if is_train and top_cols is None:\n",
        "        if len(ret_cols) > 15:\n",
        "            variances = X[ret_cols].var()\n",
        "            corr_sum = X[ret_cols].corr().abs().sum()\n",
        "            combined_score = variances * corr_sum\n",
        "            valid_cols = variances[variances > 1e-5].index\n",
        "            if len(valid_cols) < 15:\n",
        "                top_cols = valid_cols.tolist()\n",
        "            else:\n",
        "                top_cols = combined_score.loc[valid_cols].sort_values(ascending=False).head(15).index.tolist()\n",
        "        else:\n",
        "            top_cols = ret_cols\n",
        "        print(f\"Selected top return columns: {top_cols}\")\n",
        "    elif top_cols is not None:\n",
        "        ret_cols = [col for col in ret_cols if col in top_cols]\n",
        "        if not ret_cols:\n",
        "            raise ValueError(\"No return columns selected. Check top_cols consistency.\")\n",
        "\n",
        "    sector_medians = {}\n",
        "    if supplementary is not None:\n",
        "        sector_map = supplementary.set_index('ID_asset')['CLASS_LEVEL_1']\n",
        "        for col in ret_cols:\n",
        "            asset_id = int(col.replace('RET_', ''))\n",
        "            sector = sector_map.get(asset_id, np.nan)\n",
        "            if pd.notna(sector):\n",
        "                sector_assets = supplementary[supplementary['CLASS_LEVEL_1'] == sector]['ID_asset']\n",
        "                sector_cols = [f'RET_{a}' for a in sector_assets if f'RET_{a}' in X.columns]\n",
        "                if sector_cols:\n",
        "                    sector_medians[col] = X[sector_cols].median(axis=1)\n",
        "            if col in sector_medians:\n",
        "                X[col] = X[col].fillna(sector_medians[col])\n",
        "            else:\n",
        "                X[col] = X[col].fillna(X[col].median())\n",
        "\n",
        "    new_cols = {}\n",
        "    if supplementary is not None:\n",
        "        level = 'CLASS_LEVEL_1'\n",
        "        sector_groups = supplementary.groupby(level)['ID_asset'].apply(list).to_dict()\n",
        "        for sector, assets in sector_groups.items():\n",
        "            asset_cols = [f'RET_{asset}' for asset in assets if f'RET_{asset}' in ret_cols]\n",
        "            if asset_cols:\n",
        "                new_cols[f'SECTOR_AVG_{level}_{sector}'] = X[asset_cols].mean(axis=1).replace([np.inf, -np.inf], 0).fillna(0)\n",
        "        X = X.merge(supplementary[['ID_asset', level]].rename(columns={'ID_asset': 'ID_TARGET', level: f'TARGET_{level}'}),\n",
        "                    on='ID_TARGET', how='left')\n",
        "        X = pd.concat([X, pd.get_dummies(X[f'TARGET_{level}'], prefix=f'TARGET_{level}', dummy_na=True)], axis=1)\n",
        "        X = X.drop(f'TARGET_{level}', axis=1)\n",
        "\n",
        "    new_cols['MEAN_RET'] = X[ret_cols].mean(axis=1)\n",
        "    new_cols['STD_RET'] = X[ret_cols].std(axis=1)\n",
        "    new_cols['MOMENTUM_7D'] = X[ret_cols].rolling(window=7, min_periods=1).mean().mean(axis=1).replace([np.inf, -np.inf], 0).fillna(0)\n",
        "    new_cols['VOLATILITY_3D'] = X[ret_cols].rolling(window=3, min_periods=1).std().mean(axis=1).replace([np.inf, -np.inf], 0).fillna(0)\n",
        "    new_cols.update({f'CS_RANK_{col}': X.groupby('ID_DAY')[col].rank(pct=True).replace([np.inf, -np.inf], 0).fillna(0) for col in ret_cols})\n",
        "\n",
        "    if is_train:\n",
        "        corr_matrix = X[ret_cols].corr()\n",
        "        corr_pairs = corr_matrix.unstack().sort_values(ascending=False)\n",
        "        top_pairs = [(i, j) for i, j in corr_pairs.index if i < j][:5]\n",
        "        for i, j in top_pairs:\n",
        "            new_cols[f'CORR_{i}_{j}'] = X[i] * X[j]\n",
        "\n",
        "    if ret_cols:\n",
        "        pca = PCA(n_components=min(2, len(ret_cols)), random_state=42)\n",
        "        pca_features = pca.fit_transform(X[ret_cols].fillna(0))\n",
        "        for i in range(pca_features.shape[1]):\n",
        "            new_cols[f'PCA_{i}'] = pca_features[:, i]\n",
        "\n",
        "    new_cols_df = pd.DataFrame(new_cols, index=X.index, dtype=np.float32)\n",
        "    X = pd.concat([X, new_cols_df], axis=1)\n",
        "\n",
        "    feature_cols = [col for col in X.columns if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "    scaler = StandardScaler()\n",
        "    X[feature_cols] = scaler.fit_transform(X[feature_cols].replace([np.inf, -np.inf], 0).fillna(0))\n",
        "\n",
        "    if is_train:\n",
        "        y['SIGN_TARGET'] = np.where(y['RET_TARGET'] > 0, 1, 0).astype(np.int32)\n",
        "        return X, y, feature_cols, top_cols\n",
        "    return X, None, feature_cols, top_cols\n",
        "\n",
        "# Preprocess data\n",
        "try:\n",
        "    X_train, y_train, feature_cols, top_cols = preprocess_data(X_train, y_train, supplementary, is_train=True)\n",
        "    X_test, _, test_feature_cols, _ = preprocess_data(X_test, supplementary=supplementary, is_train=False, top_cols=top_cols)\n",
        "except ValueError as e:\n",
        "    print(f\"Preprocessing error: {e}\")\n",
        "    raise\n",
        "\n",
        "# Align columns\n",
        "common_cols = X_train.columns.intersection(X_test.columns)\n",
        "X_train = X_train[common_cols]\n",
        "X_test = X_test[common_cols]\n",
        "feature_cols = [col for col in common_cols if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "\n",
        "# Align y_train\n",
        "y_train = y_train.loc[X_train.index]\n",
        "\n",
        "# Define models with intermediate hyperparameter grids\n",
        "models = {\n",
        "    'LightGBM': {\n",
        "        'model': LGBMClassifier(num_leaves=31, min_child_samples=15, lambda_l1=0.3, lambda_l2=0.3,\n",
        "                                subsample=0.7, colsample_bytree=0.8, bagging_freq=5, bagging_fraction=0.7,\n",
        "                                random_state=42, n_jobs=1, verbosity=-1, class_weight='balanced', force_row_wise=True),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.02], 'num_leaves': [15], 'min_child_samples': [20], 'bagging_fraction': [0.6], 'reg_alpha': [0.1], 'reg_lambda': [0.1]},\n",
        "            {'learning_rate': [0.05], 'num_leaves': [31], 'min_child_samples': [10], 'bagging_fraction': [0.7], 'reg_alpha': [0.2], 'reg_lambda': [0.2]},\n",
        "            {'learning_rate': [0.07], 'num_leaves': [47], 'min_child_samples': [15], 'bagging_fraction': [0.8], 'reg_alpha': [0.3], 'reg_lambda': [0.3]}\n",
        "        ],\n",
        "        'callbacks': [lightgbm.early_stopping(stopping_rounds=10, verbose=False)]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'model': XGBClassifier(max_depth=4, min_child_weight=2, subsample=0.8, colsample_bytree=0.8,\n",
        "                               random_state=42, n_jobs=1, eval_metric='logloss', verbosity=0,\n",
        "                               scale_pos_weight=len(y_train[y_train['SIGN_TARGET'] == 0]) / len(y_train[y_train['SIGN_TARGET'] == 1])),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.03], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [150], 'reg_alpha': [0.1], 'reg_lambda': [1.0]},\n",
        "            {'learning_rate': [0.05], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [200], 'reg_alpha': [0.2], 'reg_lambda': [1.5]},\n",
        "            {'learning_rate': [0.07], 'max_depth': [5], 'min_child_weight': [3], 'subsample': [0.8], 'n_estimators': [150], 'reg_alpha': [0.3], 'reg_lambda': [1.0]}\n",
        "        ],\n",
        "        'callbacks': [xgboost.callback.EarlyStopping(rounds=10, metric_name='logloss', save_best=True)]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to train and predict for a single target\n",
        "def train_target(target, X_train, y_train, X_test, feature_cols, model, model_name, kf, param_grid, callbacks):\n",
        "    X_target = X_train[X_train['ID_TARGET'] == target][feature_cols]\n",
        "    y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "    weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "    low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "    weight_scale = 2.0 if target in low_performing_targets else 1.0\n",
        "    weights = weights * weight_scale\n",
        "    groups = X_train[X_train['ID_TARGET'] == target]['ID_DAY']\n",
        "    X_test_target = X_test[X_test['ID_TARGET'] == target][feature_cols]\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "    if len(X_target) < 100 or len(X_test_target) == 0:\n",
        "        print(f\"Warning: Insufficient data for ID_TARGET {target} (train: {len(X_target)}, test: {len(X_test_target)}). Skipping.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    param_results = []\n",
        "    best_params = None\n",
        "    best_score = 0\n",
        "    best_model = None\n",
        "\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        print(f\"Testing params for {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "        try:\n",
        "            model.set_params(**params)\n",
        "        except ValueError as e:\n",
        "            print(f\"Invalid params for {model_name} ID_TARGET {target}: {e}\")\n",
        "            continue\n",
        "        fold_accuracies = []\n",
        "        for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "            X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "            y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "            w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "            if model_name == 'LightGBM' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=callbacks)\n",
        "            elif model_name == 'XGBoost' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "            else:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "            y_pred = model.predict(X_val)\n",
        "            acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "            fold_accuracies.append(acc)\n",
        "        mean_acc = np.mean(fold_accuracies)\n",
        "        print(f\"{model_name} | ID_TARGET: {target} | Params: {params} | Mean Accuracy: {mean_acc:.4f} | Fold Accuracies: {fold_accuracies}\", flush=True)\n",
        "        param_results.append({\n",
        "            'params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': fold_accuracies\n",
        "        })\n",
        "        if mean_acc > best_score:\n",
        "            best_score = mean_acc\n",
        "            best_params = params\n",
        "            best_model = type(model)(**model.get_params())\n",
        "\n",
        "    if best_model is None:\n",
        "        print(f\"No valid model for {model_name} ID_TARGET {target}. Using default.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    best_model.set_params(**best_params)\n",
        "    if model_name == 'LightGBM' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=callbacks)\n",
        "    elif model_name == 'XGBoost' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "    else:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights)\n",
        "    preds = best_model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "    importance = best_model.feature_importances_\n",
        "    feature_importance = dict(zip(feature_cols, importance))\n",
        "    top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:30]\n",
        "    gc.collect()\n",
        "    return str(target), best_params, best_score, param_results, test_ids, preds, top_features\n",
        "\n",
        "# Cross-validation and training\n",
        "kf = GroupKFold(n_splits=5)\n",
        "results = {}\n",
        "predictions = {}\n",
        "param_log = {}\n",
        "top_features_all = {}\n",
        "param_summary = []\n",
        "low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\", flush=True)\n",
        "    param_log[model_name] = {}\n",
        "    top_features_all[model_name] = {}\n",
        "    results_parallel = Parallel(n_jobs=-1)(\n",
        "        delayed(train_target)(target, X_train, y_train, X_test, feature_cols, model_info['model'], model_name, kf,\n",
        "                             model_info['param_grid'], model_info['callbacks'])\n",
        "        for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\")\n",
        "    )\n",
        "    accuracies = []\n",
        "    for target, params, mean_acc, param_results, test_ids, preds, top_features in results_parallel:\n",
        "        param_log[model_name][target] = {\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'all_params': param_results\n",
        "        }\n",
        "        top_features_all[model_name][target] = top_features\n",
        "        accuracies.append(mean_acc)\n",
        "        predictions.setdefault(target, {})[model_name] = dict(zip(test_ids, preds))\n",
        "        param_summary.append({\n",
        "            'model': model_name,\n",
        "            'ID_TARGET': target,\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': param_results[-1]['fold_accuracies'] if param_results else []\n",
        "        })\n",
        "    results[model_name] = np.mean([acc for acc in accuracies if acc > 0])\n",
        "    print(f\"{model_name} Weighted Accuracy: {results[model_name]:.4f}\", flush=True)\n",
        "    print(f\"\\n{model_name} Parameter Summary:\", flush=True)\n",
        "    for summary in param_summary:\n",
        "        if summary['model'] == model_name:\n",
        "            print(f\"ID_TARGET: {summary['ID_TARGET']} | Best Params: {summary['best_params']} | Mean Accuracy: {summary['mean_accuracy']:.4f} | Fold Accuracies: {summary['fold_accuracies']}\", flush=True)\n",
        "\n",
        "# Second-pass training with top 30 features\n",
        "print(\"\\nPerforming second-pass training with top 30 features...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nSecond-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\"):\n",
        "        target_str = str(target)\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "        weight_scale = 2.0 if target in low_performing_targets else 1.0\n",
        "        weights = weights * weight_scale\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        best_params['n_estimators'] = 200\n",
        "        model.set_params(**best_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Third-pass training for low-performing targets\n",
        "print(\"\\nPerforming third-pass training for low-performing targets...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nThird-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(low_performing_targets, desc=f\"{model_name} Low-Performing Targets\"):\n",
        "        target_str = str(target)\n",
        "        if target_str not in param_log[model_name] or param_log[model_name][target_str]['mean_accuracy'] >= 0.75:\n",
        "            continue\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs() * 2.0\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        fine_tune_grid = [\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.8, 'n_estimators': 200, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.2, 'n_estimators': 250, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1}\n",
        "        ]\n",
        "        best_score = param_log[model_name][target_str]['mean_accuracy']\n",
        "        best_fine_params = best_params\n",
        "        for params in ParameterGrid(fine_tune_grid):\n",
        "            print(f\"Fine-tuning {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "            model.set_params(**params)\n",
        "            fold_accuracies = []\n",
        "            for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "                X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "                y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "                w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "                if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "                elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "                else:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "                y_pred = model.predict(X_val)\n",
        "                acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "                fold_accuracies.append(acc)\n",
        "            mean_acc = np.mean(fold_accuracies)\n",
        "            print(f\"{model_name} | ID_TARGET: {target} | Fine-tune Params: {params} | Mean Accuracy: {mean_acc:.4f}\", flush=True)\n",
        "            if mean_acc > best_score:\n",
        "                best_score = mean_acc\n",
        "                best_fine_params = params\n",
        "                param_log[model_name][target_str]['best_params'] = best_fine_params\n",
        "                param_log[model_name][target_str]['mean_accuracy'] = best_score\n",
        "                param_summary.append({\n",
        "                    'model': model_name,\n",
        "                    'ID_TARGET': target_str,\n",
        "                    'best_params': best_fine_params,\n",
        "                    'mean_accuracy': best_score,\n",
        "                    'fold_accuracies': fold_accuracies\n",
        "                })\n",
        "        model.set_params(**best_fine_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Save parameter log\n",
        "param_log_path = os.path.join(DATA_DIR, 'hyperparameters.json')\n",
        "with open(param_log_path, 'w') as f:\n",
        "    json.dump(param_log, f, indent=4)\n",
        "print(f\"Saved hyperparameter log to: {param_log_path}\", flush=True)\n",
        "files.download(param_log_path)\n",
        "\n",
        "# Ensemble predictions with dynamic weights\n",
        "final_predictions = {}\n",
        "missing_day_targets = []\n",
        "for target in X_test['ID_TARGET'].unique():\n",
        "    target_str = str(target)\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "    lgbm_acc = param_log.get('LightGBM', {}).get(target_str, {}).get('mean_accuracy', 0.5)\n",
        "    xgb_acc = param_log.get('XGBoost', {}).get(target_str, {}).get('mean_accuracy', 0.5)\n",
        "    total_acc = lgbm_acc + xgb_acc\n",
        "    ensemble_weights = {\n",
        "        'LightGBM': lgbm_acc / total_acc if total_acc > 0 else 0.5,\n",
        "        'XGBoost': xgb_acc / total_acc if total_acc > 0 else 0.5\n",
        "    }\n",
        "    for day in X_test[X_test['ID_TARGET'] == target]['ID_DAY'].unique():\n",
        "        day_idx = (X_test['ID_TARGET'] == target) & (X_test['ID_DAY'] == day)\n",
        "        day_test_ids = X_test[day_idx].index\n",
        "        if len(day_test_ids) == 0:\n",
        "            print(f\"Warning: No test samples for ID_TARGET {target} on ID_DAY {day}. Using default prediction.\")\n",
        "            missing_day_targets.append((target, day))\n",
        "            for idx in test_ids:\n",
        "                final_predictions[idx] = -1\n",
        "            continue\n",
        "        lgbm_preds = np.array([predictions[target_str].get('LightGBM', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        xgb_preds = np.array([predictions[target_str].get('XGBoost', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        ensemble_preds = ensemble_weights['LightGBM'] * lgbm_preds + ensemble_weights['XGBoost'] * xgb_preds\n",
        "        smoothed_preds = pd.Series(ensemble_preds).ewm(span=3).mean().values[-1] if len(ensemble_preds) > 0 else 0.5\n",
        "        for idx in day_test_ids:\n",
        "            final_predictions[idx] = 1 if smoothed_preds >= 0.5 else -1\n",
        "\n",
        "if missing_day_targets:\n",
        "    print(f\"Missing day-target pairs: {missing_day_targets}\")\n",
        "\n",
        "# Create output CSV\n",
        "output_df = pd.DataFrame.from_dict(final_predictions, orient='index', columns=['RET_TARGET']).reset_index()\n",
        "output_df.columns = ['ID', 'RET_TARGET']\n",
        "output_df = output_df.sort_values('ID')\n",
        "expected_ids = set(X_test.index)\n",
        "submission_ids = set(output_df['ID'])\n",
        "if expected_ids != submission_ids:\n",
        "    missing_ids = expected_ids - submission_ids\n",
        "    print(f\"Warning: Submission missing {len(missing_ids)} IDs: {missing_ids}\")\n",
        "    missing_df = pd.DataFrame({'ID': list(missing_ids), 'RET_TARGET': -1})\n",
        "    output_df = pd.concat([output_df, missing_df], ignore_index=True).sort_values('ID')\n",
        "output_path = os.path.join(DATA_DIR, 'predictions_ensemble.csv')\n",
        "output_df.to_csv(output_path, index=False)\n",
        "print(f\"Saved predictions to: {output_path}\", flush=True)\n",
        "\n",
        "# Validate output\n",
        "test_csv = pd.read_csv(output_path)\n",
        "print(f\"Output CSV shape: {test_csv.shape}\", flush=True)\n",
        "print(f\"Output CSV ID range: {test_csv['ID'].min()} to {test_csv['ID'].max()}\", flush=True)\n",
        "print(f\"Unique RET_TARGET values: {test_csv['RET_TARGET'].unique()}\", flush=True)\n",
        "print(f\"Missing values: {test_csv.isna().sum().sum()}\", flush=True)\n",
        "\n",
        "# Download the file\n",
        "files.download(output_path)\n",
        "\n",
        "# Print final results\n",
        "print(\"\\nValidation Results:\", flush=True)\n",
        "for model_name, acc in results.items():\n",
        "    print(f\"{model_name}: {acc:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-62J1RFGNEg"
      },
      "source": [
        "Model between 73.9 % and 74.2 %"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kyg8dgArGVsC",
        "outputId": "5c606326-8251-462b-b8bd-d861cc73ea94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost version: 2.1.4\n",
            "Selected top return columns: ['RET_262', 'RET_88', 'RET_172', 'RET_259', 'RET_150', 'RET_118', 'RET_216', 'RET_268', 'RET_115', 'RET_261', 'RET_59', 'RET_238', 'RET_121', 'RET_97', 'RET_30']\n",
            "\n",
            "Training LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LightGBM Targets: 100%|| 100/100 [25:47<00:00, 15.48s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightGBM Weighted Accuracy: 0.7518\n",
            "\n",
            "LightGBM Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9016 | Fold Accuracies: [np.float64(0.9952830188679245), np.float64(0.8054298642533937), np.float64(0.827906976744186), np.float64(0.7210526315789474), np.float64(0.9901477832512315), np.float64(0.8221153846153846)]\n",
            "ID_TARGET: 129.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.6700 | Fold Accuracies: [np.float64(0.6470588235294118), np.float64(0.645), np.float64(0.6570048309178744), np.float64(0.6747572815533981), np.float64(0.6132075471698113), np.float64(0.6108597285067874)]\n",
            "ID_TARGET: 136.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.6334 | Fold Accuracies: [np.float64(0.600896860986547), np.float64(0.6216216216216216), np.float64(0.6146788990825688), np.float64(0.5951219512195122), np.float64(0.5825688073394495), np.float64(0.6883720930232559)]\n",
            "ID_TARGET: 161.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.6967 | Fold Accuracies: [np.float64(0.6948356807511737), np.float64(0.6828193832599119), np.float64(0.6666666666666666), np.float64(0.7014218009478673), np.float64(0.6929824561403509), np.float64(0.6884422110552764)]\n",
            "ID_TARGET: 217.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7176 | Fold Accuracies: [np.float64(0.6784140969162996), np.float64(0.6521739130434783), np.float64(0.7031963470319634), np.float64(0.670995670995671), np.float64(0.7079646017699115), np.float64(0.7167381974248928)]\n",
            "ID_TARGET: 91.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7321 | Fold Accuracies: [np.float64(0.6495327102803738), np.float64(0.7376237623762376), np.float64(0.695852534562212), np.float64(0.6650717703349283), np.float64(0.6744186046511628), np.float64(0.726457399103139)]\n",
            "ID_TARGET: 137.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.6645 | Fold Accuracies: [np.float64(0.6157635467980296), np.float64(0.6995073891625616), np.float64(0.6417910447761194), np.float64(0.5739910313901345), np.float64(0.6634146341463415), np.float64(0.6836734693877551)]\n",
            "ID_TARGET: 8.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7559 | Fold Accuracies: [np.float64(0.788546255506608), np.float64(0.7075471698113207), np.float64(0.5661375661375662), np.float64(0.6743119266055045), np.float64(0.7661691542288557), np.float64(0.6915887850467289)]\n",
            "ID_TARGET: 3.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7232 | Fold Accuracies: [np.float64(0.6989795918367347), np.float64(0.6451612903225806), np.float64(0.6974358974358974), np.float64(0.66), np.float64(0.7038834951456311), np.float64(0.7619047619047619)]\n",
            "ID_TARGET: 9.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7285 | Fold Accuracies: [np.float64(0.6492146596858639), np.float64(0.6601941747572816), np.float64(0.7142857142857143), np.float64(0.7619047619047619), np.float64(0.634703196347032), np.float64(0.6746411483253588)]\n",
            "ID_TARGET: 131.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7019 | Fold Accuracies: [np.float64(0.6915422885572139), np.float64(0.6547085201793722), np.float64(0.7403846153846154), np.float64(0.6019417475728155), np.float64(0.6716417910447762), np.float64(0.6318181818181818)]\n",
            "ID_TARGET: 21.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.6965 | Fold Accuracies: [np.float64(0.6708860759493671), np.float64(0.6586538461538461), np.float64(0.7), np.float64(0.6589861751152074), np.float64(0.6473429951690821), np.float64(0.703862660944206)]\n",
            "ID_TARGET: 54.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8031 | Fold Accuracies: [np.float64(0.7339449541284404), np.float64(0.8310502283105022), np.float64(0.7751196172248804), np.float64(0.7559808612440191), np.float64(0.7217391304347827), np.float64(0.785)]\n",
            "ID_TARGET: 130.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7389 | Fold Accuracies: [np.float64(0.7971014492753623), np.float64(0.6434782608695652), np.float64(0.6915887850467289), np.float64(0.776255707762557), np.float64(0.7391304347826086), np.float64(0.6788990825688074)]\n",
            "ID_TARGET: 269.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7268 | Fold Accuracies: [np.float64(0.7282051282051282), np.float64(0.625), np.float64(0.7236180904522613), np.float64(0.6777251184834123), np.float64(0.7393617021276596), np.float64(0.6381909547738693)]\n",
            "ID_TARGET: 157.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7999 | Fold Accuracies: [np.float64(0.7474747474747475), np.float64(0.7631578947368421), np.float64(0.7735849056603774), np.float64(0.7714285714285715), np.float64(0.7352941176470589), np.float64(0.7755102040816326)]\n",
            "ID_TARGET: 249.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7297 | Fold Accuracies: [np.float64(0.6681222707423581), np.float64(0.6666666666666666), np.float64(0.7239819004524887), np.float64(0.7393364928909952), np.float64(0.6363636363636364), np.float64(0.7317073170731707)]\n",
            "ID_TARGET: 22.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.6825 | Fold Accuracies: [np.float64(0.6885964912280702), np.float64(0.7309417040358744), np.float64(0.6540284360189573), np.float64(0.6127450980392157), np.float64(0.6839622641509434), np.float64(0.6694915254237288)]\n",
            "ID_TARGET: 202.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.03, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6727 | Fold Accuracies: [np.float64(0.6666666666666666), np.float64(0.7016806722689075), np.float64(0.6622222222222223), np.float64(0.6981132075471698), np.float64(0.6363636363636364), np.float64(0.6267942583732058)]\n",
            "ID_TARGET: 132.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7680 | Fold Accuracies: [np.float64(0.7230046948356808), np.float64(0.7627906976744186), np.float64(0.7513227513227513), np.float64(0.7563451776649747), np.float64(0.7114427860696517), np.float64(0.6985645933014354)]\n",
            "ID_TARGET: 96.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7810 | Fold Accuracies: [np.float64(0.6854460093896714), np.float64(0.7486910994764397), np.float64(0.81), np.float64(0.7643979057591623), np.float64(0.6616161616161617), np.float64(0.8260869565217391)]\n",
            "ID_TARGET: 7.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7550 | Fold Accuracies: [np.float64(0.7075471698113207), np.float64(0.7873303167420814), np.float64(0.7101449275362319), np.float64(0.7257383966244726), np.float64(0.7452830188679245), np.float64(0.7393364928909952)]\n",
            "ID_TARGET: 178.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7225 | Fold Accuracies: [np.float64(0.6912442396313364), np.float64(0.7578947368421053), np.float64(0.7019230769230769), np.float64(0.6884422110552764), np.float64(0.6813725490196079), np.float64(0.7142857142857143)]\n",
            "ID_TARGET: 68.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7810 | Fold Accuracies: [np.float64(0.7330097087378641), np.float64(0.7740384615384616), np.float64(0.7594339622641509), np.float64(0.7281553398058253), np.float64(0.8052631578947368), np.float64(0.7894736842105263)]\n",
            "ID_TARGET: 44.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7368 | Fold Accuracies: [np.float64(0.7064676616915423), np.float64(0.7451923076923077), np.float64(0.6473214285714286), np.float64(0.7031963470319634), np.float64(0.7657657657657657), np.float64(0.7224669603524229)]\n",
            "ID_TARGET: 196.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7407 | Fold Accuracies: [np.float64(0.717948717948718), np.float64(0.7136929460580913), np.float64(0.724), np.float64(0.7035398230088495), np.float64(0.7251184834123223), np.float64(0.6653225806451613)]\n",
            "ID_TARGET: 292.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7621 | Fold Accuracies: [np.float64(0.6448598130841121), np.float64(0.7324561403508771), np.float64(0.7072072072072072), np.float64(0.6954545454545454), np.float64(0.7241379310344828), np.float64(0.7623762376237624)]\n",
            "ID_TARGET: 239.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7674 | Fold Accuracies: [np.float64(0.7729468599033816), np.float64(0.7164179104477612), np.float64(0.7461928934010152), np.float64(0.7969543147208121), np.float64(0.7079207920792079), np.float64(0.7268518518518519)]\n",
            "ID_TARGET: 279.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7371 | Fold Accuracies: [np.float64(0.6831683168316832), np.float64(0.7378640776699029), np.float64(0.7), np.float64(0.6521739130434783), np.float64(0.6981132075471698), np.float64(0.6437768240343348)]\n",
            "ID_TARGET: 38.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7621 | Fold Accuracies: [np.float64(0.6896551724137931), np.float64(0.7453703703703703), np.float64(0.719047619047619), np.float64(0.6778846153846154), np.float64(0.7101449275362319), np.float64(0.7317073170731707)]\n",
            "ID_TARGET: 209.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7506 | Fold Accuracies: [np.float64(0.696969696969697), np.float64(0.7117903930131004), np.float64(0.7323943661971831), np.float64(0.6801801801801802), np.float64(0.7649769585253456), np.float64(0.6972477064220184)]\n",
            "ID_TARGET: 207.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.6917 | Fold Accuracies: [np.float64(0.714975845410628), np.float64(0.6417112299465241), np.float64(0.7255813953488373), np.float64(0.6504854368932039), np.float64(0.6391304347826087), np.float64(0.7322175732217573)]\n",
            "ID_TARGET: 98.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7284 | Fold Accuracies: [np.float64(0.6844444444444444), np.float64(0.7055837563451777), np.float64(0.6995073891625616), np.float64(0.7488372093023256), np.float64(0.7178217821782178), np.float64(0.7596153846153846)]\n",
            "ID_TARGET: 65.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7497 | Fold Accuracies: [np.float64(0.6777251184834123), np.float64(0.7580645161290323), np.float64(0.7740384615384616), np.float64(0.7661691542288557), np.float64(0.6796116504854369), np.float64(0.7122641509433962)]\n",
            "ID_TARGET: 51.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7657 | Fold Accuracies: [np.float64(0.702020202020202), np.float64(0.7326732673267327), np.float64(0.7297297297297297), np.float64(0.7783251231527094), np.float64(0.7431192660550459), np.float64(0.7981220657276995)]\n",
            "ID_TARGET: 78.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7396 | Fold Accuracies: [np.float64(0.75), np.float64(0.6956521739130435), np.float64(0.6551724137931034), np.float64(0.705), np.float64(0.7121212121212122), np.float64(0.7729468599033816)]\n",
            "ID_TARGET: 177.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7584 | Fold Accuracies: [np.float64(0.7659574468085106), np.float64(0.6894977168949772), np.float64(0.7354260089686099), np.float64(0.7344398340248963), np.float64(0.7577092511013216), np.float64(0.7256637168141593)]\n",
            "ID_TARGET: 231.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8137 | Fold Accuracies: [np.float64(0.7767441860465116), np.float64(0.7945205479452054), np.float64(0.784688995215311), np.float64(0.7522935779816514), np.float64(0.784688995215311), np.float64(0.817351598173516)]\n",
            "ID_TARGET: 119.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7863 | Fold Accuracies: [np.float64(0.7323943661971831), np.float64(0.7559808612440191), np.float64(0.7551020408163265), np.float64(0.7403846153846154), np.float64(0.7822222222222223), np.float64(0.8010204081632653)]\n",
            "ID_TARGET: 158.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8139 | Fold Accuracies: [np.float64(0.7669902912621359), np.float64(0.8106796116504854), np.float64(0.7844036697247706), np.float64(0.7981651376146789), np.float64(0.7799043062200957), np.float64(0.8240740740740741)]\n",
            "ID_TARGET: 80.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.03, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7029 | Fold Accuracies: [np.float64(0.704225352112676), np.float64(0.7386934673366834), np.float64(0.675531914893617), np.float64(0.638095238095238), np.float64(0.7373737373737373), np.float64(0.6944444444444444)]\n",
            "ID_TARGET: 25.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7444 | Fold Accuracies: [np.float64(0.7058823529411765), np.float64(0.6944444444444444), np.float64(0.6820276497695853), np.float64(0.6934673366834171), np.float64(0.7327188940092166), np.float64(0.76)]\n",
            "ID_TARGET: 175.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7430 | Fold Accuracies: [np.float64(0.6635514018691588), np.float64(0.7798165137614679), np.float64(0.722488038277512), np.float64(0.8048780487804879), np.float64(0.7598039215686274), np.float64(0.6933962264150944)]\n",
            "ID_TARGET: 151.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7852 | Fold Accuracies: [np.float64(0.7549019607843137), np.float64(0.7419354838709677), np.float64(0.7333333333333333), np.float64(0.7405660377358491), np.float64(0.8443396226415094), np.float64(0.7990430622009569)]\n",
            "ID_TARGET: 257.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7542 | Fold Accuracies: [np.float64(0.7435897435897436), np.float64(0.726457399103139), np.float64(0.7248908296943232), np.float64(0.7276785714285714), np.float64(0.6728971962616822), np.float64(0.705607476635514)]\n",
            "ID_TARGET: 75.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7924 | Fold Accuracies: [np.float64(0.7953488372093023), np.float64(0.7286432160804021), np.float64(0.8095238095238095), np.float64(0.7916666666666666), np.float64(0.7684729064039408), np.float64(0.7105263157894737)]\n",
            "ID_TARGET: 244.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7050 | Fold Accuracies: [np.float64(0.6981981981981982), np.float64(0.6826923076923077), np.float64(0.7122641509433962), np.float64(0.6832579185520362), np.float64(0.6811594202898551), np.float64(0.6566523605150214)]\n",
            "ID_TARGET: 149.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7877 | Fold Accuracies: [np.float64(0.6954545454545454), np.float64(0.7439613526570048), np.float64(0.7766990291262136), np.float64(0.7075471698113207), np.float64(0.776255707762557), np.float64(0.7777777777777778)]\n",
            "ID_TARGET: 85.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7919 | Fold Accuracies: [np.float64(0.7476635514018691), np.float64(0.7649769585253456), np.float64(0.780373831775701), np.float64(0.7609756097560976), np.float64(0.7487437185929648), np.float64(0.8)]\n",
            "ID_TARGET: 190.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7575 | Fold Accuracies: [np.float64(0.782608695652174), np.float64(0.775330396475771), np.float64(0.670995670995671), np.float64(0.7244444444444444), np.float64(0.7594339622641509), np.float64(0.7511737089201878)]\n",
            "ID_TARGET: 13.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7464 | Fold Accuracies: [np.float64(0.7387387387387387), np.float64(0.7263681592039801), np.float64(0.6973684210526315), np.float64(0.7354260089686099), np.float64(0.7703349282296651), np.float64(0.7706422018348624)]\n",
            "ID_TARGET: 228.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7133 | Fold Accuracies: [np.float64(0.6978723404255319), np.float64(0.7180616740088106), np.float64(0.6570048309178744), np.float64(0.7072072072072072), np.float64(0.6529680365296804), np.float64(0.7399103139013453)]\n",
            "ID_TARGET: 144.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8043 | Fold Accuracies: [np.float64(0.7264150943396226), np.float64(0.7916666666666666), np.float64(0.8146341463414634), np.float64(0.7846153846153846), np.float64(0.7900552486187845), np.float64(0.793859649122807)]\n",
            "ID_TARGET: 290.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7500 | Fold Accuracies: [np.float64(0.75), np.float64(0.7714285714285715), np.float64(0.7208121827411168), np.float64(0.695067264573991), np.float64(0.6792452830188679), np.float64(0.7236180904522613)]\n",
            "ID_TARGET: 114.0 | Best Params: {'bagging_fraction': 0.75, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 31, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6952 | Fold Accuracies: [np.float64(0.7136363636363636), np.float64(0.6587677725118484), np.float64(0.6929824561403509), np.float64(0.6635514018691588), np.float64(0.7298578199052133), np.float64(0.7122641509433962)]\n",
            "ID_TARGET: 166.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7640 | Fold Accuracies: [np.float64(0.7422680412371134), np.float64(0.8144796380090498), np.float64(0.700507614213198), np.float64(0.7748917748917749), np.float64(0.7323943661971831), np.float64(0.7385321100917431)]\n",
            "ID_TARGET: 234.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7709 | Fold Accuracies: [np.float64(0.7326732673267327), np.float64(0.7431192660550459), np.float64(0.8076923076923077), np.float64(0.7397959183673469), np.float64(0.7584541062801933), np.float64(0.7699530516431925)]\n",
            "ID_TARGET: 34.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7845 | Fold Accuracies: [np.float64(0.7272727272727273), np.float64(0.7475728155339806), np.float64(0.8113207547169812), np.float64(0.7557603686635944), np.float64(0.7594339622641509), np.float64(0.75)]\n",
            "ID_TARGET: 154.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7685 | Fold Accuracies: [np.float64(0.7015706806282722), np.float64(0.7568807339449541), np.float64(0.8113207547169812), np.float64(0.7709251101321586), np.float64(0.6714285714285714), np.float64(0.7735042735042735)]\n",
            "ID_TARGET: 225.0 | Best Params: {'bagging_fraction': 0.65, 'learning_rate': 0.07, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7084 | Fold Accuracies: [np.float64(0.6398305084745762), np.float64(0.7071129707112971), np.float64(0.6991150442477876), np.float64(0.6425339366515838), np.float64(0.7385321100917431), np.float64(0.7477876106194691)]\n",
            "ID_TARGET: 185.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8273 | Fold Accuracies: [np.float64(0.7945945945945946), np.float64(0.83), np.float64(0.827027027027027), np.float64(0.735632183908046), np.float64(0.8229166666666666), np.float64(0.8095238095238095)]\n",
            "ID_TARGET: 39.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7603 | Fold Accuracies: [np.float64(0.6584158415841584), np.float64(0.7317073170731707), np.float64(0.7488372093023256), np.float64(0.7316017316017316), np.float64(0.7783251231527094), np.float64(0.7912621359223301)]\n",
            "ID_TARGET: 272.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.03, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7485 | Fold Accuracies: [np.float64(0.7629310344827587), np.float64(0.6744186046511628), np.float64(0.680365296803653), np.float64(0.7793427230046949), np.float64(0.7395348837209302), np.float64(0.7967914438502673)]\n",
            "ID_TARGET: 282.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7667 | Fold Accuracies: [np.float64(0.7009803921568627), np.float64(0.6905829596412556), np.float64(0.7546296296296297), np.float64(0.7303921568627451), np.float64(0.7714285714285715), np.float64(0.7440758293838863)]\n",
            "ID_TARGET: 90.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7629 | Fold Accuracies: [np.float64(0.7819905213270142), np.float64(0.782608695652174), np.float64(0.7524752475247525), np.float64(0.7464788732394366), np.float64(0.7772511848341233), np.float64(0.7129629629629629)]\n",
            "ID_TARGET: 52.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7499 | Fold Accuracies: [np.float64(0.7314814814814815), np.float64(0.7281553398058253), np.float64(0.7024390243902439), np.float64(0.7074468085106383), np.float64(0.7867298578199052), np.float64(0.7)]\n",
            "ID_TARGET: 258.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7478 | Fold Accuracies: [np.float64(0.7577319587628866), np.float64(0.7397260273972602), np.float64(0.7294685990338164), np.float64(0.6633663366336634), np.float64(0.7939698492462312), np.float64(0.6872037914691943)]\n",
            "ID_TARGET: 291.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7681 | Fold Accuracies: [np.float64(0.7277227722772277), np.float64(0.7072072072072072), np.float64(0.7788018433179723), np.float64(0.786046511627907), np.float64(0.7419354838709677), np.float64(0.7685185185185185)]\n",
            "ID_TARGET: 152.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7701 | Fold Accuracies: [np.float64(0.8170212765957446), np.float64(0.7227722772277227), np.float64(0.7185929648241206), np.float64(0.79), np.float64(0.6948356807511737), np.float64(0.7972972972972973)]\n",
            "ID_TARGET: 133.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7940 | Fold Accuracies: [np.float64(0.7777777777777778), np.float64(0.7464788732394366), np.float64(0.7244444444444444), np.float64(0.7723214285714286), np.float64(0.7892376681614349), np.float64(0.7733990147783252)]\n",
            "ID_TARGET: 29.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7584 | Fold Accuracies: [np.float64(0.7214611872146118), np.float64(0.7884615384615384), np.float64(0.7405660377358491), np.float64(0.681592039800995), np.float64(0.7439613526570048), np.float64(0.6604651162790698)]\n",
            "ID_TARGET: 274.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7383 | Fold Accuracies: [np.float64(0.7375565610859729), np.float64(0.7521367521367521), np.float64(0.70042194092827), np.float64(0.7056277056277056), np.float64(0.775330396475771), np.float64(0.722488038277512)]\n",
            "ID_TARGET: 106.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7953 | Fold Accuracies: [np.float64(0.7754010695187166), np.float64(0.7704918032786885), np.float64(0.776595744680851), np.float64(0.7439613526570048), np.float64(0.7473684210526316), np.float64(0.8224852071005917)]\n",
            "ID_TARGET: 173.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7925 | Fold Accuracies: [np.float64(0.7813953488372093), np.float64(0.7598039215686274), np.float64(0.771689497716895), np.float64(0.7292576419213974), np.float64(0.7201834862385321), np.float64(0.8398058252427184)]\n",
            "ID_TARGET: 33.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7602 | Fold Accuracies: [np.float64(0.7058823529411765), np.float64(0.7075471698113207), np.float64(0.7244897959183674), np.float64(0.7171717171717171), np.float64(0.695067264573991), np.float64(0.7359307359307359)]\n",
            "ID_TARGET: 69.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7122 | Fold Accuracies: [np.float64(0.7307692307692307), np.float64(0.6748768472906403), np.float64(0.678391959798995), np.float64(0.7751196172248804), np.float64(0.6229508196721312), np.float64(0.6839622641509434)]\n",
            "ID_TARGET: 17.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.6947 | Fold Accuracies: [np.float64(0.676056338028169), np.float64(0.6995305164319249), np.float64(0.6811594202898551), np.float64(0.6712328767123288), np.float64(0.7079646017699115), np.float64(0.6774193548387096)]\n",
            "ID_TARGET: 189.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7708 | Fold Accuracies: [np.float64(0.7819905213270142), np.float64(0.7702702702702703), np.float64(0.7594339622641509), np.float64(0.7336448598130841), np.float64(0.7), np.float64(0.6595744680851063)]\n",
            "ID_TARGET: 284.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7363 | Fold Accuracies: [np.float64(0.7216981132075472), np.float64(0.7400881057268722), np.float64(0.7523809523809524), np.float64(0.7216981132075472), np.float64(0.6755555555555556), np.float64(0.7611940298507462)]\n",
            "ID_TARGET: 218.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7088 | Fold Accuracies: [np.float64(0.7121951219512195), np.float64(0.6574074074074074), np.float64(0.6434782608695652), np.float64(0.7224669603524229), np.float64(0.69377990430622), np.float64(0.7123893805309734)]\n",
            "ID_TARGET: 183.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7859 | Fold Accuracies: [np.float64(0.7636363636363637), np.float64(0.7614678899082569), np.float64(0.7971698113207547), np.float64(0.776255707762557), np.float64(0.696078431372549), np.float64(0.7981220657276995)]\n",
            "ID_TARGET: 206.0 | Best Params: {'bagging_fraction': 0.75, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 31, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7601 | Fold Accuracies: [np.float64(0.7412935323383084), np.float64(0.7830188679245284), np.float64(0.765), np.float64(0.7559808612440191), np.float64(0.7641921397379913), np.float64(0.7511961722488039)]\n",
            "ID_TARGET: 93.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7241 | Fold Accuracies: [np.float64(0.6807511737089202), np.float64(0.6995305164319249), np.float64(0.7511961722488039), np.float64(0.6778846153846154), np.float64(0.6495327102803738), np.float64(0.7302325581395349)]\n",
            "ID_TARGET: 16.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7229 | Fold Accuracies: [np.float64(0.7285067873303167), np.float64(0.7598039215686274), np.float64(0.7309417040358744), np.float64(0.6744186046511628), np.float64(0.6727272727272727), np.float64(0.7058823529411765)]\n",
            "ID_TARGET: 246.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7585 | Fold Accuracies: [np.float64(0.7758620689655172), np.float64(0.8274111675126904), np.float64(0.7695852534562212), np.float64(0.6682242990654206), np.float64(0.7377777777777778), np.float64(0.726457399103139)]\n",
            "ID_TARGET: 167.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7734 | Fold Accuracies: [np.float64(0.7971014492753623), np.float64(0.7340425531914894), np.float64(0.7524752475247525), np.float64(0.6919431279620853), np.float64(0.7559808612440191), np.float64(0.7695852534562212)]\n",
            "ID_TARGET: 1.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7540 | Fold Accuracies: [np.float64(0.7524752475247525), np.float64(0.7621359223300971), np.float64(0.7277227722772277), np.float64(0.7376237623762376), np.float64(0.7526315789473684), np.float64(0.645)]\n",
            "ID_TARGET: 289.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7449 | Fold Accuracies: [np.float64(0.722488038277512), np.float64(0.691304347826087), np.float64(0.706140350877193), np.float64(0.7621359223300971), np.float64(0.7230046948356808), np.float64(0.7330097087378641)]\n",
            "ID_TARGET: 141.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8022 | Fold Accuracies: [np.float64(0.8), np.float64(0.7914691943127962), np.float64(0.7708333333333334), np.float64(0.8160377358490566), np.float64(0.7799043062200957), np.float64(0.7916666666666666)]\n",
            "ID_TARGET: 109.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7241 | Fold Accuracies: [np.float64(0.6830357142857143), np.float64(0.7162790697674418), np.float64(0.7264150943396226), np.float64(0.6880733944954128), np.float64(0.7443946188340808), np.float64(0.6768558951965066)]\n",
            "ID_TARGET: 19.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7601 | Fold Accuracies: [np.float64(0.7433628318584071), np.float64(0.759090909090909), np.float64(0.8177339901477833), np.float64(0.72), np.float64(0.7407407407407407), np.float64(0.7345132743362832)]\n",
            "ID_TARGET: 28.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7201 | Fold Accuracies: [np.float64(0.7087378640776699), np.float64(0.6597938144329897), np.float64(0.695), np.float64(0.7247706422018348), np.float64(0.7183098591549296), np.float64(0.7043478260869566)]\n",
            "ID_TARGET: 251.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7405 | Fold Accuracies: [np.float64(0.7211538461538461), np.float64(0.7355769230769231), np.float64(0.7161572052401747), np.float64(0.7311320754716981), np.float64(0.7109004739336493), np.float64(0.7303921568627451)]\n",
            "ID_TARGET: 278.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7903 | Fold Accuracies: [np.float64(0.7475247524752475), np.float64(0.7910447761194029), np.float64(0.8502415458937198), np.float64(0.748792270531401), np.float64(0.6954314720812182), np.float64(0.815)]\n",
            "ID_TARGET: 76.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7430 | Fold Accuracies: [np.float64(0.7413793103448276), np.float64(0.7589285714285714), np.float64(0.7632850241545893), np.float64(0.7442922374429224), np.float64(0.6666666666666666), np.float64(0.7242990654205608)]\n",
            "ID_TARGET: 241.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7813 | Fold Accuracies: [np.float64(0.7416267942583732), np.float64(0.7539267015706806), np.float64(0.7979274611398963), np.float64(0.7365853658536585), np.float64(0.7474226804123711), np.float64(0.7192118226600985)]\n",
            "ID_TARGET: 214.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8024 | Fold Accuracies: [np.float64(0.7801724137931034), np.float64(0.7766497461928934), np.float64(0.852017937219731), np.float64(0.746606334841629), np.float64(0.7695852534562212), np.float64(0.8018867924528302)]\n",
            "ID_TARGET: 102.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8092 | Fold Accuracies: [np.float64(0.7632850241545893), np.float64(0.8119266055045872), np.float64(0.7692307692307693), np.float64(0.7738693467336684), np.float64(0.7777777777777778), np.float64(0.7431192660550459)]\n",
            "ID_TARGET: 145.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7647 | Fold Accuracies: [np.float64(0.7910447761194029), np.float64(0.6771300448430493), np.float64(0.6778846153846154), np.float64(0.7511737089201878), np.float64(0.6985645933014354), np.float64(0.7300884955752213)]\n",
            "ID_TARGET: 155.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7968 | Fold Accuracies: [np.float64(0.8440366972477065), np.float64(0.751131221719457), np.float64(0.7616822429906542), np.float64(0.7922077922077922), np.float64(0.7748917748917749), np.float64(0.8110599078341014)]\n",
            "\n",
            "Training XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "XGBoost Targets: 100%|| 100/100 [41:29<00:00, 24.89s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Weighted Accuracy: 0.7638\n",
            "\n",
            "XGBoost Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7448 | Fold Accuracies: [np.float64(0.660377358490566), np.float64(0.6470588235294118), np.float64(0.641860465116279), np.float64(0.7315789473684211), np.float64(0.6157635467980296), np.float64(0.6346153846153846)]\n",
            "ID_TARGET: 129.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6432 | Fold Accuracies: [np.float64(0.5882352941176471), np.float64(0.67), np.float64(0.6666666666666666), np.float64(0.6310679611650486), np.float64(0.5849056603773585), np.float64(0.5656108597285068)]\n",
            "ID_TARGET: 136.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6069 | Fold Accuracies: [np.float64(0.5605381165919282), np.float64(0.5675675675675675), np.float64(0.5963302752293578), np.float64(0.6097560975609756), np.float64(0.5871559633027523), np.float64(0.5767441860465117)]\n",
            "ID_TARGET: 161.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6767 | Fold Accuracies: [np.float64(0.6431924882629108), np.float64(0.6828193832599119), np.float64(0.6388888888888888), np.float64(0.6872037914691943), np.float64(0.5964912280701754), np.float64(0.7336683417085427)]\n",
            "ID_TARGET: 217.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7674 | Fold Accuracies: [np.float64(0.788546255506608), np.float64(0.6869565217391305), np.float64(0.7214611872146118), np.float64(0.7489177489177489), np.float64(0.7389380530973452), np.float64(0.7467811158798283)]\n",
            "ID_TARGET: 91.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.2, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8215 | Fold Accuracies: [np.float64(0.7289719626168224), np.float64(0.8415841584158416), np.float64(0.728110599078341), np.float64(0.7751196172248804), np.float64(0.8046511627906977), np.float64(0.7713004484304933)]\n",
            "ID_TARGET: 137.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.2, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6748768472906403), np.float64(0.6798029556650246), np.float64(0.6517412935323383), np.float64(0.6278026905829597), np.float64(0.6634146341463415), np.float64(0.6836734693877551)]\n",
            "ID_TARGET: 8.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6543 | Fold Accuracies: [np.float64(0.5903083700440529), np.float64(0.5660377358490566), np.float64(0.6243386243386243), np.float64(0.591743119266055), np.float64(0.5870646766169154), np.float64(0.6121495327102804)]\n",
            "ID_TARGET: 3.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6661 | Fold Accuracies: [np.float64(0.6836734693877551), np.float64(0.5990783410138248), np.float64(0.6871794871794872), np.float64(0.63), np.float64(0.6553398058252428), np.float64(0.7047619047619048)]\n",
            "ID_TARGET: 9.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.2, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7179 | Fold Accuracies: [np.float64(0.6282722513089005), np.float64(0.6504854368932039), np.float64(0.7238095238095238), np.float64(0.7523809523809524), np.float64(0.6255707762557078), np.float64(0.6985645933014354)]\n",
            "ID_TARGET: 131.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6302 | Fold Accuracies: [np.float64(0.6716417910447762), np.float64(0.6098654708520179), np.float64(0.6346153846153846), np.float64(0.587378640776699), np.float64(0.6268656716417911), np.float64(0.5681818181818182)]\n",
            "ID_TARGET: 21.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7152 | Fold Accuracies: [np.float64(0.7172995780590717), np.float64(0.6442307692307693), np.float64(0.691304347826087), np.float64(0.695852534562212), np.float64(0.6811594202898551), np.float64(0.7167381974248928)]\n",
            "ID_TARGET: 54.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.8272 | Fold Accuracies: [np.float64(0.7018348623853211), np.float64(0.730593607305936), np.float64(0.7799043062200957), np.float64(0.7655502392344498), np.float64(0.7434782608695653), np.float64(0.755)]\n",
            "ID_TARGET: 130.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7590 | Fold Accuracies: [np.float64(0.7536231884057971), np.float64(0.6260869565217392), np.float64(0.6682242990654206), np.float64(0.7488584474885844), np.float64(0.6869565217391305), np.float64(0.7064220183486238)]\n",
            "ID_TARGET: 269.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6422 | Fold Accuracies: [np.float64(0.6461538461538462), np.float64(0.565), np.float64(0.6834170854271356), np.float64(0.6635071090047393), np.float64(0.6595744680851063), np.float64(0.5477386934673367)]\n",
            "ID_TARGET: 157.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7601 | Fold Accuracies: [np.float64(0.7121212121212122), np.float64(0.7526315789473684), np.float64(0.6933962264150944), np.float64(0.7380952380952381), np.float64(0.7058823529411765), np.float64(0.7346938775510204)]\n",
            "ID_TARGET: 249.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7234 | Fold Accuracies: [np.float64(0.6550218340611353), np.float64(0.6811594202898551), np.float64(0.669683257918552), np.float64(0.7298578199052133), np.float64(0.6666666666666666), np.float64(0.7317073170731707)]\n",
            "ID_TARGET: 22.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7051 | Fold Accuracies: [np.float64(0.7192982456140351), np.float64(0.7533632286995515), np.float64(0.6682464454976303), np.float64(0.6372549019607843), np.float64(0.7311320754716981), np.float64(0.6822033898305084)]\n",
            "ID_TARGET: 202.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7206 | Fold Accuracies: [np.float64(0.6714285714285714), np.float64(0.7142857142857143), np.float64(0.6755555555555556), np.float64(0.7735849056603774), np.float64(0.6666666666666666), np.float64(0.6650717703349283)]\n",
            "ID_TARGET: 132.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.7} | Mean Accuracy: 0.7446 | Fold Accuracies: [np.float64(0.7464788732394366), np.float64(0.7674418604651163), np.float64(0.7671957671957672), np.float64(0.7563451776649747), np.float64(0.7313432835820896), np.float64(0.6985645933014354)]\n",
            "ID_TARGET: 96.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.8263 | Fold Accuracies: [np.float64(0.7230046948356808), np.float64(0.7643979057591623), np.float64(0.745), np.float64(0.7958115183246073), np.float64(0.7222222222222222), np.float64(0.8097826086956522)]\n",
            "ID_TARGET: 7.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7654 | Fold Accuracies: [np.float64(0.7311320754716981), np.float64(0.7601809954751131), np.float64(0.7391304347826086), np.float64(0.7383966244725738), np.float64(0.7452830188679245), np.float64(0.7345971563981043)]\n",
            "ID_TARGET: 178.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.2, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7237 | Fold Accuracies: [np.float64(0.728110599078341), np.float64(0.7526315789473684), np.float64(0.7211538461538461), np.float64(0.7085427135678392), np.float64(0.6813725490196079), np.float64(0.7183673469387755)]\n",
            "ID_TARGET: 68.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7520 | Fold Accuracies: [np.float64(0.6796116504854369), np.float64(0.7259615384615384), np.float64(0.7452830188679245), np.float64(0.7184466019417476), np.float64(0.7947368421052632), np.float64(0.7703349282296651)]\n",
            "ID_TARGET: 44.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7582 | Fold Accuracies: [np.float64(0.746268656716418), np.float64(0.7932692307692307), np.float64(0.6696428571428571), np.float64(0.7442922374429224), np.float64(0.7927927927927928), np.float64(0.7400881057268722)]\n",
            "ID_TARGET: 196.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.8269 | Fold Accuracies: [np.float64(0.8076923076923077), np.float64(0.7551867219917012), np.float64(0.808), np.float64(0.7787610619469026), np.float64(0.7630331753554502), np.float64(0.7056451612903226)]\n",
            "ID_TARGET: 292.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7595 | Fold Accuracies: [np.float64(0.6635514018691588), np.float64(0.7412280701754386), np.float64(0.6801801801801802), np.float64(0.6818181818181818), np.float64(0.7327586206896551), np.float64(0.801980198019802)]\n",
            "ID_TARGET: 239.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7383 | Fold Accuracies: [np.float64(0.7439613526570048), np.float64(0.7213930348258707), np.float64(0.7614213197969543), np.float64(0.7766497461928934), np.float64(0.698019801980198), np.float64(0.7037037037037037)]\n",
            "ID_TARGET: 279.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7196 | Fold Accuracies: [np.float64(0.6831683168316832), np.float64(0.7087378640776699), np.float64(0.680952380952381), np.float64(0.6956521739130435), np.float64(0.6650943396226415), np.float64(0.6566523605150214)]\n",
            "ID_TARGET: 38.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7673 | Fold Accuracies: [np.float64(0.7044334975369458), np.float64(0.6990740740740741), np.float64(0.7095238095238096), np.float64(0.7067307692307693), np.float64(0.7391304347826086), np.float64(0.7414634146341463)]\n",
            "ID_TARGET: 209.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.2, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7828282828282829), np.float64(0.7554585152838428), np.float64(0.7981220657276995), np.float64(0.6936936936936937), np.float64(0.7188940092165899), np.float64(0.6834862385321101)]\n",
            "ID_TARGET: 207.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6969 | Fold Accuracies: [np.float64(0.7053140096618358), np.float64(0.6844919786096256), np.float64(0.6976744186046512), np.float64(0.616504854368932), np.float64(0.6130434782608696), np.float64(0.7238493723849372)]\n",
            "ID_TARGET: 98.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.2, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7232 | Fold Accuracies: [np.float64(0.6577777777777778), np.float64(0.6954314720812182), np.float64(0.6896551724137931), np.float64(0.7116279069767442), np.float64(0.693069306930693), np.float64(0.7740384615384616)]\n",
            "ID_TARGET: 65.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 200, 'reg_alpha': 0.3, 'reg_lambda': 1.5, 'subsample': 0.75} | Mean Accuracy: 0.7314 | Fold Accuracies: [np.float64(0.6824644549763034), np.float64(0.7849462365591398), np.float64(0.7548076923076923), np.float64(0.7512437810945274), np.float64(0.6650485436893204), np.float64(0.7358490566037735)]\n",
            "ID_TARGET: 51.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7357 | Fold Accuracies: [np.float64(0.6565656565656566), np.float64(0.7128712871287128), np.float64(0.6972972972972973), np.float64(0.6995073891625616), np.float64(0.7018348623853211), np.float64(0.7605633802816901)]\n",
            "ID_TARGET: 78.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.7} | Mean Accuracy: 0.7464 | Fold Accuracies: [np.float64(0.7941176470588235), np.float64(0.7004830917874396), np.float64(0.7142857142857143), np.float64(0.74), np.float64(0.7323232323232324), np.float64(0.7971014492753623)]\n",
            "ID_TARGET: 177.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7966 | Fold Accuracies: [np.float64(0.7787234042553192), np.float64(0.7214611872146118), np.float64(0.7802690582959642), np.float64(0.7551867219917012), np.float64(0.7577092511013216), np.float64(0.7654867256637168)]\n",
            "ID_TARGET: 231.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.2, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7813953488372093), np.float64(0.7579908675799086), np.float64(0.7559808612440191), np.float64(0.7064220183486238), np.float64(0.7703349282296651), np.float64(0.7899543378995434)]\n",
            "ID_TARGET: 119.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7803 | Fold Accuracies: [np.float64(0.7323943661971831), np.float64(0.7320574162679426), np.float64(0.7908163265306123), np.float64(0.7307692307692307), np.float64(0.7777777777777778), np.float64(0.8163265306122449)]\n",
            "ID_TARGET: 158.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7879 | Fold Accuracies: [np.float64(0.7621359223300971), np.float64(0.8058252427184466), np.float64(0.7844036697247706), np.float64(0.7660550458715596), np.float64(0.7559808612440191), np.float64(0.8194444444444444)]\n",
            "ID_TARGET: 80.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7214 | Fold Accuracies: [np.float64(0.6948356807511737), np.float64(0.7587939698492462), np.float64(0.6968085106382979), np.float64(0.6666666666666666), np.float64(0.7575757575757576), np.float64(0.6712962962962963)]\n",
            "ID_TARGET: 25.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.2, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7384 | Fold Accuracies: [np.float64(0.7401960784313726), np.float64(0.6990740740740741), np.float64(0.7096774193548387), np.float64(0.7135678391959799), np.float64(0.7511520737327189), np.float64(0.7733333333333333)]\n",
            "ID_TARGET: 175.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.2, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6495327102803738), np.float64(0.7201834862385321), np.float64(0.69377990430622), np.float64(0.7463414634146341), np.float64(0.696078431372549), np.float64(0.6367924528301887)]\n",
            "ID_TARGET: 151.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 200, 'reg_alpha': 0.3, 'reg_lambda': 1.5, 'subsample': 0.75} | Mean Accuracy: 0.7715 | Fold Accuracies: [np.float64(0.7450980392156863), np.float64(0.7373271889400922), np.float64(0.7384615384615385), np.float64(0.7547169811320755), np.float64(0.839622641509434), np.float64(0.7990430622009569)]\n",
            "ID_TARGET: 257.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7763 | Fold Accuracies: [np.float64(0.7521367521367521), np.float64(0.6860986547085202), np.float64(0.6812227074235808), np.float64(0.7767857142857143), np.float64(0.6588785046728972), np.float64(0.7850467289719626)]\n",
            "ID_TARGET: 75.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7988 | Fold Accuracies: [np.float64(0.7813953488372093), np.float64(0.7738693467336684), np.float64(0.8225108225108225), np.float64(0.7958333333333333), np.float64(0.7931034482758621), np.float64(0.7280701754385965)]\n",
            "ID_TARGET: 244.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6813 | Fold Accuracies: [np.float64(0.7027027027027027), np.float64(0.6826923076923077), np.float64(0.6981132075471698), np.float64(0.665158371040724), np.float64(0.6859903381642513), np.float64(0.6351931330472103)]\n",
            "ID_TARGET: 149.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7437 | Fold Accuracies: [np.float64(0.7090909090909091), np.float64(0.6618357487922706), np.float64(0.7718446601941747), np.float64(0.6745283018867925), np.float64(0.726027397260274), np.float64(0.7377777777777778)]\n",
            "ID_TARGET: 85.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7914 | Fold Accuracies: [np.float64(0.7523364485981309), np.float64(0.783410138248848), np.float64(0.7663551401869159), np.float64(0.7365853658536585), np.float64(0.7236180904522613), np.float64(0.8052631578947368)]\n",
            "ID_TARGET: 190.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7515 | Fold Accuracies: [np.float64(0.7729468599033816), np.float64(0.775330396475771), np.float64(0.6666666666666666), np.float64(0.72), np.float64(0.75), np.float64(0.7511737089201878)]\n",
            "ID_TARGET: 13.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.2, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8331 | Fold Accuracies: [np.float64(0.7342342342342343), np.float64(0.7313432835820896), np.float64(0.6842105263157895), np.float64(0.7488789237668162), np.float64(0.7703349282296651), np.float64(0.7889908256880734)]\n",
            "ID_TARGET: 228.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7582 | Fold Accuracies: [np.float64(0.7319148936170212), np.float64(0.73568281938326), np.float64(0.7439613526570048), np.float64(0.7297297297297297), np.float64(0.684931506849315), np.float64(0.7219730941704036)]\n",
            "ID_TARGET: 144.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7793 | Fold Accuracies: [np.float64(0.7122641509433962), np.float64(0.7638888888888888), np.float64(0.8), np.float64(0.7692307692307693), np.float64(0.7790055248618785), np.float64(0.7675438596491229)]\n",
            "ID_TARGET: 290.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.2, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.9324 | Fold Accuracies: [np.float64(0.6990740740740741), np.float64(0.7095238095238096), np.float64(0.7563451776649747), np.float64(0.6771300448430493), np.float64(0.6792452830188679), np.float64(0.6984924623115578)]\n",
            "ID_TARGET: 114.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7440 | Fold Accuracies: [np.float64(0.7136363636363636), np.float64(0.7014218009478673), np.float64(0.7236842105263158), np.float64(0.6962616822429907), np.float64(0.7725118483412322), np.float64(0.7122641509433962)]\n",
            "ID_TARGET: 166.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 200, 'reg_alpha': 0.3, 'reg_lambda': 1.5, 'subsample': 0.75} | Mean Accuracy: 0.7559 | Fold Accuracies: [np.float64(0.7474226804123711), np.float64(0.7918552036199095), np.float64(0.6954314720812182), np.float64(0.7489177489177489), np.float64(0.7276995305164319), np.float64(0.7431192660550459)]\n",
            "ID_TARGET: 234.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7719 | Fold Accuracies: [np.float64(0.7475247524752475), np.float64(0.7477064220183486), np.float64(0.8131868131868132), np.float64(0.7397959183673469), np.float64(0.7729468599033816), np.float64(0.7605633802816901)]\n",
            "ID_TARGET: 34.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7920 | Fold Accuracies: [np.float64(0.7316017316017316), np.float64(0.7524271844660194), np.float64(0.8160377358490566), np.float64(0.7695852534562212), np.float64(0.7830188679245284), np.float64(0.7644230769230769)]\n",
            "ID_TARGET: 154.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7810 | Fold Accuracies: [np.float64(0.7277486910994765), np.float64(0.7660550458715596), np.float64(0.8018867924528302), np.float64(0.788546255506608), np.float64(0.7380952380952381), np.float64(0.7905982905982906)]\n",
            "ID_TARGET: 225.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7399 | Fold Accuracies: [np.float64(0.6652542372881356), np.float64(0.7154811715481172), np.float64(0.7168141592920354), np.float64(0.6742081447963801), np.float64(0.7798165137614679), np.float64(0.7477876106194691)]\n",
            "ID_TARGET: 185.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7729 | Fold Accuracies: [np.float64(0.7135135135135136), np.float64(0.77), np.float64(0.7567567567567568), np.float64(0.7126436781609196), np.float64(0.7864583333333334), np.float64(0.719047619047619)]\n",
            "ID_TARGET: 39.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.2, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6732673267326733), np.float64(0.7560975609756098), np.float64(0.7488372093023256), np.float64(0.7359307359307359), np.float64(0.7931034482758621), np.float64(0.7961165048543689)]\n",
            "ID_TARGET: 272.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.2, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7820 | Fold Accuracies: [np.float64(0.8060344827586207), np.float64(0.7209302325581395), np.float64(0.7351598173515982), np.float64(0.8075117370892019), np.float64(0.7674418604651163), np.float64(0.8128342245989305)]\n",
            "ID_TARGET: 282.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7676 | Fold Accuracies: [np.float64(0.7205882352941176), np.float64(0.7130044843049327), np.float64(0.7546296296296297), np.float64(0.7647058823529411), np.float64(0.7761904761904762), np.float64(0.7488151658767772)]\n",
            "ID_TARGET: 90.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7687 | Fold Accuracies: [np.float64(0.7772511848341233), np.float64(0.7971014492753623), np.float64(0.7722772277227723), np.float64(0.7699530516431925), np.float64(0.7819905213270142), np.float64(0.7129629629629629)]\n",
            "ID_TARGET: 52.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7391 | Fold Accuracies: [np.float64(0.7453703703703703), np.float64(0.7427184466019418), np.float64(0.7268292682926829), np.float64(0.7180851063829787), np.float64(0.7819905213270142), np.float64(0.7095238095238096)]\n",
            "ID_TARGET: 258.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 200, 'reg_alpha': 0.3, 'reg_lambda': 1.5, 'subsample': 0.75} | Mean Accuracy: 0.7251 | Fold Accuracies: [np.float64(0.7216494845360825), np.float64(0.7168949771689498), np.float64(0.7101449275362319), np.float64(0.6633663366336634), np.float64(0.8090452261306532), np.float64(0.6777251184834123)]\n",
            "ID_TARGET: 291.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7728 | Fold Accuracies: [np.float64(0.7326732673267327), np.float64(0.7072072072072072), np.float64(0.7695852534562212), np.float64(0.7953488372093023), np.float64(0.7419354838709677), np.float64(0.7546296296296297)]\n",
            "ID_TARGET: 152.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7544 | Fold Accuracies: [np.float64(0.8), np.float64(0.7079207920792079), np.float64(0.7035175879396985), np.float64(0.775), np.float64(0.6901408450704225), np.float64(0.7927927927927928)]\n",
            "ID_TARGET: 133.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.7} | Mean Accuracy: 0.7732 | Fold Accuracies: [np.float64(0.7681159420289855), np.float64(0.7323943661971831), np.float64(0.7422222222222222), np.float64(0.7901785714285714), np.float64(0.7982062780269058), np.float64(0.8078817733990148)]\n",
            "ID_TARGET: 29.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7253 | Fold Accuracies: [np.float64(0.7077625570776256), np.float64(0.7740384615384616), np.float64(0.7216981132075472), np.float64(0.6915422885572139), np.float64(0.6714975845410628), np.float64(0.6790697674418604)]\n",
            "ID_TARGET: 274.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7650 | Fold Accuracies: [np.float64(0.751131221719457), np.float64(0.7435897435897436), np.float64(0.6962025316455697), np.float64(0.696969696969697), np.float64(0.7841409691629956), np.float64(0.7368421052631579)]\n",
            "ID_TARGET: 106.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7707 | Fold Accuracies: [np.float64(0.7433155080213903), np.float64(0.726775956284153), np.float64(0.6968085106382979), np.float64(0.714975845410628), np.float64(0.7105263157894737), np.float64(0.7869822485207101)]\n",
            "ID_TARGET: 173.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7941 | Fold Accuracies: [np.float64(0.7813953488372093), np.float64(0.7450980392156863), np.float64(0.7488584474885844), np.float64(0.7467248908296943), np.float64(0.7110091743119266), np.float64(0.8106796116504854)]\n",
            "ID_TARGET: 33.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7730 | Fold Accuracies: [np.float64(0.7194570135746606), np.float64(0.7311320754716981), np.float64(0.7653061224489796), np.float64(0.7575757575757576), np.float64(0.6905829596412556), np.float64(0.7489177489177489)]\n",
            "ID_TARGET: 69.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.2, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7292 | Fold Accuracies: [np.float64(0.7307692307692307), np.float64(0.6995073891625616), np.float64(0.7286432160804021), np.float64(0.7799043062200957), np.float64(0.6666666666666666), np.float64(0.7358490566037735)]\n",
            "ID_TARGET: 17.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7168 | Fold Accuracies: [np.float64(0.7136150234741784), np.float64(0.7230046948356808), np.float64(0.6763285024154589), np.float64(0.684931506849315), np.float64(0.7168141592920354), np.float64(0.6866359447004609)]\n",
            "ID_TARGET: 189.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7428 | Fold Accuracies: [np.float64(0.7582938388625592), np.float64(0.7387387387387387), np.float64(0.7452830188679245), np.float64(0.7149532710280374), np.float64(0.71), np.float64(0.675531914893617)]\n",
            "ID_TARGET: 284.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7384 | Fold Accuracies: [np.float64(0.7311320754716981), np.float64(0.7312775330396476), np.float64(0.7714285714285715), np.float64(0.7216981132075472), np.float64(0.6755555555555556), np.float64(0.7711442786069652)]\n",
            "ID_TARGET: 218.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7286 | Fold Accuracies: [np.float64(0.751219512195122), np.float64(0.6805555555555556), np.float64(0.6521739130434783), np.float64(0.7400881057268722), np.float64(0.722488038277512), np.float64(0.7256637168141593)]\n",
            "ID_TARGET: 183.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7812 | Fold Accuracies: [np.float64(0.759090909090909), np.float64(0.7431192660550459), np.float64(0.8018867924528302), np.float64(0.771689497716895), np.float64(0.7009803921568627), np.float64(0.7981220657276995)]\n",
            "ID_TARGET: 206.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7699 | Fold Accuracies: [np.float64(0.7313432835820896), np.float64(0.7594339622641509), np.float64(0.755), np.float64(0.7511961722488039), np.float64(0.7641921397379913), np.float64(0.7511961722488039)]\n",
            "ID_TARGET: 93.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7130 | Fold Accuracies: [np.float64(0.7089201877934272), np.float64(0.6807511737089202), np.float64(0.7320574162679426), np.float64(0.6682692307692307), np.float64(0.6355140186915887), np.float64(0.7488372093023256)]\n",
            "ID_TARGET: 16.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7216 | Fold Accuracies: [np.float64(0.7375565610859729), np.float64(0.7303921568627451), np.float64(0.726457399103139), np.float64(0.6697674418604651), np.float64(0.6909090909090909), np.float64(0.7303921568627451)]\n",
            "ID_TARGET: 246.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7639 | Fold Accuracies: [np.float64(0.7672413793103449), np.float64(0.8223350253807107), np.float64(0.7649769585253456), np.float64(0.677570093457944), np.float64(0.7111111111111111), np.float64(0.7040358744394619)]\n",
            "ID_TARGET: 167.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7908 | Fold Accuracies: [np.float64(0.7439613526570048), np.float64(0.7180851063829787), np.float64(0.7574257425742574), np.float64(0.7061611374407583), np.float64(0.7511961722488039), np.float64(0.783410138248848)]\n",
            "ID_TARGET: 1.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7549 | Fold Accuracies: [np.float64(0.7524752475247525), np.float64(0.7524271844660194), np.float64(0.7277227722772277), np.float64(0.7574257425742574), np.float64(0.7736842105263158), np.float64(0.685)]\n",
            "ID_TARGET: 289.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7478 | Fold Accuracies: [np.float64(0.7272727272727273), np.float64(0.6826086956521739), np.float64(0.6929824561403509), np.float64(0.7621359223300971), np.float64(0.7370892018779343), np.float64(0.7718446601941747)]\n",
            "ID_TARGET: 141.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7962 | Fold Accuracies: [np.float64(0.8), np.float64(0.7867298578199052), np.float64(0.7760416666666666), np.float64(0.8066037735849056), np.float64(0.7607655502392344), np.float64(0.7685185185185185)]\n",
            "ID_TARGET: 109.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7522 | Fold Accuracies: [np.float64(0.7098214285714286), np.float64(0.7348837209302326), np.float64(0.7688679245283019), np.float64(0.6972477064220184), np.float64(0.7533632286995515), np.float64(0.6986899563318777)]\n",
            "ID_TARGET: 19.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7759 | Fold Accuracies: [np.float64(0.7610619469026548), np.float64(0.7772727272727272), np.float64(0.8177339901477833), np.float64(0.755), np.float64(0.7731481481481481), np.float64(0.7566371681415929)]\n",
            "ID_TARGET: 28.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7119 | Fold Accuracies: [np.float64(0.7378640776699029), np.float64(0.711340206185567), np.float64(0.705), np.float64(0.7064220183486238), np.float64(0.7276995305164319), np.float64(0.6826086956521739)]\n",
            "ID_TARGET: 251.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.7} | Mean Accuracy: 0.7238 | Fold Accuracies: [np.float64(0.7115384615384616), np.float64(0.7163461538461539), np.float64(0.6899563318777293), np.float64(0.7452830188679245), np.float64(0.7345971563981043), np.float64(0.7450980392156863)]\n",
            "ID_TARGET: 278.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7499 | Fold Accuracies: [np.float64(0.7227722772277227), np.float64(0.7661691542288557), np.float64(0.821256038647343), np.float64(0.7342995169082126), np.float64(0.6751269035532995), np.float64(0.77)]\n",
            "ID_TARGET: 76.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7513 | Fold Accuracies: [np.float64(0.75), np.float64(0.7633928571428571), np.float64(0.7681159420289855), np.float64(0.7351598173515982), np.float64(0.6666666666666666), np.float64(0.7383177570093458)]\n",
            "ID_TARGET: 241.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7732 | Fold Accuracies: [np.float64(0.7464114832535885), np.float64(0.7329842931937173), np.float64(0.7927461139896373), np.float64(0.7414634146341463), np.float64(0.7216494845360825), np.float64(0.6995073891625616)]\n",
            "ID_TARGET: 214.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.8032 | Fold Accuracies: [np.float64(0.7844827586206896), np.float64(0.7817258883248731), np.float64(0.8251121076233184), np.float64(0.7285067873303167), np.float64(0.695852534562212), np.float64(0.8160377358490566)]\n",
            "ID_TARGET: 102.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7887 | Fold Accuracies: [np.float64(0.7632850241545893), np.float64(0.7706422018348624), np.float64(0.7897435897435897), np.float64(0.7788944723618091), np.float64(0.7936507936507936), np.float64(0.7064220183486238)]\n",
            "ID_TARGET: 145.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7404 | Fold Accuracies: [np.float64(0.7960199004975125), np.float64(0.6636771300448431), np.float64(0.6682692307692307), np.float64(0.7230046948356808), np.float64(0.6602870813397129), np.float64(0.6504424778761062)]\n",
            "ID_TARGET: 155.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.8094 | Fold Accuracies: [np.float64(0.8486238532110092), np.float64(0.755656108597285), np.float64(0.7616822429906542), np.float64(0.7878787878787878), np.float64(0.7878787878787878), np.float64(0.8202764976958525)]\n",
            "\n",
            "Performing second-pass training with top 30 features...\n",
            "\n",
            "Second-pass LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rLightGBM Targets:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   1%|          | 1/100 [00:00<01:38,  1.00it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   2%|         | 2/100 [00:01<01:18,  1.25it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   3%|         | 3/100 [00:02<01:11,  1.35it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   4%|         | 4/100 [00:02<01:05,  1.46it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   5%|         | 5/100 [00:03<01:00,  1.57it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   6%|         | 6/100 [00:04<00:56,  1.66it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   7%|         | 7/100 [00:04<00:52,  1.78it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   8%|         | 8/100 [00:05<01:04,  1.43it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   9%|         | 9/100 [00:06<01:13,  1.25it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  10%|         | 10/100 [00:07<01:14,  1.21it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  11%|         | 11/100 [00:08<01:18,  1.13it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  12%|        | 12/100 [00:09<01:10,  1.24it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  13%|        | 13/100 [00:09<01:08,  1.28it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  14%|        | 14/100 [00:10<01:05,  1.31it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  15%|        | 15/100 [00:11<01:01,  1.38it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  16%|        | 16/100 [00:11<01:00,  1.39it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  17%|        | 17/100 [00:12<00:59,  1.40it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  18%|        | 18/100 [00:13<00:54,  1.50it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  19%|        | 19/100 [00:13<00:55,  1.45it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  20%|        | 20/100 [00:14<00:52,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  21%|        | 21/100 [00:14<00:50,  1.58it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  22%|       | 22/100 [00:15<00:49,  1.59it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  23%|       | 23/100 [00:16<00:47,  1.62it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  24%|       | 24/100 [00:16<00:46,  1.64it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  25%|       | 25/100 [00:17<00:45,  1.66it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  26%|       | 26/100 [00:17<00:45,  1.64it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  27%|       | 27/100 [00:18<00:50,  1.45it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  28%|       | 28/100 [00:19<00:51,  1.40it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  29%|       | 29/100 [00:20<00:54,  1.30it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  30%|       | 30/100 [00:21<00:58,  1.20it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  31%|       | 31/100 [00:22<00:51,  1.35it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  32%|      | 32/100 [00:22<00:46,  1.45it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  33%|      | 33/100 [00:23<00:43,  1.55it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  34%|      | 34/100 [00:23<00:40,  1.64it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  35%|      | 35/100 [00:24<00:39,  1.64it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  36%|      | 36/100 [00:24<00:38,  1.65it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  37%|      | 37/100 [00:25<00:38,  1.65it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  38%|      | 38/100 [00:26<00:36,  1.71it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  39%|      | 39/100 [00:26<00:36,  1.69it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  40%|      | 40/100 [00:27<00:35,  1.67it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  41%|      | 41/100 [00:27<00:37,  1.57it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  42%|     | 42/100 [00:28<00:35,  1.62it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  43%|     | 43/100 [00:29<00:34,  1.68it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  44%|     | 44/100 [00:29<00:32,  1.72it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  45%|     | 45/100 [00:30<00:32,  1.71it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  46%|     | 46/100 [00:30<00:31,  1.72it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  47%|     | 47/100 [00:31<00:31,  1.69it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  48%|     | 48/100 [00:32<00:35,  1.47it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  49%|     | 49/100 [00:33<00:36,  1.41it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  50%|     | 50/100 [00:34<00:38,  1.29it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  51%|     | 51/100 [00:34<00:39,  1.24it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  52%|    | 52/100 [00:35<00:35,  1.34it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  53%|    | 53/100 [00:36<00:32,  1.46it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  54%|    | 54/100 [00:36<00:30,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  55%|    | 55/100 [00:37<00:29,  1.54it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  56%|    | 56/100 [00:37<00:27,  1.60it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  57%|    | 57/100 [00:38<00:25,  1.66it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  58%|    | 58/100 [00:38<00:25,  1.66it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  59%|    | 59/100 [00:39<00:24,  1.68it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  60%|    | 60/100 [00:40<00:23,  1.69it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  61%|    | 61/100 [00:40<00:23,  1.69it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  62%|   | 62/100 [00:41<00:21,  1.73it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  63%|   | 63/100 [00:41<00:20,  1.77it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  64%|   | 64/100 [00:42<00:20,  1.77it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  65%|   | 65/100 [00:43<00:20,  1.72it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  66%|   | 66/100 [00:43<00:19,  1.76it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  67%|   | 67/100 [00:44<00:19,  1.72it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  68%|   | 68/100 [00:44<00:18,  1.73it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  69%|   | 69/100 [00:45<00:19,  1.59it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  70%|   | 70/100 [00:46<00:20,  1.47it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  71%|   | 71/100 [00:47<00:20,  1.38it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  72%|  | 72/100 [00:47<00:21,  1.29it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  73%|  | 73/100 [00:48<00:20,  1.35it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  74%|  | 74/100 [00:49<00:17,  1.47it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  75%|  | 75/100 [00:49<00:16,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  76%|  | 76/100 [00:50<00:15,  1.57it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  77%|  | 77/100 [00:50<00:14,  1.60it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  78%|  | 78/100 [00:51<00:13,  1.63it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  79%|  | 79/100 [00:52<00:12,  1.66it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  80%|  | 80/100 [00:52<00:12,  1.64it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  81%|  | 81/100 [00:53<00:11,  1.66it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  82%| | 82/100 [00:54<00:11,  1.61it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  83%| | 83/100 [00:54<00:10,  1.63it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  84%| | 84/100 [00:55<00:09,  1.61it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  85%| | 85/100 [00:55<00:09,  1.65it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  86%| | 86/100 [00:56<00:08,  1.69it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  87%| | 87/100 [00:56<00:07,  1.69it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  88%| | 88/100 [00:57<00:06,  1.72it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  89%| | 89/100 [00:58<00:06,  1.72it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  90%| | 90/100 [00:58<00:06,  1.55it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  91%| | 91/100 [00:59<00:06,  1.44it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  92%|| 92/100 [01:00<00:06,  1.32it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  93%|| 93/100 [01:01<00:05,  1.25it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  94%|| 94/100 [01:02<00:04,  1.32it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  95%|| 95/100 [01:02<00:03,  1.42it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  96%|| 96/100 [01:03<00:02,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  97%|| 97/100 [01:03<00:01,  1.60it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  98%|| 98/100 [01:04<00:01,  1.68it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  99%|| 99/100 [01:05<00:00,  1.66it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets: 100%|| 100/100 [01:05<00:00,  1.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Second-pass XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Targets: 100%|| 100/100 [01:25<00:00,  1.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Performing third-pass training for low-performing targets...\n",
            "\n",
            "Third-pass LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "LightGBM Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 53648.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Third-pass XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 36792.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved hyperparameter log to: /content/hyperparameters.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_d71b697a-5d45-4e16-899b-b16773d83498\", \"hyperparameters.json\", 846418)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved predictions to: /content/predictions_ensemble.csv\n",
            "Output CSV shape: (114468, 2)\n",
            "Output CSV ID range: 0 to 114467\n",
            "Unique RET_TARGET values: [ 1 -1]\n",
            "Missing values: 0\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_b64a9d8a-6cd8-4ef1-820c-aadea6fff049\", \"predictions_ensemble.csv\", 968985)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Results:\n",
            "LightGBM: 0.7518\n",
            "XGBoost: 0.7638\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost\n",
        "from sklearn.decomposition import PCA\n",
        "from joblib import Parallel, delayed\n",
        "import json\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# Check xgboost version for compatibility\n",
        "print(f\"XGBoost version: {xgboost.__version__}\")\n",
        "if int(xgboost.__version__.split('.')[0]) < 1:\n",
        "    print(\"Warning: XGBoost version < 1.0.0 detected. Ensure compatibility with eval_metric in constructor.\")\n",
        "\n",
        "# Set up data directory\n",
        "DATA_DIR = '/content'\n",
        "\n",
        "# Load datasets\n",
        "try:\n",
        "    X_train = pd.read_csv(os.path.join(DATA_DIR, 'X_train_itDkypA.csv'), index_col='ID', dtype=np.float32)\n",
        "    y_train = pd.read_csv(os.path.join(DATA_DIR, 'y_train_3LeeT2g.csv'), index_col='ID', dtype=np.float32)\n",
        "    X_test = pd.read_csv(os.path.join(DATA_DIR, 'X_test_Beg4ey3.csv'), index_col='ID', dtype=np.float32)\n",
        "    supplementary = pd.read_csv(os.path.join(DATA_DIR, 'supplementary_data_Vkoyn8z.csv'))\n",
        "except FileNotFoundError as e:\n",
        "    raise FileNotFoundError(f\"Dataset not found: {e}. Please ensure files are uploaded to {DATA_DIR}.\")\n",
        "\n",
        "# Custom weighted accuracy metric\n",
        "def weighted_accuracy(y_true, y_pred, weights):\n",
        "    y_pred_mapped = np.where(y_pred == 1, 1, -1)\n",
        "    correct = (y_pred_mapped == np.sign(y_true)).astype(float)\n",
        "    return np.sum(np.abs(y_true) * correct) / np.sum(np.abs(y_true))\n",
        "\n",
        "# Preprocess data with enhanced feature selection\n",
        "def preprocess_data(X, y=None, supplementary=None, is_train=True, top_cols=None):\n",
        "    ret_cols = [col for col in X.columns if col.startswith('RET_')]\n",
        "    if is_train and top_cols is None:\n",
        "        if len(ret_cols) > 15:\n",
        "            variances = X[ret_cols].var()\n",
        "            corr_sum = X[ret_cols].corr().abs().sum()\n",
        "            combined_score = variances * corr_sum\n",
        "            valid_cols = variances[variances > 1e-5].index\n",
        "            if len(valid_cols) < 15:\n",
        "                top_cols = valid_cols.tolist()\n",
        "            else:\n",
        "                top_cols = combined_score.loc[valid_cols].sort_values(ascending=False).head(15).index.tolist()\n",
        "        else:\n",
        "            top_cols = ret_cols\n",
        "        print(f\"Selected top return columns: {top_cols}\")\n",
        "    elif top_cols is not None:\n",
        "        ret_cols = [col for col in ret_cols if col in top_cols]\n",
        "        if not ret_cols:\n",
        "            raise ValueError(\"No return columns selected. Check top_cols consistency.\")\n",
        "\n",
        "    sector_medians = {}\n",
        "    if supplementary is not None:\n",
        "        sector_map = supplementary.set_index('ID_asset')['CLASS_LEVEL_1']\n",
        "        for col in ret_cols:\n",
        "            asset_id = int(col.replace('RET_', ''))\n",
        "            sector = sector_map.get(asset_id, np.nan)\n",
        "            if pd.notna(sector):\n",
        "                sector_assets = supplementary[supplementary['CLASS_LEVEL_1'] == sector]['ID_asset']\n",
        "                sector_cols = [f'RET_{a}' for a in sector_assets if f'RET_{a}' in X.columns]\n",
        "                if sector_cols:\n",
        "                    sector_medians[col] = X[sector_cols].median(axis=1)\n",
        "            if col in sector_medians:\n",
        "                X[col] = X[col].fillna(sector_medians[col])\n",
        "            else:\n",
        "                X[col] = X[col].fillna(X[col].median())\n",
        "\n",
        "    new_cols = {}\n",
        "    if supplementary is not None:\n",
        "        level = 'CLASS_LEVEL_1'\n",
        "        sector_groups = supplementary.groupby(level)['ID_asset'].apply(list).to_dict()\n",
        "        for sector, assets in sector_groups.items():\n",
        "            asset_cols = [f'RET_{asset}' for asset in assets if f'RET_{asset}' in ret_cols]\n",
        "            if asset_cols:\n",
        "                new_cols[f'SECTOR_AVG_{level}_{sector}'] = X[asset_cols].mean(axis=1).replace([np.inf, -np.inf], 0).fillna(0)\n",
        "        X = X.merge(supplementary[['ID_asset', level]].rename(columns={'ID_asset': 'ID_TARGET', level: f'TARGET_{level}'}),\n",
        "                    on='ID_TARGET', how='left')\n",
        "        X = pd.concat([X, pd.get_dummies(X[f'TARGET_{level}'], prefix=f'TARGET_{level}', dummy_na=True)], axis=1)\n",
        "        X = X.drop(f'TARGET_{level}', axis=1)\n",
        "\n",
        "    new_cols['MEAN_RET'] = X[ret_cols].mean(axis=1)\n",
        "    new_cols['STD_RET'] = X[ret_cols].std(axis=1)\n",
        "    new_cols.update({f'CS_RANK_{col}': X.groupby('ID_DAY')[col].rank(pct=True).replace([np.inf, -np.inf], 0).fillna(0) for col in ret_cols})\n",
        "\n",
        "    if is_train:\n",
        "        corr_matrix = X[ret_cols].corr()\n",
        "        corr_pairs = corr_matrix.unstack().sort_values(ascending=False)\n",
        "        top_pairs = [(i, j) for i, j in corr_pairs.index if i < j][:5]\n",
        "        for i, j in top_pairs:\n",
        "            new_cols[f'CORR_{i}_{j}'] = X[i] * X[j]\n",
        "\n",
        "    if ret_cols:\n",
        "        pca = PCA(n_components=min(2, len(ret_cols)), random_state=42)\n",
        "        pca_features = pca.fit_transform(X[ret_cols].fillna(0))\n",
        "        for i in range(pca_features.shape[1]):\n",
        "            new_cols[f'PCA_{i}'] = pca_features[:, i]\n",
        "\n",
        "    new_cols_df = pd.DataFrame(new_cols, index=X.index, dtype=np.float32)\n",
        "    X = pd.concat([X, new_cols_df], axis=1)\n",
        "\n",
        "    feature_cols = [col for col in X.columns if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "    scaler = StandardScaler()\n",
        "    X[feature_cols] = scaler.fit_transform(X[feature_cols].replace([np.inf, -np.inf], 0).fillna(0))\n",
        "\n",
        "    if is_train:\n",
        "        y['SIGN_TARGET'] = np.where(y['RET_TARGET'] > 0, 1, 0).astype(np.int32)\n",
        "        return X, y, feature_cols, top_cols\n",
        "    return X, None, feature_cols, top_cols\n",
        "\n",
        "# Preprocess data\n",
        "try:\n",
        "    X_train, y_train, feature_cols, top_cols = preprocess_data(X_train, y_train, supplementary, is_train=True)\n",
        "    X_test, _, test_feature_cols, _ = preprocess_data(X_test, supplementary=supplementary, is_train=False, top_cols=top_cols)\n",
        "except ValueError as e:\n",
        "    print(f\"Preprocessing error: {e}\")\n",
        "    raise\n",
        "\n",
        "# Align columns\n",
        "common_cols = X_train.columns.intersection(X_test.columns)\n",
        "X_train = X_train[common_cols]\n",
        "X_test = X_test[common_cols]\n",
        "feature_cols = [col for col in common_cols if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "\n",
        "# Align y_train\n",
        "y_train = y_train.loc[X_train.index]\n",
        "\n",
        "# Define models with intermediate hyperparameter grids\n",
        "models = {\n",
        "    'LightGBM': {\n",
        "        'model': LGBMClassifier(num_leaves=31, min_child_samples=15, lambda_l1=0.3, lambda_l2=0.3,\n",
        "                                subsample=0.7, colsample_bytree=0.8, bagging_freq=5, bagging_fraction=0.7,\n",
        "                                random_state=42, n_jobs=1, verbosity=-1, class_weight='balanced', force_row_wise=True),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.01], 'num_leaves': [15], 'min_child_samples': [20], 'bagging_fraction': [0.6], 'reg_alpha': [0.0], 'reg_lambda': [0.0]},\n",
        "            {'learning_rate': [0.03], 'num_leaves': [31], 'min_child_samples': [10], 'bagging_fraction': [0.7], 'reg_alpha': [0.1], 'reg_lambda': [0.1]},\n",
        "            {'learning_rate': [0.05], 'num_leaves': [47], 'min_child_samples': [15], 'bagging_fraction': [0.8], 'reg_alpha': [0.2], 'reg_lambda': [0.2]},\n",
        "            {'learning_rate': [0.07], 'num_leaves': [63], 'min_child_samples': [12], 'bagging_fraction': [0.65], 'reg_alpha': [0.3], 'reg_lambda': [0.3]},\n",
        "            {'learning_rate': [0.02], 'num_leaves': [31], 'min_child_samples': [20], 'bagging_fraction': [0.75], 'reg_alpha': [0.1], 'reg_lambda': [0.1]}\n",
        "        ],\n",
        "        'callbacks': [lightgbm.early_stopping(stopping_rounds=12, verbose=False)]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'model': XGBClassifier(max_depth=4, min_child_weight=2, subsample=0.8, colsample_bytree=0.8,\n",
        "                               random_state=42, n_jobs=1, eval_metric='logloss', verbosity=0,\n",
        "                               scale_pos_weight=len(y_train[y_train['SIGN_TARGET'] == 0]) / len(y_train[y_train['SIGN_TARGET'] == 1])),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.01], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [150], 'reg_alpha': [0.0], 'reg_lambda': [1.0]},\n",
        "            {'learning_rate': [0.03], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [200], 'reg_alpha': [0.1], 'reg_lambda': [1.5]},\n",
        "            {'learning_rate': [0.05], 'max_depth': [5], 'min_child_weight': [3], 'subsample': [0.8], 'n_estimators': [150], 'reg_alpha': [0.2], 'reg_lambda': [1.0]},\n",
        "            {'learning_rate': [0.07], 'max_depth': [6], 'min_child_weight': [1], 'subsample': [0.75], 'n_estimators': [200], 'reg_alpha': [0.3], 'reg_lambda': [1.5]},\n",
        "            {'learning_rate': [0.02], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [200], 'reg_alpha': [0.1], 'reg_lambda': [1.2]}\n",
        "        ],\n",
        "        'callbacks': [xgboost.callback.EarlyStopping(rounds=12, metric_name='logloss', save_best=True)]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to train and predict for a single target\n",
        "def train_target(target, X_train, y_train, X_test, feature_cols, model, model_name, kf, param_grid, callbacks):\n",
        "    X_target = X_train[X_train['ID_TARGET'] == target][feature_cols]\n",
        "    y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "    weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "    low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "    weight_scale = 2.5 if target in low_performing_targets else 1.0\n",
        "    if len(X_target) < 500:\n",
        "        weight_scale *= 1.5\n",
        "    weights = weights * weight_scale\n",
        "    groups = X_train[X_train['ID_TARGET'] == target]['ID_DAY']\n",
        "    X_test_target = X_test[X_test['ID_TARGET'] == target][feature_cols]\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "    if len(X_target) < 100 or len(X_test_target) == 0:\n",
        "        print(f\"Warning: Insufficient data for ID_TARGET {target} (train: {len(X_target)}, test: {len(X_test_target)}). Skipping.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    param_results = []\n",
        "    best_params = None\n",
        "    best_score = 0\n",
        "    best_model = None\n",
        "\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        print(f\"Testing params for {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "        try:\n",
        "            model.set_params(**params)\n",
        "        except ValueError as e:\n",
        "            print(f\"Invalid params for {model_name} ID_TARGET {target}: {e}\")\n",
        "            continue\n",
        "        fold_accuracies = []\n",
        "        for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "            X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "            y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "            w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "            if model_name == 'LightGBM' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=callbacks)\n",
        "            elif model_name == 'XGBoost' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "            else:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "            y_pred = model.predict(X_val)\n",
        "            acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "            fold_accuracies.append(acc)\n",
        "        mean_acc = np.mean(fold_accuracies)\n",
        "        print(f\"{model_name} | ID_TARGET: {target} | Params: {params} | Mean Accuracy: {mean_acc:.4f} | Fold Accuracies: {fold_accuracies}\", flush=True)\n",
        "        param_results.append({\n",
        "            'params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': fold_accuracies\n",
        "        })\n",
        "        if mean_acc > best_score:\n",
        "            best_score = mean_acc\n",
        "            best_params = params\n",
        "            best_model = type(model)(**model.get_params())\n",
        "\n",
        "    if best_model is None:\n",
        "        print(f\"No valid model for {model_name} ID_TARGET {target}. Using default.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    best_model.set_params(**best_params)\n",
        "    if model_name == 'LightGBM' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=callbacks)\n",
        "    elif model_name == 'XGBoost' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "    else:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights)\n",
        "    preds = best_model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "    importance = best_model.feature_importances_\n",
        "    feature_importance = dict(zip(feature_cols, importance))\n",
        "    top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:30]\n",
        "    gc.collect()\n",
        "    return str(target), best_params, best_score, param_results, test_ids, preds, top_features\n",
        "\n",
        "# Cross-validation and training\n",
        "kf = GroupKFold(n_splits=6)\n",
        "results = {}\n",
        "predictions = {}\n",
        "ensemble_weights = {'LightGBM': 0.7, 'XGBoost': 0.3}\n",
        "param_log = {}\n",
        "top_features_all = {}\n",
        "param_summary = []\n",
        "low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\", flush=True)\n",
        "    param_log[model_name] = {}\n",
        "    top_features_all[model_name] = {}\n",
        "    results_parallel = Parallel(n_jobs=-1)(\n",
        "        delayed(train_target)(target, X_train, y_train, X_test, feature_cols, model_info['model'], model_name, kf,\n",
        "                             model_info['param_grid'], model_info['callbacks'])\n",
        "        for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\")\n",
        "    )\n",
        "    accuracies = []\n",
        "    for target, params, mean_acc, param_results, test_ids, preds, top_features in results_parallel:\n",
        "        param_log[model_name][target] = {\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'all_params': param_results\n",
        "        }\n",
        "        top_features_all[model_name][target] = top_features\n",
        "        accuracies.append(mean_acc)\n",
        "        predictions.setdefault(target, {})[model_name] = dict(zip(test_ids, preds))\n",
        "        param_summary.append({\n",
        "            'model': model_name,\n",
        "            'ID_TARGET': target,\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': param_results[-1]['fold_accuracies'] if param_results else []\n",
        "        })\n",
        "    results[model_name] = np.mean([acc for acc in accuracies if acc > 0])\n",
        "    print(f\"{model_name} Weighted Accuracy: {results[model_name]:.4f}\", flush=True)\n",
        "    print(f\"\\n{model_name} Parameter Summary:\", flush=True)\n",
        "    for summary in param_summary:\n",
        "        if summary['model'] == model_name:\n",
        "            print(f\"ID_TARGET: {summary['ID_TARGET']} | Best Params: {summary['best_params']} | Mean Accuracy: {summary['mean_accuracy']:.4f} | Fold Accuracies: {summary['fold_accuracies']}\", flush=True)\n",
        "\n",
        "# Second-pass training with top 30 features\n",
        "print(\"\\nPerforming second-pass training with top 30 features...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nSecond-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\"):\n",
        "        target_str = str(target)\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "        weight_scale = 2.5 if target in low_performing_targets else 1.0\n",
        "        if len(X_target) < 500:\n",
        "            weight_scale *= 1.5\n",
        "        weights = weights * weight_scale\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        best_params['n_estimators'] = 250\n",
        "        model.set_params(**best_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Third-pass training for low-performing targets\n",
        "print(\"\\nPerforming third-pass training for low-performing targets...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nThird-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(low_performing_targets, desc=f\"{model_name} Low-Performing Targets\"):\n",
        "        target_str = str(target)\n",
        "        if target_str not in param_log[model_name] or param_log[model_name][target_str]['mean_accuracy'] >= 0.75:\n",
        "            continue\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs() * 2.5\n",
        "        if len(X_target) < 500:\n",
        "            weights = weights * 1.5\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        fine_tune_grid = [\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.7, 'n_estimators': 300, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.0, 'n_estimators': 300, 'reg_alpha': best_params['reg_alpha'][0], 'reg_lambda': best_params['reg_lambda'][0]},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.3, 'n_estimators': 350, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1}\n",
        "        ]\n",
        "        best_score = param_log[model_name][target_str]['mean_accuracy']\n",
        "        best_fine_params = best_params\n",
        "        for params in ParameterGrid(fine_tune_grid):\n",
        "            print(f\"Fine-tuning {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "            model.set_params(**params)\n",
        "            fold_accuracies = []\n",
        "            for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "                X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "                y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "                w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "                if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "                elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "                else:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "                y_pred = model.predict(X_val)\n",
        "                acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "                fold_accuracies.append(acc)\n",
        "            mean_acc = np.mean(fold_accuracies)\n",
        "            print(f\"{model_name} | ID_TARGET: {target} | Fine-tune Params: {params} | Mean Accuracy: {mean_acc:.4f}\", flush=True)\n",
        "            if mean_acc > best_score:\n",
        "                best_score = mean_acc\n",
        "                best_fine_params = params\n",
        "                param_log[model_name][target_str]['best_params'] = best_fine_params\n",
        "                param_log[model_name][target_str]['mean_accuracy'] = best_score\n",
        "                param_summary.append({\n",
        "                    'model': model_name,\n",
        "                    'ID_TARGET': target_str,\n",
        "                    'best_params': best_fine_params,\n",
        "                    'mean_accuracy': best_score,\n",
        "                    'fold_accuracies': fold_accuracies\n",
        "                })\n",
        "        model.set_params(**best_fine_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Save parameter log\n",
        "param_log_path = os.path.join(DATA_DIR, 'hyperparameters.json')\n",
        "with open(param_log_path, 'w') as f:\n",
        "    json.dump(param_log, f, indent=4)\n",
        "print(f\"Saved hyperparameter log to: {param_log_path}\", flush=True)\n",
        "files.download(param_log_path)\n",
        "\n",
        "# Ensemble predictions\n",
        "final_predictions = {}\n",
        "missing_day_targets = []\n",
        "for target in X_test['ID_TARGET'].unique():\n",
        "    target_str = str(target)\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "    for day in X_test[X_test['ID_TARGET'] == target]['ID_DAY'].unique():\n",
        "        day_idx = (X_test['ID_TARGET'] == target) & (X_test['ID_DAY'] == day)\n",
        "        day_test_ids = X_test[day_idx].index\n",
        "        if len(day_test_ids) == 0:\n",
        "            print(f\"Warning: No test samples for ID_TARGET {target} on ID_DAY {day}. Using default prediction.\")\n",
        "            missing_day_targets.append((target, day))\n",
        "            for idx in test_ids:\n",
        "                final_predictions[idx] = -1\n",
        "            continue\n",
        "        lgbm_preds = np.array([predictions[target_str].get('LightGBM', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        xgb_preds = np.array([predictions[target_str].get('XGBoost', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        ensemble_preds = ensemble_weights['LightGBM'] * lgbm_preds + ensemble_weights['XGBoost'] * xgb_preds\n",
        "        smoothed_preds = pd.Series(ensemble_preds).ewm(span=3).mean().values[-1] if len(ensemble_preds) > 0 else 0.5\n",
        "        for idx in day_test_ids:\n",
        "            final_predictions[idx] = 1 if smoothed_preds >= 0.5 else -1\n",
        "\n",
        "if missing_day_targets:\n",
        "    print(f\"Missing day-target pairs: {missing_day_targets}\")\n",
        "\n",
        "# Create output CSV\n",
        "output_df = pd.DataFrame.from_dict(final_predictions, orient='index', columns=['RET_TARGET']).reset_index()\n",
        "output_df.columns = ['ID', 'RET_TARGET']\n",
        "output_df = output_df.sort_values('ID')\n",
        "expected_ids = set(X_test.index)\n",
        "submission_ids = set(output_df['ID'])\n",
        "if expected_ids != submission_ids:\n",
        "    missing_ids = expected_ids - submission_ids\n",
        "    print(f\"Warning: Submission missing {len(missing_ids)} IDs: {missing_ids}\")\n",
        "    missing_df = pd.DataFrame({'ID': list(missing_ids), 'RET_TARGET': -1})\n",
        "    output_df = pd.concat([output_df, missing_df], ignore_index=True).sort_values('ID')\n",
        "output_path = os.path.join(DATA_DIR, 'predictions_ensemble.csv')\n",
        "output_df.to_csv(output_path, index=False)\n",
        "print(f\"Saved predictions to: {output_path}\", flush=True)\n",
        "\n",
        "# Validate output\n",
        "test_csv = pd.read_csv(output_path)\n",
        "print(f\"Output CSV shape: {test_csv.shape}\", flush=True)\n",
        "print(f\"Output CSV ID range: {test_csv['ID'].min()} to {test_csv['ID'].max()}\", flush=True)\n",
        "print(f\"Unique RET_TARGET values: {test_csv['RET_TARGET'].unique()}\", flush=True)\n",
        "print(f\"Missing values: {test_csv.isna().sum().sum()}\", flush=True)\n",
        "\n",
        "# Download the file\n",
        "files.download(output_path)\n",
        "\n",
        "# Print final results\n",
        "print(\"\\nValidation Results:\", flush=True)\n",
        "for model_name, acc in results.items():\n",
        "    print(f\"{model_name}: {acc:.4f}\", flush=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzPDQ2VY9hkP"
      },
      "source": [
        "try 2 -- 73.9%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I7q4-cNsRUQ_",
        "outputId": "168cc939-3895-4d6c-f1ad-96b56a4bf5ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost version: 2.1.4\n",
            "Selected top return columns: ['RET_262', 'RET_88', 'RET_172', 'RET_259', 'RET_150', 'RET_118', 'RET_216', 'RET_268', 'RET_115', 'RET_261', 'RET_59', 'RET_238', 'RET_121', 'RET_97', 'RET_30']\n",
            "\n",
            "Training LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LightGBM Targets: 100%|| 100/100 [33:29<00:00, 20.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightGBM Weighted Accuracy: 0.7546\n",
            "\n",
            "LightGBM Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9423 | Fold Accuracies: [np.float64(0.7219251336898396), np.float64(0.7456647398843931), np.float64(0.8770949720670391), np.float64(0.7614213197969543), np.float64(0.8132530120481928), np.float64(0.7666666666666667), np.float64(0.8143712574850299)]\n",
            "ID_TARGET: 129.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.6764 | Fold Accuracies: [np.float64(0.550561797752809), np.float64(0.6628571428571428), np.float64(0.6793478260869565), np.float64(0.6091954022988506), np.float64(0.6892655367231638), np.float64(0.6703910614525139), np.float64(0.605)]\n",
            "ID_TARGET: 136.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.6486 | Fold Accuracies: [np.float64(0.6534090909090909), np.float64(0.6871794871794872), np.float64(0.6329787234042553), np.float64(0.5674157303370787), np.float64(0.6171428571428571), np.float64(0.6386138613861386), np.float64(0.5935828877005348)]\n",
            "ID_TARGET: 161.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.6938 | Fold Accuracies: [np.float64(0.6534090909090909), np.float64(0.6594594594594595), np.float64(0.6737967914438503), np.float64(0.625), np.float64(0.7231638418079096), np.float64(0.6766169154228856), np.float64(0.7119565217391305)]\n",
            "ID_TARGET: 217.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7291 | Fold Accuracies: [np.float64(0.6884422110552764), np.float64(0.6208791208791209), np.float64(0.6714975845410628), np.float64(0.7128205128205128), np.float64(0.6683417085427136), np.float64(0.7754010695187166), np.float64(0.649746192893401)]\n",
            "ID_TARGET: 91.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7349 | Fold Accuracies: [np.float64(0.6382978723404256), np.float64(0.702247191011236), np.float64(0.6413043478260869), np.float64(0.6810810810810811), np.float64(0.6720430107526881), np.float64(0.7403314917127072), np.float64(0.7471910112359551)]\n",
            "ID_TARGET: 137.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.6871 | Fold Accuracies: [np.float64(0.6936416184971098), np.float64(0.675), np.float64(0.6352201257861635), np.float64(0.6063829787234043), np.float64(0.6724137931034483), np.float64(0.6900584795321637), np.float64(0.6746987951807228)]\n",
            "ID_TARGET: 8.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7981 | Fold Accuracies: [np.float64(0.7396449704142012), np.float64(0.6878612716763006), np.float64(0.695906432748538), np.float64(0.7225130890052356), np.float64(1.0), np.float64(0.686046511627907), np.float64(0.7945945945945946)]\n",
            "ID_TARGET: 3.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7345 | Fold Accuracies: [np.float64(0.7062146892655368), np.float64(0.6416184971098265), np.float64(0.7083333333333334), np.float64(0.6892655367231638), np.float64(0.7175141242937854), np.float64(0.7222222222222222), np.float64(0.686046511627907)]\n",
            "ID_TARGET: 9.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7205 | Fold Accuracies: [np.float64(0.7134831460674157), np.float64(0.6521739130434783), np.float64(0.6444444444444445), np.float64(0.6892655367231638), np.float64(0.6728395061728395), np.float64(0.6842105263157895), np.float64(0.7098445595854922)]\n",
            "ID_TARGET: 131.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7064 | Fold Accuracies: [np.float64(0.6449704142011834), np.float64(0.5980392156862745), np.float64(0.6797752808988764), np.float64(0.6907894736842105), np.float64(0.6774193548387096), np.float64(0.6190476190476191), np.float64(0.6629834254143646)]\n",
            "ID_TARGET: 21.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.6883 | Fold Accuracies: [np.float64(0.649746192893401), np.float64(0.643979057591623), np.float64(0.6785714285714286), np.float64(0.6906077348066298), np.float64(0.6417112299465241), np.float64(0.6376811594202898), np.float64(0.7109826589595376)]\n",
            "ID_TARGET: 54.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8298 | Fold Accuracies: [np.float64(0.8051282051282052), np.float64(0.7640449438202247), np.float64(0.7801047120418848), np.float64(0.7626262626262627), np.float64(0.7909604519774012), np.float64(0.8764705882352941), np.float64(0.7556818181818182)]\n",
            "ID_TARGET: 130.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7439 | Fold Accuracies: [np.float64(0.6758241758241759), np.float64(0.6827956989247311), np.float64(0.75), np.float64(0.6666666666666666), np.float64(0.7873563218390804), np.float64(0.7150537634408602), np.float64(0.7114427860696517)]\n",
            "ID_TARGET: 269.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7371 | Fold Accuracies: [np.float64(0.72), np.float64(0.7150837988826816), np.float64(0.7168674698795181), np.float64(0.6481481481481481), np.float64(0.7085714285714285), np.float64(0.593939393939394), np.float64(0.7235294117647059)]\n",
            "ID_TARGET: 157.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7992 | Fold Accuracies: [np.float64(0.8054054054054054), np.float64(0.7588235294117647), np.float64(0.7987012987012987), np.float64(0.7386363636363636), np.float64(0.7727272727272727), np.float64(0.7724550898203593), np.float64(0.7802197802197802)]\n",
            "ID_TARGET: 249.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7649 | Fold Accuracies: [np.float64(0.703125), np.float64(0.7085714285714285), np.float64(0.6923076923076923), np.float64(0.7151162790697675), np.float64(0.7650273224043715), np.float64(0.6827956989247311), np.float64(0.7237569060773481)]\n",
            "ID_TARGET: 22.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.6836 | Fold Accuracies: [np.float64(0.6600985221674877), np.float64(0.6446700507614214), np.float64(0.7150837988826816), np.float64(0.7371794871794872), np.float64(0.6842105263157895), np.float64(0.574585635359116), np.float64(0.6490384615384616)]\n",
            "ID_TARGET: 202.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.05, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6826 | Fold Accuracies: [np.float64(0.6544502617801047), np.float64(0.6842105263157895), np.float64(0.6256684491978609), np.float64(0.6629834254143646), np.float64(0.6391752577319587), np.float64(0.6684491978609626), np.float64(0.6564102564102564)]\n",
            "ID_TARGET: 132.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7735 | Fold Accuracies: [np.float64(0.8012422360248447), np.float64(0.7701149425287356), np.float64(0.6878612716763006), np.float64(0.7243243243243244), np.float64(0.7485714285714286), np.float64(0.7415730337078652), np.float64(0.6910112359550562)]\n",
            "ID_TARGET: 96.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8274 | Fold Accuracies: [np.float64(0.802547770700637), np.float64(0.7317073170731707), np.float64(0.7643312101910829), np.float64(0.7861271676300579), np.float64(0.6524064171122995), np.float64(0.8023952095808383), np.float64(0.686046511627907)]\n",
            "ID_TARGET: 7.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7608 | Fold Accuracies: [np.float64(0.7675675675675676), np.float64(0.7149532710280374), np.float64(0.7258064516129032), np.float64(0.6839080459770115), np.float64(0.7091836734693877), np.float64(0.7556818181818182), np.float64(0.7751479289940828)]\n",
            "ID_TARGET: 178.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7357 | Fold Accuracies: [np.float64(0.6702702702702703), np.float64(0.6477272727272727), np.float64(0.7471264367816092), np.float64(0.7486910994764397), np.float64(0.726775956284153), np.float64(0.7604790419161677), np.float64(0.7219251336898396)]\n",
            "ID_TARGET: 68.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7799 | Fold Accuracies: [np.float64(0.7087912087912088), np.float64(0.7687861271676301), np.float64(0.7345679012345679), np.float64(0.8202247191011236), np.float64(0.7759562841530054), np.float64(0.7873563218390804), np.float64(0.7150837988826816)]\n",
            "ID_TARGET: 44.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7377 | Fold Accuracies: [np.float64(0.6982248520710059), np.float64(0.7589743589743589), np.float64(0.6927374301675978), np.float64(0.7070707070707071), np.float64(0.6988636363636364), np.float64(0.7315789473684211), np.float64(0.7164948453608248)]\n",
            "ID_TARGET: 196.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7403 | Fold Accuracies: [np.float64(0.6984924623115578), np.float64(0.7183098591549296), np.float64(0.6911764705882353), np.float64(0.71875), np.float64(0.6597938144329897), np.float64(0.7677725118483413), np.float64(0.6903553299492385)]\n",
            "ID_TARGET: 292.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7450 | Fold Accuracies: [np.float64(0.6486486486486487), np.float64(0.7647058823529411), np.float64(0.6836158192090396), np.float64(0.7102272727272727), np.float64(0.7052631578947368), np.float64(0.7043010752688172), np.float64(0.7)]\n",
            "ID_TARGET: 239.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7695 | Fold Accuracies: [np.float64(0.6722222222222223), np.float64(0.7643979057591623), np.float64(0.8142076502732241), np.float64(0.7182320441988951), np.float64(0.6746987951807228), np.float64(0.808641975308642), np.float64(0.7770700636942676)]\n",
            "ID_TARGET: 279.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7269 | Fold Accuracies: [np.float64(0.6583850931677019), np.float64(0.6379310344827587), np.float64(0.6666666666666666), np.float64(0.6368715083798883), np.float64(0.6526315789473685), np.float64(0.7182320441988951), np.float64(0.7357512953367875)]\n",
            "ID_TARGET: 38.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7716 | Fold Accuracies: [np.float64(0.6596858638743456), np.float64(0.7182320441988951), np.float64(0.7848837209302325), np.float64(0.7359550561797753), np.float64(0.7484276729559748), np.float64(0.6984126984126984), np.float64(0.7039106145251397)]\n",
            "ID_TARGET: 209.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7489 | Fold Accuracies: [np.float64(0.711764705882353), np.float64(0.6972972972972973), np.float64(0.7644230769230769), np.float64(0.7333333333333333), np.float64(0.6611111111111111), np.float64(0.7403314917127072), np.float64(0.7512953367875648)]\n",
            "ID_TARGET: 207.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.6927 | Fold Accuracies: [np.float64(0.7231638418079096), np.float64(0.6348314606741573), np.float64(0.6473988439306358), np.float64(0.6505376344086021), np.float64(0.6614583333333334), np.float64(0.6963350785340314), np.float64(0.7272727272727273)]\n",
            "ID_TARGET: 98.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7278 | Fold Accuracies: [np.float64(0.6666666666666666), np.float64(0.6968085106382979), np.float64(0.7368421052631579), np.float64(0.6875), np.float64(0.7228260869565217), np.float64(0.7395833333333334), np.float64(0.772972972972973)]\n",
            "ID_TARGET: 65.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7477 | Fold Accuracies: [np.float64(0.7076023391812866), np.float64(0.7005649717514124), np.float64(0.7052631578947368), np.float64(0.7403314917127072), np.float64(0.7677419354838709), np.float64(0.7277486910994765), np.float64(0.7169811320754716)]\n",
            "ID_TARGET: 51.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7774 | Fold Accuracies: [np.float64(0.7282608695652174), np.float64(0.7806451612903226), np.float64(0.782608695652174), np.float64(0.7371794871794872), np.float64(0.7604790419161677), np.float64(0.75), np.float64(0.7514450867052023)]\n",
            "ID_TARGET: 78.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7465 | Fold Accuracies: [np.float64(0.8132530120481928), np.float64(0.7017543859649122), np.float64(0.7046632124352331), np.float64(0.7374301675977654), np.float64(0.7160493827160493), np.float64(0.6569767441860465), np.float64(0.7727272727272727)]\n",
            "ID_TARGET: 177.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7516 | Fold Accuracies: [np.float64(0.7488372093023256), np.float64(0.7098445595854922), np.float64(0.6616161616161617), np.float64(0.7119565217391305), np.float64(0.7336683417085427), np.float64(0.7461928934010152), np.float64(0.8)]\n",
            "ID_TARGET: 231.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7993 | Fold Accuracies: [np.float64(0.7666666666666667), np.float64(0.7802197802197802), np.float64(0.6964285714285714), np.float64(0.8121546961325967), np.float64(0.8059701492537313), np.float64(0.8088235294117647), np.float64(0.7398843930635838)]\n",
            "ID_TARGET: 119.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7666 | Fold Accuracies: [np.float64(0.7215909090909091), np.float64(0.7777777777777778), np.float64(0.7580645161290323), np.float64(0.7514450867052023), np.float64(0.8022598870056498), np.float64(0.7471910112359551), np.float64(0.6935483870967742)]\n",
            "ID_TARGET: 158.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8030 | Fold Accuracies: [np.float64(0.7842105263157895), np.float64(0.7844311377245509), np.float64(0.8128654970760234), np.float64(0.8010471204188482), np.float64(0.7891891891891892), np.float64(0.7237569060773481), np.float64(0.7978723404255319)]\n",
            "ID_TARGET: 80.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.03, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7020 | Fold Accuracies: [np.float64(0.6684782608695652), np.float64(0.6285714285714286), np.float64(0.6486486486486487), np.float64(0.7380952380952381), np.float64(0.7584269662921348), np.float64(0.7048192771084337), np.float64(0.7202380952380952)]\n",
            "ID_TARGET: 25.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7452 | Fold Accuracies: [np.float64(0.7282051282051282), np.float64(0.7674418604651163), np.float64(0.7384615384615385), np.float64(0.7297297297297297), np.float64(0.679144385026738), np.float64(0.7251461988304093), np.float64(0.7572254335260116)]\n",
            "ID_TARGET: 175.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7376 | Fold Accuracies: [np.float64(0.7487684729064039), np.float64(0.7303370786516854), np.float64(0.7336956521739131), np.float64(0.7402597402597403), np.float64(0.7202072538860104), np.float64(0.6626506024096386), np.float64(0.7554347826086957)]\n",
            "ID_TARGET: 151.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7803 | Fold Accuracies: [np.float64(0.7142857142857143), np.float64(0.7441860465116279), np.float64(0.8106508875739645), np.float64(0.7456647398843931), np.float64(0.8), np.float64(0.7564766839378239), np.float64(0.7570621468926554)]\n",
            "ID_TARGET: 257.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7402 | Fold Accuracies: [np.float64(0.6601941747572816), np.float64(0.7457627118644068), np.float64(0.6861702127659575), np.float64(0.7262569832402235), np.float64(0.7315789473684211), np.float64(0.7142857142857143), np.float64(0.7128205128205128)]\n",
            "ID_TARGET: 75.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7944 | Fold Accuracies: [np.float64(0.75), np.float64(0.8052631578947368), np.float64(0.717391304347826), np.float64(0.7486033519553073), np.float64(0.7559808612440191), np.float64(0.8142857142857143), np.float64(0.7865853658536586)]\n",
            "ID_TARGET: 244.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.05, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7010 | Fold Accuracies: [np.float64(0.7164948453608248), np.float64(0.7034883720930233), np.float64(0.6476683937823834), np.float64(0.7182320441988951), np.float64(0.6793478260869565), np.float64(0.7096774193548387), np.float64(0.7253886010362695)]\n",
            "ID_TARGET: 149.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7656 | Fold Accuracies: [np.float64(0.8068181818181818), np.float64(0.7010869565217391), np.float64(0.7206703910614525), np.float64(0.6774193548387096), np.float64(0.7760416666666666), np.float64(0.6910994764397905), np.float64(0.7900552486187845)]\n",
            "ID_TARGET: 85.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7971 | Fold Accuracies: [np.float64(0.8100558659217877), np.float64(0.759493670886076), np.float64(0.8106508875739645), np.float64(0.7539267015706806), np.float64(0.6793478260869565), np.float64(0.8415300546448088), np.float64(0.7485714285714286)]\n",
            "ID_TARGET: 190.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7397 | Fold Accuracies: [np.float64(0.7150837988826816), np.float64(0.7309644670050761), np.float64(0.7076923076923077), np.float64(0.7578947368421053), np.float64(0.732620320855615), np.float64(0.7771428571428571), np.float64(0.7291666666666666)]\n",
            "ID_TARGET: 13.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7596 | Fold Accuracies: [np.float64(0.7254901960784313), np.float64(0.7307692307692307), np.float64(0.766497461928934), np.float64(0.7239583333333334), np.float64(0.7897727272727273), np.float64(0.7193877551020408), np.float64(0.7317073170731707)]\n",
            "ID_TARGET: 228.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7209 | Fold Accuracies: [np.float64(0.697560975609756), np.float64(0.7351351351351352), np.float64(0.6927083333333334), np.float64(0.7202072538860104), np.float64(0.6629213483146067), np.float64(0.743455497382199), np.float64(0.6455026455026455)]\n",
            "ID_TARGET: 144.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8037 | Fold Accuracies: [np.float64(0.788235294117647), np.float64(0.7595628415300546), np.float64(0.776536312849162), np.float64(0.7844311377245509), np.float64(0.7810650887573964), np.float64(0.7777777777777778), np.float64(0.8111111111111111)]\n",
            "ID_TARGET: 290.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7596 | Fold Accuracies: [np.float64(0.7457627118644068), np.float64(0.7263681592039801), np.float64(0.7202380952380952), np.float64(0.768361581920904), np.float64(0.7049180327868853), np.float64(0.6686046511627907), np.float64(0.6871508379888268)]\n",
            "ID_TARGET: 114.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.05, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7013 | Fold Accuracies: [np.float64(0.659217877094972), np.float64(0.6685714285714286), np.float64(0.6935483870967742), np.float64(0.7107843137254902), np.float64(0.6503067484662577), np.float64(0.7473684210526316), np.float64(0.6934673366834171)]\n",
            "ID_TARGET: 166.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7626 | Fold Accuracies: [np.float64(0.7431693989071039), np.float64(0.7272727272727273), np.float64(0.7085714285714285), np.float64(0.7900552486187845), np.float64(0.7861271676300579), np.float64(0.7248677248677249), np.float64(0.7614213197969543)]\n",
            "ID_TARGET: 234.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7691 | Fold Accuracies: [np.float64(0.7710843373493976), np.float64(0.8343949044585988), np.float64(0.7469879518072289), np.float64(0.7643979057591623), np.float64(0.6935483870967742), np.float64(0.7671957671957672), np.float64(0.754601226993865)]\n",
            "ID_TARGET: 34.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7805 | Fold Accuracies: [np.float64(0.7537688442211056), np.float64(0.7526881720430108), np.float64(0.7391304347826086), np.float64(0.7657142857142857), np.float64(0.7430167597765364), np.float64(0.7956989247311828), np.float64(0.7344632768361582)]\n",
            "ID_TARGET: 154.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7711 | Fold Accuracies: [np.float64(0.7555555555555555), np.float64(0.7606382978723404), np.float64(0.7598039215686274), np.float64(0.7277777777777777), np.float64(0.7204301075268817), np.float64(0.8192090395480226), np.float64(0.7005649717514124)]\n",
            "ID_TARGET: 225.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.05, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7069 | Fold Accuracies: [np.float64(0.7128712871287128), np.float64(0.7382198952879581), np.float64(0.7), np.float64(0.649746192893401), np.float64(0.7329842931937173), np.float64(0.6892655367231638), np.float64(0.6868686868686869)]\n",
            "ID_TARGET: 185.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8259 | Fold Accuracies: [np.float64(0.8121212121212121), np.float64(0.8275862068965517), np.float64(0.802547770700637), np.float64(0.8175675675675675), np.float64(0.8323353293413174), np.float64(0.8106508875739645), np.float64(0.7650602409638554)]\n",
            "ID_TARGET: 39.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7607 | Fold Accuracies: [np.float64(0.712707182320442), np.float64(0.7527472527472527), np.float64(0.7032967032967034), np.float64(0.7528089887640449), np.float64(0.7348066298342542), np.float64(0.7666666666666667), np.float64(0.7247191011235955)]\n",
            "ID_TARGET: 272.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7606 | Fold Accuracies: [np.float64(0.7724867724867724), np.float64(0.7175141242937854), np.float64(0.7422680412371134), np.float64(0.7261904761904762), np.float64(0.7197802197802198), np.float64(0.7666666666666667), np.float64(0.7905759162303665)]\n",
            "ID_TARGET: 282.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7643 | Fold Accuracies: [np.float64(0.7243243243243244), np.float64(0.6958762886597938), np.float64(0.7582417582417582), np.float64(0.8125), np.float64(0.7083333333333334), np.float64(0.6758241758241759), np.float64(0.7403314917127072)]\n",
            "ID_TARGET: 90.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7617 | Fold Accuracies: [np.float64(0.7277777777777777), np.float64(0.7771084337349398), np.float64(0.7608695652173914), np.float64(0.7705882352941177), np.float64(0.7912087912087912), np.float64(0.7243243243243244), np.float64(0.7305699481865285)]\n",
            "ID_TARGET: 52.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7486 | Fold Accuracies: [np.float64(0.7337278106508875), np.float64(0.776595744680851), np.float64(0.7219251336898396), np.float64(0.7454545454545455), np.float64(0.7192982456140351), np.float64(0.6666666666666666), np.float64(0.7925531914893617)]\n",
            "ID_TARGET: 258.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7417 | Fold Accuracies: [np.float64(0.7272727272727273), np.float64(0.7403314917127072), np.float64(0.6894736842105263), np.float64(0.7222222222222222), np.float64(0.7133333333333334), np.float64(0.7543859649122807), np.float64(0.7074468085106383)]\n",
            "ID_TARGET: 291.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7780 | Fold Accuracies: [np.float64(0.7033492822966507), np.float64(0.7540983606557377), np.float64(0.7150837988826816), np.float64(0.7970297029702971), np.float64(0.7670454545454546), np.float64(0.7469879518072289), np.float64(0.7988505747126436)]\n",
            "ID_TARGET: 152.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7688 | Fold Accuracies: [np.float64(0.7374301675977654), np.float64(0.7921348314606742), np.float64(0.7297297297297297), np.float64(0.7540983606557377), np.float64(0.7606382978723404), np.float64(0.7619047619047619), np.float64(0.7789473684210526)]\n",
            "ID_TARGET: 133.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8000 | Fold Accuracies: [np.float64(0.7311827956989247), np.float64(0.7566137566137566), np.float64(0.7932960893854749), np.float64(0.7704918032786885), np.float64(0.7760416666666666), np.float64(0.8031914893617021), np.float64(0.7808988764044944)]\n",
            "ID_TARGET: 29.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7579 | Fold Accuracies: [np.float64(0.6511627906976745), np.float64(0.7195767195767195), np.float64(0.75), np.float64(0.7897435897435897), np.float64(0.6686390532544378), np.float64(0.7100591715976331), np.float64(0.7443181818181818)]\n",
            "ID_TARGET: 274.0 | Best Params: {'bagging_fraction': 0.75, 'learning_rate': 0.1, 'min_child_samples': 20, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.1} | Mean Accuracy: 0.7428 | Fold Accuracies: [np.float64(0.717948717948718), np.float64(0.7068062827225131), np.float64(0.7166666666666667), np.float64(0.8121827411167513), np.float64(0.7422680412371134), np.float64(0.7487684729064039), np.float64(0.6381909547738693)]\n",
            "ID_TARGET: 106.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8011 | Fold Accuracies: [np.float64(0.7454545454545455), np.float64(0.7771084337349398), np.float64(0.65625), np.float64(0.7756410256410257), np.float64(0.8322981366459627), np.float64(0.7682119205298014), np.float64(0.7818181818181819)]\n",
            "ID_TARGET: 173.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7889 | Fold Accuracies: [np.float64(0.75), np.float64(0.7193877551020408), np.float64(0.770949720670391), np.float64(0.776595744680851), np.float64(0.7958115183246073), np.float64(0.76), np.float64(0.7705882352941177)]\n",
            "ID_TARGET: 33.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7753 | Fold Accuracies: [np.float64(0.726775956284153), np.float64(0.73224043715847), np.float64(0.7037037037037037), np.float64(0.7074468085106383), np.float64(0.7102272727272727), np.float64(0.7419354838709677), np.float64(0.7613636363636364)]\n",
            "ID_TARGET: 69.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7183 | Fold Accuracies: [np.float64(0.6946107784431138), np.float64(0.7393617021276596), np.float64(0.6927374301675978), np.float64(0.6705202312138728), np.float64(0.688622754491018), np.float64(0.7380952380952381), np.float64(0.7209302325581395)]\n",
            "ID_TARGET: 17.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7036 | Fold Accuracies: [np.float64(0.6983240223463687), np.float64(0.5818181818181818), np.float64(0.6666666666666666), np.float64(0.7070707070707071), np.float64(0.7021276595744681), np.float64(0.7025641025641025), np.float64(0.7135678391959799)]\n",
            "ID_TARGET: 189.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7695 | Fold Accuracies: [np.float64(0.7336956521739131), np.float64(0.7861271676300579), np.float64(0.7352941176470589), np.float64(0.7430167597765364), np.float64(0.7619047619047619), np.float64(0.7395833333333334), np.float64(0.6740331491712708)]\n",
            "ID_TARGET: 284.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7343 | Fold Accuracies: [np.float64(0.7567567567567568), np.float64(0.7189189189189189), np.float64(0.6559139784946236), np.float64(0.7094972067039106), np.float64(0.75), np.float64(0.7486338797814208), np.float64(0.7142857142857143)]\n",
            "ID_TARGET: 218.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7168 | Fold Accuracies: [np.float64(0.6863905325443787), np.float64(0.717948717948718), np.float64(0.69), np.float64(0.7103825136612022), np.float64(0.703125), np.float64(0.7158469945355191), np.float64(0.6492146596858639)]\n",
            "ID_TARGET: 183.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7894 | Fold Accuracies: [np.float64(0.7816091954022989), np.float64(0.7790697674418605), np.float64(0.7597765363128491), np.float64(0.7572254335260116), np.float64(0.7475247524752475), np.float64(0.7411167512690355), np.float64(0.7619047619047619)]\n",
            "ID_TARGET: 206.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7576 | Fold Accuracies: [np.float64(0.8156424581005587), np.float64(0.7613636363636364), np.float64(0.7764705882352941), np.float64(0.7049180327868853), np.float64(0.7580645161290323), np.float64(0.7213114754098361), np.float64(0.7486338797814208)]\n",
            "ID_TARGET: 93.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7196 | Fold Accuracies: [np.float64(0.7135135135135136), np.float64(0.6337209302325582), np.float64(0.7640449438202247), np.float64(0.6885245901639344), np.float64(0.6720430107526881), np.float64(0.6464088397790055), np.float64(0.7005347593582888)]\n",
            "ID_TARGET: 16.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7377 | Fold Accuracies: [np.float64(0.7539267015706806), np.float64(0.6976744186046512), np.float64(0.6789473684210526), np.float64(0.6263736263736264), np.float64(0.6927374301675978), np.float64(0.7309644670050761), np.float64(0.7613636363636364)]\n",
            "ID_TARGET: 246.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7640 | Fold Accuracies: [np.float64(0.6923076923076923), np.float64(0.8057142857142857), np.float64(0.7872340425531915), np.float64(0.7239583333333334), np.float64(0.7448979591836735), np.float64(0.7613636363636364), np.float64(0.7311827956989247)]\n",
            "ID_TARGET: 167.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7783 | Fold Accuracies: [np.float64(0.7556818181818182), np.float64(0.7740112994350282), np.float64(0.7529411764705882), np.float64(0.7383720930232558), np.float64(0.7395833333333334), np.float64(0.7674418604651163), np.float64(0.76)]\n",
            "ID_TARGET: 1.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7596 | Fold Accuracies: [np.float64(0.7142857142857143), np.float64(0.7444444444444445), np.float64(0.7752808988764045), np.float64(0.7333333333333333), np.float64(0.688622754491018), np.float64(0.7607361963190185), np.float64(0.7803468208092486)]\n",
            "ID_TARGET: 289.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7500 | Fold Accuracies: [np.float64(0.735632183908046), np.float64(0.7379679144385026), np.float64(0.7431693989071039), np.float64(0.7081081081081081), np.float64(0.7043010752688172), np.float64(0.7595628415300546), np.float64(0.7216494845360825)]\n",
            "ID_TARGET: 141.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8070 | Fold Accuracies: [np.float64(0.7903225806451613), np.float64(0.7674418604651163), np.float64(0.8166666666666667), np.float64(0.7818181818181819), np.float64(0.8152173913043478), np.float64(0.7333333333333333), np.float64(0.8138297872340425)]\n",
            "ID_TARGET: 109.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7197 | Fold Accuracies: [np.float64(0.7142857142857143), np.float64(0.6789473684210526), np.float64(0.6903553299492385), np.float64(0.6842105263157895), np.float64(0.648936170212766), np.float64(0.7900552486187845), np.float64(0.6927374301675978)]\n",
            "ID_TARGET: 19.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7562 | Fold Accuracies: [np.float64(0.783625730994152), np.float64(0.7105263157894737), np.float64(0.7513227513227513), np.float64(0.7252747252747253), np.float64(0.7864583333333334), np.float64(0.7354497354497355), np.float64(0.7359550561797753)]\n",
            "ID_TARGET: 28.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7065 | Fold Accuracies: [np.float64(0.6910994764397905), np.float64(0.672316384180791), np.float64(0.6988636363636364), np.float64(0.7247191011235955), np.float64(0.6892655367231638), np.float64(0.6470588235294118), np.float64(0.72)]\n",
            "ID_TARGET: 251.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7467 | Fold Accuracies: [np.float64(0.7164948453608248), np.float64(0.7540983606557377), np.float64(0.6878306878306878), np.float64(0.7021276595744681), np.float64(0.791907514450867), np.float64(0.71875), np.float64(0.6864864864864865)]\n",
            "ID_TARGET: 278.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7866 | Fold Accuracies: [np.float64(0.776536312849162), np.float64(0.7727272727272727), np.float64(0.73125), np.float64(0.7401129943502824), np.float64(0.8287292817679558), np.float64(0.8263473053892215), np.float64(0.7298850574712644)]\n",
            "ID_TARGET: 76.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7421 | Fold Accuracies: [np.float64(0.7525773195876289), np.float64(0.7789473684210526), np.float64(0.7237569060773481), np.float64(0.7225130890052356), np.float64(0.6822916666666666), np.float64(0.7102272727272727), np.float64(0.7853403141361257)]\n",
            "ID_TARGET: 241.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7784 | Fold Accuracies: [np.float64(0.7071823204419889), np.float64(0.7692307692307693), np.float64(0.7611111111111111), np.float64(0.7514450867052023), np.float64(0.711764705882353), np.float64(0.7784810126582279), np.float64(0.7560975609756098)]\n",
            "ID_TARGET: 214.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7988 | Fold Accuracies: [np.float64(0.7860696517412935), np.float64(0.8333333333333334), np.float64(0.7908163265306123), np.float64(0.7094972067039106), np.float64(0.7758620689655172), np.float64(0.7403314917127072), np.float64(0.7563451776649747)]\n",
            "ID_TARGET: 102.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8002 | Fold Accuracies: [np.float64(0.7553191489361702), np.float64(0.7777777777777778), np.float64(0.7696629213483146), np.float64(0.7796610169491526), np.float64(0.7426900584795322), np.float64(0.815028901734104), np.float64(0.751412429378531)]\n",
            "ID_TARGET: 145.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7728 | Fold Accuracies: [np.float64(0.723404255319149), np.float64(0.7819148936170213), np.float64(0.7135135135135136), np.float64(0.7098445595854922), np.float64(0.7814207650273224), np.float64(0.7307692307692307), np.float64(0.7267080745341615)]\n",
            "ID_TARGET: 155.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.01, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7965 | Fold Accuracies: [np.float64(0.8195876288659794), np.float64(0.8277777777777777), np.float64(0.7602040816326531), np.float64(0.7563451776649747), np.float64(0.7796610169491526), np.float64(0.7900552486187845), np.float64(0.748792270531401)]\n",
            "\n",
            "Training XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "XGBoost Targets: 100%|| 100/100 [52:22<00:00, 31.43s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Weighted Accuracy: 0.8488\n",
            "\n",
            "XGBoost Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7675 | Fold Accuracies: [np.float64(0.732620320855615), np.float64(0.6936416184971098), np.float64(0.7932960893854749), np.float64(0.6345177664974619), np.float64(0.8313253012048193), np.float64(0.7833333333333333), np.float64(0.7844311377245509)]\n",
            "ID_TARGET: 129.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6427 | Fold Accuracies: [np.float64(0.5224719101123596), np.float64(0.6742857142857143), np.float64(0.6195652173913043), np.float64(0.5977011494252874), np.float64(0.6440677966101694), np.float64(0.6815642458100558), np.float64(0.57)]\n",
            "ID_TARGET: 136.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6202 | Fold Accuracies: [np.float64(0.6647727272727273), np.float64(0.6307692307692307), np.float64(0.5851063829787234), np.float64(0.5674157303370787), np.float64(0.6), np.float64(0.6089108910891089), np.float64(0.5935828877005348)]\n",
            "ID_TARGET: 161.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 217.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 91.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 137.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.2, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 8.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6600 | Fold Accuracies: [np.float64(0.6035502958579881), np.float64(0.6936416184971098), np.float64(0.6257309941520468), np.float64(0.5445026178010471), np.float64(0.585), np.float64(0.6744186046511628), np.float64(0.6486486486486487)]\n",
            "ID_TARGET: 3.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6755 | Fold Accuracies: [np.float64(0.6497175141242938), np.float64(0.6184971098265896), np.float64(0.7023809523809523), np.float64(0.6779661016949152), np.float64(0.6666666666666666), np.float64(0.7166666666666667), np.float64(0.6744186046511628)]\n",
            "ID_TARGET: 9.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 131.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.6491 | Fold Accuracies: [np.float64(0.6686390532544378), np.float64(0.5637254901960784), np.float64(0.6685393258426966), np.float64(0.6907894736842105), np.float64(0.6935483870967742), np.float64(0.6507936507936508), np.float64(0.6077348066298343)]\n",
            "ID_TARGET: 21.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7217 | Fold Accuracies: [np.float64(0.6345177664974619), np.float64(0.6387434554973822), np.float64(0.6785714285714286), np.float64(0.6795580110497238), np.float64(0.679144385026738), np.float64(0.6231884057971014), np.float64(0.7052023121387283)]\n",
            "ID_TARGET: 54.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.8235 | Fold Accuracies: [np.float64(0.7282051282051282), np.float64(0.797752808988764), np.float64(0.675392670157068), np.float64(0.7373737373737373), np.float64(0.7853107344632768), np.float64(0.7058823529411765), np.float64(0.6988636363636364)]\n",
            "ID_TARGET: 130.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7573 | Fold Accuracies: [np.float64(0.7142857142857143), np.float64(0.6451612903225806), np.float64(0.75), np.float64(0.6567164179104478), np.float64(0.7068965517241379), np.float64(0.6989247311827957), np.float64(0.7164179104477612)]\n",
            "ID_TARGET: 269.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6490 | Fold Accuracies: [np.float64(0.7257142857142858), np.float64(0.6759776536312849), np.float64(0.7108433734939759), np.float64(0.6172839506172839), np.float64(0.6342857142857142), np.float64(0.5272727272727272), np.float64(0.6470588235294118)]\n",
            "ID_TARGET: 157.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7609 | Fold Accuracies: [np.float64(0.7837837837837838), np.float64(0.7176470588235294), np.float64(0.7597402597402597), np.float64(0.6875), np.float64(0.6931818181818182), np.float64(0.7425149700598802), np.float64(0.7197802197802198)]\n",
            "ID_TARGET: 249.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7400 | Fold Accuracies: [np.float64(0.7291666666666666), np.float64(0.68), np.float64(0.6593406593406593), np.float64(0.6744186046511628), np.float64(0.7650273224043715), np.float64(0.6827956989247311), np.float64(0.7292817679558011)]\n",
            "ID_TARGET: 22.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.7448 | Fold Accuracies: [np.float64(0.6699507389162561), np.float64(0.6852791878172588), np.float64(1.0), np.float64(0.782051282051282), np.float64(0.7894736842105263), np.float64(0.6187845303867403), np.float64(0.6682692307692307)]\n",
            "ID_TARGET: 202.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7289 | Fold Accuracies: [np.float64(0.7329842931937173), np.float64(0.7263157894736842), np.float64(0.7112299465240641), np.float64(0.7071823204419889), np.float64(0.7371134020618557), np.float64(0.679144385026738), np.float64(0.7025641025641025)]\n",
            "ID_TARGET: 132.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.9848 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.8932584269662921), np.float64(1.0)]\n",
            "ID_TARGET: 96.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 7.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 178.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.7269 | Fold Accuracies: [np.float64(0.6864864864864865), np.float64(0.7102272727272727), np.float64(0.7816091954022989), np.float64(0.7382198952879581), np.float64(0.7158469945355191), np.float64(0.7604790419161677), np.float64(0.6951871657754011)]\n",
            "ID_TARGET: 68.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7509 | Fold Accuracies: [np.float64(0.6758241758241759), np.float64(0.7398843930635838), np.float64(0.7222222222222222), np.float64(0.7640449438202247), np.float64(0.7595628415300546), np.float64(0.7701149425287356), np.float64(0.7094972067039106)]\n",
            "ID_TARGET: 44.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.8063 | Fold Accuracies: [np.float64(0.8520710059171598), np.float64(0.7897435897435897), np.float64(0.7653631284916201), np.float64(0.8181818181818182), np.float64(0.7727272727272727), np.float64(0.8157894736842105), np.float64(0.8298969072164949)]\n",
            "ID_TARGET: 196.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.9551 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.828125), np.float64(1.0), np.float64(1.0), np.float64(0.8578680203045685)]\n",
            "ID_TARGET: 292.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7603 | Fold Accuracies: [np.float64(0.7405405405405405), np.float64(0.7745098039215687), np.float64(0.7401129943502824), np.float64(0.8011363636363636), np.float64(0.7473684210526316), np.float64(0.7634408602150538), np.float64(0.71)]\n",
            "ID_TARGET: 239.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.7} | Mean Accuracy: 0.7421 | Fold Accuracies: [np.float64(0.6333333333333333), np.float64(0.7120418848167539), np.float64(0.7650273224043715), np.float64(0.6685082872928176), np.float64(0.6265060240963856), np.float64(0.7530864197530864), np.float64(0.7197452229299363)]\n",
            "ID_TARGET: 279.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 38.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 209.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.2, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 207.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.7131 | Fold Accuracies: [np.float64(0.7175141242937854), np.float64(0.6629213483146067), np.float64(0.7167630057803468), np.float64(0.7096774193548387), np.float64(0.7291666666666666), np.float64(0.7068062827225131), np.float64(0.7486631016042781)]\n",
            "ID_TARGET: 98.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 65.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 51.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7386 | Fold Accuracies: [np.float64(0.6195652173913043), np.float64(0.6967741935483871), np.float64(0.657608695652174), np.float64(0.6730769230769231), np.float64(0.7065868263473054), np.float64(0.635), np.float64(0.6127167630057804)]\n",
            "ID_TARGET: 78.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 177.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7949 | Fold Accuracies: [np.float64(0.7488372093023256), np.float64(0.7461139896373057), np.float64(0.6767676767676768), np.float64(0.6902173913043478), np.float64(0.7437185929648241), np.float64(0.766497461928934), np.float64(0.7891891891891892)]\n",
            "ID_TARGET: 231.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.2, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 119.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7736 | Fold Accuracies: [np.float64(0.6818181818181818), np.float64(0.7602339181286549), np.float64(0.7365591397849462), np.float64(0.7398843930635838), np.float64(0.7853107344632768), np.float64(0.7078651685393258), np.float64(0.6720430107526881)]\n",
            "ID_TARGET: 158.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7805 | Fold Accuracies: [np.float64(0.7578947368421053), np.float64(0.7784431137724551), np.float64(0.7953216374269005), np.float64(0.774869109947644), np.float64(0.7567567567567568), np.float64(0.7182320441988951), np.float64(0.7819148936170213)]\n",
            "ID_TARGET: 80.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7205 | Fold Accuracies: [np.float64(0.6739130434782609), np.float64(0.6285714285714286), np.float64(0.6486486486486487), np.float64(0.75), np.float64(0.7752808988764045), np.float64(0.7048192771084337), np.float64(0.7321428571428571)]\n",
            "ID_TARGET: 25.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 175.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.2, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 151.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7711 | Fold Accuracies: [np.float64(0.72), np.float64(0.7093023255813954), np.float64(0.8224852071005917), np.float64(0.7745664739884393), np.float64(0.8), np.float64(0.772020725388601), np.float64(0.768361581920904)]\n",
            "ID_TARGET: 257.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.9618 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.9052631578947369), np.float64(0.8275862068965517), np.float64(1.0)]\n",
            "ID_TARGET: 75.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7928 | Fold Accuracies: [np.float64(0.7555555555555555), np.float64(0.8157894736842105), np.float64(0.7554347826086957), np.float64(0.7653631284916201), np.float64(0.7416267942583732), np.float64(0.8095238095238095), np.float64(0.8048780487804879)]\n",
            "ID_TARGET: 244.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 149.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 85.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 190.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7519 | Fold Accuracies: [np.float64(0.7374301675977654), np.float64(0.7309644670050761), np.float64(0.7282051282051282), np.float64(0.7578947368421053), np.float64(0.7593582887700535), np.float64(0.7657142857142857), np.float64(0.7083333333333334)]\n",
            "ID_TARGET: 13.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 228.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 144.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.7940 | Fold Accuracies: [np.float64(0.7352941176470589), np.float64(0.7486338797814208), np.float64(0.7932960893854749), np.float64(0.7604790419161677), np.float64(1.0), np.float64(0.708994708994709), np.float64(0.8111111111111111)]\n",
            "ID_TARGET: 290.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 114.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7459 | Fold Accuracies: [np.float64(0.664804469273743), np.float64(0.7028571428571428), np.float64(0.7204301075268817), np.float64(0.7303921568627451), np.float64(0.656441717791411), np.float64(0.7894736842105263), np.float64(0.7437185929648241)]\n",
            "ID_TARGET: 166.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 200, 'reg_alpha': 0.3, 'reg_lambda': 1.5, 'subsample': 0.75} | Mean Accuracy: 0.7611 | Fold Accuracies: [np.float64(0.6939890710382514), np.float64(0.6647727272727273), np.float64(0.72), np.float64(0.7513812154696132), np.float64(0.7803468208092486), np.float64(0.7407407407407407), np.float64(0.7461928934010152)]\n",
            "ID_TARGET: 234.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7800 | Fold Accuracies: [np.float64(0.7710843373493976), np.float64(0.8280254777070064), np.float64(0.7530120481927711), np.float64(0.7591623036649214), np.float64(0.6989247311827957), np.float64(0.7407407407407407), np.float64(0.7668711656441718)]\n",
            "ID_TARGET: 34.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7917 | Fold Accuracies: [np.float64(0.7788944723618091), np.float64(0.7903225806451613), np.float64(0.7717391304347826), np.float64(0.8285714285714286), np.float64(0.7541899441340782), np.float64(0.8172043010752689), np.float64(0.7457627118644068)]\n",
            "ID_TARGET: 154.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7820 | Fold Accuracies: [np.float64(0.7611111111111111), np.float64(0.7446808510638298), np.float64(0.7794117647058824), np.float64(0.7222222222222222), np.float64(0.7688172043010753), np.float64(0.8192090395480226), np.float64(0.7457627118644068)]\n",
            "ID_TARGET: 225.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7352 | Fold Accuracies: [np.float64(0.7227722772277227), np.float64(0.7382198952879581), np.float64(0.7142857142857143), np.float64(0.6852791878172588), np.float64(0.7486910994764397), np.float64(0.7231638418079096), np.float64(0.6666666666666666)]\n",
            "ID_TARGET: 185.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.8387 | Fold Accuracies: [np.float64(1.0), np.float64(0.6896551724137931), np.float64(1.0), np.float64(1.0), np.float64(0.7904191616766467), np.float64(0.7041420118343196), np.float64(0.6867469879518072)]\n",
            "ID_TARGET: 39.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 272.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 282.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.8739 | Fold Accuracies: [np.float64(1.0), np.float64(0.7010309278350515), np.float64(0.8516483516483516), np.float64(0.8352272727272727), np.float64(0.9107142857142857), np.float64(0.8186813186813187), np.float64(1.0)]\n",
            "ID_TARGET: 90.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7785 | Fold Accuracies: [np.float64(0.7555555555555555), np.float64(0.7771084337349398), np.float64(0.7880434782608695), np.float64(0.8058823529411765), np.float64(0.8076923076923077), np.float64(0.7351351351351352), np.float64(0.7409326424870466)]\n",
            "ID_TARGET: 52.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.8876 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(0.8663101604278075), np.float64(0.7878787878787878), np.float64(1.0), np.float64(0.7023809523809523), np.float64(0.8563829787234043)]\n",
            "ID_TARGET: 258.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7339 | Fold Accuracies: [np.float64(0.7142857142857143), np.float64(0.7071823204419889), np.float64(0.7263157894736842), np.float64(0.6767676767676768), np.float64(0.68), np.float64(0.7134502923976608), np.float64(0.6914893617021277)]\n",
            "ID_TARGET: 291.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7780 | Fold Accuracies: [np.float64(0.7081339712918661), np.float64(0.7923497267759563), np.float64(0.7821229050279329), np.float64(0.7871287128712872), np.float64(0.7727272727272727), np.float64(0.7469879518072289), np.float64(0.7758620689655172)]\n",
            "ID_TARGET: 152.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 133.0 | Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.7} | Mean Accuracy: 0.7768 | Fold Accuracies: [np.float64(0.6559139784946236), np.float64(0.6825396825396826), np.float64(0.8044692737430168), np.float64(0.73224043715847), np.float64(0.6927083333333334), np.float64(0.7340425531914894), np.float64(0.7640449438202247)]\n",
            "ID_TARGET: 29.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 274.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7654 | Fold Accuracies: [np.float64(0.7487179487179487), np.float64(0.806282722513089), np.float64(0.7444444444444445), np.float64(0.8020304568527918), np.float64(0.788659793814433), np.float64(0.7487684729064039), np.float64(0.6984924623115578)]\n",
            "ID_TARGET: 106.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 173.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 33.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.8905 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(0.7195767195767195), np.float64(0.8829787234042553), np.float64(1.0), np.float64(0.7903225806451613), np.float64(0.8409090909090909)]\n",
            "ID_TARGET: 69.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.7469 | Fold Accuracies: [np.float64(0.7305389221556886), np.float64(0.7340425531914894), np.float64(0.7318435754189944), np.float64(0.6994219653179191), np.float64(0.7964071856287425), np.float64(0.7916666666666666), np.float64(0.7441860465116279)]\n",
            "ID_TARGET: 17.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7206 | Fold Accuracies: [np.float64(0.7318435754189944), np.float64(0.593939393939394), np.float64(0.6432748538011696), np.float64(0.7474747474747475), np.float64(0.7127659574468085), np.float64(0.7435897435897436), np.float64(0.7085427135678392)]\n",
            "ID_TARGET: 189.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 284.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7397 | Fold Accuracies: [np.float64(0.7135135135135136), np.float64(0.7081081081081081), np.float64(0.6236559139784946), np.float64(0.664804469273743), np.float64(0.7111111111111111), np.float64(0.6994535519125683), np.float64(0.6878306878306878)]\n",
            "ID_TARGET: 218.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7272 | Fold Accuracies: [np.float64(0.6923076923076923), np.float64(0.7076923076923077), np.float64(0.705), np.float64(0.726775956284153), np.float64(0.7083333333333334), np.float64(0.7540983606557377), np.float64(0.6701570680628273)]\n",
            "ID_TARGET: 183.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7787 | Fold Accuracies: [np.float64(0.7701149425287356), np.float64(0.7441860465116279), np.float64(0.7094972067039106), np.float64(0.7167630057803468), np.float64(0.6683168316831684), np.float64(0.7309644670050761), np.float64(0.7724867724867724)]\n",
            "ID_TARGET: 206.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7656 | Fold Accuracies: [np.float64(0.7877094972067039), np.float64(0.7329545454545454), np.float64(0.7470588235294118), np.float64(0.6612021857923497), np.float64(0.7473118279569892), np.float64(0.6939890710382514), np.float64(0.7377049180327869)]\n",
            "ID_TARGET: 93.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7277 | Fold Accuracies: [np.float64(0.7027027027027027), np.float64(0.627906976744186), np.float64(0.7191011235955056), np.float64(0.6721311475409836), np.float64(0.6559139784946236), np.float64(0.6243093922651933), np.float64(0.7219251336898396)]\n",
            "ID_TARGET: 16.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7254 | Fold Accuracies: [np.float64(0.7225130890052356), np.float64(0.6802325581395349), np.float64(0.6842105263157895), np.float64(0.6263736263736264), np.float64(0.6703910614525139), np.float64(0.7208121827411168), np.float64(0.75)]\n",
            "ID_TARGET: 246.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.8582 | Fold Accuracies: [np.float64(0.6307692307692307), np.float64(1.0), np.float64(1.0), np.float64(0.7083333333333334), np.float64(0.6683673469387755), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 167.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 1.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7617 | Fold Accuracies: [np.float64(0.6956521739130435), np.float64(0.7333333333333333), np.float64(0.7752808988764045), np.float64(0.7277777777777777), np.float64(0.7125748502994012), np.float64(0.7423312883435583), np.float64(0.7745664739884393)]\n",
            "ID_TARGET: 289.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 141.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7947 | Fold Accuracies: [np.float64(0.7741935483870968), np.float64(0.7732558139534884), np.float64(0.7722222222222223), np.float64(0.7878787878787878), np.float64(0.8043478260869565), np.float64(0.7757575757575758), np.float64(0.7978723404255319)]\n",
            "ID_TARGET: 109.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7480 | Fold Accuracies: [np.float64(0.7142857142857143), np.float64(0.7), np.float64(0.7106598984771574), np.float64(0.7263157894736842), np.float64(0.6861702127659575), np.float64(0.7845303867403315), np.float64(0.6759776536312849)]\n",
            "ID_TARGET: 19.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.2, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7701 | Fold Accuracies: [np.float64(0.8187134502923976), np.float64(0.7), np.float64(0.7724867724867724), np.float64(0.7142857142857143), np.float64(0.8020833333333334), np.float64(0.7566137566137566), np.float64(0.7640449438202247)]\n",
            "ID_TARGET: 28.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.7069 | Fold Accuracies: [np.float64(0.7015706806282722), np.float64(0.6836158192090396), np.float64(0.6875), np.float64(0.7640449438202247), np.float64(0.7231638418079096), np.float64(0.6684491978609626), np.float64(0.72)]\n",
            "ID_TARGET: 251.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 278.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7590 | Fold Accuracies: [np.float64(0.7597765363128491), np.float64(0.7272727272727273), np.float64(0.71875), np.float64(0.6836158192090396), np.float64(0.7624309392265194), np.float64(0.7844311377245509), np.float64(0.7068965517241379)]\n",
            "ID_TARGET: 76.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 241.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 214.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.8016 | Fold Accuracies: [np.float64(0.736318407960199), np.float64(0.7988505747126436), np.float64(0.7755102040816326), np.float64(0.7094972067039106), np.float64(0.764367816091954), np.float64(0.6961325966850829), np.float64(0.6802030456852792)]\n",
            "ID_TARGET: 102.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 145.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.7646 | Fold Accuracies: [np.float64(0.7074468085106383), np.float64(0.7819148936170213), np.float64(0.7837837837837838), np.float64(0.7202072538860104), np.float64(0.825136612021858), np.float64(0.7637362637362637), np.float64(0.7701863354037267)]\n",
            "ID_TARGET: 155.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.8074 | Fold Accuracies: [np.float64(0.8247422680412371), np.float64(0.8444444444444444), np.float64(0.7602040816326531), np.float64(0.7563451776649747), np.float64(0.8192090395480226), np.float64(0.7790055248618785), np.float64(0.7198067632850241)]\n",
            "\n",
            "Performing second-pass training with top 30 features...\n",
            "\n",
            "Second-pass LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rLightGBM Targets:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   1%|          | 1/100 [00:01<02:45,  1.67s/it]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   2%|         | 2/100 [00:02<02:10,  1.34s/it]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   3%|         | 3/100 [00:03<01:56,  1.20s/it]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   4%|         | 4/100 [00:04<01:34,  1.01it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   5%|         | 5/100 [00:05<01:21,  1.17it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   6%|         | 6/100 [00:05<01:11,  1.32it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   7%|         | 7/100 [00:06<01:04,  1.45it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   8%|         | 8/100 [00:06<01:06,  1.39it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   9%|         | 9/100 [00:07<01:06,  1.36it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  10%|         | 10/100 [00:08<01:03,  1.41it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  11%|         | 11/100 [00:09<01:05,  1.37it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  12%|        | 12/100 [00:09<01:04,  1.37it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  13%|        | 13/100 [00:10<01:05,  1.34it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  14%|        | 14/100 [00:11<01:05,  1.31it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  15%|        | 15/100 [00:12<01:03,  1.33it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  16%|        | 16/100 [00:13<01:03,  1.32it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  17%|        | 17/100 [00:13<01:05,  1.27it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  18%|        | 18/100 [00:14<01:08,  1.20it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  19%|        | 19/100 [00:15<01:12,  1.12it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  20%|        | 20/100 [00:16<01:13,  1.08it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  21%|        | 21/100 [00:17<01:08,  1.16it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  22%|       | 22/100 [00:18<01:03,  1.23it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  23%|       | 23/100 [00:18<01:00,  1.28it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  24%|       | 24/100 [00:19<00:56,  1.34it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  25%|       | 25/100 [00:20<00:53,  1.39it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  26%|       | 26/100 [00:20<00:52,  1.40it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  27%|       | 27/100 [00:21<00:52,  1.40it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  28%|       | 28/100 [00:22<00:49,  1.47it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  29%|       | 29/100 [00:22<00:48,  1.47it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  30%|       | 30/100 [00:23<00:47,  1.48it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  31%|       | 31/100 [00:24<00:44,  1.55it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  32%|      | 32/100 [00:24<00:44,  1.54it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  33%|      | 33/100 [00:25<00:42,  1.58it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  34%|      | 34/100 [00:26<00:41,  1.60it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  35%|      | 35/100 [00:26<00:41,  1.57it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  36%|      | 36/100 [00:27<00:44,  1.44it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  37%|      | 37/100 [00:28<00:48,  1.29it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  38%|      | 38/100 [00:29<00:50,  1.24it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  39%|      | 39/100 [00:30<00:53,  1.14it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  40%|      | 40/100 [00:31<00:48,  1.22it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  41%|      | 41/100 [00:31<00:47,  1.24it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  42%|     | 42/100 [00:32<00:44,  1.32it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  43%|     | 43/100 [00:33<00:41,  1.38it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  44%|     | 44/100 [00:33<00:38,  1.44it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  45%|     | 45/100 [00:34<00:37,  1.45it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  46%|     | 46/100 [00:35<00:36,  1.48it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  47%|     | 47/100 [00:35<00:35,  1.49it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  48%|     | 48/100 [00:36<00:35,  1.47it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  49%|     | 49/100 [00:37<00:33,  1.52it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  50%|     | 50/100 [00:37<00:33,  1.49it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  51%|     | 51/100 [00:38<00:32,  1.52it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  52%|    | 52/100 [00:39<00:31,  1.51it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  53%|    | 53/100 [00:39<00:30,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  54%|    | 54/100 [00:40<00:30,  1.50it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  55%|    | 55/100 [00:41<00:33,  1.36it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  56%|    | 56/100 [00:42<00:35,  1.26it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  57%|    | 57/100 [00:43<00:36,  1.18it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  58%|    | 58/100 [00:44<00:35,  1.18it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  59%|    | 59/100 [00:44<00:32,  1.26it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  60%|    | 60/100 [00:45<00:30,  1.29it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  61%|    | 61/100 [00:46<00:28,  1.35it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  62%|   | 62/100 [00:46<00:26,  1.41it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  63%|   | 63/100 [00:47<00:24,  1.50it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  64%|   | 64/100 [00:48<00:23,  1.51it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  65%|   | 65/100 [00:48<00:23,  1.50it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  66%|   | 66/100 [00:49<00:22,  1.54it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  67%|   | 67/100 [00:49<00:21,  1.52it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  68%|   | 68/100 [00:50<00:20,  1.54it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  69%|   | 69/100 [00:51<00:20,  1.54it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  70%|   | 70/100 [00:51<00:19,  1.58it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  71%|   | 71/100 [00:52<00:18,  1.59it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  72%|  | 72/100 [00:52<00:16,  1.70it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  73%|  | 73/100 [00:53<00:15,  1.71it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  74%|  | 74/100 [00:54<00:17,  1.51it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  75%|  | 75/100 [00:55<00:18,  1.32it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  76%|  | 76/100 [00:56<00:19,  1.21it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  77%|  | 77/100 [00:57<00:19,  1.17it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  78%|  | 78/100 [00:57<00:17,  1.26it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  79%|  | 79/100 [00:58<00:15,  1.33it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  80%|  | 80/100 [00:59<00:14,  1.35it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  81%|  | 81/100 [00:59<00:13,  1.39it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  82%| | 82/100 [01:00<00:12,  1.41it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  83%| | 83/100 [01:01<00:11,  1.44it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  84%| | 84/100 [01:02<00:11,  1.44it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  85%| | 85/100 [01:02<00:10,  1.46it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  86%| | 86/100 [01:03<00:09,  1.49it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  87%| | 87/100 [01:04<00:08,  1.48it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  88%| | 88/100 [01:04<00:07,  1.51it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  89%| | 89/100 [01:05<00:07,  1.51it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  90%| | 90/100 [01:06<00:06,  1.49it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  91%| | 91/100 [01:06<00:05,  1.52it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  92%|| 92/100 [01:07<00:05,  1.41it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  93%|| 93/100 [01:08<00:05,  1.28it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  94%|| 94/100 [01:09<00:04,  1.22it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  95%|| 95/100 [01:10<00:04,  1.14it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  96%|| 96/100 [01:10<00:03,  1.25it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  97%|| 97/100 [01:11<00:02,  1.34it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  98%|| 98/100 [01:12<00:01,  1.41it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  99%|| 99/100 [01:12<00:00,  1.42it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets: 100%|| 100/100 [01:13<00:00,  1.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Second-pass XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Targets: 100%|| 100/100 [01:31<00:00,  1.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Performing third-pass training for low-performing targets...\n",
            "\n",
            "Third-pass LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "LightGBM Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 88555.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Third-pass XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 54024.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Performing fourth-pass training for very low-performing targets...\n",
            "\n",
            "Fourth-pass LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "LightGBM Very Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 102985.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fourth-pass XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Very Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 89240.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved hyperparameter log to: /content/hyperparameters.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_0dad958f-cbd0-4ddd-bfbf-11e5c4744db7\", \"hyperparameters.json\", 1045717)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved predictions to: /content/predictions_ensemble.csv\n",
            "Output CSV shape: (114468, 2)\n",
            "Output CSV ID range: 0 to 114467\n",
            "Unique RET_TARGET values: [ 1 -1]\n",
            "Missing values: 0\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_390af415-87c0-47d9-ba82-5e8696ca56a7\", \"predictions_ensemble.csv\", 969456)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Results:\n",
            "LightGBM: 0.7546\n",
            "XGBoost: 0.8488\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost\n",
        "from sklearn.decomposition import PCA\n",
        "from joblib import Parallel, delayed\n",
        "import json\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# Check xgboost version for compatibility\n",
        "print(f\"XGBoost version: {xgboost.__version__}\")\n",
        "if int(xgboost.__version__.split('.')[0]) < 1:\n",
        "    print(\"Warning: XGBoost version < 1.0.0 detected. Ensure compatibility with eval_metric in constructor.\")\n",
        "\n",
        "# Set up data directory\n",
        "DATA_DIR = '/content'\n",
        "\n",
        "# Load datasets\n",
        "try:\n",
        "    X_train = pd.read_csv(os.path.join(DATA_DIR, 'X_train_itDkypA.csv'), index_col='ID', dtype=np.float32)\n",
        "    y_train = pd.read_csv(os.path.join(DATA_DIR, 'y_train_3LeeT2g.csv'), index_col='ID', dtype=np.float32)\n",
        "    X_test = pd.read_csv(os.path.join(DATA_DIR, 'X_test_Beg4ey3.csv'), index_col='ID', dtype=np.float32)\n",
        "    supplementary = pd.read_csv(os.path.join(DATA_DIR, 'supplementary_data_Vkoyn8z.csv'))\n",
        "except FileNotFoundError as e:\n",
        "    raise FileNotFoundError(f\"Dataset not found: {e}. Please ensure files are uploaded to {DATA_DIR}.\")\n",
        "\n",
        "# Custom weighted accuracy metric\n",
        "def weighted_accuracy(y_true, y_pred, weights):\n",
        "    y_pred_mapped = np.where(y_pred == 1, 1, -1)\n",
        "    correct = (y_pred_mapped == np.sign(y_true)).astype(float)\n",
        "    return np.sum(np.abs(y_true) * correct) / np.sum(np.abs(y_true))\n",
        "\n",
        "# Preprocess data with enhanced feature selection\n",
        "def preprocess_data(X, y=None, supplementary=None, is_train=True, top_cols=None):\n",
        "    ret_cols = [col for col in X.columns if col.startswith('RET_')]\n",
        "\n",
        "    # Dynamic feature selection with minimum variance threshold\n",
        "    if is_train and top_cols is None:\n",
        "        if len(ret_cols) > 15:\n",
        "            variances = X[ret_cols].var()\n",
        "            corr_sum = X[ret_cols].corr().abs().sum()\n",
        "            combined_score = variances * corr_sum\n",
        "            # Filter out low-variance features (threshold = 1e-5)\n",
        "            valid_cols = variances[variances > 1e-5].index\n",
        "            if len(valid_cols) < 15:\n",
        "                top_cols = valid_cols.tolist()\n",
        "            else:\n",
        "                top_cols = combined_score.loc[valid_cols].sort_values(ascending=False).head(15).index.tolist()\n",
        "        else:\n",
        "            top_cols = ret_cols\n",
        "        print(f\"Selected top return columns: {top_cols}\")\n",
        "    elif top_cols is not None:\n",
        "        ret_cols = [col for col in ret_cols if col in top_cols]\n",
        "        if not ret_cols:\n",
        "            raise ValueError(\"No return columns selected. Check top_cols consistency.\")\n",
        "\n",
        "    # Cache sector-based medians\n",
        "    sector_medians = {}\n",
        "    if supplementary is not None:\n",
        "        sector_map = supplementary.set_index('ID_asset')['CLASS_LEVEL_1']\n",
        "        for col in ret_cols:\n",
        "            asset_id = int(col.replace('RET_', ''))\n",
        "            sector = sector_map.get(asset_id, np.nan)\n",
        "            if pd.notna(sector):\n",
        "                sector_assets = supplementary[supplementary['CLASS_LEVEL_1'] == sector]['ID_asset']\n",
        "                sector_cols = [f'RET_{a}' for a in sector_assets if f'RET_{a}' in X.columns]\n",
        "                if sector_cols:\n",
        "                    sector_medians[col] = X[sector_cols].median(axis=1)\n",
        "            if col in sector_medians:\n",
        "                X[col] = X[col].fillna(sector_medians[col])\n",
        "            else:\n",
        "                X[col] = X[col].fillna(X[col].median())\n",
        "\n",
        "    # Sector-based features\n",
        "    new_cols = {}\n",
        "    if supplementary is not None:\n",
        "        level = 'CLASS_LEVEL_1'\n",
        "        sector_groups = supplementary.groupby(level)['ID_asset'].apply(list).to_dict()\n",
        "        for sector, assets in sector_groups.items():\n",
        "            asset_cols = [f'RET_{asset}' for asset in assets if f'RET_{asset}' in ret_cols]\n",
        "            if asset_cols:\n",
        "                new_cols[f'SECTOR_AVG_{level}_{sector}'] = X[asset_cols].mean(axis=1).replace([np.inf, -np.inf], 0).fillna(0)\n",
        "        X = X.merge(supplementary[['ID_asset', level]].rename(columns={'ID_asset': 'ID_TARGET', level: f'TARGET_{level}'}),\n",
        "                    on='ID_TARGET', how='left')\n",
        "        X = pd.concat([X, pd.get_dummies(X[f'TARGET_{level}'], prefix=f'TARGET_{level}', dummy_na=True)], axis=1)\n",
        "        X = X.drop(f'TARGET_{level}', axis=1)\n",
        "\n",
        "    # Cross-sectional features\n",
        "    new_cols['MEAN_RET'] = X[ret_cols].mean(axis=1)\n",
        "    new_cols['STD_RET'] = X[ret_cols].std(axis=1)\n",
        "    new_cols.update({f'CS_RANK_{col}': X.groupby('ID_DAY')[col].rank(pct=True).replace([np.inf, -np.inf], 0).fillna(0) for col in ret_cols})\n",
        "\n",
        "    # Correlation-based features (top 5 pairs)\n",
        "    if is_train:\n",
        "        corr_matrix = X[ret_cols].corr()\n",
        "        corr_pairs = corr_matrix.unstack().sort_values(ascending=False)\n",
        "        top_pairs = [(i, j) for i, j in corr_pairs.index if i < j][:5]\n",
        "        for i, j in top_pairs:\n",
        "            new_cols[f'CORR_{i}_{j}'] = X[i] * X[j]\n",
        "\n",
        "    # PCA features (2 components)\n",
        "    if ret_cols:\n",
        "        pca = PCA(n_components=min(2, len(ret_cols)), random_state=42)\n",
        "        pca_features = pca.fit_transform(X[ret_cols].fillna(0))\n",
        "        for i in range(pca_features.shape[1]):\n",
        "            new_cols[f'PCA_{i}'] = pca_features[:, i]\n",
        "\n",
        "    # Add new features to DataFrame\n",
        "    new_cols_df = pd.DataFrame(new_cols, index=X.index, dtype=np.float32)\n",
        "    X = pd.concat([X, new_cols_df], axis=1)\n",
        "\n",
        "    # Standardize numerical features\n",
        "    feature_cols = [col for col in X.columns if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "    scaler = StandardScaler()\n",
        "    X[feature_cols] = scaler.fit_transform(X[feature_cols].replace([np.inf, -np.inf], 0).fillna(0))\n",
        "\n",
        "    if is_train:\n",
        "        y['SIGN_TARGET'] = np.where(y['RET_TARGET'] > 0, 1, 0).astype(np.int32)\n",
        "        return X, y, feature_cols, top_cols\n",
        "    return X, None, feature_cols, top_cols\n",
        "\n",
        "# Preprocess data\n",
        "try:\n",
        "    X_train, y_train, feature_cols, top_cols = preprocess_data(X_train, y_train, supplementary, is_train=True)\n",
        "    X_test, _, test_feature_cols, _ = preprocess_data(X_test, supplementary=supplementary, is_train=False, top_cols=top_cols)\n",
        "except ValueError as e:\n",
        "    print(f\"Preprocessing error: {e}\")\n",
        "    raise\n",
        "\n",
        "# Align columns\n",
        "common_cols = X_train.columns.intersection(X_test.columns)\n",
        "X_train = X_train[common_cols]\n",
        "X_test = X_test[common_cols]\n",
        "feature_cols = [col for col in common_cols if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "\n",
        "# Align y_train\n",
        "y_train = y_train.loc[X_train.index]\n",
        "\n",
        "# Define models with expanded hyperparameter grids\n",
        "models = {\n",
        "    'LightGBM': {\n",
        "        'model': LGBMClassifier(num_leaves=31, min_child_samples=15, lambda_l1=0.3, lambda_l2=0.3,\n",
        "                                subsample=0.7, colsample_bytree=0.8, bagging_freq=5, bagging_fraction=0.7,\n",
        "                                random_state=42, n_jobs=1, verbosity=-1, class_weight='balanced', force_row_wise=True),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.01], 'num_leaves': [15], 'min_child_samples': [20], 'bagging_fraction': [0.6], 'reg_alpha': [0.0], 'reg_lambda': [0.0]},\n",
        "            {'learning_rate': [0.03], 'num_leaves': [31], 'min_child_samples': [10], 'bagging_fraction': [0.7], 'reg_alpha': [0.1], 'reg_lambda': [0.1]},\n",
        "            {'learning_rate': [0.05], 'num_leaves': [47], 'min_child_samples': [15], 'bagging_fraction': [0.8], 'reg_alpha': [0.2], 'reg_lambda': [0.2]},\n",
        "            {'learning_rate': [0.07], 'num_leaves': [63], 'min_child_samples': [12], 'bagging_fraction': [0.65], 'reg_alpha': [0.3], 'reg_lambda': [0.3]},\n",
        "            {'learning_rate': [0.1], 'num_leaves': [31], 'min_child_samples': [20], 'bagging_fraction': [0.75], 'reg_alpha': [0.0], 'reg_lambda': [0.1]},\n",
        "            {'learning_rate': [0.02], 'num_leaves': [47], 'min_child_samples': [10], 'bagging_fraction': [0.7], 'reg_alpha': [0.2], 'reg_lambda': [0.0]}\n",
        "        ],\n",
        "        'callbacks': [lightgbm.early_stopping(stopping_rounds=15, verbose=False)]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'model': XGBClassifier(max_depth=4, min_child_weight=2, subsample=0.8, colsample_bytree=0.8,\n",
        "                               random_state=42, n_jobs=1, eval_metric='logloss', verbosity=0,\n",
        "                               scale_pos_weight=len(y_train[y_train['SIGN_TARGET'] == 0]) / len(y_train[y_train['SIGN_TARGET'] == 1])),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.01], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [150], 'reg_alpha': [0.0], 'reg_lambda': [1.0]},\n",
        "            {'learning_rate': [0.03], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [200], 'reg_alpha': [0.1], 'reg_lambda': [1.5]},\n",
        "            {'learning_rate': [0.05], 'max_depth': [5], 'min_child_weight': [3], 'subsample': [0.8], 'n_estimators': [150], 'reg_alpha': [0.2], 'reg_lambda': [1.0]},\n",
        "            {'learning_rate': [0.07], 'max_depth': [6], 'min_child_weight': [1], 'subsample': [0.75], 'n_estimators': [200], 'reg_alpha': [0.3], 'reg_lambda': [1.5]},\n",
        "            {'learning_rate': [0.1], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [250], 'reg_alpha': [0.0], 'reg_lambda': [1.0]},\n",
        "            {'learning_rate': [0.02], 'max_depth': [5], 'min_child_weight': [3], 'subsample': [0.65], 'n_estimators': [200], 'reg_alpha': [0.1], 'reg_lambda': [1.2]}\n",
        "        ],\n",
        "        'callbacks': [xgboost.callback.EarlyStopping(rounds=15, metric_name='logloss', save_best=True)]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to train and predict for a single target\n",
        "def train_target(target, X_train, y_train, X_test, feature_cols, model, model_name, kf, param_grid, callbacks):\n",
        "    X_target = X_train[X_train['ID_TARGET'] == target][feature_cols]\n",
        "    y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "    weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "    low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "    # Dynamic weight scaling based on sample size\n",
        "    weight_scale = 2.0 if target in low_performing_targets else 1.0\n",
        "    if len(X_target) < 500:\n",
        "        weight_scale *= 1.5  # Boost weights for small targets\n",
        "    weights = weights * weight_scale\n",
        "    groups = X_train[X_train['ID_TARGET'] == target]['ID_DAY']\n",
        "    X_test_target = X_test[X_test['ID_TARGET'] == target][feature_cols]\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "    # Check for sufficient data\n",
        "    if len(X_target) < 100 or len(X_test_target) == 0:\n",
        "        print(f\"Warning: Insufficient data for ID_TARGET {target} (train: {len(X_target)}, test: {len(X_test_target)}). Skipping.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    param_results = []\n",
        "    best_params = None\n",
        "    best_score = 0\n",
        "    best_model = None\n",
        "\n",
        "    # First-pass grid search with sample weights\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        print(f\"Testing params for {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "        try:\n",
        "            model.set_params(**params)\n",
        "        except ValueError as e:\n",
        "            print(f\"Invalid params for {model_name} ID_TARGET {target}: {e}\")\n",
        "            continue\n",
        "        fold_accuracies = []\n",
        "        for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "            X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "            y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "            w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "\n",
        "            if model_name == 'LightGBM' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=callbacks)\n",
        "            elif model_name == 'XGBoost' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "            else:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "            y_pred = model.predict(X_val)\n",
        "            acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "            fold_accuracies.append(acc)\n",
        "\n",
        "        mean_acc = np.mean(fold_accuracies)\n",
        "        print(f\"{model_name} | ID_TARGET: {target} | Params: {params} | Mean Accuracy: {mean_acc:.4f} | Fold Accuracies: {fold_accuracies}\", flush=True)\n",
        "        param_results.append({\n",
        "            'params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': fold_accuracies\n",
        "        })\n",
        "        if mean_acc > best_score:\n",
        "            best_score = mean_acc\n",
        "            best_params = params\n",
        "            best_model = type(model)(**model.get_params())\n",
        "\n",
        "    # Train with best parameters\n",
        "    if best_model is None:\n",
        "        print(f\"No valid model for {model_name} ID_TARGET {target}. Using default.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    best_model.set_params(**best_params)\n",
        "    if model_name == 'LightGBM' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=callbacks)\n",
        "    elif model_name == 'XGBoost' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "    else:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights)\n",
        "\n",
        "    # Predict\n",
        "    preds = best_model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "\n",
        "    # Feature importance\n",
        "    importance = best_model.feature_importances_\n",
        "    feature_importance = dict(zip(feature_cols, importance))\n",
        "    top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:30]\n",
        "\n",
        "    # Clean up memory\n",
        "    gc.collect()\n",
        "\n",
        "    return str(target), best_params, best_score, param_results, test_ids, preds, top_features\n",
        "\n",
        "# Cross-validation and training\n",
        "kf = GroupKFold(n_splits=7)  # Increased to 7 folds\n",
        "results = {}\n",
        "predictions = {}\n",
        "ensemble_weights = {'LightGBM': 0.7, 'XGBoost': 0.3}\n",
        "param_log = {}\n",
        "top_features_all = {}\n",
        "param_summary = []\n",
        "low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\", flush=True)\n",
        "    param_log[model_name] = {}\n",
        "    top_features_all[model_name] = {}\n",
        "\n",
        "    # First-pass training\n",
        "    results_parallel = Parallel(n_jobs=-1)(\n",
        "        delayed(train_target)(target, X_train, y_train, X_test, feature_cols, model_info['model'], model_name, kf,\n",
        "                             model_info['param_grid'], model_info['callbacks'])\n",
        "        for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\")\n",
        "    )\n",
        "\n",
        "    # Collect results\n",
        "    accuracies = []\n",
        "    for target, params, mean_acc, param_results, test_ids, preds, top_features in results_parallel:\n",
        "        param_log[model_name][target] = {\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'all_params': param_results\n",
        "        }\n",
        "        top_features_all[model_name][target] = top_features\n",
        "        accuracies.append(mean_acc)\n",
        "        predictions.setdefault(target, {})[model_name] = dict(zip(test_ids, preds))\n",
        "        param_summary.append({\n",
        "            'model': model_name,\n",
        "            'ID_TARGET': target,\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': param_results[-1]['fold_accuracies'] if param_results else []\n",
        "        })\n",
        "\n",
        "    results[model_name] = np.mean([acc for acc in accuracies if acc > 0])  # Exclude skipped targets\n",
        "    print(f\"{model_name} Weighted Accuracy: {results[model_name]:.4f}\", flush=True)\n",
        "\n",
        "    # Print parameter summary\n",
        "    print(f\"\\n{model_name} Parameter Summary:\", flush=True)\n",
        "    for summary in param_summary:\n",
        "        if summary['model'] == model_name:\n",
        "            print(f\"ID_TARGET: {summary['ID_TARGET']} | Best Params: {summary['best_params']} | Mean Accuracy: {summary['mean_accuracy']:.4f} | Fold Accuracies: {summary['fold_accuracies']}\", flush=True)\n",
        "\n",
        "# Second-pass training with top 30 features\n",
        "print(\"\\nPerforming second-pass training with top 30 features...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nSecond-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\"):\n",
        "        target_str = str(target)\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "        weight_scale = 2.0 if target in low_performing_targets else 1.0\n",
        "        if len(X_target) < 500:\n",
        "            weight_scale *= 1.5\n",
        "        weights = weights * weight_scale\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        best_params['n_estimators'] = 300  # Use integer instead of list\n",
        "        model.set_params(**best_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Third-pass training for low-performing targets\n",
        "print(\"\\nPerforming third-pass training for low-performing targets...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nThird-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(low_performing_targets, desc=f\"{model_name} Low-Performing Targets\"):\n",
        "        target_str = str(target)\n",
        "        if target_str not in param_log[model_name] or param_log[model_name][target_str]['mean_accuracy'] >= 0.75:\n",
        "            continue  # Skip if already performing well\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs() * 3.0  # Increase weight\n",
        "        if len(X_target) < 500:\n",
        "            weights = weights * 1.5\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        # Fine-tune parameters for low-performing targets with scalar values\n",
        "        fine_tune_grid = [\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.7, 'n_estimators': 400, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.3, 'n_estimators': 400, 'reg_alpha': best_params['reg_alpha'][0], 'reg_lambda': best_params['reg_lambda'][0]}\n",
        "        ]\n",
        "        best_score = param_log[model_name][target_str]['mean_accuracy']\n",
        "        best_fine_params = best_params\n",
        "\n",
        "        for params in ParameterGrid(fine_tune_grid):\n",
        "            print(f\"Fine-tuning {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "            model.set_params(**params)\n",
        "            fold_accuracies = []\n",
        "            for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "                X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "                y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "                w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "                if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "                elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "                else:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "                y_pred = model.predict(X_val)\n",
        "                acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "                fold_accuracies.append(acc)\n",
        "            mean_acc = np.mean(fold_accuracies)\n",
        "            print(f\"{model_name} | ID_TARGET: {target} | Fine-tune Params: {params} | Mean Accuracy: {mean_acc:.4f}\", flush=True)\n",
        "            if mean_acc > best_score:\n",
        "                best_score = mean_acc\n",
        "                best_fine_params = params\n",
        "                param_log[model_name][target_str]['best_params'] = best_fine_params\n",
        "                param_log[model_name][target_str]['mean_accuracy'] = best_score\n",
        "                param_summary.append({\n",
        "                    'model': model_name,\n",
        "                    'ID_TARGET': target_str,\n",
        "                    'best_params': best_fine_params,\n",
        "                    'mean_accuracy': best_score,\n",
        "                    'fold_accuracies': fold_accuracies\n",
        "                })\n",
        "\n",
        "        # Retrain with fine-tuned parameters\n",
        "        model.set_params(**best_fine_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Fourth-pass training for very low-performing targets\n",
        "print(\"\\nPerforming fourth-pass training for very low-performing targets...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nFourth-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(low_performing_targets, desc=f\"{model_name} Very Low-Performing Targets\"):\n",
        "        target_str = str(target)\n",
        "        if target_str not in param_log[model_name] or param_log[model_name][target_str]['mean_accuracy'] >= 0.70:\n",
        "            continue  # Skip if accuracy >= 0.70\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs() * 3.0  # High weight\n",
        "        if len(X_target) < 500:\n",
        "            weights = weights * 1.5\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        # Expanded fine-tuning grid for very low-performing targets with scalar values\n",
        "        fine_tune_grid = [\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.5, 'n_estimators': 400, 'reg_alpha': best_params['reg_alpha'][0] + 0.2, 'reg_lambda': best_params['reg_lambda'][0] + 0.2},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.5, 'n_estimators': 400, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1},\n",
        "            {'learning_rate': best_params['learning_rate'][0], 'n_estimators': 500, 'reg_alpha': best_params['reg_alpha'][0], 'reg_lambda': best_params['reg_lambda'][0]}\n",
        "        ]\n",
        "        best_score = param_log[model_name][target_str]['mean_accuracy']\n",
        "        best_fine_params = best_params\n",
        "\n",
        "        for params in ParameterGrid(fine_tune_grid):\n",
        "            print(f\"Fine-tuning {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "            model.set_params(**params)\n",
        "            fold_accuracies = []\n",
        "            for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "                X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "                y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "                w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "                if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "                elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "                else:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "                y_pred = model.predict(X_val)\n",
        "                acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "                fold_accuracies.append(acc)\n",
        "            mean_acc = np.mean(fold_accuracies)\n",
        "            print(f\"{model_name} | ID_TARGET: {target} | Fine-tune Params: {params} | Mean Accuracy: {mean_acc:.4f}\", flush=True)\n",
        "            if mean_acc > best_score:\n",
        "                best_score = mean_acc\n",
        "                best_fine_params = params\n",
        "                param_log[model_name][target_str]['best_params'] = best_fine_params\n",
        "                param_log[model_name][target_str]['mean_accuracy'] = best_score\n",
        "                param_summary.append({\n",
        "                    'model': model_name,\n",
        "                    'ID_TARGET': target_str,\n",
        "                    'best_params': best_fine_params,\n",
        "                    'mean_accuracy': best_score,\n",
        "                    'fold_accuracies': fold_accuracies\n",
        "                })\n",
        "\n",
        "        # Retrain with fine-tuned parameters\n",
        "        model.set_params(**best_fine_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Save parameter log\n",
        "param_log_path = os.path.join(DATA_DIR, 'hyperparameters.json')\n",
        "with open(param_log_path, 'w') as f:\n",
        "    json.dump(param_log, f, indent=4)\n",
        "print(f\"Saved hyperparameter log to: {param_log_path}\", flush=True)\n",
        "files.download(param_log_path)\n",
        "\n",
        "# Ensemble predictions\n",
        "final_predictions = {}\n",
        "missing_day_targets = []\n",
        "for target in X_test['ID_TARGET'].unique():\n",
        "    target_str = str(target)\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "    for day in X_test[X_test['ID_TARGET'] == target]['ID_DAY'].unique():\n",
        "        day_idx = (X_test['ID_TARGET'] == target) & (X_test['ID_DAY'] == day)\n",
        "        day_test_ids = X_test[day_idx].index\n",
        "        if len(day_test_ids) == 0:\n",
        "            print(f\"Warning: No test samples for ID_TARGET {target} on ID_DAY {day}. Using default prediction.\")\n",
        "            missing_day_targets.append((target, day))\n",
        "            for idx in test_ids:\n",
        "                final_predictions[idx] = -1\n",
        "            continue\n",
        "        lgbm_preds = np.array([predictions[target_str].get('LightGBM', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        xgb_preds = np.array([predictions[target_str].get('XGBoost', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        ensemble_preds = ensemble_weights['LightGBM'] * lgbm_preds + ensemble_weights['XGBoost'] * xgb_preds\n",
        "        # Apply exponential moving average for smoothing\n",
        "        smoothed_preds = pd.Series(ensemble_preds).ewm(span=3).mean().values[-1] if len(ensemble_preds) > 0 else 0.5\n",
        "        for idx in day_test_ids:\n",
        "            final_predictions[idx] = 1 if smoothed_preds >= 0.5 else -1\n",
        "\n",
        "if missing_day_targets:\n",
        "    print(f\"Missing day-target pairs: {missing_day_targets}\")\n",
        "\n",
        "# Create output CSV\n",
        "output_df = pd.DataFrame.from_dict(final_predictions, orient='index', columns=['RET_TARGET']).reset_index()\n",
        "output_df.columns = ['ID', 'RET_TARGET']\n",
        "output_df = output_df.sort_values('ID')\n",
        "expected_ids = set(X_test.index)\n",
        "submission_ids = set(output_df['ID'])\n",
        "if expected_ids != submission_ids:\n",
        "    missing_ids = expected_ids - submission_ids\n",
        "    print(f\"Warning: Submission missing {len(missing_ids)} IDs: {missing_ids}\")\n",
        "    missing_df = pd.DataFrame({'ID': list(missing_ids), 'RET_TARGET': -1})\n",
        "    output_df = pd.concat([output_df, missing_df], ignore_index=True).sort_values('ID')\n",
        "output_path = os.path.join(DATA_DIR, 'predictions_ensemble.csv')\n",
        "output_df.to_csv(output_path, index=False)\n",
        "print(f\"Saved predictions to: {output_path}\", flush=True)\n",
        "\n",
        "# Validate output\n",
        "test_csv = pd.read_csv(output_path)\n",
        "print(f\"Output CSV shape: {test_csv.shape}\", flush=True)\n",
        "print(f\"Output CSV ID range: {test_csv['ID'].min()} to {test_csv['ID'].max()}\", flush=True)\n",
        "print(f\"Unique RET_TARGET values: {test_csv['RET_TARGET'].unique()}\", flush=True)\n",
        "print(f\"Missing values: {test_csv.isna().sum().sum()}\", flush=True)\n",
        "\n",
        "# Download the file\n",
        "files.download(output_path)\n",
        "\n",
        "# Print final results\n",
        "print(\"\\nValidation Results:\", flush=True)\n",
        "for model_name, acc in results.items():\n",
        "    print(f\"{model_name}: {acc:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HivDwlj_rcQD"
      },
      "source": [
        "try try - 73%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p65HVEFMrdDW",
        "outputId": "108b34af-4537-482b-cf5f-ac1bc4cdb510"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost version: 2.1.4\n",
            "Selected top return columns: ['RET_262', 'RET_88', 'RET_172', 'RET_259', 'RET_118', 'RET_150', 'RET_261', 'RET_268', 'RET_115', 'RET_216', 'RET_238', 'RET_59', 'RET_30', 'RET_97', 'RET_122']\n",
            "\n",
            "Training LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LightGBM Targets: 100%|| 101/101 [58:45<00:00, 34.91s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightGBM Weighted Accuracy: 0.7985\n",
            "\n",
            "LightGBM Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6257668711656442), np.float64(0.7515527950310559), np.float64(0.7692307692307693), np.float64(0.6606060606060606), np.float64(0.6408839779005525), np.float64(0.8169934640522876), np.float64(0.7232704402515723)]\n",
            "ID_TARGET: 129.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7565 | Fold Accuracies: [np.float64(0.61875), np.float64(0.6296296296296297), np.float64(0.610062893081761), np.float64(0.6802325581395349), np.float64(0.6172839506172839), np.float64(0.5974842767295597), np.float64(0.625)]\n",
            "ID_TARGET: 136.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7171 | Fold Accuracies: [np.float64(0.6415094339622641), np.float64(0.5949367088607594), np.float64(0.6457142857142857), np.float64(0.6477272727272727), np.float64(0.5857988165680473), np.float64(0.6091954022988506), np.float64(0.5961538461538461)]\n",
            "ID_TARGET: 161.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7306 | Fold Accuracies: [np.float64(0.5771812080536913), np.float64(0.6742857142857143), np.float64(0.6463414634146342), np.float64(0.6545454545454545), np.float64(0.7023809523809523), np.float64(0.7016574585635359), np.float64(0.6280487804878049)]\n",
            "ID_TARGET: 217.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8085 | Fold Accuracies: [np.float64(0.718562874251497), np.float64(0.6666666666666666), np.float64(0.6704545454545454), np.float64(0.655367231638418), np.float64(0.6604938271604939), np.float64(0.6590909090909091), np.float64(0.7282608695652174)]\n",
            "ID_TARGET: 91.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8267 | Fold Accuracies: [np.float64(0.7329192546583851), np.float64(0.7), np.float64(0.6863905325443787), np.float64(0.7103448275862069), np.float64(0.6037735849056604), np.float64(0.7055214723926381), np.float64(0.6506024096385542)]\n",
            "ID_TARGET: 137.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7364 | Fold Accuracies: [np.float64(0.5944055944055944), np.float64(0.6666666666666666), np.float64(0.6809815950920245), np.float64(0.6774193548387096), np.float64(0.5766871165644172), np.float64(0.6265060240963856), np.float64(0.6624203821656051)]\n",
            "ID_TARGET: 8.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8743 | Fold Accuracies: [np.float64(0.7441860465116279), np.float64(0.6855345911949685), np.float64(0.8181818181818182), np.float64(0.779874213836478), np.float64(0.8116883116883117), np.float64(0.6976744186046512), np.float64(0.56)]\n",
            "ID_TARGET: 3.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8336 | Fold Accuracies: [np.float64(0.6643835616438356), np.float64(0.74375), np.float64(0.7861635220125787), np.float64(0.6966292134831461), np.float64(0.6887417218543046), np.float64(0.6026490066225165), np.float64(0.6751592356687898)]\n",
            "ID_TARGET: 9.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8174 | Fold Accuracies: [np.float64(0.6724137931034483), np.float64(0.6547619047619048), np.float64(0.7834394904458599), np.float64(0.6397058823529411), np.float64(0.5941176470588235), np.float64(0.6973684210526315), np.float64(0.5632911392405063)]\n",
            "ID_TARGET: 131.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8020 | Fold Accuracies: [np.float64(0.6571428571428571), np.float64(0.6708860759493671), np.float64(0.7321428571428571), np.float64(0.6875), np.float64(0.7197452229299363), np.float64(0.6458333333333334), np.float64(0.5632911392405063)]\n",
            "ID_TARGET: 21.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7011 | Fold Accuracies: [np.float64(0.562874251497006), np.float64(0.6441717791411042), np.float64(0.6625766871165644), np.float64(0.5689655172413793), np.float64(0.7419354838709677), np.float64(0.6704545454545454), np.float64(0.6470588235294118)]\n",
            "ID_TARGET: 54.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8840 | Fold Accuracies: [np.float64(0.6624203821656051), np.float64(0.6754966887417219), np.float64(0.6571428571428571), np.float64(0.7904191616766467), np.float64(0.6848484848484848), np.float64(0.7065217391304348), np.float64(0.8238993710691824)]\n",
            "ID_TARGET: 130.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8535 | Fold Accuracies: [np.float64(0.8085106382978723), np.float64(0.7672955974842768), np.float64(0.7028571428571428), np.float64(0.7041420118343196), np.float64(0.7159763313609467), np.float64(0.7619047619047619), np.float64(0.7861271676300579)]\n",
            "ID_TARGET: 269.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8071 | Fold Accuracies: [np.float64(0.676056338028169), np.float64(0.6516129032258065), np.float64(0.6818181818181818), np.float64(0.6858974358974359), np.float64(0.6274509803921569), np.float64(0.6143790849673203), np.float64(0.6754966887417219)]\n",
            "ID_TARGET: 157.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8341 | Fold Accuracies: [np.float64(0.7161290322580646), np.float64(0.726027397260274), np.float64(0.7987421383647799), np.float64(0.8079470198675497), np.float64(0.6369426751592356), np.float64(0.6948051948051948), np.float64(0.7514450867052023)]\n",
            "ID_TARGET: 249.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8086 | Fold Accuracies: [np.float64(0.7225433526011561), np.float64(0.7192982456140351), np.float64(0.7307692307692307), np.float64(0.6627218934911243), np.float64(0.6137931034482759), np.float64(0.7515527950310559), np.float64(0.7701863354037267)]\n",
            "ID_TARGET: 22.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7122 | Fold Accuracies: [np.float64(0.6506024096385542), np.float64(0.6648351648351648), np.float64(0.7028571428571428), np.float64(0.6987951807228916), np.float64(0.6547619047619048), np.float64(0.6287425149700598), np.float64(0.7197452229299363)]\n",
            "ID_TARGET: 202.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.6610 | Fold Accuracies: [np.float64(0.6235294117647059), np.float64(0.6645569620253164), np.float64(0.6608187134502924), np.float64(0.6744186046511628), np.float64(0.6235294117647059), np.float64(0.5964912280701754), np.float64(0.6022099447513812)]\n",
            "ID_TARGET: 132.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8100 | Fold Accuracies: [np.float64(0.7804878048780488), np.float64(0.75), np.float64(0.7189542483660131), np.float64(0.7577639751552795), np.float64(0.6956521739130435), np.float64(0.7161290322580646), np.float64(0.75)]\n",
            "ID_TARGET: 96.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8195 | Fold Accuracies: [np.float64(0.7647058823529411), np.float64(0.6785714285714286), np.float64(0.6710526315789473), np.float64(0.6713286713286714), np.float64(0.6818181818181818), np.float64(0.6601307189542484), np.float64(0.6575342465753424)]\n",
            "ID_TARGET: 7.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8299 | Fold Accuracies: [np.float64(0.7161290322580646), np.float64(0.7471264367816092), np.float64(0.7045454545454546), np.float64(0.7612903225806451), np.float64(0.7513513513513513), np.float64(0.75625), np.float64(0.7597765363128491)]\n",
            "ID_TARGET: 178.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7532 | Fold Accuracies: [np.float64(0.7383720930232558), np.float64(0.6708860759493671), np.float64(0.6666666666666666), np.float64(0.7), np.float64(0.7202380952380952), np.float64(0.75625), np.float64(0.7114093959731543)]\n",
            "ID_TARGET: 68.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7956 | Fold Accuracies: [np.float64(0.6867469879518072), np.float64(0.7453416149068323), np.float64(0.7531645569620253), np.float64(0.7215189873417721), np.float64(0.7297297297297297), np.float64(0.7577639751552795), np.float64(0.75)]\n",
            "ID_TARGET: 44.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7997 | Fold Accuracies: [np.float64(0.757396449704142), np.float64(0.7278481012658228), np.float64(0.6962025316455697), np.float64(0.7090909090909091), np.float64(0.6994219653179191), np.float64(0.6646706586826348), np.float64(0.688622754491018)]\n",
            "ID_TARGET: 196.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7967 | Fold Accuracies: [np.float64(0.6464088397790055), np.float64(0.6594594594594595), np.float64(0.6836158192090396), np.float64(0.6864864864864865), np.float64(0.6453488372093024), np.float64(0.7083333333333334), np.float64(0.7215909090909091)]\n",
            "ID_TARGET: 292.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8071 | Fold Accuracies: [np.float64(0.6402116402116402), np.float64(0.6833333333333333), np.float64(0.7142857142857143), np.float64(0.7483870967741936), np.float64(0.6363636363636364), np.float64(0.703030303030303), np.float64(0.6820809248554913)]\n",
            "ID_TARGET: 239.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7988 | Fold Accuracies: [np.float64(0.7407407407407407), np.float64(0.710691823899371), np.float64(0.71875), np.float64(0.7123287671232876), np.float64(0.7818181818181819), np.float64(0.7204968944099379), np.float64(0.7432432432432432)]\n",
            "ID_TARGET: 279.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8173 | Fold Accuracies: [np.float64(0.7450980392156863), np.float64(0.7393939393939394), np.float64(0.6644295302013423), np.float64(0.6666666666666666), np.float64(0.7076023391812866), np.float64(0.7341040462427746), np.float64(0.6047904191616766)]\n",
            "ID_TARGET: 38.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8580 | Fold Accuracies: [np.float64(0.6167664670658682), np.float64(0.6180555555555556), np.float64(0.6518987341772152), np.float64(0.6770186335403726), np.float64(0.723404255319149), np.float64(0.7062146892655368), np.float64(0.7257142857142858)]\n",
            "ID_TARGET: 209.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7800 | Fold Accuracies: [np.float64(0.7531645569620253), np.float64(0.6666666666666666), np.float64(0.6395348837209303), np.float64(0.6867469879518072), np.float64(0.7570621468926554), np.float64(0.6705882352941176), np.float64(0.6282051282051282)]\n",
            "ID_TARGET: 207.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7370 | Fold Accuracies: [np.float64(0.7051282051282052), np.float64(0.6139240506329114), np.float64(0.6896551724137931), np.float64(0.6339869281045751), np.float64(0.7222222222222222), np.float64(0.6338797814207651), np.float64(0.6724137931034483)]\n",
            "ID_TARGET: 98.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7685 | Fold Accuracies: [np.float64(0.7125), np.float64(0.6835443037974683), np.float64(0.7371794871794872), np.float64(0.7169811320754716), np.float64(0.5987654320987654), np.float64(0.7245508982035929), np.float64(0.703030303030303)]\n",
            "ID_TARGET: 65.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7774 | Fold Accuracies: [np.float64(0.7602339181286549), np.float64(0.7419354838709677), np.float64(0.7283950617283951), np.float64(0.6455696202531646), np.float64(0.678082191780822), np.float64(0.6387096774193548), np.float64(0.7741935483870968)]\n",
            "ID_TARGET: 51.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8040 | Fold Accuracies: [np.float64(0.75), np.float64(0.7933333333333333), np.float64(0.6776315789473685), np.float64(0.7770700636942676), np.float64(0.7290322580645161), np.float64(0.7169811320754716), np.float64(0.7105263157894737)]\n",
            "ID_TARGET: 78.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7885 | Fold Accuracies: [np.float64(0.7517241379310344), np.float64(0.7142857142857143), np.float64(0.5986394557823129), np.float64(0.7283950617283951), np.float64(0.7114093959731543), np.float64(0.6624203821656051), np.float64(0.7484662576687117)]\n",
            "ID_TARGET: 177.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7432 | Fold Accuracies: [np.float64(0.703030303030303), np.float64(0.7215189873417721), np.float64(0.7081081081081081), np.float64(0.7527472527472527), np.float64(0.6923076923076923), np.float64(0.6863905325443787), np.float64(0.7065217391304348)]\n",
            "ID_TARGET: 231.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8483 | Fold Accuracies: [np.float64(0.7922077922077922), np.float64(0.7514450867052023), np.float64(0.7804878048780488), np.float64(0.7423312883435583), np.float64(0.7771084337349398), np.float64(0.7374301675977654), np.float64(0.75)]\n",
            "ID_TARGET: 119.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8116 | Fold Accuracies: [np.float64(0.8079470198675497), np.float64(0.7784810126582279), np.float64(0.779874213836478), np.float64(0.7232704402515723), np.float64(0.7239263803680982), np.float64(0.7515923566878981), np.float64(0.7231638418079096)]\n",
            "ID_TARGET: 158.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8371 | Fold Accuracies: [np.float64(0.7959183673469388), np.float64(0.8214285714285714), np.float64(0.7900552486187845), np.float64(0.7583892617449665), np.float64(0.8242424242424242), np.float64(0.7615894039735099), np.float64(0.7932960893854749)]\n",
            "ID_TARGET: 80.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7310 | Fold Accuracies: [np.float64(0.6291390728476821), np.float64(0.6687898089171974), np.float64(0.675), np.float64(0.676829268292683), np.float64(0.7134146341463414), np.float64(0.72), np.float64(0.7687861271676301)]\n",
            "ID_TARGET: 25.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7882 | Fold Accuracies: [np.float64(0.7341040462427746), np.float64(0.6772151898734177), np.float64(0.6496815286624203), np.float64(0.7207792207792207), np.float64(0.6946107784431138), np.float64(0.7375), np.float64(0.7375)]\n",
            "ID_TARGET: 175.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8328 | Fold Accuracies: [np.float64(0.7006802721088435), np.float64(0.6585365853658537), np.float64(0.7396449704142012), np.float64(0.7724550898203593), np.float64(0.7439024390243902), np.float64(0.7151515151515152), np.float64(0.7171052631578947)]\n",
            "ID_TARGET: 151.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8145 | Fold Accuracies: [np.float64(0.8121212121212121), np.float64(0.8012422360248447), np.float64(0.7548387096774194), np.float64(0.7407407407407407), np.float64(0.7329192546583851), np.float64(0.7672955974842768), np.float64(0.7516339869281046)]\n",
            "ID_TARGET: 257.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7763 | Fold Accuracies: [np.float64(0.6827956989247311), np.float64(0.73125), np.float64(0.7485029940119761), np.float64(0.6611111111111111), np.float64(0.7325581395348837), np.float64(0.7142857142857143), np.float64(0.6419753086419753)]\n",
            "ID_TARGET: 75.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8373 | Fold Accuracies: [np.float64(0.7966101694915254), np.float64(0.7950310559006211), np.float64(0.7647058823529411), np.float64(0.6890243902439024), np.float64(0.7547169811320755), np.float64(0.7542857142857143), np.float64(0.7857142857142857)]\n",
            "ID_TARGET: 244.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7342 | Fold Accuracies: [np.float64(0.6609195402298851), np.float64(0.6931818181818182), np.float64(0.7058823529411765), np.float64(0.5963855421686747), np.float64(0.70625), np.float64(0.6303030303030303), np.float64(0.7251461988304093)]\n",
            "ID_TARGET: 149.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8290 | Fold Accuracies: [np.float64(0.7025316455696202), np.float64(0.7530120481927711), np.float64(0.7450980392156863), np.float64(0.732620320855615), np.float64(0.6686746987951807), np.float64(0.6329113924050633), np.float64(0.7584269662921348)]\n",
            "ID_TARGET: 85.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8367 | Fold Accuracies: [np.float64(0.7349397590361446), np.float64(0.75), np.float64(0.7658227848101266), np.float64(0.7), np.float64(0.8), np.float64(0.7712418300653595), np.float64(0.7435897435897436)]\n",
            "ID_TARGET: 190.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7555 | Fold Accuracies: [np.float64(0.6729559748427673), np.float64(0.6900584795321637), np.float64(0.7457627118644068), np.float64(0.7239263803680982), np.float64(0.7134502923976608), np.float64(0.7209302325581395), np.float64(0.8012048192771084)]\n",
            "ID_TARGET: 13.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7770 | Fold Accuracies: [np.float64(0.6906077348066298), np.float64(0.7423312883435583), np.float64(0.7261904761904762), np.float64(0.6949152542372882), np.float64(0.7023809523809523), np.float64(0.7086092715231788), np.float64(0.7928994082840237)]\n",
            "ID_TARGET: 228.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7630 | Fold Accuracies: [np.float64(0.7345679012345679), np.float64(0.6882352941176471), np.float64(0.6966292134831461), np.float64(0.6728395061728395), np.float64(0.7108433734939759), np.float64(0.7043010752688172), np.float64(0.6646706586826348)]\n",
            "ID_TARGET: 144.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8360 | Fold Accuracies: [np.float64(0.7831325301204819), np.float64(0.7647058823529411), np.float64(0.8263888888888888), np.float64(0.7290322580645161), np.float64(0.7705882352941177), np.float64(0.7898089171974523), np.float64(0.8081395348837209)]\n",
            "ID_TARGET: 290.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8179 | Fold Accuracies: [np.float64(0.6331360946745562), np.float64(0.7791411042944786), np.float64(0.6756756756756757), np.float64(0.7177914110429447), np.float64(0.7317073170731707), np.float64(0.75625), np.float64(0.7044025157232704)]\n",
            "ID_TARGET: 114.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7147 | Fold Accuracies: [np.float64(0.6904761904761905), np.float64(0.7044025157232704), np.float64(0.6242424242424243), np.float64(0.7391304347826086), np.float64(0.7530864197530864), np.float64(0.6742857142857143), np.float64(0.7062146892655368)]\n",
            "ID_TARGET: 166.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8134 | Fold Accuracies: [np.float64(0.7470588235294118), np.float64(0.6746987951807228), np.float64(0.7885714285714286), np.float64(0.7439024390243902), np.float64(0.7172413793103448), np.float64(0.7207792207792207), np.float64(0.7674418604651163)]\n",
            "ID_TARGET: 234.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7894 | Fold Accuracies: [np.float64(0.7088607594936709), np.float64(0.7354838709677419), np.float64(0.8322981366459627), np.float64(0.6538461538461539), np.float64(0.7421383647798742), np.float64(0.7210884353741497), np.float64(0.7597402597402597)]\n",
            "ID_TARGET: 34.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8210 | Fold Accuracies: [np.float64(0.7068965517241379), np.float64(0.7300613496932515), np.float64(0.7151898734177216), np.float64(0.7419354838709677), np.float64(0.7471264367816092), np.float64(0.8), np.float64(0.7843137254901961)]\n",
            "ID_TARGET: 154.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8072 | Fold Accuracies: [np.float64(0.7303370786516854), np.float64(0.743421052631579), np.float64(0.6928104575163399), np.float64(0.75), np.float64(0.7309941520467836), np.float64(0.793939393939394), np.float64(0.776536312849162)]\n",
            "ID_TARGET: 225.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7423 | Fold Accuracies: [np.float64(0.6967741935483871), np.float64(0.7222222222222222), np.float64(0.7357512953367875), np.float64(0.6944444444444444), np.float64(0.6896551724137931), np.float64(0.6826347305389222), np.float64(0.7471264367816092)]\n",
            "ID_TARGET: 185.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8624 | Fold Accuracies: [np.float64(0.8366013071895425), np.float64(0.7181208053691275), np.float64(0.7484276729559748), np.float64(0.7692307692307693), np.float64(0.7666666666666667), np.float64(0.7384615384615385), np.float64(0.7482014388489209)]\n",
            "ID_TARGET: 39.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7970 | Fold Accuracies: [np.float64(0.7290322580645161), np.float64(0.7100591715976331), np.float64(0.76), np.float64(0.6794871794871795), np.float64(0.7025316455696202), np.float64(0.6948051948051948), np.float64(0.7018633540372671)]\n",
            "ID_TARGET: 272.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7818 | Fold Accuracies: [np.float64(0.7341772151898734), np.float64(0.8011049723756906), np.float64(0.7712418300653595), np.float64(0.793939393939394), np.float64(0.7660818713450293), np.float64(0.7295597484276729), np.float64(0.7426900584795322)]\n",
            "ID_TARGET: 282.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8083 | Fold Accuracies: [np.float64(0.7848101265822784), np.float64(0.7272727272727273), np.float64(0.7215189873417721), np.float64(0.7142857142857143), np.float64(0.7251461988304093), np.float64(0.6666666666666666), np.float64(0.7450980392156863)]\n",
            "ID_TARGET: 90.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7847 | Fold Accuracies: [np.float64(0.7791411042944786), np.float64(0.7556818181818182), np.float64(0.7712418300653595), np.float64(0.7668711656441718), np.float64(0.7417218543046358), np.float64(0.757396449704142), np.float64(0.7672955974842768)]\n",
            "ID_TARGET: 52.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7557 | Fold Accuracies: [np.float64(0.7124183006535948), np.float64(0.691358024691358), np.float64(0.7590361445783133), np.float64(0.7375), np.float64(0.7151162790697675), np.float64(0.6944444444444444), np.float64(0.7278481012658228)]\n",
            "ID_TARGET: 258.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7620 | Fold Accuracies: [np.float64(0.7218543046357616), np.float64(0.7214285714285714), np.float64(0.7528089887640449), np.float64(0.718562874251497), np.float64(0.7012195121951219), np.float64(0.6993464052287581), np.float64(0.7046979865771812)]\n",
            "ID_TARGET: 291.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8096 | Fold Accuracies: [np.float64(0.7019867549668874), np.float64(0.7705882352941177), np.float64(0.6787878787878788), np.float64(0.7388888888888889), np.float64(0.7848837209302325), np.float64(0.7398843930635838), np.float64(0.7828947368421053)]\n",
            "ID_TARGET: 152.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8194 | Fold Accuracies: [np.float64(0.7732558139534884), np.float64(0.7162162162162162), np.float64(0.7070063694267515), np.float64(0.7151898734177216), np.float64(0.8100558659217877), np.float64(0.759493670886076), np.float64(0.7294117647058823)]\n",
            "ID_TARGET: 133.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8379 | Fold Accuracies: [np.float64(0.73125), np.float64(0.8284023668639053), np.float64(0.8263473053892215), np.float64(0.7325581395348837), np.float64(0.6890243902439024), np.float64(0.7898089171974523), np.float64(0.7630057803468208)]\n",
            "ID_TARGET: 29.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8177 | Fold Accuracies: [np.float64(0.7051282051282052), np.float64(0.7439024390243902), np.float64(0.7114093959731543), np.float64(0.6942675159235668), np.float64(0.7052023121387283), np.float64(0.7222222222222222), np.float64(0.7168674698795181)]\n",
            "ID_TARGET: 274.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7602 | Fold Accuracies: [np.float64(0.7017543859649122), np.float64(0.7289156626506024), np.float64(0.7759562841530054), np.float64(0.7125748502994012), np.float64(0.7058823529411765), np.float64(0.6982248520710059), np.float64(0.7243243243243244)]\n",
            "ID_TARGET: 106.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8517 | Fold Accuracies: [np.float64(0.7428571428571429), np.float64(0.7014925373134329), np.float64(0.7450980392156863), np.float64(0.7867647058823529), np.float64(0.7103448275862069), np.float64(0.7986577181208053), np.float64(0.7183098591549296)]\n",
            "ID_TARGET: 173.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8713 | Fold Accuracies: [np.float64(0.7572254335260116), np.float64(0.7613636363636364), np.float64(0.7612903225806451), np.float64(0.7484276729559748), np.float64(0.7658227848101266), np.float64(0.8214285714285714), np.float64(0.7852760736196319)]\n",
            "ID_TARGET: 33.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8207 | Fold Accuracies: [np.float64(0.7371428571428571), np.float64(0.6976744186046512), np.float64(0.7093023255813954), np.float64(0.7134502923976608), np.float64(0.7467532467532467), np.float64(0.6424242424242425), np.float64(0.7207792207792207)]\n",
            "ID_TARGET: 69.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7451 | Fold Accuracies: [np.float64(0.7098765432098766), np.float64(0.6291390728476821), np.float64(0.7), np.float64(0.6408450704225352), np.float64(0.7310344827586207), np.float64(0.689873417721519), np.float64(0.782608695652174)]\n",
            "ID_TARGET: 17.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7757 | Fold Accuracies: [np.float64(0.6904761904761905), np.float64(0.6761363636363636), np.float64(0.61875), np.float64(0.6832298136645962), np.float64(0.6727272727272727), np.float64(0.6836158192090396), np.float64(0.6748466257668712)]\n",
            "ID_TARGET: 189.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8661 | Fold Accuracies: [np.float64(0.6967741935483871), np.float64(0.7791411042944786), np.float64(0.7549668874172185), np.float64(0.7828571428571428), np.float64(0.7207792207792207), np.float64(0.7532467532467533), np.float64(0.7466666666666667)]\n",
            "ID_TARGET: 284.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7436 | Fold Accuracies: [np.float64(0.7300613496932515), np.float64(0.7278481012658228), np.float64(0.6379310344827587), np.float64(0.7735849056603774), np.float64(0.7616279069767442), np.float64(0.6705882352941176), np.float64(0.7228915662650602)]\n",
            "ID_TARGET: 218.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7682 | Fold Accuracies: [np.float64(0.6848484848484848), np.float64(0.7), np.float64(0.73224043715847), np.float64(0.7189189189189189), np.float64(0.7116564417177914), np.float64(0.6842105263157895), np.float64(0.7687861271676301)]\n",
            "ID_TARGET: 183.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8126 | Fold Accuracies: [np.float64(0.8106508875739645), np.float64(0.7615894039735099), np.float64(0.7516339869281046), np.float64(0.7530864197530864), np.float64(0.7456647398843931), np.float64(0.7252747252747253), np.float64(0.7763975155279503)]\n",
            "ID_TARGET: 206.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7888 | Fold Accuracies: [np.float64(0.7972027972027972), np.float64(0.7928994082840237), np.float64(0.7639751552795031), np.float64(0.7569060773480663), np.float64(0.7283236994219653), np.float64(0.7151898734177216), np.float64(0.7124183006535948)]\n",
            "ID_TARGET: 93.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7884 | Fold Accuracies: [np.float64(0.695906432748538), np.float64(0.6331360946745562), np.float64(0.697986577181208), np.float64(0.6488095238095238), np.float64(0.6488095238095238), np.float64(0.7453416149068323), np.float64(0.7210884353741497)]\n",
            "ID_TARGET: 16.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7644 | Fold Accuracies: [np.float64(0.7660818713450293), np.float64(0.6802721088435374), np.float64(0.6589595375722543), np.float64(0.6583850931677019), np.float64(0.7289156626506024), np.float64(0.7111111111111111), np.float64(0.68)]\n",
            "ID_TARGET: 246.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8010 | Fold Accuracies: [np.float64(0.7245508982035929), np.float64(0.7657142857142857), np.float64(0.7630057803468208), np.float64(0.7625), np.float64(0.6951219512195121), np.float64(0.7160493827160493), np.float64(0.7267441860465116)]\n",
            "ID_TARGET: 167.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8118 | Fold Accuracies: [np.float64(0.7245508982035929), np.float64(0.740506329113924), np.float64(0.7724137931034483), np.float64(0.7625), np.float64(0.7635135135135135), np.float64(0.7034482758620689), np.float64(0.7043010752688172)]\n",
            "ID_TARGET: 1.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7934 | Fold Accuracies: [np.float64(0.7034482758620689), np.float64(0.8066666666666666), np.float64(0.7018633540372671), np.float64(0.7452229299363057), np.float64(0.7142857142857143), np.float64(0.738562091503268), np.float64(0.6918238993710691)]\n",
            "ID_TARGET: 289.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7931 | Fold Accuracies: [np.float64(0.757396449704142), np.float64(0.7378048780487805), np.float64(0.815028901734104), np.float64(0.7062146892655368), np.float64(0.7651006711409396), np.float64(0.676829268292683), np.float64(0.7682926829268293)]\n",
            "ID_TARGET: 141.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8302 | Fold Accuracies: [np.float64(0.7828571428571428), np.float64(0.8082191780821918), np.float64(0.7421383647798742), np.float64(0.7114093959731543), np.float64(0.7267441860465116), np.float64(0.8376623376623377), np.float64(0.8104575163398693)]\n",
            "ID_TARGET: 109.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7518 | Fold Accuracies: [np.float64(0.6686746987951807), np.float64(0.7159763313609467), np.float64(0.7245508982035929), np.float64(0.6777777777777778), np.float64(0.6623376623376623), np.float64(0.6863905325443787), np.float64(0.6526315789473685)]\n",
            "ID_TARGET: 19.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7673 | Fold Accuracies: [np.float64(0.6419753086419753), np.float64(0.7206703910614525), np.float64(0.7177914110429447), np.float64(0.7727272727272727), np.float64(0.7133333333333334), np.float64(0.7289156626506024), np.float64(0.813953488372093)]\n",
            "ID_TARGET: 28.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7575 | Fold Accuracies: [np.float64(0.6646341463414634), np.float64(0.6329113924050633), np.float64(0.643312101910828), np.float64(0.691358024691358), np.float64(0.7544910179640718), np.float64(0.7108433734939759), np.float64(0.7037037037037037)]\n",
            "ID_TARGET: 251.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7850 | Fold Accuracies: [np.float64(0.7055214723926381), np.float64(0.7349397590361446), np.float64(0.7515527950310559), np.float64(0.7662337662337663), np.float64(0.7232704402515723), np.float64(0.6568047337278107), np.float64(0.7218934911242604)]\n",
            "ID_TARGET: 278.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8247 | Fold Accuracies: [np.float64(0.7058823529411765), np.float64(0.8072289156626506), np.float64(0.7482517482517482), np.float64(0.782051282051282), np.float64(0.7254901960784313), np.float64(0.7168674698795181), np.float64(0.7702702702702703)]\n",
            "ID_TARGET: 76.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.7680 | Fold Accuracies: [np.float64(0.7093023255813954), np.float64(0.7076023391812866), np.float64(0.6942675159235668), np.float64(0.7333333333333333), np.float64(0.7134831460674157), np.float64(0.7625), np.float64(0.7888198757763976)]\n",
            "ID_TARGET: 241.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8275 | Fold Accuracies: [np.float64(0.7352941176470589), np.float64(0.7261146496815286), np.float64(0.7612903225806451), np.float64(0.7354838709677419), np.float64(0.7419354838709677), np.float64(0.7391304347826086), np.float64(0.7724137931034483)]\n",
            "ID_TARGET: 214.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8661 | Fold Accuracies: [np.float64(0.7784431137724551), np.float64(0.8353658536585366), np.float64(0.7898089171974523), np.float64(0.7901234567901234), np.float64(0.8081395348837209), np.float64(0.75), np.float64(0.7329545454545454)]\n",
            "ID_TARGET: 102.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8395 | Fold Accuracies: [np.float64(0.7452229299363057), np.float64(0.7215189873417721), np.float64(0.74375), np.float64(0.8064516129032258), np.float64(0.803921568627451), np.float64(0.7222222222222222), np.float64(0.7622377622377622)]\n",
            "ID_TARGET: 145.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.005, 'min_child_samples': 20, 'num_leaves': 47, 'reg_alpha': 0.1, 'reg_lambda': 0.3} | Mean Accuracy: 0.8490 | Fold Accuracies: [np.float64(0.7559523809523809), np.float64(0.7960526315789473), np.float64(0.6904761904761905), np.float64(0.7547169811320755), np.float64(0.6835443037974683), np.float64(0.6855345911949685), np.float64(0.6428571428571429)]\n",
            "ID_TARGET: 155.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.005, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8287 | Fold Accuracies: [np.float64(0.8087431693989071), np.float64(0.7151898734177216), np.float64(0.8333333333333334), np.float64(0.7777777777777778), np.float64(0.7901234567901234), np.float64(0.7897727272727273), np.float64(0.7770700636942676)]\n",
            "ID_TARGET: nan | Best Params: {} | Mean Accuracy: 0.0000 | Fold Accuracies: []\n",
            "\n",
            "Training XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "XGBoost Targets: 100%|| 101/101 [1:23:05<00:00, 49.36s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Weighted Accuracy: 0.9894\n",
            "\n",
            "XGBoost Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.950920245398773), np.float64(0.9627329192546584), np.float64(0.9935897435897436), np.float64(0.9515151515151515), np.float64(0.9502762430939227), np.float64(0.934640522875817), np.float64(1.0)]\n",
            "ID_TARGET: 129.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.5875), np.float64(0.6234567901234568), np.float64(0.6037735849056604), np.float64(0.6744186046511628), np.float64(0.6296296296296297), np.float64(0.6477987421383647), np.float64(0.6306818181818182)]\n",
            "ID_TARGET: 136.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6415094339622641), np.float64(0.6139240506329114), np.float64(0.6342857142857142), np.float64(0.625), np.float64(0.5502958579881657), np.float64(0.5459770114942529), np.float64(0.5769230769230769)]\n",
            "ID_TARGET: 161.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6308724832214765), np.float64(0.6857142857142857), np.float64(0.6707317073170732), np.float64(0.7151515151515152), np.float64(0.6547619047619048), np.float64(0.6961325966850829), np.float64(0.6585365853658537)]\n",
            "ID_TARGET: 217.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8023952095808383), np.float64(0.7816091954022989), np.float64(0.7670454545454546), np.float64(0.7740112994350282), np.float64(0.808641975308642), np.float64(0.7727272727272727), np.float64(0.7228260869565217)]\n",
            "ID_TARGET: 91.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8012422360248447), np.float64(0.8235294117647058), np.float64(0.7751479289940828), np.float64(0.8275862068965517), np.float64(0.7610062893081762), np.float64(0.8098159509202454), np.float64(0.7469879518072289)]\n",
            "ID_TARGET: 137.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6153846153846154), np.float64(0.6474358974358975), np.float64(0.6503067484662577), np.float64(0.7225806451612903), np.float64(0.6932515337423313), np.float64(0.6807228915662651), np.float64(0.6751592356687898)]\n",
            "ID_TARGET: 8.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6395348837209303), np.float64(0.710691823899371), np.float64(0.6424242424242425), np.float64(0.6981132075471698), np.float64(0.6298701298701299), np.float64(0.6453488372093024), np.float64(0.6666666666666666)]\n",
            "ID_TARGET: 3.0 | Best Params: {'learning_rate': 0.005, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7840 | Fold Accuracies: [np.float64(0.6712328767123288), np.float64(0.7), np.float64(0.6352201257861635), np.float64(0.6629213483146067), np.float64(0.6556291390728477), np.float64(0.6556291390728477), np.float64(0.7070063694267515)]\n",
            "ID_TARGET: 9.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7011494252873564), np.float64(0.6904761904761905), np.float64(0.7834394904458599), np.float64(0.7426470588235294), np.float64(0.6058823529411764), np.float64(0.6973684210526315), np.float64(0.569620253164557)]\n",
            "ID_TARGET: 131.0 | Best Params: {'learning_rate': 0.005, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7820 | Fold Accuracies: [np.float64(0.5542857142857143), np.float64(0.6518987341772152), np.float64(0.6607142857142857), np.float64(0.5965909090909091), np.float64(0.6496815286624203), np.float64(0.6319444444444444), np.float64(0.6265822784810127)]\n",
            "ID_TARGET: 21.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6407185628742516), np.float64(0.6932515337423313), np.float64(0.7730061349693251), np.float64(0.6091954022988506), np.float64(0.7741935483870968), np.float64(0.6818181818181818), np.float64(0.7)]\n",
            "ID_TARGET: 54.0 | Best Params: {'learning_rate': 0.005, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.9423 | Fold Accuracies: [np.float64(0.7133757961783439), np.float64(0.7350993377483444), np.float64(0.7542857142857143), np.float64(0.7305389221556886), np.float64(0.696969696969697), np.float64(0.7663043478260869), np.float64(0.6855345911949685)]\n",
            "ID_TARGET: 130.0 | Best Params: {'learning_rate': 0.005, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.8812 | Fold Accuracies: [np.float64(0.7393617021276596), np.float64(0.7484276729559748), np.float64(0.76), np.float64(0.7396449704142012), np.float64(0.6686390532544378), np.float64(0.7278911564625851), np.float64(0.6878612716763006)]\n",
            "ID_TARGET: 269.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 7, 'min_child_weight': 5, 'n_estimators': 300, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.75} | Mean Accuracy: 0.9256 | Fold Accuracies: [np.float64(0.5704225352112676), np.float64(0.6451612903225806), np.float64(0.6428571428571429), np.float64(0.6217948717948718), np.float64(0.5882352941176471), np.float64(0.6209150326797386), np.float64(0.6490066225165563)]\n",
            "ID_TARGET: 157.0 | Best Params: {'learning_rate': 0.005, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.8090 | Fold Accuracies: [np.float64(0.6516129032258065), np.float64(0.6917808219178082), np.float64(0.7547169811320755), np.float64(0.7549668874172185), np.float64(0.6878980891719745), np.float64(0.6428571428571429), np.float64(0.6763005780346821)]\n",
            "ID_TARGET: 249.0 | Best Params: {'learning_rate': 0.005, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.8161 | Fold Accuracies: [np.float64(0.6936416184971098), np.float64(0.7134502923976608), np.float64(0.6794871794871795), np.float64(0.6804733727810651), np.float64(0.6620689655172414), np.float64(0.7701863354037267), np.float64(0.7329192546583851)]\n",
            "ID_TARGET: 22.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6867469879518072), np.float64(0.7142857142857143), np.float64(0.7142857142857143), np.float64(0.7710843373493976), np.float64(0.625), np.float64(0.6407185628742516), np.float64(0.7452229299363057)]\n",
            "ID_TARGET: 202.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6941176470588235), np.float64(0.6962025316455697), np.float64(0.6432748538011696), np.float64(0.7034883720930233), np.float64(0.6470588235294118), np.float64(0.6257309941520468), np.float64(0.6850828729281768)]\n",
            "ID_TARGET: 132.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7682926829268293), np.float64(0.7432432432432432), np.float64(0.7450980392156863), np.float64(0.7453416149068323), np.float64(0.7080745341614907), np.float64(0.6967741935483871), np.float64(0.7317073170731707)]\n",
            "ID_TARGET: 96.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.9281045751633987), np.float64(0.8857142857142857), np.float64(0.8421052631578947), np.float64(0.916083916083916), np.float64(0.9155844155844156), np.float64(0.8627450980392157), np.float64(0.8904109589041096)]\n",
            "ID_TARGET: 7.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7612903225806451), np.float64(0.7931034482758621), np.float64(0.7272727272727273), np.float64(0.7870967741935484), np.float64(0.7945945945945946), np.float64(0.8125), np.float64(0.8044692737430168)]\n",
            "ID_TARGET: 178.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.75), np.float64(0.6962025316455697), np.float64(0.6918238993710691), np.float64(0.6588235294117647), np.float64(0.7261904761904762), np.float64(0.75625), np.float64(0.7046979865771812)]\n",
            "ID_TARGET: 68.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6807228915662651), np.float64(0.7577639751552795), np.float64(0.7215189873417721), np.float64(0.7341772151898734), np.float64(0.7364864864864865), np.float64(0.7577639751552795), np.float64(0.7236842105263158)]\n",
            "ID_TARGET: 44.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7869822485207101), np.float64(0.810126582278481), np.float64(0.7468354430379747), np.float64(0.793939393939394), np.float64(0.7109826589595376), np.float64(0.7425149700598802), np.float64(0.718562874251497)]\n",
            "ID_TARGET: 196.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8453038674033149), np.float64(0.8324324324324325), np.float64(0.8587570621468926), np.float64(0.7567567567567568), np.float64(0.7383720930232558), np.float64(0.8489583333333334), np.float64(0.7897727272727273)]\n",
            "ID_TARGET: 292.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7248677248677249), np.float64(0.7666666666666667), np.float64(0.7559523809523809), np.float64(0.8193548387096774), np.float64(0.7532467532467533), np.float64(0.7151515151515152), np.float64(0.7109826589595376)]\n",
            "ID_TARGET: 239.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7407407407407407), np.float64(0.7169811320754716), np.float64(0.6875), np.float64(0.7328767123287672), np.float64(0.7636363636363637), np.float64(0.7453416149068323), np.float64(0.7432432432432432)]\n",
            "ID_TARGET: 279.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7843137254901961), np.float64(0.7878787878787878), np.float64(0.7181208053691275), np.float64(0.703030303030303), np.float64(0.6374269005847953), np.float64(0.8265895953757225), np.float64(0.6227544910179641)]\n",
            "ID_TARGET: 38.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7485029940119761), np.float64(0.7847222222222222), np.float64(0.7215189873417721), np.float64(0.6894409937888198), np.float64(0.8439716312056738), np.float64(0.7966101694915254), np.float64(0.7371428571428571)]\n",
            "ID_TARGET: 209.0 | Best Params: {'learning_rate': 0.01, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 150, 'reg_alpha': 0.5, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 207.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7115384615384616), np.float64(0.6455696202531646), np.float64(0.7011494252873564), np.float64(0.6862745098039216), np.float64(0.7283950617283951), np.float64(0.6666666666666666), np.float64(0.6149425287356322)]\n",
            "ID_TARGET: 98.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.70625), np.float64(0.6772151898734177), np.float64(0.7692307692307693), np.float64(0.6981132075471698), np.float64(0.5987654320987654), np.float64(0.7065868263473054), np.float64(0.7454545454545455)]\n",
            "ID_TARGET: 65.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7602339181286549), np.float64(0.7548387096774194), np.float64(0.7345679012345679), np.float64(0.6455696202531646), np.float64(0.7054794520547946), np.float64(0.6709677419354839), np.float64(0.7806451612903226)]\n",
            "ID_TARGET: 51.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6858974358974359), np.float64(0.7333333333333333), np.float64(0.631578947368421), np.float64(0.7197452229299363), np.float64(0.6516129032258065), np.float64(0.6226415094339622), np.float64(0.6644736842105263)]\n",
            "ID_TARGET: 78.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8275862068965517), np.float64(0.7639751552795031), np.float64(0.7142857142857143), np.float64(0.7160493827160493), np.float64(0.7449664429530202), np.float64(0.7070063694267515), np.float64(0.7914110429447853)]\n",
            "ID_TARGET: 177.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7757575757575758), np.float64(0.7911392405063291), np.float64(0.7621621621621621), np.float64(0.7802197802197802), np.float64(0.6871794871794872), np.float64(0.7337278106508875), np.float64(0.7391304347826086)]\n",
            "ID_TARGET: 231.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8116883116883117), np.float64(0.7456647398843931), np.float64(0.7926829268292683), np.float64(0.7177914110429447), np.float64(0.7590361445783133), np.float64(0.7262569832402235), np.float64(0.7948717948717948)]\n",
            "ID_TARGET: 119.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8410596026490066), np.float64(0.7848101265822784), np.float64(0.7610062893081762), np.float64(0.7484276729559748), np.float64(0.7914110429447853), np.float64(0.7388535031847133), np.float64(0.7740112994350282)]\n",
            "ID_TARGET: 158.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.782312925170068), np.float64(0.8035714285714286), np.float64(0.7292817679558011), np.float64(0.7785234899328859), np.float64(0.8545454545454545), np.float64(0.7682119205298014), np.float64(0.776536312849162)]\n",
            "ID_TARGET: 80.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6754966887417219), np.float64(0.7197452229299363), np.float64(0.6875), np.float64(0.6646341463414634), np.float64(0.6951219512195121), np.float64(0.7), np.float64(0.7456647398843931)]\n",
            "ID_TARGET: 25.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7398843930635838), np.float64(0.6962025316455697), np.float64(0.7070063694267515), np.float64(0.7142857142857143), np.float64(0.7365269461077845), np.float64(0.75625), np.float64(0.75)]\n",
            "ID_TARGET: 175.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6530612244897959), np.float64(0.6341463414634146), np.float64(0.727810650887574), np.float64(0.7305389221556886), np.float64(0.75), np.float64(0.6484848484848484), np.float64(0.6578947368421053)]\n",
            "ID_TARGET: 151.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8), np.float64(0.8012422360248447), np.float64(0.7741935483870968), np.float64(0.7777777777777778), np.float64(0.7080745341614907), np.float64(0.779874213836478), np.float64(0.7581699346405228)]\n",
            "ID_TARGET: 257.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6827956989247311), np.float64(0.7625), np.float64(0.7485029940119761), np.float64(0.6611111111111111), np.float64(0.7441860465116279), np.float64(0.6971428571428572), np.float64(0.6419753086419753)]\n",
            "ID_TARGET: 75.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.807909604519774), np.float64(0.8136645962732919), np.float64(0.7705882352941177), np.float64(0.7560975609756098), np.float64(0.7735849056603774), np.float64(0.7714285714285715), np.float64(0.8095238095238095)]\n",
            "ID_TARGET: 244.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6781609195402298), np.float64(0.6647727272727273), np.float64(0.7470588235294118), np.float64(0.6686746987951807), np.float64(0.70625), np.float64(0.6181818181818182), np.float64(0.7251461988304093)]\n",
            "ID_TARGET: 149.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7341772151898734), np.float64(0.7469879518072289), np.float64(0.738562091503268), np.float64(0.6524064171122995), np.float64(0.6445783132530121), np.float64(0.620253164556962), np.float64(0.7415730337078652)]\n",
            "ID_TARGET: 85.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7108433734939759), np.float64(0.7756410256410257), np.float64(0.7341772151898734), np.float64(0.7352941176470589), np.float64(0.7933333333333333), np.float64(0.7908496732026143), np.float64(0.7435897435897436)]\n",
            "ID_TARGET: 190.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6855345911949685), np.float64(0.6842105263157895), np.float64(0.7570621468926554), np.float64(0.7423312883435583), np.float64(0.7192982456140351), np.float64(0.7325581395348837), np.float64(0.8132530120481928)]\n",
            "ID_TARGET: 13.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7237569060773481), np.float64(0.754601226993865), np.float64(0.7559523809523809), np.float64(0.6779661016949152), np.float64(0.7440476190476191), np.float64(0.7218543046357616), np.float64(0.7751479289940828)]\n",
            "ID_TARGET: 228.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8209876543209876), np.float64(0.7529411764705882), np.float64(0.7134831460674157), np.float64(0.7407407407407407), np.float64(0.7409638554216867), np.float64(0.7473118279569892), np.float64(0.7485029940119761)]\n",
            "ID_TARGET: 144.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7710843373493976), np.float64(0.7647058823529411), np.float64(0.8333333333333334), np.float64(0.7419354838709677), np.float64(0.7941176470588235), np.float64(0.7961783439490446), np.float64(0.7906976744186046)]\n",
            "ID_TARGET: 290.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6923076923076923), np.float64(0.754601226993865), np.float64(0.6554054054054054), np.float64(0.7116564417177914), np.float64(0.774390243902439), np.float64(0.79375), np.float64(0.7610062893081762)]\n",
            "ID_TARGET: 114.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6785714285714286), np.float64(0.7044025157232704), np.float64(0.6727272727272727), np.float64(0.7453416149068323), np.float64(0.7407407407407407), np.float64(0.68), np.float64(0.7457627118644068)]\n",
            "ID_TARGET: 166.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7058823529411765), np.float64(0.6867469879518072), np.float64(0.8114285714285714), np.float64(0.7560975609756098), np.float64(0.7172413793103448), np.float64(0.7142857142857143), np.float64(0.7674418604651163)]\n",
            "ID_TARGET: 234.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7215189873417721), np.float64(0.7483870967741936), np.float64(0.8571428571428571), np.float64(0.7115384615384616), np.float64(0.7484276729559748), np.float64(0.782312925170068), np.float64(0.7857142857142857)]\n",
            "ID_TARGET: 34.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7413793103448276), np.float64(0.7300613496932515), np.float64(0.7658227848101266), np.float64(0.7677419354838709), np.float64(0.7931034482758621), np.float64(0.8), np.float64(0.7973856209150327)]\n",
            "ID_TARGET: 154.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7865168539325843), np.float64(0.7894736842105263), np.float64(0.7254901960784313), np.float64(0.7738095238095238), np.float64(0.7777777777777778), np.float64(0.8), np.float64(0.8044692737430168)]\n",
            "ID_TARGET: 225.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7483870967741936), np.float64(0.6888888888888889), np.float64(0.7150259067357513), np.float64(0.7), np.float64(0.6954022988505747), np.float64(0.7005988023952096), np.float64(0.7701149425287356)]\n",
            "ID_TARGET: 185.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7843137254901961), np.float64(0.7181208053691275), np.float64(0.6540880503144654), np.float64(0.7482517482517482), np.float64(0.7133333333333334), np.float64(0.7), np.float64(0.7553956834532374)]\n",
            "ID_TARGET: 39.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7806451612903226), np.float64(0.7514792899408284), np.float64(0.76), np.float64(0.6666666666666666), np.float64(0.7974683544303798), np.float64(0.7402597402597403), np.float64(0.7577639751552795)]\n",
            "ID_TARGET: 272.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8037974683544303), np.float64(0.8066298342541437), np.float64(0.8104575163398693), np.float64(0.7818181818181819), np.float64(0.7543859649122807), np.float64(0.7358490566037735), np.float64(0.7777777777777778)]\n",
            "ID_TARGET: 282.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.810126582278481), np.float64(0.7215909090909091), np.float64(0.7531645569620253), np.float64(0.7337662337662337), np.float64(0.7485380116959064), np.float64(0.7023809523809523), np.float64(0.7712418300653595)]\n",
            "ID_TARGET: 90.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7791411042944786), np.float64(0.7556818181818182), np.float64(0.7712418300653595), np.float64(0.7730061349693251), np.float64(0.7615894039735099), np.float64(0.7751479289940828), np.float64(0.8113207547169812)]\n",
            "ID_TARGET: 52.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7058823529411765), np.float64(0.7222222222222222), np.float64(0.7409638554216867), np.float64(0.7625), np.float64(0.7558139534883721), np.float64(0.7361111111111112), np.float64(0.7215189873417721)]\n",
            "ID_TARGET: 258.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6821192052980133), np.float64(0.7071428571428572), np.float64(0.6966292134831461), np.float64(0.6766467065868264), np.float64(0.7195121951219512), np.float64(0.6797385620915033), np.float64(0.697986577181208)]\n",
            "ID_TARGET: 291.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6821192052980133), np.float64(0.7705882352941177), np.float64(0.6787878787878788), np.float64(0.7), np.float64(0.7965116279069767), np.float64(0.7283236994219653), np.float64(0.8092105263157895)]\n",
            "ID_TARGET: 152.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7674418604651163), np.float64(0.7432432432432432), np.float64(0.6878980891719745), np.float64(0.7215189873417721), np.float64(0.7877094972067039), np.float64(0.7341772151898734), np.float64(0.7235294117647059)]\n",
            "ID_TARGET: 133.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.76875), np.float64(0.834319526627219), np.float64(0.8083832335329342), np.float64(0.7267441860465116), np.float64(0.725609756097561), np.float64(0.7961783439490446), np.float64(0.7803468208092486)]\n",
            "ID_TARGET: 29.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6346153846153846), np.float64(0.75), np.float64(0.7315436241610739), np.float64(0.6560509554140127), np.float64(0.7052023121387283), np.float64(0.7222222222222222), np.float64(0.7108433734939759)]\n",
            "ID_TARGET: 274.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7426900584795322), np.float64(0.7590361445783133), np.float64(0.7759562841530054), np.float64(0.7305389221556886), np.float64(0.7294117647058823), np.float64(0.7396449704142012), np.float64(0.7351351351351352)]\n",
            "ID_TARGET: 106.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6785714285714286), np.float64(0.6492537313432836), np.float64(0.7581699346405228), np.float64(0.75), np.float64(0.7034482758620689), np.float64(0.825503355704698), np.float64(0.704225352112676)]\n",
            "ID_TARGET: 173.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7456647398843931), np.float64(0.7386363636363636), np.float64(0.7354838709677419), np.float64(0.8113207547169812), np.float64(0.7784810126582279), np.float64(0.8333333333333334), np.float64(0.754601226993865)]\n",
            "ID_TARGET: 33.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7771428571428571), np.float64(0.7558139534883721), np.float64(0.7325581395348837), np.float64(0.7134502923976608), np.float64(0.7857142857142857), np.float64(0.696969696969697), np.float64(0.7727272727272727)]\n",
            "ID_TARGET: 69.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7098765432098766), np.float64(0.6887417218543046), np.float64(0.71875), np.float64(0.7323943661971831), np.float64(0.7724137931034483), np.float64(0.7088607594936709), np.float64(0.7950310559006211)]\n",
            "ID_TARGET: 17.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7321428571428571), np.float64(0.6875), np.float64(0.6375), np.float64(0.7329192546583851), np.float64(0.696969696969697), np.float64(0.751412429378531), np.float64(0.7361963190184049)]\n",
            "ID_TARGET: 189.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7419354838709677), np.float64(0.7852760736196319), np.float64(0.7483443708609272), np.float64(0.7257142857142858), np.float64(0.7467532467532467), np.float64(0.7532467532467533), np.float64(0.7733333333333333)]\n",
            "ID_TARGET: 284.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7300613496932515), np.float64(0.7215189873417721), np.float64(0.6264367816091954), np.float64(0.7610062893081762), np.float64(0.7848837209302325), np.float64(0.6705882352941176), np.float64(0.7168674698795181)]\n",
            "ID_TARGET: 218.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.696969696969697), np.float64(0.7875), np.float64(0.7650273224043715), np.float64(0.7405405405405405), np.float64(0.7116564417177914), np.float64(0.6900584795321637), np.float64(0.7745664739884393)]\n",
            "ID_TARGET: 183.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8106508875739645), np.float64(0.7880794701986755), np.float64(0.7647058823529411), np.float64(0.7777777777777778), np.float64(0.7341040462427746), np.float64(0.7692307692307693), np.float64(0.7763975155279503)]\n",
            "ID_TARGET: 206.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7902097902097902), np.float64(0.7810650887573964), np.float64(0.7453416149068323), np.float64(0.7458563535911602), np.float64(0.7167630057803468), np.float64(0.7341772151898734), np.float64(0.7320261437908496)]\n",
            "ID_TARGET: 93.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6666666666666666), np.float64(0.6863905325443787), np.float64(0.7046979865771812), np.float64(0.625), np.float64(0.6488095238095238), np.float64(0.7701863354037267), np.float64(0.7142857142857143)]\n",
            "ID_TARGET: 16.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7894736842105263), np.float64(0.7210884353741497), np.float64(0.7052023121387283), np.float64(0.6273291925465838), np.float64(0.7289156626506024), np.float64(0.6888888888888889), np.float64(0.68)]\n",
            "ID_TARGET: 246.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7544910179640718), np.float64(0.7714285714285715), np.float64(0.7687861271676301), np.float64(0.8), np.float64(0.6707317073170732), np.float64(0.7654320987654321), np.float64(0.7616279069767442)]\n",
            "ID_TARGET: 167.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8143712574850299), np.float64(0.7215189873417721), np.float64(0.8068965517241379), np.float64(0.83125), np.float64(0.8243243243243243), np.float64(0.7448275862068966), np.float64(0.6827956989247311)]\n",
            "ID_TARGET: 1.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7103448275862069), np.float64(0.8266666666666667), np.float64(0.7142857142857143), np.float64(0.7579617834394905), np.float64(0.7142857142857143), np.float64(0.7450980392156863), np.float64(0.7610062893081762)]\n",
            "ID_TARGET: 289.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7633136094674556), np.float64(0.7195121951219512), np.float64(0.8323699421965318), np.float64(0.672316384180791), np.float64(0.7583892617449665), np.float64(0.7073170731707317), np.float64(0.7926829268292683)]\n",
            "ID_TARGET: 141.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7485714285714286), np.float64(0.8698630136986302), np.float64(0.7547169811320755), np.float64(0.7181208053691275), np.float64(0.7383720930232558), np.float64(0.8701298701298701), np.float64(0.8104575163398693)]\n",
            "ID_TARGET: 109.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7289156626506024), np.float64(0.7514792899408284), np.float64(0.7904191616766467), np.float64(0.7166666666666667), np.float64(0.7467532467532467), np.float64(0.7396449704142012), np.float64(0.6947368421052632)]\n",
            "ID_TARGET: 19.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7222222222222222), np.float64(0.7486033519553073), np.float64(0.7423312883435583), np.float64(0.7954545454545454), np.float64(0.7933333333333333), np.float64(0.7409638554216867), np.float64(0.8313953488372093)]\n",
            "ID_TARGET: 28.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6829268292682927), np.float64(0.6518987341772152), np.float64(0.6751592356687898), np.float64(0.6790123456790124), np.float64(0.7604790419161677), np.float64(0.7228915662650602), np.float64(0.7530864197530864)]\n",
            "ID_TARGET: 251.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6748466257668712), np.float64(0.7349397590361446), np.float64(0.7701863354037267), np.float64(0.7987012987012987), np.float64(0.7547169811320755), np.float64(0.6982248520710059), np.float64(0.7100591715976331)]\n",
            "ID_TARGET: 278.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6993464052287581), np.float64(0.7771084337349398), np.float64(0.7412587412587412), np.float64(0.782051282051282), np.float64(0.6993464052287581), np.float64(0.6807228915662651), np.float64(0.722972972972973)]\n",
            "ID_TARGET: 76.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6918604651162791), np.float64(0.7134502923976608), np.float64(0.6942675159235668), np.float64(0.7555555555555555), np.float64(0.7134831460674157), np.float64(0.7625), np.float64(0.8074534161490683)]\n",
            "ID_TARGET: 241.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7205882352941176), np.float64(0.7452229299363057), np.float64(0.7354838709677419), np.float64(0.7161290322580646), np.float64(0.7419354838709677), np.float64(0.7391304347826086), np.float64(0.7931034482758621)]\n",
            "ID_TARGET: 214.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7544910179640718), np.float64(0.7682926829268293), np.float64(0.8152866242038217), np.float64(0.8209876543209876), np.float64(0.7558139534883721), np.float64(0.7440476190476191), np.float64(0.6988636363636364)]\n",
            "ID_TARGET: 102.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7707006369426752), np.float64(0.7151898734177216), np.float64(0.75), np.float64(0.8193548387096774), np.float64(0.7712418300653595), np.float64(0.7407407407407407), np.float64(0.7622377622377622)]\n",
            "ID_TARGET: 145.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7023809523809523), np.float64(0.7236842105263158), np.float64(0.6904761904761905), np.float64(0.6855345911949685), np.float64(0.7341772151898734), np.float64(0.7484276729559748), np.float64(0.6153846153846154)]\n",
            "ID_TARGET: 155.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8087431693989071), np.float64(0.7215189873417721), np.float64(0.8448275862068966), np.float64(0.7777777777777778), np.float64(0.808641975308642), np.float64(0.7727272727272727), np.float64(0.7961783439490446)]\n",
            "ID_TARGET: nan | Best Params: {} | Mean Accuracy: 0.0000 | Fold Accuracies: []\n",
            "\n",
            "Performing second-pass training with top 30 features...\n",
            "\n",
            "Second-pass LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rLightGBM Targets:   0%|          | 0/101 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   1%|          | 1/101 [00:01<02:09,  1.29s/it]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   2%|         | 2/101 [00:02<01:38,  1.01it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   3%|         | 3/101 [00:02<01:30,  1.08it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   4%|         | 4/101 [00:03<01:23,  1.16it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   5%|         | 5/101 [00:04<01:15,  1.27it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   6%|         | 6/101 [00:04<01:10,  1.35it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   7%|         | 7/101 [00:05<01:04,  1.46it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   8%|         | 8/101 [00:06<01:11,  1.30it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   9%|         | 9/101 [00:07<01:16,  1.20it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  10%|         | 10/101 [00:08<01:10,  1.28it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  11%|         | 11/101 [00:09<01:15,  1.19it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  12%|        | 12/101 [00:09<01:14,  1.20it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  13%|        | 13/101 [00:11<01:27,  1.01it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  14%|        | 14/101 [00:12<01:31,  1.05s/it]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  15%|        | 15/101 [00:13<01:32,  1.08s/it]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  16%|        | 16/101 [00:14<01:29,  1.05s/it]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  17%|        | 17/101 [00:15<01:26,  1.03s/it]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  18%|        | 18/101 [00:16<01:17,  1.07it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  19%|        | 19/101 [00:17<01:12,  1.14it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  20%|        | 20/101 [00:17<01:06,  1.21it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  21%|        | 21/101 [00:18<01:03,  1.27it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  22%|       | 22/101 [00:19<01:00,  1.31it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  23%|       | 23/101 [00:19<00:59,  1.32it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  24%|       | 24/101 [00:20<00:58,  1.32it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  25%|       | 25/101 [00:21<00:56,  1.36it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  26%|       | 26/101 [00:22<00:56,  1.33it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  27%|       | 27/101 [00:22<00:55,  1.32it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  28%|       | 28/101 [00:23<00:52,  1.39it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  29%|       | 29/101 [00:24<00:58,  1.23it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  30%|       | 30/101 [00:25<01:02,  1.13it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  31%|       | 31/101 [00:26<01:03,  1.10it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  32%|      | 32/101 [00:27<01:01,  1.12it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  33%|      | 33/101 [00:28<00:55,  1.22it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  34%|      | 34/101 [00:28<00:51,  1.31it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  35%|      | 35/101 [00:29<00:49,  1.33it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  36%|      | 36/101 [00:30<00:47,  1.36it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  37%|      | 37/101 [00:30<00:46,  1.38it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  38%|      | 38/101 [00:31<00:44,  1.43it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  39%|      | 39/101 [00:32<00:45,  1.38it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  40%|      | 40/101 [00:33<00:44,  1.36it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  41%|      | 41/101 [00:33<00:44,  1.34it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  42%|     | 42/101 [00:34<00:43,  1.37it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  43%|     | 43/101 [00:35<00:41,  1.41it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  44%|     | 44/101 [00:35<00:39,  1.43it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  45%|     | 45/101 [00:36<00:39,  1.40it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  46%|     | 46/101 [00:37<00:41,  1.32it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  47%|     | 47/101 [00:38<00:47,  1.15it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  48%|     | 48/101 [00:39<00:50,  1.04it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  49%|     | 49/101 [00:40<00:49,  1.05it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  50%|     | 50/101 [00:41<00:46,  1.11it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  50%|     | 51/101 [00:42<00:41,  1.21it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  51%|    | 52/101 [00:42<00:39,  1.25it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  52%|    | 53/101 [00:43<00:36,  1.32it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  53%|    | 54/101 [00:44<00:34,  1.36it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  54%|    | 55/101 [00:44<00:33,  1.36it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  55%|    | 56/101 [00:45<00:32,  1.39it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  56%|    | 57/101 [00:46<00:30,  1.43it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  57%|    | 58/101 [00:47<00:30,  1.41it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  58%|    | 59/101 [00:47<00:29,  1.41it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  59%|    | 60/101 [00:48<00:29,  1.40it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  60%|    | 61/101 [00:49<00:28,  1.41it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  61%|   | 62/101 [00:49<00:27,  1.43it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  62%|   | 63/101 [00:50<00:25,  1.48it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  63%|   | 64/101 [00:51<00:28,  1.29it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  64%|   | 65/101 [00:52<00:31,  1.14it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  65%|   | 66/101 [00:53<00:32,  1.08it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  66%|   | 67/101 [00:54<00:30,  1.13it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  67%|   | 68/101 [00:55<00:26,  1.23it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  68%|   | 69/101 [00:55<00:24,  1.30it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  69%|   | 70/101 [00:56<00:22,  1.37it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  70%|   | 71/101 [00:57<00:21,  1.41it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  71%|  | 72/101 [00:57<00:20,  1.41it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  72%|  | 73/101 [00:58<00:19,  1.46it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  73%|  | 74/101 [00:59<00:18,  1.47it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  74%|  | 75/101 [00:59<00:17,  1.45it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  75%|  | 76/101 [01:00<00:17,  1.45it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  76%|  | 77/101 [01:01<00:16,  1.42it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  77%|  | 78/101 [01:01<00:16,  1.43it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  78%|  | 79/101 [01:02<00:15,  1.40it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  79%|  | 80/101 [01:03<00:15,  1.40it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  80%|  | 81/101 [01:04<00:15,  1.30it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  81%|  | 82/101 [01:05<00:16,  1.15it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  82%| | 83/101 [01:06<00:17,  1.06it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  83%| | 84/101 [01:07<00:16,  1.02it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  84%| | 85/101 [01:08<00:14,  1.11it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  85%| | 86/101 [01:08<00:12,  1.20it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  86%| | 87/101 [01:09<00:11,  1.24it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  87%| | 88/101 [01:10<00:09,  1.30it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  88%| | 89/101 [01:11<00:08,  1.34it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  89%| | 90/101 [01:11<00:08,  1.34it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  90%| | 91/101 [01:12<00:07,  1.38it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  91%| | 92/101 [01:13<00:06,  1.33it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  92%|| 93/101 [01:13<00:05,  1.36it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  93%|| 94/101 [01:14<00:05,  1.39it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  94%|| 95/101 [01:15<00:04,  1.38it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  95%|| 96/101 [01:16<00:03,  1.42it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  96%|| 97/101 [01:16<00:02,  1.38it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  97%|| 98/101 [01:17<00:02,  1.35it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  98%|| 99/101 [01:18<00:01,  1.15it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets: 100%|| 101/101 [01:19<00:00,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: No features for ID_TARGET nan. Skipping.\n",
            "\n",
            "Second-pass XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Targets: 100%|| 101/101 [01:16<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: No features for ID_TARGET nan. Skipping.\n",
            "\n",
            "Performing third-pass training for low-performing targets...\n",
            "\n",
            "Third-pass LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "LightGBM Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 59150.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Third-pass XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 60947.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Performing fourth-pass training for very low-performing targets...\n",
            "\n",
            "Fourth-pass LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "LightGBM Very Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 52015.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fourth-pass XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Very Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 117998.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved hyperparameter log to: /content/hyperparameters.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_024c5df7-8940-47b9-9116-211b38a387f3\", \"hyperparameters.json\", 1964712)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved predictions to: /content/predictions_ensemble.csv\n",
            "Output CSV shape: (114468, 2)\n",
            "Output CSV ID range: 0 to 114467\n",
            "Unique RET_TARGET values: [ 1 -1]\n",
            "Missing values: 0\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_82202066-78e4-4ade-8e75-b37ff0edd7a6\", \"predictions_ensemble.csv\", 963964)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Results:\n",
            "LightGBM: 0.7985\n",
            "XGBoost: 0.9894\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost\n",
        "from sklearn.decomposition import PCA\n",
        "from joblib import Parallel, delayed\n",
        "import json\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# Check xgboost version for compatibility\n",
        "print(f\"XGBoost version: {xgboost.__version__}\")\n",
        "if int(xgboost.__version__.split('.')[0]) < 1:\n",
        "    print(\"Warning: XGBoost version < 1.0.0 detected. Ensure compatibility with eval_metric in constructor.\")\n",
        "\n",
        "# Set up data directory\n",
        "DATA_DIR = '/content'\n",
        "\n",
        "# Load datasets\n",
        "try:\n",
        "    X_train = pd.read_csv(os.path.join(DATA_DIR, 'X_train_itDkypA.csv'), index_col='ID', dtype=np.float32)\n",
        "    y_train = pd.read_csv(os.path.join(DATA_DIR, 'y_train_3LeeT2g.csv'), index_col='ID', dtype=np.float32)\n",
        "    X_test = pd.read_csv(os.path.join(DATA_DIR, 'X_test_Beg4ey3.csv'), index_col='ID', dtype=np.float32)\n",
        "    supplementary = pd.read_csv(os.path.join(DATA_DIR, 'supplementary_data_Vkoyn8z.csv'))\n",
        "except FileNotFoundError as e:\n",
        "    raise FileNotFoundError(f\"Dataset not found: {e}. Please ensure files are uploaded to {DATA_DIR}.\")\n",
        "\n",
        "# Custom weighted accuracy metric\n",
        "def weighted_accuracy(y_true, y_pred, weights):\n",
        "    y_pred_mapped = np.where(y_pred == 1, 1, -1)\n",
        "    correct = (y_pred_mapped == np.sign(y_true)).astype(float)\n",
        "    return np.sum(np.abs(y_true) * correct) / np.sum(np.abs(y_true))\n",
        "\n",
        "# Preprocess data with enhanced feature selection\n",
        "def preprocess_data(X, y=None, supplementary=None, is_train=True, top_cols=None):\n",
        "    ret_cols = [col for col in X.columns if col.startswith('RET_')]\n",
        "\n",
        "    # Dynamic feature selection with minimum variance threshold\n",
        "    if is_train and top_cols is None:\n",
        "        if len(ret_cols) > 15:\n",
        "            variances = X[ret_cols].var()\n",
        "            corr_sum = X[ret_cols].corr().abs().sum()\n",
        "            combined_score = variances * corr_sum\n",
        "            # Filter out low-variance features (threshold = 1e-5)\n",
        "            valid_cols = variances[variances > 1e-5].index\n",
        "            if len(valid_cols) < 15:\n",
        "                top_cols = valid_cols.tolist()\n",
        "            else:\n",
        "                top_cols = combined_score.loc[valid_cols].sort_values(ascending=False).head(15).index.tolist()\n",
        "        else:\n",
        "            top_cols = ret_cols\n",
        "        print(f\"Selected top return columns: {top_cols}\")\n",
        "    elif top_cols is not None:\n",
        "        ret_cols = [col for col in ret_cols if col in top_cols]\n",
        "        if not ret_cols:\n",
        "            raise ValueError(\"No return columns selected. Check top_cols consistency.\")\n",
        "\n",
        "    # Cache sector-based medians\n",
        "    sector_medians = {}\n",
        "    if supplementary is not None:\n",
        "        sector_map = supplementary.set_index('ID_asset')['CLASS_LEVEL_1']\n",
        "        for col in ret_cols:\n",
        "            asset_id = int(col.replace('RET_', ''))\n",
        "            sector = sector_map.get(asset_id, np.nan)\n",
        "            if pd.notna(sector):\n",
        "                sector_assets = supplementary[supplementary['CLASS_LEVEL_1'] == sector]['ID_asset']\n",
        "                sector_cols = [f'RET_{a}' for a in sector_assets if f'RET_{a}' in X.columns]\n",
        "                if sector_cols:\n",
        "                    sector_medians[col] = X[sector_cols].median(axis=1)\n",
        "            if col in sector_medians:\n",
        "                X[col] = X[col].fillna(sector_medians[col])\n",
        "            else:\n",
        "                X[col] = X[col].fillna(X[col].median())\n",
        "\n",
        "    # Sector-based features\n",
        "    new_cols = {}\n",
        "    if supplementary is not None:\n",
        "        level = 'CLASS_LEVEL_1'\n",
        "        sector_groups = supplementary.groupby(level)['ID_asset'].apply(list).to_dict()\n",
        "        for sector, assets in sector_groups.items():\n",
        "            asset_cols = [f'RET_{asset}' for asset in assets if f'RET_{asset}' in ret_cols]\n",
        "            if asset_cols:\n",
        "                new_cols[f'SECTOR_AVG_{level}_{sector}'] = X[asset_cols].mean(axis=1).replace([np.inf, -np.inf], 0).fillna(0)\n",
        "        X = X.merge(supplementary[['ID_asset', level]].rename(columns={'ID_asset': 'ID_TARGET', level: f'TARGET_{level}'}),\n",
        "                    on='ID_TARGET', how='left')\n",
        "        X = pd.concat([X, pd.get_dummies(X[f'TARGET_{level}'], prefix=f'TARGET_{level}', dummy_na=True)], axis=1)\n",
        "        X = X.drop(f'TARGET_{level}', axis=1)\n",
        "\n",
        "    # Cross-sectional features\n",
        "    new_cols['MEAN_RET'] = X[ret_cols].mean(axis=1)\n",
        "    new_cols['STD_RET'] = X[ret_cols].std(axis=1)\n",
        "    new_cols.update({f'CS_RANK_{col}': X.groupby('ID_DAY')[col].rank(pct=True).replace([np.inf, -np.inf], 0).fillna(0) for col in ret_cols})\n",
        "\n",
        "    # Correlation-based features (top 5 pairs)\n",
        "    if is_train:\n",
        "        corr_matrix = X[ret_cols].corr()\n",
        "        corr_pairs = corr_matrix.unstack().sort_values(ascending=False)\n",
        "        top_pairs = [(i, j) for i, j in corr_pairs.index if i < j][:5]\n",
        "        for i, j in top_pairs:\n",
        "            new_cols[f'CORR_{i}_{j}'] = X[i] * X[j]\n",
        "\n",
        "    # PCA features (2 components)\n",
        "    if ret_cols:\n",
        "        pca = PCA(n_components=min(2, len(ret_cols)), random_state=42)\n",
        "        pca_features = pca.fit_transform(X[ret_cols].fillna(0))\n",
        "        for i in range(pca_features.shape[1]):\n",
        "            new_cols[f'PCA_{i}'] = pca_features[:, i]\n",
        "\n",
        "    # Add new features to DataFrame\n",
        "    new_cols_df = pd.DataFrame(new_cols, index=X.index, dtype=np.float32)\n",
        "    X = pd.concat([X, new_cols_df], axis=1)\n",
        "\n",
        "    # Standardize numerical features\n",
        "    feature_cols = [col for col in X.columns if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "    scaler = StandardScaler()\n",
        "    X[feature_cols] = scaler.fit_transform(X[feature_cols].replace([np.inf, -np.inf], 0).fillna(0))\n",
        "\n",
        "    if is_train:\n",
        "        y['SIGN_TARGET'] = np.where(y['RET_TARGET'] > 0, 1, 0).astype(np.int32)\n",
        "        return X, y, feature_cols, top_cols\n",
        "    return X, None, feature_cols, top_cols\n",
        "\n",
        "# Preprocess data\n",
        "try:\n",
        "    X_train, y_train, feature_cols, top_cols = preprocess_data(X_train, y_train, supplementary, is_train=True)\n",
        "    X_test, _, test_feature_cols, _ = preprocess_data(X_test, supplementary=supplementary, is_train=False, top_cols=top_cols)\n",
        "except ValueError as e:\n",
        "    print(f\"Preprocessing error: {e}\")\n",
        "    raise\n",
        "\n",
        "# Align columns\n",
        "common_cols = X_train.columns.intersection(X_test.columns)\n",
        "X_train = X_train[common_cols]\n",
        "X_test = X_test[common_cols]\n",
        "feature_cols = [col for col in common_cols if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "\n",
        "# Align y_train\n",
        "y_train = y_train.loc[X_train.index]\n",
        "\n",
        "# Define models with expanded hyperparameter grids\n",
        "models = {\n",
        "    'LightGBM': {\n",
        "        'model': LGBMClassifier(num_leaves=31, min_child_samples=15, lambda_l1=0.3, lambda_l2=0.3,\n",
        "                                subsample=0.7, colsample_bytree=0.8, bagging_freq=5, bagging_fraction=0.7,\n",
        "                                random_state=42, n_jobs=1, verbosity=-1, class_weight='balanced', force_row_wise=True),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.005], 'num_leaves': [15], 'min_child_samples': [10], 'bagging_fraction': [0.6], 'reg_alpha': [0.0], 'reg_lambda': [0.0]},\n",
        "            {'learning_rate': [0.01], 'num_leaves': [31], 'min_child_samples': [15], 'bagging_fraction': [0.7], 'reg_alpha': [0.1], 'reg_lambda': [0.1]},\n",
        "            {'learning_rate': [0.03], 'num_leaves': [47], 'min_child_samples': [20], 'bagging_fraction': [0.8], 'reg_alpha': [0.2], 'reg_lambda': [0.2]},\n",
        "            {'learning_rate': [0.05], 'num_leaves': [63], 'min_child_samples': [12], 'bagging_fraction': [0.65], 'reg_alpha': [0.3], 'reg_lambda': [0.3]},\n",
        "            {'learning_rate': [0.07], 'num_leaves': [79], 'min_child_samples': [30], 'bagging_fraction': [0.75], 'reg_alpha': [0.4], 'reg_lambda': [0.4]},\n",
        "            {'learning_rate': [0.1], 'num_leaves': [15], 'min_child_samples': [10], 'bagging_fraction': [0.6], 'reg_alpha': [0.0], 'reg_lambda': [0.1]},\n",
        "            {'learning_rate': [0.15], 'num_leaves': [31], 'min_child_samples': [15], 'bagging_fraction': [0.7], 'reg_alpha': [0.2], 'reg_lambda': [0.0]},\n",
        "            {'learning_rate': [0.005], 'num_leaves': [47], 'min_child_samples': [20], 'bagging_fraction': [0.8], 'reg_alpha': [0.1], 'reg_lambda': [0.3]},\n",
        "            {'learning_rate': [0.01], 'num_leaves': [63], 'min_child_samples': [12], 'bagging_fraction': [0.65], 'reg_alpha': [0.3], 'reg_lambda': [0.2]},\n",
        "            {'learning_rate': [0.03], 'num_leaves': [79], 'min_child_samples': [30], 'bagging_fraction': [0.75], 'reg_alpha': [0.4], 'reg_lambda': [0.1]},\n",
        "            {'learning_rate': [0.05], 'num_leaves': [15], 'min_child_samples': [10], 'bagging_fraction': [0.6], 'reg_alpha': [0.0], 'reg_lambda': [0.4]},\n",
        "            {'learning_rate': [0.07], 'num_leaves': [31], 'min_child_samples': [15], 'bagging_fraction': [0.7], 'reg_alpha': [0.2], 'reg_lambda': [0.0]}\n",
        "        ],\n",
        "        'callbacks': [lightgbm.early_stopping(stopping_rounds=15, verbose=False)]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'model': XGBClassifier(max_depth=4, min_child_weight=2, subsample=0.8, colsample_bytree=0.8,\n",
        "                               random_state=42, n_jobs=1, eval_metric='logloss', verbosity=0,\n",
        "                               scale_pos_weight=len(y_train[y_train['SIGN_TARGET'] == 0]) / len(y_train[y_train['SIGN_TARGET'] == 1])),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.005], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [100], 'reg_alpha': [0.0], 'reg_lambda': [1.0]},\n",
        "            {'learning_rate': [0.01], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [150], 'reg_alpha': [0.5], 'reg_lambda': [1.5]},\n",
        "            {'learning_rate': [0.03], 'max_depth': [5], 'min_child_weight': [3], 'subsample': [0.8], 'n_estimators': [200], 'reg_alpha': [1.0], 'reg_lambda': [2.0]},\n",
        "            {'learning_rate': [0.05], 'max_depth': [6], 'min_child_weight': [4], 'subsample': [0.65], 'n_estimators': [250], 'reg_alpha': [0.0], 'reg_lambda': [1.0]},\n",
        "            {'learning_rate': [0.07], 'max_depth': [7], 'min_child_weight': [5], 'subsample': [0.75], 'n_estimators': [300], 'reg_alpha': [0.5], 'reg_lambda': [1.5]},\n",
        "            {'learning_rate': [0.1], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [100], 'reg_alpha': [1.0], 'reg_lambda': [2.0]},\n",
        "            {'learning_rate': [0.15], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [150], 'reg_alpha': [0.0], 'reg_lambda': [1.0]},\n",
        "            {'learning_rate': [0.005], 'max_depth': [5], 'min_child_weight': [3], 'subsample': [0.8], 'n_estimators': [200], 'reg_alpha': [0.5], 'reg_lambda': [1.5]},\n",
        "            {'learning_rate': [0.01], 'max_depth': [6], 'min_child_weight': [4], 'subsample': [0.65], 'n_estimators': [250], 'reg_alpha': [1.0], 'reg_lambda': [2.0]},\n",
        "            {'learning_rate': [0.03], 'max_depth': [7], 'min_child_weight': [5], 'subsample': [0.75], 'n_estimators': [300], 'reg_alpha': [0.0], 'reg_lambda': [1.0]},\n",
        "            {'learning_rate': [0.05], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [100], 'reg_alpha': [0.5], 'reg_lambda': [1.5]},\n",
        "            {'learning_rate': [0.07], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [150], 'reg_alpha': [1.0], 'reg_lambda': [2.0]}\n",
        "        ],\n",
        "        'callbacks': [xgboost.callback.EarlyStopping(rounds=15, metric_name='logloss', save_best=True)]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to train and predict for a single target\n",
        "def train_target(target, X_train, y_train, X_test, feature_cols, model, model_name, kf, param_grid, callbacks):\n",
        "    X_target = X_train[X_train['ID_TARGET'] == target][feature_cols]\n",
        "    y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "    weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "    low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "    # Dynamic weight scaling based on sample size\n",
        "    weight_scale = 2.0 if target in low_performing_targets else 1.0\n",
        "    if len(X_target) < 500:\n",
        "        weight_scale *= 1.5  # Boost weights for small targets\n",
        "    weights = weights * weight_scale\n",
        "    groups = X_train[X_train['ID_TARGET'] == target]['ID_DAY']\n",
        "    X_test_target = X_test[X_test['ID_TARGET'] == target][feature_cols]\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "    # Check for sufficient data\n",
        "    if len(X_target) < 100 or len(X_test_target) == 0:\n",
        "        print(f\"Warning: Insufficient data for ID_TARGET {target} (train: {len(X_target)}, test: {len(X_test_target)}). Skipping.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    param_results = []\n",
        "    best_params = None\n",
        "    best_score = 0\n",
        "    best_model = None\n",
        "\n",
        "    # First-pass grid search with sample weights\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        print(f\"Testing params for {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "        try:\n",
        "            model.set_params(**params)\n",
        "        except ValueError as e:\n",
        "            print(f\"Invalid params for {model_name} ID_TARGET {target}: {e}\")\n",
        "            continue\n",
        "        fold_accuracies = []\n",
        "        for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "            X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "            y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "            w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "\n",
        "            if model_name == 'LightGBM' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=callbacks)\n",
        "            elif model_name == 'XGBoost' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "            else:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "            y_pred = model.predict(X_val)\n",
        "            acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "            fold_accuracies.append(acc)\n",
        "\n",
        "        mean_acc = np.mean(fold_accuracies)\n",
        "        print(f\"{model_name} | ID_TARGET: {target} | Params: {params} | Mean Accuracy: {mean_acc:.4f} | Fold Accuracies: {fold_accuracies}\", flush=True)\n",
        "        param_results.append({\n",
        "            'params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': fold_accuracies\n",
        "        })\n",
        "        if mean_acc > best_score:\n",
        "            best_score = mean_acc\n",
        "            best_params = params\n",
        "            best_model = type(model)(**model.get_params())\n",
        "\n",
        "    # Train with best parameters\n",
        "    if best_model is None:\n",
        "        print(f\"No valid model for {model_name} ID_TARGET {target}. Using default.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    best_model.set_params(**best_params)\n",
        "    if model_name == 'LightGBM' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=callbacks)\n",
        "    elif model_name == 'XGBoost' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "    else:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights)\n",
        "\n",
        "    # Predict\n",
        "    preds = best_model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "\n",
        "    # Feature importance\n",
        "    importance = best_model.feature_importances_\n",
        "    feature_importance = dict(zip(feature_cols, importance))\n",
        "    top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:30]\n",
        "\n",
        "    # Clean up memory\n",
        "    gc.collect()\n",
        "\n",
        "    return str(target), best_params, best_score, param_results, test_ids, preds, top_features\n",
        "\n",
        "# Cross-validation and training\n",
        "kf = GroupKFold(n_splits=7)  # Increased to 7 folds\n",
        "results = {}\n",
        "predictions = {}\n",
        "ensemble_weights = {'LightGBM': 0.7, 'XGBoost': 0.3}\n",
        "param_log = {}\n",
        "top_features_all = {}\n",
        "param_summary = []\n",
        "low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\", flush=True)\n",
        "    param_log[model_name] = {}\n",
        "    top_features_all[model_name] = {}\n",
        "\n",
        "    # First-pass training\n",
        "    results_parallel = Parallel(n_jobs=-1)(\n",
        "        delayed(train_target)(target, X_train, y_train, X_test, feature_cols, model_info['model'], model_name, kf,\n",
        "                             model_info['param_grid'], model_info['callbacks'])\n",
        "        for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\")\n",
        "    )\n",
        "\n",
        "    # Collect results\n",
        "    accuracies = []\n",
        "    for target, params, mean_acc, param_results, test_ids, preds, top_features in results_parallel:\n",
        "        param_log[model_name][target] = {\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'all_params': param_results\n",
        "        }\n",
        "        top_features_all[model_name][target] = top_features\n",
        "        accuracies.append(mean_acc)\n",
        "        predictions.setdefault(target, {})[model_name] = dict(zip(test_ids, preds))\n",
        "        param_summary.append({\n",
        "            'model': model_name,\n",
        "            'ID_TARGET': target,\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': param_results[-1]['fold_accuracies'] if param_results else []\n",
        "        })\n",
        "\n",
        "    results[model_name] = np.mean([acc for acc in accuracies if acc > 0])  # Exclude skipped targets\n",
        "    print(f\"{model_name} Weighted Accuracy: {results[model_name]:.4f}\", flush=True)\n",
        "\n",
        "    # Print parameter summary\n",
        "    print(f\"\\n{model_name} Parameter Summary:\", flush=True)\n",
        "    for summary in param_summary:\n",
        "        if summary['model'] == model_name:\n",
        "            print(f\"ID_TARGET: {summary['ID_TARGET']} | Best Params: {summary['best_params']} | Mean Accuracy: {summary['mean_accuracy']:.4f} | Fold Accuracies: {summary['fold_accuracies']}\", flush=True)\n",
        "\n",
        "# Second-pass training with top 30 features\n",
        "print(\"\\nPerforming second-pass training with top 30 features...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nSecond-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\"):\n",
        "        target_str = str(target)\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "        weight_scale = 2.0 if target in low_performing_targets else 1.0\n",
        "        if len(X_target) < 500:\n",
        "            weight_scale *= 1.5\n",
        "        weights = weights * weight_scale\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        best_params['n_estimators'] = 300  # Use integer instead of list\n",
        "        model.set_params(**best_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Third-pass training for low-performing targets\n",
        "print(\"\\nPerforming third-pass training for low-performing targets...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nThird-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(low_performing_targets, desc=f\"{model_name} Low-Performing Targets\"):\n",
        "        target_str = str(target)\n",
        "        if target_str not in param_log[model_name] or param_log[model_name][target_str]['mean_accuracy'] >= 0.75:\n",
        "            continue  # Skip if already performing well\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs() * 3.0  # Increase weight\n",
        "        if len(X_target) < 500:\n",
        "            weights = weights * 1.5\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        # Expanded fine-tuning grid for low-performing targets\n",
        "        fine_tune_grid = [\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.5, 'n_estimators': 400, 'reg_alpha': best_params['reg_alpha'][0] + 0.2, 'reg_lambda': best_params['reg_lambda'][0] + 0.2},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.7, 'n_estimators': 450, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.3, 'n_estimators': 400, 'reg_alpha': best_params['reg_alpha'][0], 'reg_lambda': best_params['reg_lambda'][0]},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.5, 'n_estimators': 450, 'reg_alpha': best_params['reg_alpha'][0] + 0.3, 'reg_lambda': best_params['reg_lambda'][0] + 0.3},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.6, 'n_estimators': 500, 'reg_alpha': best_params['reg_alpha'][0] + 0.15, 'reg_lambda': best_params['reg_lambda'][0] + 0.15},\n",
        "            {'learning_rate': best_params['learning_rate'][0], 'n_estimators': 550, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.2}\n",
        "        ]\n",
        "        best_score = param_log[model_name][target_str]['mean_accuracy']\n",
        "        best_fine_params = best_params\n",
        "\n",
        "        for params in ParameterGrid(fine_tune_grid):\n",
        "            print(f\"Fine-tuning {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "            model.set_params(**params)\n",
        "            fold_accuracies = []\n",
        "            for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "                X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "                y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "                w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "                if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "                elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "                else:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "                y_pred = model.predict(X_val)\n",
        "                acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "                fold_accuracies.append(acc)\n",
        "            mean_acc = np.mean(fold_accuracies)\n",
        "            print(f\"{model_name} | ID_TARGET: {target} | Fine-tune Params: {params} | Mean Accuracy: {mean_acc:.4f}\", flush=True)\n",
        "            if mean_acc > best_score:\n",
        "                best_score = mean_acc\n",
        "                best_fine_params = params\n",
        "                param_log[model_name][target_str]['best_params'] = best_fine_params\n",
        "                param_log[model_name][target_str]['mean_accuracy'] = best_score\n",
        "                param_summary.append({\n",
        "                    'model': model_name,\n",
        "                    'ID_TARGET': target_str,\n",
        "                    'best_params': best_fine_params,\n",
        "                    'mean_accuracy': best_score,\n",
        "                    'fold_accuracies': fold_accuracies\n",
        "                })\n",
        "\n",
        "        # Retrain with fine-tuned parameters\n",
        "        model.set_params(**best_fine_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Fourth-pass training for very low-performing targets\n",
        "print(\"\\nPerforming fourth-pass training for very low-performing targets...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nFourth-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(low_performing_targets, desc=f\"{model_name} Very Low-Performing Targets\"):\n",
        "        target_str = str(target)\n",
        "        if target_str not in param_log[model_name] or param_log[model_name][target_str]['mean_accuracy'] >= 0.70:\n",
        "            continue  # Skip if accuracy >= 0.70\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs() * 3.0  # High weight\n",
        "        if len(X_target) < 500:\n",
        "            weights = weights * 1.5\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        # Expanded fine-tuning grid for very low-performing targets\n",
        "        fine_tune_grid = [\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.4, 'n_estimators': 400, 'reg_alpha': best_params['reg_alpha'][0] + 0.3, 'reg_lambda': best_params['reg_lambda'][0] + 0.3},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.6, 'n_estimators': 450, 'reg_alpha': best_params['reg_alpha'][0] + 0.2, 'reg_lambda': best_params['reg_lambda'][0] + 0.2},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.8, 'n_estimators': 500, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.2, 'n_estimators': 400, 'reg_alpha': best_params['reg_alpha'][0], 'reg_lambda': best_params['reg_lambda'][0]},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.4, 'n_estimators': 450, 'reg_alpha': best_params['reg_alpha'][0] + 0.15, 'reg_lambda': best_params['reg_lambda'][0] + 0.15},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.6, 'n_estimators': 500, 'reg_alpha': best_params['reg_alpha'][0] + 0.25, 'reg_lambda': best_params['reg_lambda'][0] + 0.25}\n",
        "        ]\n",
        "        best_score = param_log[model_name][target_str]['mean_accuracy']\n",
        "        best_fine_params = best_params\n",
        "\n",
        "        for params in ParameterGrid(fine_tune_grid):\n",
        "            print(f\"Fine-tuning {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "            model.set_params(**params)\n",
        "            fold_accuracies = []\n",
        "            for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "                X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "                y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "                w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "                if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "                elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "                else:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "                y_pred = model.predict(X_val)\n",
        "                acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "                fold_accuracies.append(acc)\n",
        "            mean_acc = np.mean(fold_accuracies)\n",
        "            print(f\"{model_name} | ID_TARGET: {target} | Fine-tune Params: {params} | Mean Accuracy: {mean_acc:.4f}\", flush=True)\n",
        "            if mean_acc > best_score:\n",
        "                best_score = mean_acc\n",
        "                best_fine_params = params\n",
        "                param_log[model_name][target_str]['best_params'] = best_fine_params\n",
        "                param_log[model_name][target_str]['mean_accuracy'] = best_score\n",
        "                param_summary.append({\n",
        "                    'model': model_name,\n",
        "                    'ID_TARGET': target_str,\n",
        "                    'best_params': best_fine_params,\n",
        "                    'mean_accuracy': best_score,\n",
        "                    'fold_accuracies': fold_accuracies\n",
        "                })\n",
        "\n",
        "        # Retrain with fine-tuned parameters\n",
        "        model.set_params(**best_fine_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Save parameter log\n",
        "param_log_path = os.path.join(DATA_DIR, 'hyperparameters.json')\n",
        "with open(param_log_path, 'w') as f:\n",
        "    json.dump(param_log, f, indent=4)\n",
        "print(f\"Saved hyperparameter log to: {param_log_path}\", flush=True)\n",
        "files.download(param_log_path)\n",
        "\n",
        "# Ensemble predictions\n",
        "final_predictions = {}\n",
        "missing_day_targets = []\n",
        "for target in X_test['ID_TARGET'].unique():\n",
        "    target_str = str(target)\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "    for day in X_test[X_test['ID_TARGET'] == target]['ID_DAY'].unique():\n",
        "        day_idx = (X_test['ID_TARGET'] == target) & (X_test['ID_DAY'] == day)\n",
        "        day_test_ids = X_test[day_idx].index\n",
        "        if len(day_test_ids) == 0:\n",
        "            print(f\"Warning: No test samples for ID_TARGET {target} on ID_DAY {day}. Using default prediction.\")\n",
        "            missing_day_targets.append((target, day))\n",
        "            for idx in test_ids:\n",
        "                final_predictions[idx] = -1\n",
        "            continue\n",
        "        lgbm_preds = np.array([predictions[target_str].get('LightGBM', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        xgb_preds = np.array([predictions[target_str].get('XGBoost', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        ensemble_preds = ensemble_weights['LightGBM'] * lgbm_preds + ensemble_weights['XGBoost'] * xgb_preds\n",
        "        # Apply exponential moving average for smoothing\n",
        "        smoothed_preds = pd.Series(ensemble_preds).ewm(span=3).mean().values[-1] if len(ensemble_preds) > 0 else 0.5\n",
        "        for idx in day_test_ids:\n",
        "            final_predictions[idx] = 1 if smoothed_preds >= 0.5 else -1\n",
        "\n",
        "if missing_day_targets:\n",
        "    print(f\"Missing day-target pairs: {missing_day_targets}\")\n",
        "\n",
        "# Create output CSV\n",
        "output_df = pd.DataFrame.from_dict(final_predictions, orient='index', columns=['RET_TARGET']).reset_index()\n",
        "output_df.columns = ['ID', 'RET_TARGET']\n",
        "output_df = output_df.sort_values('ID')\n",
        "expected_ids = set(X_test.index)\n",
        "submission_ids = set(output_df['ID'])\n",
        "if expected_ids != submission_ids:\n",
        "    missing_ids = expected_ids - submission_ids\n",
        "    print(f\"Warning: Submission missing {len(missing_ids)} IDs: {missing_ids}\")\n",
        "    missing_df = pd.DataFrame({'ID': list(missing_ids), 'RET_TARGET': -1})\n",
        "    output_df = pd.concat([output_df, missing_df], ignore_index=True).sort_values('ID')\n",
        "output_path = os.path.join(DATA_DIR, 'predictions_ensemble.csv')\n",
        "output_df.to_csv(output_path, index=False)\n",
        "print(f\"Saved predictions to: {output_path}\", flush=True)\n",
        "\n",
        "# Validate output\n",
        "test_csv = pd.read_csv(output_path)\n",
        "print(f\"Output CSV shape: {test_csv.shape}\", flush=True)\n",
        "print(f\"Output CSV ID range: {test_csv['ID'].min()} to {test_csv['ID'].max()}\", flush=True)\n",
        "print(f\"Unique RET_TARGET values: {test_csv['RET_TARGET'].unique()}\", flush=True)\n",
        "print(f\"Missing values: {test_csv.isna().sum().sum()}\", flush=True)\n",
        "\n",
        "# Download the file\n",
        "files.download(output_path)\n",
        "\n",
        "# Print final results\n",
        "print(\"\\nValidation Results:\", flush=True)\n",
        "for model_name, acc in results.items():\n",
        "    print(f\"{model_name}: {acc:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH3lwmtcWWSX"
      },
      "source": [
        "try new -- not yet submit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MO9Pwlk-WXMu",
        "outputId": "7733cef5-0991-4ccc-d36a-22ca3483044f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost version: 2.1.4\n",
            "Selected top return columns: ['RET_262', 'RET_88', 'RET_172', 'RET_259', 'RET_118', 'RET_150', 'RET_261', 'RET_268', 'RET_115', 'RET_216', 'RET_238', 'RET_59', 'RET_30', 'RET_97', 'RET_122']\n",
            "\n",
            "Training LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LightGBM Targets: 100%|| 101/101 [1:24:34<00:00, 50.25s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightGBM Weighted Accuracy: 0.8597\n",
            "\n",
            "LightGBM Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.9877300613496932), np.float64(1.0), np.float64(1.0), np.float64(0.9939393939393939), np.float64(0.988950276243094), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 129.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8942 | Fold Accuracies: [np.float64(0.73125), np.float64(0.7345679012345679), np.float64(0.7169811320754716), np.float64(0.8430232558139535), np.float64(0.7407407407407407), np.float64(0.7672955974842768), np.float64(0.7670454545454546)]\n",
            "ID_TARGET: 136.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8180 | Fold Accuracies: [np.float64(0.7735849056603774), np.float64(0.6835443037974683), np.float64(0.7371428571428571), np.float64(0.7727272727272727), np.float64(0.7159763313609467), np.float64(0.6839080459770115), np.float64(0.6474358974358975)]\n",
            "ID_TARGET: 161.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.8395 | Fold Accuracies: [np.float64(0.7651006711409396), np.float64(0.7371428571428571), np.float64(0.7804878048780488), np.float64(0.7696969696969697), np.float64(0.7738095238095238), np.float64(0.7513812154696132), np.float64(0.676829268292683)]\n",
            "ID_TARGET: 217.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9343 | Fold Accuracies: [np.float64(0.8383233532934131), np.float64(0.8333333333333334), np.float64(0.7840909090909091), np.float64(0.8135593220338984), np.float64(0.8518518518518519), np.float64(0.8181818181818182), np.float64(0.7771739130434783)]\n",
            "ID_TARGET: 91.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9120 | Fold Accuracies: [np.float64(0.84472049689441), np.float64(0.8352941176470589), np.float64(0.8106508875739645), np.float64(0.8758620689655172), np.float64(0.8301886792452831), np.float64(0.8098159509202454), np.float64(0.8132530120481928)]\n",
            "ID_TARGET: 137.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8124 | Fold Accuracies: [np.float64(0.6923076923076923), np.float64(0.7371794871794872), np.float64(0.7791411042944786), np.float64(0.7806451612903226), np.float64(0.7177914110429447), np.float64(0.7289156626506024), np.float64(0.7388535031847133)]\n",
            "ID_TARGET: 8.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9915 | Fold Accuracies: [np.float64(0.8953488372093024), np.float64(0.8867924528301887), np.float64(0.8787878787878788), np.float64(0.9245283018867925), np.float64(0.9025974025974026), np.float64(0.8546511627906976), np.float64(0.8466666666666667)]\n",
            "ID_TARGET: 3.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9425 | Fold Accuracies: [np.float64(0.8287671232876712), np.float64(0.88125), np.float64(0.8427672955974843), np.float64(0.7808988764044944), np.float64(0.7947019867549668), np.float64(0.8211920529801324), np.float64(0.8598726114649682)]\n",
            "ID_TARGET: 9.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9609 | Fold Accuracies: [np.float64(0.7931034482758621), np.float64(0.8333333333333334), np.float64(0.89171974522293), np.float64(0.8235294117647058), np.float64(0.8529411764705882), np.float64(0.7960526315789473), np.float64(0.7911392405063291)]\n",
            "ID_TARGET: 131.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9043 | Fold Accuracies: [np.float64(0.7828571428571428), np.float64(0.810126582278481), np.float64(0.8095238095238095), np.float64(0.7670454545454546), np.float64(0.8407643312101911), np.float64(0.8402777777777778), np.float64(0.8227848101265823)]\n",
            "ID_TARGET: 21.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7549 | Fold Accuracies: [np.float64(0.6407185628742516), np.float64(0.7116564417177914), np.float64(0.7852760736196319), np.float64(0.5804597701149425), np.float64(0.7795698924731183), np.float64(0.7045454545454546), np.float64(0.7176470588235294)]\n",
            "ID_TARGET: 54.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9375 | Fold Accuracies: [np.float64(0.8535031847133758), np.float64(0.8410596026490066), np.float64(0.8971428571428571), np.float64(0.8502994011976048), np.float64(0.8545454545454545), np.float64(0.907608695652174), np.float64(0.9308176100628931)]\n",
            "ID_TARGET: 130.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.9092 | Fold Accuracies: [np.float64(0.8617021276595744), np.float64(0.8805031446540881), np.float64(0.8457142857142858), np.float64(0.8224852071005917), np.float64(0.834319526627219), np.float64(0.8435374149659864), np.float64(0.8208092485549133)]\n",
            "ID_TARGET: 269.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9257 | Fold Accuracies: [np.float64(0.7816901408450704), np.float64(0.832258064516129), np.float64(0.8181818181818182), np.float64(0.8525641025641025), np.float64(0.7581699346405228), np.float64(0.8235294117647058), np.float64(0.8278145695364238)]\n",
            "ID_TARGET: 157.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.8561 | Fold Accuracies: [np.float64(0.7677419354838709), np.float64(0.8424657534246576), np.float64(0.8867924528301887), np.float64(0.8543046357615894), np.float64(0.8280254777070064), np.float64(0.7727272727272727), np.float64(0.861271676300578)]\n",
            "ID_TARGET: 249.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.8823 | Fold Accuracies: [np.float64(0.7630057803468208), np.float64(0.8128654970760234), np.float64(0.7628205128205128), np.float64(0.7988165680473372), np.float64(0.7655172413793103), np.float64(0.8509316770186336), np.float64(0.8757763975155279)]\n",
            "ID_TARGET: 22.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.7624 | Fold Accuracies: [np.float64(0.6807228915662651), np.float64(0.7197802197802198), np.float64(0.7371428571428571), np.float64(0.8012048192771084), np.float64(0.6309523809523809), np.float64(0.6287425149700598), np.float64(0.7707006369426752)]\n",
            "ID_TARGET: 202.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.6812 | Fold Accuracies: [np.float64(0.6588235294117647), np.float64(0.6392405063291139), np.float64(0.6374269005847953), np.float64(0.6976744186046512), np.float64(0.6294117647058823), np.float64(0.6081871345029239), np.float64(0.6574585635359116)]\n",
            "ID_TARGET: 132.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.9044 | Fold Accuracies: [np.float64(0.8292682926829268), np.float64(0.8175675675675675), np.float64(0.8104575163398693), np.float64(0.8571428571428571), np.float64(0.7701863354037267), np.float64(0.8129032258064516), np.float64(0.823170731707317)]\n",
            "ID_TARGET: 96.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9221 | Fold Accuracies: [np.float64(0.8169934640522876), np.float64(0.8214285714285714), np.float64(0.7302631578947368), np.float64(0.8111888111888111), np.float64(0.8571428571428571), np.float64(0.7581699346405228), np.float64(0.8493150684931506)]\n",
            "ID_TARGET: 7.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8791 | Fold Accuracies: [np.float64(0.8129032258064516), np.float64(0.8563218390804598), np.float64(0.7727272727272727), np.float64(0.8129032258064516), np.float64(0.8432432432432433), np.float64(0.85), np.float64(0.8659217877094972)]\n",
            "ID_TARGET: 178.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8203 | Fold Accuracies: [np.float64(0.7848837209302325), np.float64(0.7341772151898734), np.float64(0.7295597484276729), np.float64(0.7352941176470589), np.float64(0.7619047619047619), np.float64(0.80625), np.float64(0.7583892617449665)]\n",
            "ID_TARGET: 68.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.8418 | Fold Accuracies: [np.float64(0.7650602409638554), np.float64(0.8012422360248447), np.float64(0.7721518987341772), np.float64(0.810126582278481), np.float64(0.8040540540540541), np.float64(0.8074534161490683), np.float64(0.8026315789473685)]\n",
            "ID_TARGET: 44.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8941 | Fold Accuracies: [np.float64(0.7988165680473372), np.float64(0.8734177215189873), np.float64(0.7721518987341772), np.float64(0.8484848484848485), np.float64(0.7861271676300579), np.float64(0.7245508982035929), np.float64(0.8143712574850299)]\n",
            "ID_TARGET: 196.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8846 | Fold Accuracies: [np.float64(0.8287292817679558), np.float64(0.8108108108108109), np.float64(0.8587570621468926), np.float64(0.7783783783783784), np.float64(0.7209302325581395), np.float64(0.8125), np.float64(0.7556818181818182)]\n",
            "ID_TARGET: 292.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8962 | Fold Accuracies: [np.float64(0.7936507936507936), np.float64(0.8222222222222222), np.float64(0.8035714285714286), np.float64(0.864516129032258), np.float64(0.7792207792207793), np.float64(0.7333333333333333), np.float64(0.7572254335260116)]\n",
            "ID_TARGET: 239.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8902 | Fold Accuracies: [np.float64(0.8209876543209876), np.float64(0.7735849056603774), np.float64(0.775), np.float64(0.8356164383561644), np.float64(0.8121212121212121), np.float64(0.7888198757763976), np.float64(0.8243243243243243)]\n",
            "ID_TARGET: 279.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9296 | Fold Accuracies: [np.float64(0.8300653594771242), np.float64(0.8909090909090909), np.float64(0.7986577181208053), np.float64(0.8424242424242424), np.float64(0.695906432748538), np.float64(0.8728323699421965), np.float64(0.7485029940119761)]\n",
            "ID_TARGET: 38.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9515 | Fold Accuracies: [np.float64(0.8383233532934131), np.float64(0.8402777777777778), np.float64(0.8417721518987342), np.float64(0.7888198757763976), np.float64(0.8723404255319149), np.float64(0.8813559322033898), np.float64(0.8514285714285714)]\n",
            "ID_TARGET: 209.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8983 | Fold Accuracies: [np.float64(0.8417721518987342), np.float64(0.7575757575757576), np.float64(0.8081395348837209), np.float64(0.8253012048192772), np.float64(0.847457627118644), np.float64(0.8), np.float64(0.6923076923076923)]\n",
            "ID_TARGET: 207.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8286 | Fold Accuracies: [np.float64(0.7307692307692307), np.float64(0.7088607594936709), np.float64(0.7413793103448276), np.float64(0.7450980392156863), np.float64(0.7654320987654321), np.float64(0.7759562841530054), np.float64(0.6839080459770115)]\n",
            "ID_TARGET: 98.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.8184 | Fold Accuracies: [np.float64(0.75625), np.float64(0.7784810126582279), np.float64(0.7948717948717948), np.float64(0.7610062893081762), np.float64(0.6790123456790124), np.float64(0.7784431137724551), np.float64(0.8)]\n",
            "ID_TARGET: 65.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8477 | Fold Accuracies: [np.float64(0.8011695906432749), np.float64(0.832258064516129), np.float64(0.7777777777777778), np.float64(0.6962025316455697), np.float64(0.7808219178082192), np.float64(0.7290322580645161), np.float64(0.8451612903225807)]\n",
            "ID_TARGET: 51.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8920 | Fold Accuracies: [np.float64(0.8397435897435898), np.float64(0.8866666666666667), np.float64(0.7894736842105263), np.float64(0.8343949044585988), np.float64(0.7741935483870968), np.float64(0.8238993710691824), np.float64(0.8026315789473685)]\n",
            "ID_TARGET: 78.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.8500 | Fold Accuracies: [np.float64(0.8275862068965517), np.float64(0.8198757763975155), np.float64(0.7074829931972789), np.float64(0.7654320987654321), np.float64(0.7919463087248322), np.float64(0.7770700636942676), np.float64(0.8220858895705522)]\n",
            "ID_TARGET: 177.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7675 | Fold Accuracies: [np.float64(0.7333333333333333), np.float64(0.7658227848101266), np.float64(0.7783783783783784), np.float64(0.7692307692307693), np.float64(0.6871794871794872), np.float64(0.7337278106508875), np.float64(0.7336956521739131)]\n",
            "ID_TARGET: 231.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8963 | Fold Accuracies: [np.float64(0.8701298701298701), np.float64(0.791907514450867), np.float64(0.8475609756097561), np.float64(0.803680981595092), np.float64(0.8493975903614458), np.float64(0.8547486033519553), np.float64(0.8782051282051282)]\n",
            "ID_TARGET: 119.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.8292 | Fold Accuracies: [np.float64(0.8741721854304636), np.float64(0.8037974683544303), np.float64(0.7924528301886793), np.float64(0.779874213836478), np.float64(0.8220858895705522), np.float64(0.7770700636942676), np.float64(0.8192090395480226)]\n",
            "ID_TARGET: 158.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8801 | Fold Accuracies: [np.float64(0.8231292517006803), np.float64(0.8511904761904762), np.float64(0.8176795580110497), np.float64(0.8120805369127517), np.float64(0.8787878787878788), np.float64(0.8344370860927153), np.float64(0.8212290502793296)]\n",
            "ID_TARGET: 80.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7805 | Fold Accuracies: [np.float64(0.6556291390728477), np.float64(0.7388535031847133), np.float64(0.7), np.float64(0.725609756097561), np.float64(0.7560975609756098), np.float64(0.7333333333333333), np.float64(0.7630057803468208)]\n",
            "ID_TARGET: 25.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8636 | Fold Accuracies: [np.float64(0.8265895953757225), np.float64(0.7658227848101266), np.float64(0.7707006369426752), np.float64(0.7727272727272727), np.float64(0.8203592814371258), np.float64(0.80625), np.float64(0.7875)]\n",
            "ID_TARGET: 175.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8866 | Fold Accuracies: [np.float64(0.8775510204081632), np.float64(0.7926829268292683), np.float64(0.8698224852071006), np.float64(0.844311377245509), np.float64(0.8658536585365854), np.float64(0.7757575757575758), np.float64(0.8223684210526315)]\n",
            "ID_TARGET: 151.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8493 | Fold Accuracies: [np.float64(0.8484848484848485), np.float64(0.8260869565217391), np.float64(0.8193548387096774), np.float64(0.8209876543209876), np.float64(0.7577639751552795), np.float64(0.7987421383647799), np.float64(0.8366013071895425)]\n",
            "ID_TARGET: 257.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.8206 | Fold Accuracies: [np.float64(0.7526881720430108), np.float64(0.79375), np.float64(0.8502994011976048), np.float64(0.6666666666666666), np.float64(0.8255813953488372), np.float64(0.7657142857142857), np.float64(0.7160493827160493)]\n",
            "ID_TARGET: 75.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8756 | Fold Accuracies: [np.float64(0.847457627118644), np.float64(0.8385093167701864), np.float64(0.8176470588235294), np.float64(0.7926829268292683), np.float64(0.8490566037735849), np.float64(0.8342857142857143), np.float64(0.8690476190476191)]\n",
            "ID_TARGET: 244.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.7928 | Fold Accuracies: [np.float64(0.735632183908046), np.float64(0.6988636363636364), np.float64(0.8058823529411765), np.float64(0.6987951807228916), np.float64(0.76875), np.float64(0.6606060606060606), np.float64(0.7602339181286549)]\n",
            "ID_TARGET: 149.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8947 | Fold Accuracies: [np.float64(0.810126582278481), np.float64(0.7891566265060241), np.float64(0.9019607843137255), np.float64(0.8288770053475936), np.float64(0.8072289156626506), np.float64(0.759493670886076), np.float64(0.8876404494382022)]\n",
            "ID_TARGET: 85.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8952 | Fold Accuracies: [np.float64(0.8253012048192772), np.float64(0.8269230769230769), np.float64(0.8227848101265823), np.float64(0.7823529411764706), np.float64(0.8666666666666667), np.float64(0.8366013071895425), np.float64(0.8846153846153846)]\n",
            "ID_TARGET: 190.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.7962 | Fold Accuracies: [np.float64(0.6792452830188679), np.float64(0.7485380116959064), np.float64(0.768361581920904), np.float64(0.7668711656441718), np.float64(0.7426900584795322), np.float64(0.7267441860465116), np.float64(0.8373493975903614)]\n",
            "ID_TARGET: 13.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8012 | Fold Accuracies: [np.float64(0.7790055248618785), np.float64(0.7668711656441718), np.float64(0.7678571428571429), np.float64(0.7288135593220338), np.float64(0.7619047619047619), np.float64(0.7748344370860927), np.float64(0.8165680473372781)]\n",
            "ID_TARGET: 228.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8046 | Fold Accuracies: [np.float64(0.8148148148148148), np.float64(0.7529411764705882), np.float64(0.7191011235955056), np.float64(0.7469135802469136), np.float64(0.7409638554216867), np.float64(0.7795698924731183), np.float64(0.7485029940119761)]\n",
            "ID_TARGET: 144.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8796 | Fold Accuracies: [np.float64(0.8253012048192772), np.float64(0.8562091503267973), np.float64(0.875), np.float64(0.8193548387096774), np.float64(0.8), np.float64(0.8152866242038217), np.float64(0.8662790697674418)]\n",
            "ID_TARGET: 290.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9345 | Fold Accuracies: [np.float64(0.7692307692307693), np.float64(0.8159509202453987), np.float64(0.7702702702702703), np.float64(0.8220858895705522), np.float64(0.8536585365853658), np.float64(0.86875), np.float64(0.8050314465408805)]\n",
            "ID_TARGET: 114.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.7467 | Fold Accuracies: [np.float64(0.7023809523809523), np.float64(0.7232704402515723), np.float64(0.6727272727272727), np.float64(0.7204968944099379), np.float64(0.7469135802469136), np.float64(0.6742857142857143), np.float64(0.751412429378531)]\n",
            "ID_TARGET: 166.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8879 | Fold Accuracies: [np.float64(0.8058823529411765), np.float64(0.8012048192771084), np.float64(0.88), np.float64(0.8719512195121951), np.float64(0.8275862068965517), np.float64(0.7792207792207793), np.float64(0.8197674418604651)]\n",
            "ID_TARGET: 234.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8060 | Fold Accuracies: [np.float64(0.7658227848101266), np.float64(0.7741935483870968), np.float64(0.8819875776397516), np.float64(0.6987179487179487), np.float64(0.7861635220125787), np.float64(0.7687074829931972), np.float64(0.7792207792207793)]\n",
            "ID_TARGET: 34.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8687 | Fold Accuracies: [np.float64(0.7873563218390804), np.float64(0.7791411042944786), np.float64(0.8227848101265823), np.float64(0.832258064516129), np.float64(0.8448275862068966), np.float64(0.8529411764705882), np.float64(0.803921568627451)]\n",
            "ID_TARGET: 154.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8227 | Fold Accuracies: [np.float64(0.8146067415730337), np.float64(0.7960526315789473), np.float64(0.7843137254901961), np.float64(0.7857142857142857), np.float64(0.8128654970760234), np.float64(0.8121212121212121), np.float64(0.8268156424581006)]\n",
            "ID_TARGET: 225.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7839 | Fold Accuracies: [np.float64(0.7354838709677419), np.float64(0.7277777777777777), np.float64(0.7512953367875648), np.float64(0.7222222222222222), np.float64(0.7413793103448276), np.float64(0.7305389221556886), np.float64(0.7931034482758621)]\n",
            "ID_TARGET: 185.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9500 | Fold Accuracies: [np.float64(0.8823529411764706), np.float64(0.8590604026845637), np.float64(0.8616352201257862), np.float64(0.8741258741258742), np.float64(0.7866666666666666), np.float64(0.8923076923076924), np.float64(0.8705035971223022)]\n",
            "ID_TARGET: 39.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8546 | Fold Accuracies: [np.float64(0.8580645161290322), np.float64(0.7810650887573964), np.float64(0.8114285714285714), np.float64(0.7564102564102564), np.float64(0.7911392405063291), np.float64(0.7987012987012987), np.float64(0.8012422360248447)]\n",
            "ID_TARGET: 272.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8337 | Fold Accuracies: [np.float64(0.7848101265822784), np.float64(0.8453038674033149), np.float64(0.7908496732026143), np.float64(0.7878787878787878), np.float64(0.7660818713450293), np.float64(0.7610062893081762), np.float64(0.7602339181286549)]\n",
            "ID_TARGET: 282.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.8418 | Fold Accuracies: [np.float64(0.8544303797468354), np.float64(0.7784090909090909), np.float64(0.8354430379746836), np.float64(0.7727272727272727), np.float64(0.7894736842105263), np.float64(0.7619047619047619), np.float64(0.8366013071895425)]\n",
            "ID_TARGET: 90.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.7954 | Fold Accuracies: [np.float64(0.7668711656441718), np.float64(0.7727272727272727), np.float64(0.7973856209150327), np.float64(0.7914110429447853), np.float64(0.7549668874172185), np.float64(0.8106508875739645), np.float64(0.7987421383647799)]\n",
            "ID_TARGET: 52.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8091 | Fold Accuracies: [np.float64(0.7189542483660131), np.float64(0.7407407407407407), np.float64(0.7891566265060241), np.float64(0.7875), np.float64(0.7558139534883721), np.float64(0.7638888888888888), np.float64(0.7658227848101266)]\n",
            "ID_TARGET: 258.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8224 | Fold Accuracies: [np.float64(0.7682119205298014), np.float64(0.8285714285714286), np.float64(0.7471910112359551), np.float64(0.7604790419161677), np.float64(0.7987804878048781), np.float64(0.7254901960784313), np.float64(0.7919463087248322)]\n",
            "ID_TARGET: 291.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8676 | Fold Accuracies: [np.float64(0.7417218543046358), np.float64(0.8588235294117647), np.float64(0.7696969696969697), np.float64(0.8055555555555556), np.float64(0.8546511627906976), np.float64(0.791907514450867), np.float64(0.8421052631578947)]\n",
            "ID_TARGET: 152.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9016 | Fold Accuracies: [np.float64(0.8081395348837209), np.float64(0.8175675675675675), np.float64(0.7898089171974523), np.float64(0.7911392405063291), np.float64(0.8715083798882681), np.float64(0.8417721518987342), np.float64(0.7705882352941177)]\n",
            "ID_TARGET: 133.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.8699 | Fold Accuracies: [np.float64(0.81875), np.float64(0.8579881656804734), np.float64(0.8682634730538922), np.float64(0.813953488372093), np.float64(0.7987804878048781), np.float64(0.8407643312101911), np.float64(0.861271676300578)]\n",
            "ID_TARGET: 29.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9079 | Fold Accuracies: [np.float64(0.7884615384615384), np.float64(0.8658536585365854), np.float64(0.8187919463087249), np.float64(0.7579617834394905), np.float64(0.8034682080924855), np.float64(0.8580246913580247), np.float64(0.8493975903614458)]\n",
            "ID_TARGET: 274.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.8108 | Fold Accuracies: [np.float64(0.7602339181286549), np.float64(0.7891566265060241), np.float64(0.8142076502732241), np.float64(0.7724550898203593), np.float64(0.7470588235294118), np.float64(0.7455621301775148), np.float64(0.7567567567567568)]\n",
            "ID_TARGET: 106.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9230 | Fold Accuracies: [np.float64(0.85), np.float64(0.8134328358208955), np.float64(0.8562091503267973), np.float64(0.8529411764705882), np.float64(0.8551724137931035), np.float64(0.912751677852349), np.float64(0.8169014084507042)]\n",
            "ID_TARGET: 173.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8972 | Fold Accuracies: [np.float64(0.8670520231213873), np.float64(0.8465909090909091), np.float64(0.8258064516129032), np.float64(0.8679245283018868), np.float64(0.8670886075949367), np.float64(0.9047619047619048), np.float64(0.9141104294478528)]\n",
            "ID_TARGET: 33.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.8716 | Fold Accuracies: [np.float64(0.8285714285714286), np.float64(0.7965116279069767), np.float64(0.8372093023255814), np.float64(0.7602339181286549), np.float64(0.8441558441558441), np.float64(0.7515151515151515), np.float64(0.8311688311688312)]\n",
            "ID_TARGET: 69.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8123 | Fold Accuracies: [np.float64(0.7160493827160493), np.float64(0.6754966887417219), np.float64(0.75), np.float64(0.704225352112676), np.float64(0.8), np.float64(0.7341772151898734), np.float64(0.8136645962732919)]\n",
            "ID_TARGET: 17.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.8387 | Fold Accuracies: [np.float64(0.7797619047619048), np.float64(0.7727272727272727), np.float64(0.74375), np.float64(0.8322981366459627), np.float64(0.7454545454545455), np.float64(0.8248587570621468), np.float64(0.7668711656441718)]\n",
            "ID_TARGET: 189.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9404 | Fold Accuracies: [np.float64(0.832258064516129), np.float64(0.8834355828220859), np.float64(0.8543046357615894), np.float64(0.8857142857142857), np.float64(0.8311688311688312), np.float64(0.8506493506493507), np.float64(0.86)]\n",
            "ID_TARGET: 284.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.7641 | Fold Accuracies: [np.float64(0.754601226993865), np.float64(0.7468354430379747), np.float64(0.632183908045977), np.float64(0.7861635220125787), np.float64(0.7965116279069767), np.float64(0.7294117647058823), np.float64(0.7650602409638554)]\n",
            "ID_TARGET: 218.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8287 | Fold Accuracies: [np.float64(0.7090909090909091), np.float64(0.78125), np.float64(0.7759562841530054), np.float64(0.7621621621621621), np.float64(0.7484662576687117), np.float64(0.7192982456140351), np.float64(0.8208092485549133)]\n",
            "ID_TARGET: 183.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.8534 | Fold Accuracies: [np.float64(0.8402366863905325), np.float64(0.8211920529801324), np.float64(0.803921568627451), np.float64(0.8148148148148148), np.float64(0.7803468208092486), np.float64(0.8021978021978022), np.float64(0.8322981366459627)]\n",
            "ID_TARGET: 206.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.8226 | Fold Accuracies: [np.float64(0.7972027972027972), np.float64(0.8224852071005917), np.float64(0.8198757763975155), np.float64(0.7790055248618785), np.float64(0.7456647398843931), np.float64(0.7911392405063291), np.float64(0.7516339869281046)]\n",
            "ID_TARGET: 93.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8441 | Fold Accuracies: [np.float64(0.7309941520467836), np.float64(0.7810650887573964), np.float64(0.825503355704698), np.float64(0.7678571428571429), np.float64(0.75), np.float64(0.8136645962732919), np.float64(0.8571428571428571)]\n",
            "ID_TARGET: 16.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8108 | Fold Accuracies: [np.float64(0.8128654970760234), np.float64(0.7687074829931972), np.float64(0.8034682080924855), np.float64(0.6708074534161491), np.float64(0.8132530120481928), np.float64(0.7444444444444445), np.float64(0.74)]\n",
            "ID_TARGET: 246.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.8273 | Fold Accuracies: [np.float64(0.8323353293413174), np.float64(0.8285714285714286), np.float64(0.838150289017341), np.float64(0.8375), np.float64(0.6829268292682927), np.float64(0.7777777777777778), np.float64(0.7848837209302325)]\n",
            "ID_TARGET: 167.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8648 | Fold Accuracies: [np.float64(0.8502994011976048), np.float64(0.7784810126582279), np.float64(0.8551724137931035), np.float64(0.8625), np.float64(0.8243243243243243), np.float64(0.7655172413793103), np.float64(0.7634408602150538)]\n",
            "ID_TARGET: 1.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8430 | Fold Accuracies: [np.float64(0.7448275862068966), np.float64(0.8533333333333334), np.float64(0.7639751552795031), np.float64(0.8089171974522293), np.float64(0.7482993197278912), np.float64(0.8235294117647058), np.float64(0.8050314465408805)]\n",
            "ID_TARGET: 289.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8411 | Fold Accuracies: [np.float64(0.8224852071005917), np.float64(0.75), np.float64(0.8439306358381503), np.float64(0.7231638418079096), np.float64(0.7785234899328859), np.float64(0.7560975609756098), np.float64(0.8536585365853658)]\n",
            "ID_TARGET: 141.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8557 | Fold Accuracies: [np.float64(0.8228571428571428), np.float64(0.8835616438356164), np.float64(0.779874213836478), np.float64(0.7583892617449665), np.float64(0.7790697674418605), np.float64(0.8896103896103896), np.float64(0.8431372549019608)]\n",
            "ID_TARGET: 109.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.8099 | Fold Accuracies: [np.float64(0.7228915662650602), np.float64(0.7751479289940828), np.float64(0.8023952095808383), np.float64(0.7222222222222222), np.float64(0.7337662337662337), np.float64(0.7751479289940828), np.float64(0.7263157894736842)]\n",
            "ID_TARGET: 19.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8404 | Fold Accuracies: [np.float64(0.7037037037037037), np.float64(0.7821229050279329), np.float64(0.7607361963190185), np.float64(0.7897727272727273), np.float64(0.7866666666666666), np.float64(0.7710843373493976), np.float64(0.813953488372093)]\n",
            "ID_TARGET: 28.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.8079 | Fold Accuracies: [np.float64(0.7317073170731707), np.float64(0.740506329113924), np.float64(0.732484076433121), np.float64(0.7654320987654321), np.float64(0.8083832335329342), np.float64(0.8012048192771084), np.float64(0.7407407407407407)]\n",
            "ID_TARGET: 251.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8268 | Fold Accuracies: [np.float64(0.7607361963190185), np.float64(0.7831325301204819), np.float64(0.8198757763975155), np.float64(0.8181818181818182), np.float64(0.7672955974842768), np.float64(0.7396449704142012), np.float64(0.7810650887573964)]\n",
            "ID_TARGET: 278.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8963 | Fold Accuracies: [np.float64(0.803921568627451), np.float64(0.8493975903614458), np.float64(0.8251748251748252), np.float64(0.8589743589743589), np.float64(0.7843137254901961), np.float64(0.8313253012048193), np.float64(0.831081081081081)]\n",
            "ID_TARGET: 76.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8092 | Fold Accuracies: [np.float64(0.75), np.float64(0.7309941520467836), np.float64(0.7579617834394905), np.float64(0.7722222222222223), np.float64(0.7640449438202247), np.float64(0.79375), np.float64(0.8322981366459627)]\n",
            "ID_TARGET: 241.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.8709 | Fold Accuracies: [np.float64(0.8308823529411765), np.float64(0.8343949044585988), np.float64(0.8193548387096774), np.float64(0.8258064516129032), np.float64(0.832258064516129), np.float64(0.8322981366459627), np.float64(0.8482758620689655)]\n",
            "ID_TARGET: 214.0 | Best Params: {'bagging_fraction': 0.65, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 12, 'num_leaves': 63, 'reg_alpha': 0.3, 'reg_lambda': 0.2} | Mean Accuracy: 0.8745 | Fold Accuracies: [np.float64(0.8622754491017964), np.float64(0.8963414634146342), np.float64(0.8980891719745223), np.float64(0.8765432098765432), np.float64(0.8488372093023255), np.float64(0.8511904761904762), np.float64(0.8409090909090909)]\n",
            "ID_TARGET: 102.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8850 | Fold Accuracies: [np.float64(0.8726114649681529), np.float64(0.810126582278481), np.float64(0.8125), np.float64(0.8709677419354839), np.float64(0.869281045751634), np.float64(0.8148148148148148), np.float64(0.8461538461538461)]\n",
            "ID_TARGET: 145.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 10, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9518 | Fold Accuracies: [np.float64(0.8630952380952381), np.float64(0.9013157894736842), np.float64(0.8273809523809523), np.float64(0.8553459119496856), np.float64(0.8607594936708861), np.float64(0.8805031446540881), np.float64(0.8076923076923077)]\n",
            "ID_TARGET: 155.0 | Best Params: {'bagging_fraction': 0.7, 'colsample_bytree': 0.6, 'learning_rate': 0.003, 'min_child_samples': 15, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8656 | Fold Accuracies: [np.float64(0.8524590163934426), np.float64(0.7721518987341772), np.float64(0.867816091954023), np.float64(0.8166666666666667), np.float64(0.8333333333333334), np.float64(0.8181818181818182), np.float64(0.8280254777070064)]\n",
            "ID_TARGET: nan | Best Params: {} | Mean Accuracy: 0.0000 | Fold Accuracies: []\n",
            "\n",
            "Training XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "XGBoost Targets: 100%|| 101/101 [2:02:18<00:00, 72.66s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Weighted Accuracy: 0.9945\n",
            "\n",
            "XGBoost Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.003, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 129.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8125), np.float64(0.7407407407407407), np.float64(0.6792452830188679), np.float64(1.0), np.float64(0.8333333333333334), np.float64(1.0), np.float64(0.7329545454545454)]\n",
            "ID_TARGET: 136.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(0.7151898734177216), np.float64(0.6857142857142857), np.float64(0.6875), np.float64(0.7633136094674556), np.float64(0.6149425287356322), np.float64(0.6987179487179487)]\n",
            "ID_TARGET: 161.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(0.6285714285714286), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.6464088397790055), np.float64(0.6158536585365854)]\n",
            "ID_TARGET: 217.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.003, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 91.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8385093167701864), np.float64(0.8176470588235294), np.float64(0.7928994082840237), np.float64(1.0), np.float64(0.7861635220125787), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 137.0 | Best Params: {'gamma': 0.2, 'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 8.0 | Best Params: {'gamma': 0.2, 'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 3.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.003, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.8733 | Fold Accuracies: [np.float64(0.684931506849315), np.float64(0.65625), np.float64(0.7672955974842768), np.float64(0.6123595505617978), np.float64(0.6225165562913907), np.float64(0.6622516556291391), np.float64(0.6878980891719745)]\n",
            "ID_TARGET: 9.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.003, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 131.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.003, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.8550 | Fold Accuracies: [np.float64(0.6914285714285714), np.float64(0.7468354430379747), np.float64(0.7440476190476191), np.float64(0.6875), np.float64(0.7770700636942676), np.float64(0.8055555555555556), np.float64(0.740506329113924)]\n",
            "ID_TARGET: 21.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7005988023952096), np.float64(0.7116564417177914), np.float64(0.7852760736196319), np.float64(0.6436781609195402), np.float64(0.8118279569892473), np.float64(0.7215909090909091), np.float64(0.7352941176470589)]\n",
            "ID_TARGET: 54.0 | Best Params: {'gamma': 0.2, 'learning_rate': 0.003, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(0.9428571428571428), np.float64(0.7784431137724551), np.float64(0.8848484848484849), np.float64(0.9456521739130435), np.float64(0.8238993710691824)]\n",
            "ID_TARGET: 130.0 | Best Params: {'gamma': 0.2, 'learning_rate': 0.003, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.65} | Mean Accuracy: 0.9740 | Fold Accuracies: [np.float64(0.8404255319148937), np.float64(0.89937106918239), np.float64(0.88), np.float64(0.8579881656804734), np.float64(0.7928994082840237), np.float64(0.8571428571428571), np.float64(0.8439306358381503)]\n",
            "ID_TARGET: 269.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.005, 'max_depth': 7, 'min_child_weight': 5, 'n_estimators': 300, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.75} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.676056338028169), np.float64(0.6516129032258065), np.float64(0.6428571428571429), np.float64(0.6346153846153846), np.float64(0.6601307189542484), np.float64(0.6470588235294118), np.float64(0.6423841059602649)]\n",
            "ID_TARGET: 157.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.003, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.8281 | Fold Accuracies: [np.float64(0.7548387096774194), np.float64(0.8082191780821918), np.float64(0.8742138364779874), np.float64(0.8410596026490066), np.float64(0.7834394904458599), np.float64(0.7662337662337663), np.float64(0.7514450867052023)]\n",
            "ID_TARGET: 249.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.003, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.9155 | Fold Accuracies: [np.float64(0.7225433526011561), np.float64(0.6783625730994152), np.float64(0.6794871794871795), np.float64(0.7041420118343196), np.float64(0.6827586206896552), np.float64(0.7950310559006211), np.float64(0.8012422360248447)]\n",
            "ID_TARGET: 22.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7650602409638554), np.float64(0.7087912087912088), np.float64(0.76), np.float64(0.7951807228915663), np.float64(0.6130952380952381), np.float64(0.592814371257485), np.float64(0.7643312101910829)]\n",
            "ID_TARGET: 202.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(0.7953216374269005), np.float64(1.0), np.float64(0.8235294117647058), np.float64(1.0), np.float64(0.6850828729281768)]\n",
            "ID_TARGET: 132.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7439024390243902), np.float64(0.7635135135135135), np.float64(0.7843137254901961), np.float64(0.7515527950310559), np.float64(0.7018633540372671), np.float64(0.7354838709677419), np.float64(0.6951219512195121)]\n",
            "ID_TARGET: 96.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.003, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 7.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(0.8295454545454546), np.float64(1.0), np.float64(0.8432432432432433), np.float64(1.0), np.float64(0.8212290502793296)]\n",
            "ID_TARGET: 178.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.686046511627907), np.float64(0.6582278481012658), np.float64(0.610062893081761), np.float64(0.6411764705882353), np.float64(0.6785714285714286), np.float64(0.68125), np.float64(0.738255033557047)]\n",
            "ID_TARGET: 68.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7108433734939759), np.float64(0.7391304347826086), np.float64(0.740506329113924), np.float64(0.7468354430379747), np.float64(0.7567567567567568), np.float64(0.7639751552795031), np.float64(0.7236842105263158)]\n",
            "ID_TARGET: 44.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8284023668639053), np.float64(0.8481012658227848), np.float64(0.8164556962025317), np.float64(0.8363636363636363), np.float64(0.7861271676300579), np.float64(0.7904191616766467), np.float64(0.7724550898203593)]\n",
            "ID_TARGET: 196.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.003, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 292.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.9047619047619048), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.896969696969697), np.float64(1.0)]\n",
            "ID_TARGET: 239.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7345679012345679), np.float64(0.7169811320754716), np.float64(0.68125), np.float64(0.7054794520547946), np.float64(0.7454545454545455), np.float64(0.7018633540372671), np.float64(0.7364864864864865)]\n",
            "ID_TARGET: 279.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 38.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 209.0 | Best Params: {'gamma': 0.1, 'learning_rate': 0.005, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 150, 'reg_alpha': 0.5, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 207.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7884615384615384), np.float64(0.740506329113924), np.float64(0.7183908045977011), np.float64(0.7973856209150327), np.float64(0.7592592592592593), np.float64(0.6775956284153005), np.float64(0.6954022988505747)]\n",
            "ID_TARGET: 98.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7375), np.float64(0.7911392405063291), np.float64(0.7948717948717948), np.float64(0.7547169811320755), np.float64(0.6728395061728395), np.float64(1.0), np.float64(0.8)]\n",
            "ID_TARGET: 65.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7602339181286549), np.float64(0.832258064516129), np.float64(1.0), np.float64(0.9113924050632911), np.float64(1.0), np.float64(0.6516129032258065), np.float64(0.7290322580645161)]\n",
            "ID_TARGET: 51.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6987179487179487), np.float64(0.7333333333333333), np.float64(0.6447368421052632), np.float64(0.7197452229299363), np.float64(0.6645161290322581), np.float64(0.6666666666666666), np.float64(0.6710526315789473)]\n",
            "ID_TARGET: 78.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.9241379310344827), np.float64(0.8136645962732919), np.float64(0.8027210884353742), np.float64(0.8395061728395061), np.float64(0.7651006711409396), np.float64(0.8789808917197452), np.float64(0.7791411042944786)]\n",
            "ID_TARGET: 177.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7515151515151515), np.float64(0.7151898734177216), np.float64(0.8378378378378378), np.float64(0.7362637362637363), np.float64(0.6717948717948717), np.float64(0.7455621301775148), np.float64(0.7445652173913043)]\n",
            "ID_TARGET: 231.0 | Best Params: {'gamma': 0.2, 'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 119.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8278145695364238), np.float64(0.7911392405063291), np.float64(0.779874213836478), np.float64(0.7484276729559748), np.float64(0.8098159509202454), np.float64(0.7515923566878981), np.float64(0.8022598870056498)]\n",
            "ID_TARGET: 158.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7619047619047619), np.float64(0.7857142857142857), np.float64(0.7071823204419889), np.float64(0.7986577181208053), np.float64(0.8484848484848485), np.float64(0.7549668874172185), np.float64(0.7821229050279329)]\n",
            "ID_TARGET: 80.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6622516556291391), np.float64(0.6751592356687898), np.float64(0.69375), np.float64(0.6646341463414634), np.float64(0.7012195121951219), np.float64(0.72), np.float64(0.6994219653179191)]\n",
            "ID_TARGET: 25.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7225433526011561), np.float64(0.6772151898734177), np.float64(0.7133757961783439), np.float64(0.7272727272727273), np.float64(0.718562874251497), np.float64(0.7125), np.float64(0.78125)]\n",
            "ID_TARGET: 175.0 | Best Params: {'gamma': 0.2, 'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 151.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8), np.float64(0.8074534161490683), np.float64(0.8129032258064516), np.float64(0.8024691358024691), np.float64(0.7142857142857143), np.float64(0.7987421383647799), np.float64(0.8562091503267973)]\n",
            "ID_TARGET: 257.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6989247311827957), np.float64(0.8125), np.float64(0.8982035928143712), np.float64(0.7555555555555555), np.float64(0.8430232558139535), np.float64(0.6971428571428572), np.float64(0.6234567901234568)]\n",
            "ID_TARGET: 75.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8926553672316384), np.float64(0.8633540372670807), np.float64(0.8470588235294118), np.float64(0.8597560975609756), np.float64(0.8490566037735849), np.float64(0.8457142857142858), np.float64(0.8869047619047619)]\n",
            "ID_TARGET: 244.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(0.6590909090909091), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.703030303030303), np.float64(0.7719298245614035)]\n",
            "ID_TARGET: 149.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6962025316455697), np.float64(0.7168674698795181), np.float64(0.8496732026143791), np.float64(0.6470588235294118), np.float64(0.6385542168674698), np.float64(0.6139240506329114), np.float64(0.6966292134831461)]\n",
            "ID_TARGET: 85.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8975903614457831), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 190.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6855345911949685), np.float64(0.6842105263157895), np.float64(0.751412429378531), np.float64(0.7239263803680982), np.float64(0.7368421052631579), np.float64(0.7151162790697675), np.float64(0.7951807228915663)]\n",
            "ID_TARGET: 13.0 | Best Params: {'gamma': 0.2, 'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 228.0 | Best Params: {'gamma': 0.2, 'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 144.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7409638554216867), np.float64(0.7254901960784313), np.float64(0.8263888888888888), np.float64(0.6903225806451613), np.float64(0.7588235294117647), np.float64(0.7898089171974523), np.float64(0.7674418604651163)]\n",
            "ID_TARGET: 290.0 | Best Params: {'gamma': 0.2, 'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 114.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6904761904761905), np.float64(0.6792452830188679), np.float64(0.6848484848484848), np.float64(0.7018633540372671), np.float64(0.7901234567901234), np.float64(0.6628571428571428), np.float64(0.672316384180791)]\n",
            "ID_TARGET: 166.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7235294117647059), np.float64(0.6987951807228916), np.float64(0.7942857142857143), np.float64(0.7621951219512195), np.float64(0.696551724137931), np.float64(0.6753246753246753), np.float64(0.75)]\n",
            "ID_TARGET: 234.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7341772151898734), np.float64(0.8129032258064516), np.float64(0.8944099378881988), np.float64(0.7371794871794872), np.float64(0.8238993710691824), np.float64(0.8231292517006803), np.float64(0.8051948051948052)]\n",
            "ID_TARGET: 34.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7586206896551724), np.float64(0.7975460122699386), np.float64(0.8227848101265823), np.float64(0.8064516129032258), np.float64(0.8275862068965517), np.float64(0.8235294117647058), np.float64(0.8104575163398693)]\n",
            "ID_TARGET: 154.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7808988764044944), np.float64(0.7828947368421053), np.float64(0.7058823529411765), np.float64(0.7976190476190477), np.float64(0.7894736842105263), np.float64(0.8363636363636363), np.float64(0.7932960893854749)]\n",
            "ID_TARGET: 225.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8258064516129032), np.float64(0.7666666666666667), np.float64(0.7616580310880829), np.float64(0.7222222222222222), np.float64(0.7586206896551724), np.float64(0.7245508982035929), np.float64(0.8045977011494253)]\n",
            "ID_TARGET: 185.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7320261437908496), np.float64(0.738255033557047), np.float64(0.7232704402515723), np.float64(0.6993006993006993), np.float64(0.6866666666666666), np.float64(0.6923076923076923), np.float64(0.7553956834532374)]\n",
            "ID_TARGET: 39.0 | Best Params: {'gamma': 0.2, 'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 272.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 282.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.759493670886076), np.float64(0.6988636363636364), np.float64(0.759493670886076), np.float64(0.7272727272727273), np.float64(0.7076023391812866), np.float64(0.6666666666666666), np.float64(0.7581699346405228)]\n",
            "ID_TARGET: 90.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7914110429447853), np.float64(0.7613636363636364), np.float64(0.7843137254901961), np.float64(0.7975460122699386), np.float64(0.7483443708609272), np.float64(0.8106508875739645), np.float64(0.7924528301886793)]\n",
            "ID_TARGET: 52.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6535947712418301), np.float64(0.6419753086419753), np.float64(0.6626506024096386), np.float64(0.7375), np.float64(0.7267441860465116), np.float64(0.7569444444444444), np.float64(0.6582278481012658)]\n",
            "ID_TARGET: 258.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6423841059602649), np.float64(0.7071428571428572), np.float64(0.6966292134831461), np.float64(0.6706586826347305), np.float64(0.676829268292683), np.float64(0.7450980392156863), np.float64(0.6912751677852349)]\n",
            "ID_TARGET: 291.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6158940397350994), np.float64(0.7705882352941177), np.float64(0.7212121212121212), np.float64(0.7), np.float64(0.7267441860465116), np.float64(0.7052023121387283), np.float64(0.8157894736842105)]\n",
            "ID_TARGET: 152.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7383720930232558), np.float64(0.8175675675675675), np.float64(0.7070063694267515), np.float64(0.689873417721519), np.float64(0.8324022346368715), np.float64(0.759493670886076), np.float64(0.6941176470588235)]\n",
            "ID_TARGET: 133.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.76875), np.float64(0.8106508875739645), np.float64(0.7964071856287425), np.float64(0.7325581395348837), np.float64(0.725609756097561), np.float64(0.7898089171974523), np.float64(0.7341040462427746)]\n",
            "ID_TARGET: 29.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7692307692307693), np.float64(0.7865853658536586), np.float64(0.7651006711409396), np.float64(0.7133757961783439), np.float64(0.7687861271676301), np.float64(0.8148148148148148), np.float64(0.8072289156626506)]\n",
            "ID_TARGET: 274.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.9005847953216374), np.float64(0.8554216867469879), np.float64(0.8360655737704918), np.float64(0.8263473053892215), np.float64(0.8235294117647058), np.float64(0.8757396449704142), np.float64(0.8216216216216217)]\n",
            "ID_TARGET: 106.0 | Best Params: {'gamma': 0.2, 'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 173.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.791907514450867), np.float64(0.7386363636363636), np.float64(0.7096774193548387), np.float64(0.7484276729559748), np.float64(0.7721518987341772), np.float64(0.8214285714285714), np.float64(0.7730061349693251)]\n",
            "ID_TARGET: 33.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8457142857142858), np.float64(0.7790697674418605), np.float64(0.8372093023255814), np.float64(0.7309941520467836), np.float64(0.8701298701298701), np.float64(0.8303030303030303), np.float64(0.8636363636363636)]\n",
            "ID_TARGET: 69.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7469135802469136), np.float64(0.7218543046357616), np.float64(0.7625), np.float64(0.7746478873239436), np.float64(0.7724137931034483), np.float64(0.7911392405063291), np.float64(0.8260869565217391)]\n",
            "ID_TARGET: 17.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7321428571428571), np.float64(0.6647727272727273), np.float64(0.7125), np.float64(0.7950310559006211), np.float64(0.6848484848484848), np.float64(0.7570621468926554), np.float64(0.7177914110429447)]\n",
            "ID_TARGET: 189.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(0.8588957055214724), np.float64(0.7417218543046358), np.float64(0.8), np.float64(0.7402597402597403), np.float64(0.7142857142857143), np.float64(0.76)]\n",
            "ID_TARGET: 284.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7423312883435583), np.float64(0.7151898734177216), np.float64(0.6149425287356322), np.float64(0.7484276729559748), np.float64(0.7674418604651163), np.float64(0.711764705882353), np.float64(0.7228915662650602)]\n",
            "ID_TARGET: 218.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7333333333333333), np.float64(0.8125), np.float64(0.7377049180327869), np.float64(0.7297297297297297), np.float64(0.803680981595092), np.float64(0.672514619883041), np.float64(0.8786127167630058)]\n",
            "ID_TARGET: 183.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8284023668639053), np.float64(0.8079470198675497), np.float64(0.7647058823529411), np.float64(0.7839506172839507), np.float64(0.7687861271676301), np.float64(0.7802197802197802), np.float64(0.782608695652174)]\n",
            "ID_TARGET: 206.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7552447552447552), np.float64(0.757396449704142), np.float64(0.7018633540372671), np.float64(0.7182320441988951), np.float64(0.7052023121387283), np.float64(0.7278481012658228), np.float64(0.6928104575163399)]\n",
            "ID_TARGET: 93.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6491228070175439), np.float64(0.6390532544378699), np.float64(0.6912751677852349), np.float64(0.6130952380952381), np.float64(0.625), np.float64(0.7453416149068323), np.float64(0.7482993197278912)]\n",
            "ID_TARGET: 16.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7953216374269005), np.float64(0.7482993197278912), np.float64(0.6820809248554913), np.float64(0.577639751552795), np.float64(0.7048192771084337), np.float64(0.6333333333333333), np.float64(0.6466666666666666)]\n",
            "ID_TARGET: 246.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7305389221556886), np.float64(0.7942857142857143), np.float64(0.7976878612716763), np.float64(0.76875), np.float64(0.6585365853658537), np.float64(0.7469135802469136), np.float64(0.7558139534883721)]\n",
            "ID_TARGET: 167.0 | Best Params: {'gamma': 0.2, 'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 1.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7655172413793103), np.float64(0.8533333333333334), np.float64(0.7763975155279503), np.float64(0.802547770700637), np.float64(0.7551020408163265), np.float64(0.7712418300653595), np.float64(0.8176100628930818)]\n",
            "ID_TARGET: 289.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8106508875739645), np.float64(0.7439024390243902), np.float64(0.815028901734104), np.float64(0.7062146892655368), np.float64(0.7919463087248322), np.float64(0.7012195121951219), np.float64(0.7987804878048781)]\n",
            "ID_TARGET: 141.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8171428571428572), np.float64(0.8424657534246576), np.float64(0.7924528301886793), np.float64(0.7919463087248322), np.float64(0.7906976744186046), np.float64(0.9155844155844156), np.float64(0.8496732026143791)]\n",
            "ID_TARGET: 109.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6746987951807228), np.float64(0.7692307692307693), np.float64(0.8682634730538922), np.float64(0.7277777777777777), np.float64(0.8181818181818182), np.float64(0.8165680473372781), np.float64(0.7105263157894737)]\n",
            "ID_TARGET: 19.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7530864197530864), np.float64(0.8044692737430168), np.float64(0.7730061349693251), np.float64(0.8579545454545454), np.float64(0.84), np.float64(0.8253012048192772), np.float64(0.8546511627906976)]\n",
            "ID_TARGET: 28.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6829268292682927), np.float64(0.6265822784810127), np.float64(0.6878980891719745), np.float64(0.7716049382716049), np.float64(0.718562874251497), np.float64(0.7469879518072289), np.float64(0.7160493827160493)]\n",
            "ID_TARGET: 251.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6441717791411042), np.float64(0.8012048192771084), np.float64(0.6832298136645962), np.float64(0.8311688311688312), np.float64(0.7484276729559748), np.float64(0.6804733727810651), np.float64(0.7100591715976331)]\n",
            "ID_TARGET: 278.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6928104575163399), np.float64(0.7650602409638554), np.float64(0.6993006993006993), np.float64(0.7564102564102564), np.float64(0.6862745098039216), np.float64(0.6626506024096386), np.float64(0.7297297297297297)]\n",
            "ID_TARGET: 76.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6976744186046512), np.float64(1.0), np.float64(1.0), np.float64(0.7777777777777778), np.float64(0.7303370786516854), np.float64(0.8625), np.float64(0.9440993788819876)]\n",
            "ID_TARGET: 241.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7867647058823529), np.float64(0.8280254777070064), np.float64(0.7096774193548387), np.float64(0.6903225806451613), np.float64(0.7032258064516129), np.float64(0.6583850931677019), np.float64(0.7172413793103448)]\n",
            "ID_TARGET: 214.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7125748502994012), np.float64(0.7560975609756098), np.float64(0.821656050955414), np.float64(0.7592592592592593), np.float64(0.7616279069767442), np.float64(0.6726190476190477), np.float64(0.7045454545454546)]\n",
            "ID_TARGET: 102.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.821656050955414), np.float64(0.740506329113924), np.float64(0.8), np.float64(0.832258064516129), np.float64(0.8235294117647058), np.float64(0.6666666666666666), np.float64(0.8041958041958042)]\n",
            "ID_TARGET: 145.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8809523809523809), np.float64(1.0), np.float64(0.7738095238095238), np.float64(0.8364779874213837), np.float64(0.8037974683544303), np.float64(0.7987421383647799), np.float64(0.7472527472527473)]\n",
            "ID_TARGET: 155.0 | Best Params: {'gamma': 0.0, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8524590163934426), np.float64(0.7468354430379747), np.float64(0.8735632183908046), np.float64(0.8111111111111111), np.float64(0.8703703703703703), np.float64(0.875), np.float64(0.8535031847133758)]\n",
            "ID_TARGET: nan | Best Params: {} | Mean Accuracy: 0.0000 | Fold Accuracies: []\n",
            "\n",
            "Performing second-pass training with top 30 features...\n",
            "\n",
            "Second-pass LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rLightGBM Targets:   0%|          | 0/101 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   1%|          | 1/101 [00:01<02:48,  1.68s/it]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   2%|         | 2/101 [00:02<02:09,  1.31s/it]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   3%|         | 3/101 [00:03<01:56,  1.18s/it]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   4%|         | 4/101 [00:04<01:54,  1.18s/it]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   5%|         | 5/101 [00:05<01:34,  1.02it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   6%|         | 6/101 [00:06<01:21,  1.17it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   7%|         | 7/101 [00:06<01:12,  1.30it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   8%|         | 8/101 [00:07<01:09,  1.33it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   9%|         | 9/101 [00:08<01:08,  1.34it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  10%|         | 10/101 [00:08<01:04,  1.42it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  11%|         | 11/101 [00:09<01:07,  1.33it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  12%|        | 12/101 [00:10<01:05,  1.37it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  13%|        | 13/101 [00:11<01:09,  1.27it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  14%|        | 14/101 [00:12<01:11,  1.21it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  15%|        | 15/101 [00:12<01:07,  1.27it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  16%|        | 16/101 [00:13<01:08,  1.24it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  17%|        | 17/101 [00:14<01:09,  1.21it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  18%|        | 18/101 [00:15<01:11,  1.17it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  19%|        | 19/101 [00:16<01:13,  1.11it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  20%|        | 20/101 [00:17<01:15,  1.08it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  21%|        | 21/101 [00:18<01:13,  1.09it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  22%|       | 22/101 [00:19<01:06,  1.18it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  23%|       | 23/101 [00:19<01:01,  1.28it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  24%|       | 24/101 [00:20<00:58,  1.32it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  25%|       | 25/101 [00:21<00:55,  1.37it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  26%|       | 26/101 [00:21<00:53,  1.39it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  27%|       | 27/101 [00:22<00:52,  1.40it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  28%|       | 28/101 [00:23<00:49,  1.48it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  29%|       | 29/101 [00:23<00:48,  1.48it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  30%|       | 30/101 [00:24<00:47,  1.48it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  31%|       | 31/101 [00:25<00:45,  1.55it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  32%|      | 32/101 [00:25<00:44,  1.55it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  33%|      | 33/101 [00:26<00:42,  1.58it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  34%|      | 34/101 [00:26<00:41,  1.60it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  35%|      | 35/101 [00:27<00:41,  1.58it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  36%|      | 36/101 [00:28<00:41,  1.56it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  37%|      | 37/101 [00:29<00:47,  1.35it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  38%|      | 38/101 [00:30<00:48,  1.29it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  39%|      | 39/101 [00:31<00:55,  1.13it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  40%|      | 40/101 [00:32<00:53,  1.14it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  41%|      | 41/101 [00:32<00:49,  1.21it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  42%|     | 42/101 [00:33<00:45,  1.30it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  43%|     | 43/101 [00:34<00:42,  1.38it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  44%|     | 44/101 [00:34<00:39,  1.44it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  45%|     | 45/101 [00:35<00:38,  1.46it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  46%|     | 46/101 [00:35<00:37,  1.48it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  47%|     | 47/101 [00:36<00:36,  1.47it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  48%|     | 48/101 [00:37<00:35,  1.49it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  49%|     | 49/101 [00:37<00:33,  1.54it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  50%|     | 50/101 [00:38<00:34,  1.49it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  50%|     | 51/101 [00:39<00:32,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  51%|    | 52/101 [00:39<00:31,  1.54it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  52%|    | 53/101 [00:40<00:30,  1.56it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  53%|    | 54/101 [00:41<00:30,  1.54it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  54%|    | 55/101 [00:41<00:30,  1.50it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  55%|    | 56/101 [00:42<00:33,  1.33it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  56%|    | 57/101 [00:43<00:35,  1.26it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  57%|    | 58/101 [00:44<00:36,  1.18it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  58%|    | 59/101 [00:45<00:34,  1.23it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  59%|    | 60/101 [00:46<00:32,  1.28it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  60%|    | 61/101 [00:46<00:29,  1.36it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  61%|   | 62/101 [00:47<00:27,  1.43it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  62%|   | 63/101 [00:47<00:25,  1.51it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  63%|   | 64/101 [00:48<00:24,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  64%|   | 65/101 [00:49<00:23,  1.51it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  65%|   | 66/101 [00:49<00:22,  1.55it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  66%|   | 67/101 [00:50<00:22,  1.54it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  67%|   | 68/101 [00:51<00:21,  1.55it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  68%|   | 69/101 [00:51<00:20,  1.57it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  69%|   | 70/101 [00:52<00:19,  1.60it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  70%|   | 71/101 [00:53<00:18,  1.59it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  71%|  | 72/101 [00:53<00:18,  1.59it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  72%|  | 73/101 [00:54<00:17,  1.63it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  73%|  | 74/101 [00:54<00:16,  1.63it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  74%|  | 75/101 [00:55<00:18,  1.41it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  75%|  | 76/101 [00:56<00:19,  1.29it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  76%|  | 77/101 [00:57<00:20,  1.15it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  77%|  | 78/101 [00:58<00:19,  1.15it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  78%|  | 79/101 [00:59<00:17,  1.23it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  79%|  | 80/101 [01:00<00:16,  1.28it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  80%|  | 81/101 [01:00<00:15,  1.33it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  81%|  | 82/101 [01:01<00:13,  1.36it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  82%| | 83/101 [01:02<00:12,  1.44it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  83%| | 84/101 [01:02<00:11,  1.43it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  84%| | 85/101 [01:03<00:11,  1.45it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  85%| | 86/101 [01:04<00:10,  1.50it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  86%| | 87/101 [01:04<00:09,  1.47it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  87%| | 88/101 [01:05<00:08,  1.51it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  88%| | 89/101 [01:05<00:07,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  89%| | 90/101 [01:06<00:07,  1.51it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  90%| | 91/101 [01:07<00:06,  1.55it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  91%| | 92/101 [01:07<00:06,  1.49it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  92%|| 93/101 [01:08<00:05,  1.43it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  93%|| 94/101 [01:09<00:05,  1.31it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  94%|| 95/101 [01:10<00:05,  1.20it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  95%|| 96/101 [01:11<00:04,  1.15it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  96%|| 97/101 [01:12<00:03,  1.22it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  97%|| 98/101 [01:12<00:02,  1.33it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  98%|| 99/101 [01:13<00:01,  1.38it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets: 100%|| 101/101 [01:14<00:00,  1.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: No features for ID_TARGET nan. Skipping.\n",
            "\n",
            "Second-pass XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Targets: 100%|| 101/101 [01:19<00:00,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: No features for ID_TARGET nan. Skipping.\n",
            "\n",
            "Performing third-pass training for low-performing targets...\n",
            "\n",
            "Third-pass LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "LightGBM Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 58848.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Third-pass XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 59532.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Performing fourth-pass training for very low-performing targets...\n",
            "\n",
            "Fourth-pass LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "LightGBM Very Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 54990.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fourth-pass XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Very Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 123032.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved hyperparameter log to: /content/hyperparameters.json\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_89b85e46-d089-42cb-aa2e-08513815dd96\", \"hyperparameters.json\", 3059066)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved predictions to: /content/predictions_ensemble.csv\n",
            "Output CSV shape: (114468, 2)\n",
            "Output CSV ID range: 0 to 114467\n",
            "Unique RET_TARGET values: [ 1 -1]\n",
            "Missing values: 0\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_a05e4ca5-d7ad-4923-887e-7fa7962c3fb6\", \"predictions_ensemble.csv\", 958135)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Results:\n",
            "LightGBM: 0.8597\n",
            "XGBoost: 0.9945\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost\n",
        "from sklearn.decomposition import PCA\n",
        "from joblib import Parallel, delayed\n",
        "import json\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# Check xgboost version for compatibility\n",
        "print(f\"XGBoost version: {xgboost.__version__}\")\n",
        "if int(xgboost.__version__.split('.')[0]) < 1:\n",
        "    print(\"Warning: XGBoost version < 1.0.0 detected. Ensure compatibility with eval_metric in constructor.\")\n",
        "\n",
        "# Set up data directory\n",
        "DATA_DIR = '/content'\n",
        "\n",
        "# Load datasets\n",
        "try:\n",
        "    X_train = pd.read_csv(os.path.join(DATA_DIR, 'X_train_itDkypA.csv'), index_col='ID', dtype=np.float32)\n",
        "    y_train = pd.read_csv(os.path.join(DATA_DIR, 'y_train_3LeeT2g.csv'), index_col='ID', dtype=np.float32)\n",
        "    X_test = pd.read_csv(os.path.join(DATA_DIR, 'X_test_Beg4ey3.csv'), index_col='ID', dtype=np.float32)\n",
        "    supplementary = pd.read_csv(os.path.join(DATA_DIR, 'supplementary_data_Vkoyn8z.csv'))\n",
        "except FileNotFoundError as e:\n",
        "    raise FileNotFoundError(f\"Dataset not found: {e}. Please ensure files are uploaded to {DATA_DIR}.\")\n",
        "\n",
        "# Custom weighted accuracy metric\n",
        "def weighted_accuracy(y_true, y_pred, weights):\n",
        "    y_pred_mapped = np.where(y_pred == 1, 1, -1)\n",
        "    correct = (y_pred_mapped == np.sign(y_true)).astype(float)\n",
        "    return np.sum(np.abs(y_true) * correct) / np.sum(np.abs(y_true))\n",
        "\n",
        "# Preprocess data with enhanced feature selection\n",
        "def preprocess_data(X, y=None, supplementary=None, is_train=True, top_cols=None):\n",
        "    ret_cols = [col for col in X.columns if col.startswith('RET_')]\n",
        "\n",
        "    # Dynamic feature selection with minimum variance threshold\n",
        "    if is_train and top_cols is None:\n",
        "        if len(ret_cols) > 15:\n",
        "            variances = X[ret_cols].var()\n",
        "            corr_sum = X[ret_cols].corr().abs().sum()\n",
        "            combined_score = variances * corr_sum\n",
        "            valid_cols = variances[variances > 1e-5].index\n",
        "            if len(valid_cols) < 15:\n",
        "                top_cols = valid_cols.tolist()\n",
        "            else:\n",
        "                top_cols = combined_score.loc[valid_cols].sort_values(ascending=False).head(15).index.tolist()\n",
        "        else:\n",
        "            top_cols = ret_cols\n",
        "        print(f\"Selected top return columns: {top_cols}\")\n",
        "    elif top_cols is not None:\n",
        "        ret_cols = [col for col in ret_cols if col in top_cols]\n",
        "        if not ret_cols:\n",
        "            raise ValueError(\"No return columns selected. Check top_cols consistency.\")\n",
        "\n",
        "    # Cache sector-based medians\n",
        "    sector_medians = {}\n",
        "    if supplementary is not None:\n",
        "        sector_map = supplementary.set_index('ID_asset')['CLASS_LEVEL_1']\n",
        "        for col in ret_cols:\n",
        "            asset_id = int(col.replace('RET_', ''))\n",
        "            sector = sector_map.get(asset_id, np.nan)\n",
        "            if pd.notna(sector):\n",
        "                sector_assets = supplementary[supplementary['CLASS_LEVEL_1'] == sector]['ID_asset']\n",
        "                sector_cols = [f'RET_{a}' for a in sector_assets if f'RET_{a}' in X.columns]\n",
        "                if sector_cols:\n",
        "                    sector_medians[col] = X[sector_cols].median(axis=1)\n",
        "            if col in sector_medians:\n",
        "                X[col] = X[col].fillna(sector_medians[col])\n",
        "            else:\n",
        "                X[col] = X[col].fillna(X[col].median())\n",
        "\n",
        "    # Sector-based features\n",
        "    new_cols = {}\n",
        "    if supplementary is not None:\n",
        "        level = 'CLASS_LEVEL_1'\n",
        "        sector_groups = supplementary.groupby(level)['ID_asset'].apply(list).to_dict()\n",
        "        for sector, assets in sector_groups.items():\n",
        "            asset_cols = [f'RET_{asset}' for asset in assets if f'RET_{asset}' in ret_cols]\n",
        "            if asset_cols:\n",
        "                new_cols[f'SECTOR_AVG_{level}_{sector}'] = X[asset_cols].mean(axis=1).replace([np.inf, -np.inf], 0).fillna(0)\n",
        "        X = X.merge(supplementary[['ID_asset', level]].rename(columns={'ID_asset': 'ID_TARGET', level: f'TARGET_{level}'}),\n",
        "                    on='ID_TARGET', how='left')\n",
        "        X = pd.concat([X, pd.get_dummies(X[f'TARGET_{level}'], prefix=f'TARGET_{level}', dummy_na=True)], axis=1)\n",
        "        X = X.drop(f'TARGET_{level}', axis=1)\n",
        "\n",
        "    # Cross-sectional features\n",
        "    new_cols['MEAN_RET'] = X[ret_cols].mean(axis=1)\n",
        "    new_cols['STD_RET'] = X[ret_cols].std(axis=1)\n",
        "    new_cols.update({f'CS_RANK_{col}': X.groupby('ID_DAY')[col].rank(pct=True).replace([np.inf, -np.inf], 0).fillna(0) for col in ret_cols})\n",
        "\n",
        "    # Correlation-based features (top 5 pairs)\n",
        "    if is_train:\n",
        "        corr_matrix = X[ret_cols].corr()\n",
        "        corr_pairs = corr_matrix.unstack().sort_values(ascending=False)\n",
        "        top_pairs = [(i, j) for i, j in corr_pairs.index if i < j][:5]\n",
        "        for i, j in top_pairs:\n",
        "            new_cols[f'CORR_{i}_{j}'] = X[i] * X[j]\n",
        "\n",
        "    # PCA features (2 components)\n",
        "    if ret_cols:\n",
        "        pca = PCA(n_components=min(2, len(ret_cols)), random_state=42)\n",
        "        pca_features = pca.fit_transform(X[ret_cols].fillna(0))\n",
        "        for i in range(pca_features.shape[1]):\n",
        "            new_cols[f'PCA_{i}'] = pca_features[:, i]\n",
        "\n",
        "    # Add new features to DataFrame\n",
        "    new_cols_df = pd.DataFrame(new_cols, index=X.index, dtype=np.float32)\n",
        "    X = pd.concat([X, new_cols_df], axis=1)\n",
        "\n",
        "    # Standardize numerical features\n",
        "    feature_cols = [col for col in X.columns if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "    scaler = StandardScaler()\n",
        "    X[feature_cols] = scaler.fit_transform(X[feature_cols].replace([np.inf, -np.inf], 0).fillna(0))\n",
        "\n",
        "    if is_train:\n",
        "        y['SIGN_TARGET'] = np.where(y['RET_TARGET'] > 0, 1, 0).astype(np.int32)\n",
        "        return X, y, feature_cols, top_cols\n",
        "    return X, None, feature_cols, top_cols\n",
        "\n",
        "# Preprocess data\n",
        "try:\n",
        "    X_train, y_train, feature_cols, top_cols = preprocess_data(X_train, y_train, supplementary, is_train=True)\n",
        "    X_test, _, test_feature_cols, _ = preprocess_data(X_test, supplementary=supplementary, is_train=False, top_cols=top_cols)\n",
        "except ValueError as e:\n",
        "    print(f\"Preprocessing error: {e}\")\n",
        "    raise\n",
        "\n",
        "# Align columns\n",
        "common_cols = X_train.columns.intersection(X_test.columns)\n",
        "X_train = X_train[common_cols]\n",
        "X_test = X_test[common_cols]\n",
        "feature_cols = [col for col in common_cols if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "\n",
        "# Align y_train\n",
        "y_train = y_train.loc[X_train.index]\n",
        "\n",
        "# Define models with further expanded hyperparameter grids\n",
        "models = {\n",
        "    'LightGBM': {\n",
        "        'model': LGBMClassifier(num_leaves=31, min_child_samples=15, lambda_l1=0.3, lambda_l2=0.3,\n",
        "                                subsample=0.7, colsample_bytree=0.8, bagging_freq=5, bagging_fraction=0.7,\n",
        "                                random_state=42, n_jobs=1, verbosity=-1, class_weight='balanced', force_row_wise=True),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.003], 'num_leaves': [15], 'min_child_samples': [10], 'bagging_fraction': [0.6], 'reg_alpha': [0.0], 'reg_lambda': [0.0], 'colsample_bytree': [0.6]},\n",
        "            {'learning_rate': [0.005], 'num_leaves': [31], 'min_child_samples': [15], 'bagging_fraction': [0.7], 'reg_alpha': [0.1], 'reg_lambda': [0.1], 'colsample_bytree': [0.7]},\n",
        "            {'learning_rate': [0.01], 'num_leaves': [47], 'min_child_samples': [20], 'bagging_fraction': [0.8], 'reg_alpha': [0.2], 'reg_lambda': [0.2], 'colsample_bytree': [0.8]},\n",
        "            {'learning_rate': [0.03], 'num_leaves': [63], 'min_child_samples': [12], 'bagging_fraction': [0.65], 'reg_alpha': [0.3], 'reg_lambda': [0.3], 'colsample_bytree': [0.9]},\n",
        "            {'learning_rate': [0.05], 'num_leaves': [79], 'min_child_samples': [30], 'bagging_fraction': [0.75], 'reg_alpha': [0.4], 'reg_lambda': [0.4], 'colsample_bytree': [0.6]},\n",
        "            {'learning_rate': [0.07], 'num_leaves': [15], 'min_child_samples': [10], 'bagging_fraction': [0.6], 'reg_alpha': [0.0], 'reg_lambda': [0.1], 'colsample_bytree': [0.7]},\n",
        "            {'learning_rate': [0.1], 'num_leaves': [31], 'min_child_samples': [15], 'bagging_fraction': [0.7], 'reg_alpha': [0.2], 'reg_lambda': [0.0], 'colsample_bytree': [0.8]},\n",
        "            {'learning_rate': [0.15], 'num_leaves': [47], 'min_child_samples': [20], 'bagging_fraction': [0.8], 'reg_alpha': [0.1], 'reg_lambda': [0.3], 'colsample_bytree': [0.9]},\n",
        "            {'learning_rate': [0.003], 'num_leaves': [63], 'min_child_samples': [12], 'bagging_fraction': [0.65], 'reg_alpha': [0.3], 'reg_lambda': [0.2], 'colsample_bytree': [0.6]},\n",
        "            {'learning_rate': [0.005], 'num_leaves': [79], 'min_child_samples': [30], 'bagging_fraction': [0.75], 'reg_alpha': [0.4], 'reg_lambda': [0.1], 'colsample_bytree': [0.7]},\n",
        "            {'learning_rate': [0.01], 'num_leaves': [15], 'min_child_samples': [10], 'bagging_fraction': [0.6], 'reg_alpha': [0.0], 'reg_lambda': [0.4], 'colsample_bytree': [0.8]},\n",
        "            {'learning_rate': [0.03], 'num_leaves': [31], 'min_child_samples': [15], 'bagging_fraction': [0.7], 'reg_alpha': [0.2], 'reg_lambda': [0.0], 'colsample_bytree': [0.9]},\n",
        "            {'learning_rate': [0.05], 'num_leaves': [47], 'min_child_samples': [20], 'bagging_fraction': [0.8], 'reg_alpha': [0.5], 'reg_lambda': [0.5], 'colsample_bytree': [0.6]},\n",
        "            {'learning_rate': [0.07], 'num_leaves': [63], 'min_child_samples': [12], 'bagging_fraction': [0.65], 'reg_alpha': [0.1], 'reg_lambda': [0.2], 'colsample_bytree': [0.7]},\n",
        "            {'learning_rate': [0.1], 'num_leaves': [79], 'min_child_samples': [30], 'bagging_fraction': [0.75], 'reg_alpha': [0.3], 'reg_lambda': [0.3], 'colsample_bytree': [0.8]},\n",
        "            {'learning_rate': [0.15], 'num_leaves': [15], 'min_child_samples': [10], 'bagging_fraction': [0.6], 'reg_alpha': [0.4], 'reg_lambda': [0.1], 'colsample_bytree': [0.9]},\n",
        "            {'learning_rate': [0.003], 'num_leaves': [31], 'min_child_samples': [15], 'bagging_fraction': [0.7], 'reg_alpha': [0.0], 'reg_lambda': [0.0], 'colsample_bytree': [0.6]},\n",
        "            {'learning_rate': [0.005], 'num_leaves': [47], 'min_child_samples': [20], 'bagging_fraction': [0.8], 'reg_alpha': [0.2], 'reg_lambda': [0.2], 'colsample_bytree': [0.7]}\n",
        "        ],\n",
        "        'callbacks': [lightgbm.early_stopping(stopping_rounds=15, verbose=False)]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'model': XGBClassifier(max_depth=4, min_child_weight=2, subsample=0.8, colsample_bytree=0.8,\n",
        "                               random_state=42, n_jobs=1, eval_metric='logloss', verbosity=0,\n",
        "                               scale_pos_weight=len(y_train[y_train['SIGN_TARGET'] == 0]) / len(y_train[y_train['SIGN_TARGET'] == 1])),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.003], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [100], 'reg_alpha': [0.0], 'reg_lambda': [1.0], 'gamma': [0.0]},\n",
        "            {'learning_rate': [0.005], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [150], 'reg_alpha': [0.5], 'reg_lambda': [1.5], 'gamma': [0.1]},\n",
        "            {'learning_rate': [0.01], 'max_depth': [5], 'min_child_weight': [3], 'subsample': [0.8], 'n_estimators': [200], 'reg_alpha': [1.0], 'reg_lambda': [2.0], 'gamma': [0.2]},\n",
        "            {'learning_rate': [0.03], 'max_depth': [6], 'min_child_weight': [4], 'subsample': [0.65], 'n_estimators': [250], 'reg_alpha': [0.0], 'reg_lambda': [1.0], 'gamma': [0.0]},\n",
        "            {'learning_rate': [0.05], 'max_depth': [7], 'min_child_weight': [5], 'subsample': [0.75], 'n_estimators': [300], 'reg_alpha': [0.5], 'reg_lambda': [1.5], 'gamma': [0.1]},\n",
        "            {'learning_rate': [0.07], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [100], 'reg_alpha': [1.0], 'reg_lambda': [2.0], 'gamma': [0.2]},\n",
        "            {'learning_rate': [0.1], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [150], 'reg_alpha': [0.0], 'reg_lambda': [1.0], 'gamma': [0.0]},\n",
        "            {'learning_rate': [0.15], 'max_depth': [5], 'min_child_weight': [3], 'subsample': [0.8], 'n_estimators': [200], 'reg_alpha': [0.5], 'reg_lambda': [1.5], 'gamma': [0.1]},\n",
        "            {'learning_rate': [0.003], 'max_depth': [6], 'min_child_weight': [4], 'subsample': [0.65], 'n_estimators': [250], 'reg_alpha': [1.0], 'reg_lambda': [2.0], 'gamma': [0.2]},\n",
        "            {'learning_rate': [0.005], 'max_depth': [7], 'min_child_weight': [5], 'subsample': [0.75], 'n_estimators': [300], 'reg_alpha': [0.0], 'reg_lambda': [1.0], 'gamma': [0.0]},\n",
        "            {'learning_rate': [0.01], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [100], 'reg_alpha': [0.5], 'reg_lambda': [1.5], 'gamma': [0.1]},\n",
        "            {'learning_rate': [0.03], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [150], 'reg_alpha': [1.0], 'reg_lambda': [2.0], 'gamma': [0.2]},\n",
        "            {'learning_rate': [0.05], 'max_depth': [5], 'min_child_weight': [3], 'subsample': [0.8], 'n_estimators': [200], 'reg_alpha': [0.0], 'reg_lambda': [1.0], 'gamma': [0.0]},\n",
        "            {'learning_rate': [0.07], 'max_depth': [6], 'min_child_weight': [4], 'subsample': [0.65], 'n_estimators': [250], 'reg_alpha': [0.5], 'reg_lambda': [1.5], 'gamma': [0.1]},\n",
        "            {'learning_rate': [0.1], 'max_depth': [7], 'min_child_weight': [5], 'subsample': [0.75], 'n_estimators': [300], 'reg_alpha': [1.0], 'reg_lambda': [2.0], 'gamma': [0.2]},\n",
        "            {'learning_rate': [0.15], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [100], 'reg_alpha': [0.0], 'reg_lambda': [1.0], 'gamma': [0.0]},\n",
        "            {'learning_rate': [0.003], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [150], 'reg_alpha': [0.5], 'reg_lambda': [1.5], 'gamma': [0.1]},\n",
        "            {'learning_rate': [0.005], 'max_depth': [5], 'min_child_weight': [3], 'subsample': [0.8], 'n_estimators': [200], 'reg_alpha': [1.0], 'reg_lambda': [2.0], 'gamma': [0.2]}\n",
        "        ],\n",
        "        'callbacks': [xgboost.callback.EarlyStopping(rounds=15, metric_name='logloss', save_best=True)]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to train and predict for a single target\n",
        "def train_target(target, X_train, y_train, X_test, feature_cols, model, model_name, kf, param_grid, callbacks):\n",
        "    X_target = X_train[X_train['ID_TARGET'] == target][feature_cols]\n",
        "    y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "    weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "    low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "    # Dynamic weight scaling based on sample size\n",
        "    weight_scale = 2.0 if target in low_performing_targets else 1.0\n",
        "    if len(X_target) < 500:\n",
        "        weight_scale *= 1.5  # Boost weights for small targets\n",
        "    weights = weights * weight_scale\n",
        "    groups = X_train[X_train['ID_TARGET'] == target]['ID_DAY']\n",
        "    X_test_target = X_test[X_test['ID_TARGET'] == target][feature_cols]\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "    # Check for sufficient data\n",
        "    if len(X_target) < 100 or len(X_test_target) == 0:\n",
        "        print(f\"Warning: Insufficient data for ID_TARGET {target} (train: {len(X_target)}, test: {len(X_test_target)}). Skipping.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    param_results = []\n",
        "    best_params = None\n",
        "    best_score = 0\n",
        "    best_model = None\n",
        "\n",
        "    # First-pass grid search with sample weights\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        print(f\"Testing params for {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "        try:\n",
        "            model.set_params(**params)\n",
        "        except ValueError as e:\n",
        "            print(f\"Invalid params for {model_name} ID_TARGET {target}: {e}\")\n",
        "            continue\n",
        "        fold_accuracies = []\n",
        "        for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "            X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "            y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "            w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "\n",
        "            if model_name == 'LightGBM' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=callbacks)\n",
        "            elif model_name == 'XGBoost' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "            else:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "            y_pred = model.predict(X_val)\n",
        "            acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "            fold_accuracies.append(acc)\n",
        "\n",
        "        mean_acc = np.mean(fold_accuracies)\n",
        "        print(f\"{model_name} | ID_TARGET: {target} | Params: {params} | Mean Accuracy: {mean_acc:.4f} | Fold Accuracies: {fold_accuracies}\", flush=True)\n",
        "        param_results.append({\n",
        "            'params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': fold_accuracies\n",
        "        })\n",
        "        if mean_acc > best_score:\n",
        "            best_score = mean_acc\n",
        "            best_params = params\n",
        "            best_model = type(model)(**model.get_params())\n",
        "\n",
        "    # Train with best parameters\n",
        "    if best_model is None:\n",
        "        print(f\"No valid model for {model_name} ID_TARGET {target}. Using default.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    best_model.set_params(**best_params)\n",
        "    if model_name == 'LightGBM' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=callbacks)\n",
        "    elif model_name == 'XGBoost' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "    else:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights)\n",
        "\n",
        "    # Predict\n",
        "    preds = best_model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "\n",
        "    # Feature importance\n",
        "    importance = best_model.feature_importances_\n",
        "    feature_importance = dict(zip(feature_cols, importance))\n",
        "    top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:30]\n",
        "\n",
        "    # Clean up memory\n",
        "    gc.collect()\n",
        "\n",
        "    return str(target), best_params, best_score, param_results, test_ids, preds, top_features\n",
        "\n",
        "# Cross-validation and training\n",
        "kf = GroupKFold(n_splits=7)  # Increased to 7 folds\n",
        "results = {}\n",
        "predictions = {}\n",
        "ensemble_weights = {'LightGBM': 0.7, 'XGBoost': 0.3}\n",
        "param_log = {}\n",
        "top_features_all = {}\n",
        "param_summary = []\n",
        "low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\", flush=True)\n",
        "    param_log[model_name] = {}\n",
        "    top_features_all[model_name] = {}\n",
        "\n",
        "    # First-pass training\n",
        "    results_parallel = Parallel(n_jobs=-1)(\n",
        "        delayed(train_target)(target, X_train, y_train, X_test, feature_cols, model_info['model'], model_name, kf,\n",
        "                             model_info['param_grid'], model_info['callbacks'])\n",
        "        for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\")\n",
        "    )\n",
        "\n",
        "    # Collect results\n",
        "    accuracies = []\n",
        "    for target, params, mean_acc, param_results, test_ids, preds, top_features in results_parallel:\n",
        "        param_log[model_name][target] = {\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'all_params': param_results\n",
        "        }\n",
        "        top_features_all[model_name][target] = top_features\n",
        "        accuracies.append(mean_acc)\n",
        "        predictions.setdefault(target, {})[model_name] = dict(zip(test_ids, preds))\n",
        "        param_summary.append({\n",
        "            'model': model_name,\n",
        "            'ID_TARGET': target,\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': param_results[-1]['fold_accuracies'] if param_results else []\n",
        "        })\n",
        "\n",
        "    results[model_name] = np.mean([acc for acc in accuracies if acc > 0])  # Exclude skipped targets\n",
        "    print(f\"{model_name} Weighted Accuracy: {results[model_name]:.4f}\", flush=True)\n",
        "\n",
        "    # Print parameter summary\n",
        "    print(f\"\\n{model_name} Parameter Summary:\", flush=True)\n",
        "    for summary in param_summary:\n",
        "        if summary['model'] == model_name:\n",
        "            print(f\"ID_TARGET: {summary['ID_TARGET']} | Best Params: {summary['best_params']} | Mean Accuracy: {summary['mean_accuracy']:.4f} | Fold Accuracies: {summary['fold_accuracies']}\", flush=True)\n",
        "\n",
        "# Second-pass training with top 30 features\n",
        "print(\"\\nPerforming second-pass training with top 30 features...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nSecond-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\"):\n",
        "        target_str = str(target)\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "        weight_scale = 2.0 if target in low_performing_targets else 1.0\n",
        "        if len(X_target) < 500:\n",
        "            weight_scale *= 1.5\n",
        "        weights = weights * weight_scale\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        best_params['n_estimators'] = 300  # Use integer instead of list\n",
        "        model.set_params(**best_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Third-pass training for low-performing targets\n",
        "print(\"\\nPerforming third-pass training for low-performing targets...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nThird-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(low_performing_targets, desc=f\"{model_name} Low-Performing Targets\"):\n",
        "        target_str = str(target)\n",
        "        if target_str not in param_log[model_name] or param_log[model_name][target_str]['mean_accuracy'] >= 0.75:\n",
        "            continue  # Skip if already performing well\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs() * 3.0  # Increase weight\n",
        "        if len(X_target) < 500:\n",
        "            weights = weights * 1.5\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        # Further expanded fine-tuning grid for low-performing targets\n",
        "        fine_tune_grid = [\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.3, 'n_estimators': 400, 'reg_alpha': best_params['reg_alpha'][0] + 0.3, 'reg_lambda': best_params['reg_lambda'][0] + 0.3},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.5, 'n_estimators': 450, 'reg_alpha': best_params['reg_alpha'][0] + 0.2, 'reg_lambda': best_params['reg_lambda'][0] + 0.2},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.7, 'n_estimators': 500, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.0, 'n_estimators': 400, 'reg_alpha': best_params['reg_alpha'][0], 'reg_lambda': best_params['reg_lambda'][0]},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.3, 'n_estimators': 450, 'reg_alpha': best_params['reg_alpha'][0] + 0.15, 'reg_lambda': best_params['reg_lambda'][0] + 0.15},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.5, 'n_estimators': 500, 'reg_alpha': best_params['reg_alpha'][0] + 0.25, 'reg_lambda': best_params['reg_lambda'][0] + 0.25},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.4, 'n_estimators': 550, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.8, 'n_estimators': 600, 'reg_alpha': best_params['reg_alpha'][0] + 0.2, 'reg_lambda': best_params['reg_lambda'][0] + 0.2},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.2, 'n_estimators': 450, 'reg_alpha': best_params['reg_alpha'][0] + 0.3, 'reg_lambda': best_params['reg_lambda'][0] + 0.3}\n",
        "        ]\n",
        "        best_score = param_log[model_name][target_str]['mean_accuracy']\n",
        "        best_fine_params = best_params\n",
        "\n",
        "        for params in ParameterGrid(fine_tune_grid):\n",
        "            print(f\"Fine-tuning {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "            model.set_params(**params)\n",
        "            fold_accuracies = []\n",
        "            for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "                X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "                y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "                w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "                if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "                elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "                else:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "                y_pred = model.predict(X_val)\n",
        "                acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "                fold_accuracies.append(acc)\n",
        "            mean_acc = np.mean(fold_accuracies)\n",
        "            print(f\"{model_name} | ID_TARGET: {target} | Fine-tune Params: {params} | Mean Accuracy: {mean_acc:.4f}\", flush=True)\n",
        "            if mean_acc > best_score:\n",
        "                best_score = mean_acc\n",
        "                best_fine_params = params\n",
        "                param_log[model_name][target_str]['best_params'] = best_fine_params\n",
        "                param_log[model_name][target_str]['mean_accuracy'] = best_score\n",
        "                param_summary.append({\n",
        "                    'model': model_name,\n",
        "                    'ID_TARGET': target_str,\n",
        "                    'best_params': best_fine_params,\n",
        "                    'mean_accuracy': best_score,\n",
        "                    'fold_accuracies': fold_accuracies\n",
        "                })\n",
        "\n",
        "        # Retrain with fine-tuned parameters\n",
        "        model.set_params(**best_fine_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Fourth-pass training for very low-performing targets\n",
        "print(\"\\nPerforming fourth-pass training for very low-performing targets...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nFourth-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(low_performing_targets, desc=f\"{model_name} Very Low-Performing Targets\"):\n",
        "        target_str = str(target)\n",
        "        if target_str not in param_log[model_name] or param_log[model_name][target_str]['mean_accuracy'] >= 0.70:\n",
        "            continue  # Skip if accuracy >= 0.70\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs() * 3.0  # High weight\n",
        "        if len(X_target) < 500:\n",
        "            weights = weights * 1.5\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        # Further expanded fine-tuning grid for very low-performing targets\n",
        "        fine_tune_grid = [\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.2, 'n_estimators': 400, 'reg_alpha': best_params['reg_alpha'][0] + 0.4, 'reg_lambda': best_params['reg_lambda'][0] + 0.4},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.4, 'n_estimators': 450, 'reg_alpha': best_params['reg_alpha'][0] + 0.3, 'reg_lambda': best_params['reg_lambda'][0] + 0.3},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.6, 'n_estimators': 500, 'reg_alpha': best_params['reg_alpha'][0] + 0.2, 'reg_lambda': best_params['reg_lambda'][0] + 0.2},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.8, 'n_estimators': 550, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.0, 'n_estimators': 400, 'reg_alpha': best_params['reg_alpha'][0], 'reg_lambda': best_params['reg_lambda'][0]},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.2, 'n_estimators': 450, 'reg_alpha': best_params['reg_alpha'][0] + 0.15, 'reg_lambda': best_params['reg_lambda'][0] + 0.15},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.4, 'n_estimators': 500, 'reg_alpha': best_params['reg_alpha'][0] + 0.25, 'reg_lambda': best_params['reg_lambda'][0] + 0.25},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.6, 'n_estimators': 550, 'reg_alpha': best_params['reg_alpha'][0] + 0.3, 'reg_lambda': best_params['reg_lambda'][0] + 0.3},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.5, 'n_estimators': 600, 'reg_alpha': best_params['reg_alpha'][0] + 0.2, 'reg_lambda': best_params['reg_lambda'][0] + 0.2}\n",
        "        ]\n",
        "        best_score = param_log[model_name][target_str]['mean_accuracy']\n",
        "        best_fine_params = best_params\n",
        "\n",
        "        for params in ParameterGrid(fine_tune_grid):\n",
        "            print(f\"Fine-tuning {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "            model.set_params(**params)\n",
        "            fold_accuracies = []\n",
        "            for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "                X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "                y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "                w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "                if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "                elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "                else:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "                y_pred = model.predict(X_val)\n",
        "                acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "                fold_accuracies.append(acc)\n",
        "            mean_acc = np.mean(fold_accuracies)\n",
        "            print(f\"{model_name} | ID_TARGET: {target} | Fine-tune Params: {params} | Mean Accuracy: {mean_acc:.4f}\", flush=True)\n",
        "            if mean_acc > best_score:\n",
        "                best_score = mean_acc\n",
        "                best_fine_params = params\n",
        "                param_log[model_name][target_str]['best_params'] = best_fine_params\n",
        "                param_log[model_name][target_str]['mean_accuracy'] = best_score\n",
        "                param_summary.append({\n",
        "                    'model': model_name,\n",
        "                    'ID_TARGET': target_str,\n",
        "                    'best_params': best_fine_params,\n",
        "                    'mean_accuracy': best_score,\n",
        "                    'fold_accuracies': fold_accuracies\n",
        "                })\n",
        "\n",
        "        # Retrain with fine-tuned parameters\n",
        "        model.set_params(**best_fine_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Save parameter log\n",
        "param_log_path = os.path.join(DATA_DIR, 'hyperparameters.json')\n",
        "with open(param_log_path, 'w') as f:\n",
        "    json.dump(param_log, f, indent=4)\n",
        "print(f\"Saved hyperparameter log to: {param_log_path}\", flush=True)\n",
        "files.download(param_log_path)\n",
        "\n",
        "# Ensemble predictions\n",
        "final_predictions = {}\n",
        "missing_day_targets = []\n",
        "for target in X_test['ID_TARGET'].unique():\n",
        "    target_str = str(target)\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "    for day in X_test[X_test['ID_TARGET'] == target]['ID_DAY'].unique():\n",
        "        day_idx = (X_test['ID_TARGET'] == target) & (X_test['ID_DAY'] == day)\n",
        "        day_test_ids = X_test[day_idx].index\n",
        "        if len(day_test_ids) == 0:\n",
        "            print(f\"Warning: No test samples for ID_TARGET {target} on ID_DAY {day}. Using default prediction.\")\n",
        "            missing_day_targets.append((target, day))\n",
        "            for idx in test_ids:\n",
        "                final_predictions[idx] = -1\n",
        "            continue\n",
        "        lgbm_preds = np.array([predictions[target_str].get('LightGBM', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        xgb_preds = np.array([predictions[target_str].get('XGBoost', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        ensemble_preds = ensemble_weights['LightGBM'] * lgbm_preds + ensemble_weights['XGBoost'] * xgb_preds\n",
        "        # Apply exponential moving average for smoothing\n",
        "        smoothed_preds = pd.Series(ensemble_preds).ewm(span=3).mean().values[-1] if len(ensemble_preds) > 0 else 0.5\n",
        "        for idx in day_test_ids:\n",
        "            final_predictions[idx] = 1 if smoothed_preds >= 0.5 else -1\n",
        "\n",
        "if missing_day_targets:\n",
        "    print(f\"Missing day-target pairs: {missing_day_targets}\")\n",
        "\n",
        "# Create output CSV\n",
        "output_df = pd.DataFrame.from_dict(final_predictions, orient='index', columns=['RET_TARGET']).reset_index()\n",
        "output_df.columns = ['ID', 'RET_TARGET']\n",
        "output_df = output_df.sort_values('ID')\n",
        "expected_ids = set(X_test.index)\n",
        "submission_ids = set(output_df['ID'])\n",
        "if expected_ids != submission_ids:\n",
        "    missing_ids = expected_ids - submission_ids\n",
        "    print(f\"Warning: Submission missing {len(missing_ids)} IDs: {missing_ids}\")\n",
        "    missing_df = pd.DataFrame({'ID': list(missing_ids), 'RET_TARGET': -1})\n",
        "    output_df = pd.concat([output_df, missing_df], ignore_index=True).sort_values('ID')\n",
        "output_path = os.path.join(DATA_DIR, 'predictions_ensemble.csv')\n",
        "output_df.to_csv(output_path, index=False)\n",
        "print(f\"Saved predictions to: {output_path}\", flush=True)\n",
        "\n",
        "# Validate output\n",
        "test_csv = pd.read_csv(output_path)\n",
        "print(f\"Output CSV shape: {test_csv.shape}\", flush=True)\n",
        "print(f\"Output CSV ID range: {test_csv['ID'].min()} to {test_csv['ID'].max()}\", flush=True)\n",
        "print(f\"Unique RET_TARGET values: {test_csv['RET_TARGET'].unique()}\", flush=True)\n",
        "print(f\"Missing values: {test_csv.isna().sum().sum()}\", flush=True)\n",
        "\n",
        "# Download the file\n",
        "files.download(output_path)\n",
        "\n",
        "# Print final results\n",
        "print(\"\\nValidation Results:\", flush=True)\n",
        "for model_name, acc in results.items():\n",
        "    print(f\"{model_name}: {acc:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLR2qKn8I9h_"
      },
      "source": [
        "try new -65%, overfit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "atSlJuU8I-U6",
        "outputId": "c09f4fa7-29d0-4461-bb8a-75aec8315adf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost version: 2.1.4\n",
            "Selected top return columns: ['RET_262', 'RET_88', 'RET_172', 'RET_259', 'RET_118', 'RET_150', 'RET_261', 'RET_268', 'RET_115', 'RET_216', 'RET_238', 'RET_59', 'RET_30', 'RET_97', 'RET_122']\n",
            "\n",
            "Training LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LightGBM Targets: 100%|| 101/101 [1:23:26<00:00, 49.57s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightGBM Weighted Accuracy: 0.9858\n",
            "\n",
            "LightGBM Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8282208588957055), np.float64(1.0), np.float64(1.0), np.float64(0.9030303030303031), np.float64(1.0), np.float64(1.0), np.float64(0.9559748427672956)]\n",
            "ID_TARGET: 129.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.65), np.float64(0.6728395061728395), np.float64(0.5786163522012578), np.float64(0.7325581395348837), np.float64(0.6481481481481481), np.float64(0.6477987421383647), np.float64(0.6931818181818182)]\n",
            "ID_TARGET: 136.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6729559748427673), np.float64(0.620253164556962), np.float64(0.7142857142857143), np.float64(0.6818181818181818), np.float64(0.6035502958579881), np.float64(0.6206896551724138), np.float64(0.6153846153846154)]\n",
            "ID_TARGET: 161.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6174496644295302), np.float64(0.6857142857142857), np.float64(0.6646341463414634), np.float64(0.696969696969697), np.float64(0.6607142857142857), np.float64(0.6464088397790055), np.float64(0.6341463414634146)]\n",
            "ID_TARGET: 217.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7485029940119761), np.float64(0.7068965517241379), np.float64(0.6704545454545454), np.float64(0.6892655367231638), np.float64(0.7098765432098766), np.float64(0.7159090909090909), np.float64(0.7228260869565217)]\n",
            "ID_TARGET: 91.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7888198757763976), np.float64(0.7411764705882353), np.float64(0.727810650887574), np.float64(0.7310344827586207), np.float64(0.6666666666666666), np.float64(0.7300613496932515), np.float64(0.6686746987951807)]\n",
            "ID_TARGET: 137.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6223776223776224), np.float64(0.6794871794871795), np.float64(0.7116564417177914), np.float64(0.7354838709677419), np.float64(0.6196319018404908), np.float64(0.6204819277108434), np.float64(0.7070063694267515)]\n",
            "ID_TARGET: 8.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7732558139534884), np.float64(0.8867924528301887), np.float64(0.703030303030303), np.float64(0.779874213836478), np.float64(0.7077922077922078), np.float64(0.813953488372093), np.float64(0.72)]\n",
            "ID_TARGET: 3.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7602739726027398), np.float64(0.8), np.float64(0.8050314465408805), np.float64(0.7134831460674157), np.float64(0.7350993377483444), np.float64(0.7152317880794702), np.float64(0.7707006369426752)]\n",
            "ID_TARGET: 9.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7126436781609196), np.float64(0.7083333333333334), np.float64(0.7961783439490446), np.float64(0.6838235294117647), np.float64(0.711764705882353), np.float64(0.7236842105263158), np.float64(0.6455696202531646)]\n",
            "ID_TARGET: 131.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6914285714285714), np.float64(0.6962025316455697), np.float64(0.7380952380952381), np.float64(0.6761363636363636), np.float64(0.821656050955414), np.float64(0.6736111111111112), np.float64(0.7088607594936709)]\n",
            "ID_TARGET: 21.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.2, 'num_leaves': 15, 'reg_alpha': 0.5, 'reg_lambda': 0.5} | Mean Accuracy: 0.9932 | Fold Accuracies: [np.float64(0.5688622754491018), np.float64(0.6441717791411042), np.float64(0.7423312883435583), np.float64(0.5574712643678161), np.float64(0.7311827956989247), np.float64(0.6704545454545454), np.float64(0.6764705882352942)]\n",
            "ID_TARGET: 54.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7707006369426752), np.float64(0.7218543046357616), np.float64(0.8057142857142857), np.float64(0.7904191616766467), np.float64(0.8303030303030303), np.float64(0.8097826086956522), np.float64(0.8238993710691824)]\n",
            "ID_TARGET: 130.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7819148936170213), np.float64(0.7547169811320755), np.float64(0.7828571428571428), np.float64(0.7633136094674556), np.float64(0.757396449704142), np.float64(0.8707482993197279), np.float64(0.7398843930635838)]\n",
            "ID_TARGET: 269.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7183098591549296), np.float64(0.7354838709677419), np.float64(0.7467532467532467), np.float64(0.7371794871794872), np.float64(0.6928104575163399), np.float64(0.7189542483660131), np.float64(0.7615894039735099)]\n",
            "ID_TARGET: 157.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7677419354838709), np.float64(0.7808219178082192), np.float64(0.8679245283018868), np.float64(0.8211920529801324), np.float64(0.7643312101910829), np.float64(0.7272727272727273), np.float64(0.7803468208092486)]\n",
            "ID_TARGET: 249.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7398843930635838), np.float64(0.7426900584795322), np.float64(0.6923076923076923), np.float64(0.757396449704142), np.float64(0.7310344827586207), np.float64(0.7888198757763976), np.float64(0.782608695652174)]\n",
            "ID_TARGET: 22.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.2, 'num_leaves': 15, 'reg_alpha': 0.5, 'reg_lambda': 0.5} | Mean Accuracy: 0.9266 | Fold Accuracies: [np.float64(0.6506024096385542), np.float64(0.7032967032967034), np.float64(0.7085714285714285), np.float64(0.7168674698795181), np.float64(0.6190476190476191), np.float64(0.5988023952095808), np.float64(0.7452229299363057)]\n",
            "ID_TARGET: 202.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8627 | Fold Accuracies: [np.float64(0.6235294117647059), np.float64(0.6329113924050633), np.float64(0.6257309941520468), np.float64(0.6686046511627907), np.float64(0.6588235294117647), np.float64(0.5906432748538012), np.float64(0.6629834254143646)]\n",
            "ID_TARGET: 132.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8048780487804879), np.float64(0.7837837837837838), np.float64(0.7777777777777778), np.float64(0.8260869565217391), np.float64(0.7018633540372671), np.float64(0.7419354838709677), np.float64(0.7987804878048781)]\n",
            "ID_TARGET: 96.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7712418300653595), np.float64(0.85), np.float64(0.6842105263157895), np.float64(0.7762237762237763), np.float64(0.7597402597402597), np.float64(0.7189542483660131), np.float64(0.7602739726027398)]\n",
            "ID_TARGET: 7.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7354838709677419), np.float64(0.7816091954022989), np.float64(0.7386363636363636), np.float64(0.7870967741935484), np.float64(0.7675675675675676), np.float64(0.79375), np.float64(0.7988826815642458)]\n",
            "ID_TARGET: 178.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9773 | Fold Accuracies: [np.float64(0.7558139534883721), np.float64(0.6772151898734177), np.float64(0.6729559748427673), np.float64(0.6882352941176471), np.float64(0.7083333333333334), np.float64(0.75), np.float64(0.7046979865771812)]\n",
            "ID_TARGET: 68.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6927710843373494), np.float64(0.8012422360248447), np.float64(0.7658227848101266), np.float64(0.7721518987341772), np.float64(0.7837837837837838), np.float64(0.7763975155279503), np.float64(0.7697368421052632)]\n",
            "ID_TARGET: 44.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7396449704142012), np.float64(0.7658227848101266), np.float64(0.689873417721519), np.float64(0.7878787878787878), np.float64(0.7167630057803468), np.float64(0.6467065868263473), np.float64(0.7245508982035929)]\n",
            "ID_TARGET: 196.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7292817679558011), np.float64(0.7189189189189189), np.float64(0.7853107344632768), np.float64(0.6810810810810811), np.float64(0.6686046511627907), np.float64(0.734375), np.float64(0.7272727272727273)]\n",
            "ID_TARGET: 292.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6984126984126984), np.float64(0.7555555555555555), np.float64(0.7380952380952381), np.float64(0.7870967741935484), np.float64(0.7207792207792207), np.float64(0.6727272727272727), np.float64(0.7109826589595376)]\n",
            "ID_TARGET: 239.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7777777777777778), np.float64(0.7169811320754716), np.float64(0.71875), np.float64(0.7671232876712328), np.float64(0.7696969696969697), np.float64(0.7453416149068323), np.float64(0.7635135135135135)]\n",
            "ID_TARGET: 279.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7777777777777778), np.float64(0.8181818181818182), np.float64(0.7248322147651006), np.float64(0.7393939393939394), np.float64(0.6783625730994152), np.float64(0.8034682080924855), np.float64(0.6467065868263473)]\n",
            "ID_TARGET: 38.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.718562874251497), np.float64(0.7638888888888888), np.float64(0.7721518987341772), np.float64(0.7080745341614907), np.float64(0.7872340425531915), np.float64(0.7966101694915254), np.float64(0.8)]\n",
            "ID_TARGET: 209.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7848101265822784), np.float64(0.7212121212121212), np.float64(0.7267441860465116), np.float64(0.7108433734939759), np.float64(0.7796610169491526), np.float64(0.7294117647058823), np.float64(0.6474358974358975)]\n",
            "ID_TARGET: 207.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7051282051282052), np.float64(0.6455696202531646), np.float64(0.7241379310344828), np.float64(0.6666666666666666), np.float64(0.7407407407407407), np.float64(0.6721311475409836), np.float64(0.6379310344827587)]\n",
            "ID_TARGET: 98.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.75), np.float64(0.7468354430379747), np.float64(0.7692307692307693), np.float64(0.7232704402515723), np.float64(0.6111111111111112), np.float64(0.7544910179640718), np.float64(0.7515151515151515)]\n",
            "ID_TARGET: 65.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7660818713450293), np.float64(0.7806451612903226), np.float64(0.7530864197530864), np.float64(0.6518987341772152), np.float64(0.726027397260274), np.float64(0.6774193548387096), np.float64(0.8)]\n",
            "ID_TARGET: 51.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7948717948717948), np.float64(0.8066666666666666), np.float64(0.7236842105263158), np.float64(0.7961783439490446), np.float64(0.7419354838709677), np.float64(0.7484276729559748), np.float64(0.7105263157894737)]\n",
            "ID_TARGET: 78.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.2, 'num_leaves': 15, 'reg_alpha': 0.5, 'reg_lambda': 0.5} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7655172413793103), np.float64(0.7888198757763976), np.float64(0.6666666666666666), np.float64(0.7407407407407407), np.float64(0.7516778523489933), np.float64(0.7006369426751592), np.float64(0.7914110429447853)]\n",
            "ID_TARGET: 177.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9058 | Fold Accuracies: [np.float64(0.7393939393939394), np.float64(0.740506329113924), np.float64(0.7783783783783784), np.float64(0.7417582417582418), np.float64(0.6820512820512821), np.float64(0.7218934911242604), np.float64(0.7336956521739131)]\n",
            "ID_TARGET: 231.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8441558441558441), np.float64(0.7687861271676301), np.float64(0.823170731707317), np.float64(0.754601226993865), np.float64(0.8433734939759037), np.float64(0.7932960893854749), np.float64(0.8461538461538461)]\n",
            "ID_TARGET: 119.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.2, 'num_leaves': 15, 'reg_alpha': 0.5, 'reg_lambda': 0.5} | Mean Accuracy: 0.9911 | Fold Accuracies: [np.float64(0.8543046357615894), np.float64(0.7911392405063291), np.float64(0.7735849056603774), np.float64(0.7484276729559748), np.float64(0.803680981595092), np.float64(0.7388535031847133), np.float64(0.7853107344632768)]\n",
            "ID_TARGET: 158.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7891156462585034), np.float64(0.8452380952380952), np.float64(0.7955801104972375), np.float64(0.7785234899328859), np.float64(0.8484848484848485), np.float64(0.8145695364238411), np.float64(0.8044692737430168)]\n",
            "ID_TARGET: 80.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.2, 'num_leaves': 15, 'reg_alpha': 0.5, 'reg_lambda': 0.5} | Mean Accuracy: 0.9992 | Fold Accuracies: [np.float64(0.6556291390728477), np.float64(0.6878980891719745), np.float64(0.7), np.float64(0.7134146341463414), np.float64(0.7317073170731707), np.float64(0.7066666666666667), np.float64(0.7572254335260116)]\n",
            "ID_TARGET: 25.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7572254335260116), np.float64(0.689873417721519), np.float64(0.6878980891719745), np.float64(0.7467532467532467), np.float64(0.7005988023952096), np.float64(0.74375), np.float64(0.75625)]\n",
            "ID_TARGET: 175.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7414965986394558), np.float64(0.6829268292682927), np.float64(0.8047337278106509), np.float64(0.8023952095808383), np.float64(0.8048780487804879), np.float64(0.7151515151515152), np.float64(0.756578947368421)]\n",
            "ID_TARGET: 151.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.2, 'num_leaves': 15, 'reg_alpha': 0.5, 'reg_lambda': 0.5} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8424242424242424), np.float64(0.8136645962732919), np.float64(0.7935483870967742), np.float64(0.7962962962962963), np.float64(0.7267080745341615), np.float64(0.7861635220125787), np.float64(0.7777777777777778)]\n",
            "ID_TARGET: 257.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9832 | Fold Accuracies: [np.float64(0.6935483870967742), np.float64(0.75625), np.float64(0.7964071856287425), np.float64(0.6444444444444445), np.float64(0.75), np.float64(0.7542857142857143), np.float64(0.6666666666666666)]\n",
            "ID_TARGET: 75.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7909604519774012), np.float64(0.8198757763975155), np.float64(0.7764705882352941), np.float64(0.75), np.float64(0.7987421383647799), np.float64(0.8), np.float64(0.8154761904761905)]\n",
            "ID_TARGET: 244.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6781609195402298), np.float64(0.6704545454545454), np.float64(0.7764705882352941), np.float64(0.6566265060240963), np.float64(0.73125), np.float64(0.6242424242424243), np.float64(0.7426900584795322)]\n",
            "ID_TARGET: 149.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.2, 'num_leaves': 15, 'reg_alpha': 0.5, 'reg_lambda': 0.5} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.759493670886076), np.float64(0.7590361445783133), np.float64(0.8169934640522876), np.float64(0.786096256684492), np.float64(0.7168674698795181), np.float64(0.6772151898734177), np.float64(0.8258426966292135)]\n",
            "ID_TARGET: 85.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7530120481927711), np.float64(0.7692307692307693), np.float64(0.7974683544303798), np.float64(0.7470588235294118), np.float64(0.8066666666666666), np.float64(0.803921568627451), np.float64(0.7628205128205128)]\n",
            "ID_TARGET: 190.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.2, 'num_leaves': 15, 'reg_alpha': 0.5, 'reg_lambda': 0.5} | Mean Accuracy: 0.9743 | Fold Accuracies: [np.float64(0.6792452830188679), np.float64(0.7076023391812866), np.float64(0.7288135593220338), np.float64(0.754601226993865), np.float64(0.7134502923976608), np.float64(0.7093023255813954), np.float64(0.8192771084337349)]\n",
            "ID_TARGET: 13.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9282 | Fold Accuracies: [np.float64(0.7182320441988951), np.float64(0.7607361963190185), np.float64(0.7559523809523809), np.float64(0.7062146892655368), np.float64(0.7440476190476191), np.float64(0.7615894039735099), np.float64(0.8106508875739645)]\n",
            "ID_TARGET: 228.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.2, 'num_leaves': 15, 'reg_alpha': 0.5, 'reg_lambda': 0.5} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7469135802469136), np.float64(0.7352941176470589), np.float64(0.6797752808988764), np.float64(0.7222222222222222), np.float64(0.6867469879518072), np.float64(0.7204301075268817), np.float64(0.6946107784431138)]\n",
            "ID_TARGET: 144.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8132530120481928), np.float64(0.8300653594771242), np.float64(0.8541666666666666), np.float64(0.8064516129032258), np.float64(0.7941176470588235), np.float64(0.8152866242038217), np.float64(0.8430232558139535)]\n",
            "ID_TARGET: 290.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6923076923076923), np.float64(0.7484662576687117), np.float64(0.6621621621621622), np.float64(0.7730061349693251), np.float64(0.7987804878048781), np.float64(0.8), np.float64(0.7547169811320755)]\n",
            "ID_TARGET: 114.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8808 | Fold Accuracies: [np.float64(0.6845238095238095), np.float64(0.6792452830188679), np.float64(0.6787878787878788), np.float64(0.7329192546583851), np.float64(0.7654320987654321), np.float64(0.6571428571428571), np.float64(0.751412429378531)]\n",
            "ID_TARGET: 166.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7529411764705882), np.float64(0.7048192771084337), np.float64(0.8114285714285714), np.float64(0.7560975609756098), np.float64(0.7241379310344828), np.float64(0.7207792207792207), np.float64(0.75)]\n",
            "ID_TARGET: 234.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9037 | Fold Accuracies: [np.float64(0.740506329113924), np.float64(0.7612903225806451), np.float64(0.8695652173913043), np.float64(0.7051282051282052), np.float64(0.7672955974842768), np.float64(0.7142857142857143), np.float64(0.7727272727272727)]\n",
            "ID_TARGET: 34.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.2, 'num_leaves': 15, 'reg_alpha': 0.5, 'reg_lambda': 0.5} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7701149425287356), np.float64(0.7484662576687117), np.float64(0.7784810126582279), np.float64(0.7741935483870968), np.float64(0.7931034482758621), np.float64(0.8176470588235294), np.float64(0.7777777777777778)]\n",
            "ID_TARGET: 154.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.2, 'num_leaves': 15, 'reg_alpha': 0.5, 'reg_lambda': 0.5} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7471910112359551), np.float64(0.7894736842105263), np.float64(0.738562091503268), np.float64(0.7857142857142857), np.float64(0.7660818713450293), np.float64(0.8), np.float64(0.7877094972067039)]\n",
            "ID_TARGET: 225.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9413 | Fold Accuracies: [np.float64(0.7290322580645161), np.float64(0.7055555555555556), np.float64(0.7253886010362695), np.float64(0.7), np.float64(0.6839080459770115), np.float64(0.688622754491018), np.float64(0.7701149425287356)]\n",
            "ID_TARGET: 185.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8562091503267973), np.float64(0.7986577181208053), np.float64(0.7987421383647799), np.float64(0.8111888111888111), np.float64(0.7933333333333333), np.float64(0.8692307692307693), np.float64(0.8273381294964028)]\n",
            "ID_TARGET: 39.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.2, 'num_leaves': 15, 'reg_alpha': 0.5, 'reg_lambda': 0.5} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7935483870967742), np.float64(0.7396449704142012), np.float64(0.7828571428571428), np.float64(0.6858974358974359), np.float64(0.7658227848101266), np.float64(0.7337662337662337), np.float64(0.7453416149068323)]\n",
            "ID_TARGET: 272.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9512 | Fold Accuracies: [np.float64(0.7341772151898734), np.float64(0.8011049723756906), np.float64(0.738562091503268), np.float64(0.7636363636363637), np.float64(0.7602339181286549), np.float64(0.7358490566037735), np.float64(0.7485380116959064)]\n",
            "ID_TARGET: 282.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8417721518987342), np.float64(0.7556818181818182), np.float64(0.7848101265822784), np.float64(0.7077922077922078), np.float64(0.7543859649122807), np.float64(0.7142857142857143), np.float64(0.7908496732026143)]\n",
            "ID_TARGET: 90.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.8216 | Fold Accuracies: [np.float64(0.7484662576687117), np.float64(0.7613636363636364), np.float64(0.7647058823529411), np.float64(0.7852760736196319), np.float64(0.7615894039735099), np.float64(0.7928994082840237), np.float64(0.7861635220125787)]\n",
            "ID_TARGET: 52.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9264 | Fold Accuracies: [np.float64(0.6928104575163399), np.float64(0.6975308641975309), np.float64(0.7771084337349398), np.float64(0.75), np.float64(0.7325581395348837), np.float64(0.7222222222222222), np.float64(0.7215189873417721)]\n",
            "ID_TARGET: 258.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.2, 'num_leaves': 15, 'reg_alpha': 0.5, 'reg_lambda': 0.5} | Mean Accuracy: 0.9924 | Fold Accuracies: [np.float64(0.695364238410596), np.float64(0.7428571428571429), np.float64(0.7303370786516854), np.float64(0.7005988023952096), np.float64(0.7439024390243902), np.float64(0.6993464052287581), np.float64(0.7248322147651006)]\n",
            "ID_TARGET: 291.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6887417218543046), np.float64(0.8235294117647058), np.float64(0.7212121212121212), np.float64(0.7611111111111111), np.float64(0.7965116279069767), np.float64(0.7514450867052023), np.float64(0.7894736842105263)]\n",
            "ID_TARGET: 152.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8081395348837209), np.float64(0.7702702702702703), np.float64(0.7261146496815286), np.float64(0.7721518987341772), np.float64(0.7821229050279329), np.float64(0.7848101265822784), np.float64(0.7470588235294118)]\n",
            "ID_TARGET: 133.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7625), np.float64(0.834319526627219), np.float64(0.8502994011976048), np.float64(0.7732558139534884), np.float64(0.7621951219512195), np.float64(0.8280254777070064), np.float64(0.7976878612716763)]\n",
            "ID_TARGET: 29.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7115384615384616), np.float64(0.8109756097560976), np.float64(0.7583892617449665), np.float64(0.7070063694267515), np.float64(0.7225433526011561), np.float64(0.7469135802469136), np.float64(0.7831325301204819)]\n",
            "ID_TARGET: 274.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9351 | Fold Accuracies: [np.float64(0.7251461988304093), np.float64(0.7590361445783133), np.float64(0.7704918032786885), np.float64(0.718562874251497), np.float64(0.7058823529411765), np.float64(0.7100591715976331), np.float64(0.7189189189189189)]\n",
            "ID_TARGET: 106.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7714285714285715), np.float64(0.7686567164179104), np.float64(0.803921568627451), np.float64(0.8161764705882353), np.float64(0.7724137931034483), np.float64(0.8657718120805369), np.float64(0.7816901408450704)]\n",
            "ID_TARGET: 173.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8092485549132948), np.float64(0.7840909090909091), np.float64(0.7935483870967742), np.float64(0.8113207547169812), np.float64(0.8354430379746836), np.float64(0.875), np.float64(0.8343558282208589)]\n",
            "ID_TARGET: 33.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7942857142857143), np.float64(0.7732558139534884), np.float64(0.7674418604651163), np.float64(0.7192982456140351), np.float64(0.7597402597402597), np.float64(0.6909090909090909), np.float64(0.7662337662337663)]\n",
            "ID_TARGET: 69.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.2, 'num_leaves': 15, 'reg_alpha': 0.5, 'reg_lambda': 0.5} | Mean Accuracy: 0.9532 | Fold Accuracies: [np.float64(0.691358024691358), np.float64(0.6556291390728477), np.float64(0.7), np.float64(0.6690140845070423), np.float64(0.7862068965517242), np.float64(0.7215189873417721), np.float64(0.7950310559006211)]\n",
            "ID_TARGET: 17.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.2, 'num_leaves': 15, 'reg_alpha': 0.5, 'reg_lambda': 0.5} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7142857142857143), np.float64(0.6988636363636364), np.float64(0.6625), np.float64(0.7763975155279503), np.float64(0.6909090909090909), np.float64(0.7288135593220338), np.float64(0.7055214723926381)]\n",
            "ID_TARGET: 189.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7806451612903226), np.float64(0.8466257668711656), np.float64(0.8079470198675497), np.float64(0.7885714285714286), np.float64(0.7662337662337663), np.float64(0.7662337662337663), np.float64(0.8066666666666666)]\n",
            "ID_TARGET: 284.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9356 | Fold Accuracies: [np.float64(0.7361963190184049), np.float64(0.7151898734177216), np.float64(0.632183908045977), np.float64(0.7672955974842768), np.float64(0.8023255813953488), np.float64(0.6941176470588235), np.float64(0.7108433734939759)]\n",
            "ID_TARGET: 218.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.703030303030303), np.float64(0.75), np.float64(0.73224043715847), np.float64(0.7351351351351352), np.float64(0.7423312883435583), np.float64(0.6842105263157895), np.float64(0.791907514450867)]\n",
            "ID_TARGET: 183.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.834319526627219), np.float64(0.8145695364238411), np.float64(0.7581699346405228), np.float64(0.7962962962962963), np.float64(0.7514450867052023), np.float64(0.7857142857142857), np.float64(0.782608695652174)]\n",
            "ID_TARGET: 206.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.2, 'num_leaves': 15, 'reg_alpha': 0.5, 'reg_lambda': 0.5} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7832167832167832), np.float64(0.7751479289940828), np.float64(0.7515527950310559), np.float64(0.7569060773480663), np.float64(0.7167630057803468), np.float64(0.7341772151898734), np.float64(0.7189542483660131)]\n",
            "ID_TARGET: 93.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.695906432748538), np.float64(0.6923076923076923), np.float64(0.7181208053691275), np.float64(0.6964285714285714), np.float64(0.7083333333333334), np.float64(0.7701863354037267), np.float64(0.7482993197278912)]\n",
            "ID_TARGET: 16.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.2, 'num_leaves': 15, 'reg_alpha': 0.5, 'reg_lambda': 0.5} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8070175438596491), np.float64(0.7346938775510204), np.float64(0.7514450867052023), np.float64(0.6708074534161491), np.float64(0.7168674698795181), np.float64(0.7166666666666667), np.float64(0.7133333333333334)]\n",
            "ID_TARGET: 246.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.2, 'num_leaves': 15, 'reg_alpha': 0.5, 'reg_lambda': 0.5} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7844311377245509), np.float64(0.7771428571428571), np.float64(0.8034682080924855), np.float64(0.78125), np.float64(0.6890243902439024), np.float64(0.7345679012345679), np.float64(0.7732558139534884)]\n",
            "ID_TARGET: 167.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7844311377245509), np.float64(0.7341772151898734), np.float64(0.7862068965517242), np.float64(0.81875), np.float64(0.7905405405405406), np.float64(0.7103448275862069), np.float64(0.6935483870967742)]\n",
            "ID_TARGET: 1.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7172413793103448), np.float64(0.82), np.float64(0.7515527950310559), np.float64(0.7643312101910829), np.float64(0.7142857142857143), np.float64(0.7647058823529411), np.float64(0.7358490566037735)]\n",
            "ID_TARGET: 289.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7692307692307693), np.float64(0.725609756097561), np.float64(0.8323699421965318), np.float64(0.711864406779661), np.float64(0.7516778523489933), np.float64(0.725609756097561), np.float64(0.8109756097560976)]\n",
            "ID_TARGET: 141.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9557 | Fold Accuracies: [np.float64(0.7657142857142857), np.float64(0.8561643835616438), np.float64(0.7610062893081762), np.float64(0.738255033557047), np.float64(0.75), np.float64(0.8766233766233766), np.float64(0.8104575163398693)]\n",
            "ID_TARGET: 109.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6927710843373494), np.float64(0.7514792899408284), np.float64(0.7664670658682635), np.float64(0.6944444444444444), np.float64(0.6623376623376623), np.float64(0.727810650887574), np.float64(0.6684210526315789)]\n",
            "ID_TARGET: 19.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9722 | Fold Accuracies: [np.float64(0.6666666666666666), np.float64(0.7150837988826816), np.float64(0.7361963190184049), np.float64(0.7556818181818182), np.float64(0.72), np.float64(0.7289156626506024), np.float64(0.7906976744186046)]\n",
            "ID_TARGET: 28.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.2, 'num_leaves': 15, 'reg_alpha': 0.5, 'reg_lambda': 0.5} | Mean Accuracy: 0.9859 | Fold Accuracies: [np.float64(0.676829268292683), np.float64(0.6518987341772152), np.float64(0.6878980891719745), np.float64(0.6666666666666666), np.float64(0.7425149700598802), np.float64(0.7409638554216867), np.float64(0.7222222222222222)]\n",
            "ID_TARGET: 251.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7055214723926381), np.float64(0.7590361445783133), np.float64(0.7950310559006211), np.float64(0.8051948051948052), np.float64(0.7232704402515723), np.float64(0.6982248520710059), np.float64(0.7514792899408284)]\n",
            "ID_TARGET: 278.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7320261437908496), np.float64(0.8012048192771084), np.float64(0.7692307692307693), np.float64(0.8205128205128205), np.float64(0.7516339869281046), np.float64(0.7409638554216867), np.float64(0.7635135135135135)]\n",
            "ID_TARGET: 76.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.2, 'num_leaves': 15, 'reg_alpha': 0.5, 'reg_lambda': 0.5} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7209302325581395), np.float64(0.7134502923976608), np.float64(0.7133757961783439), np.float64(0.7555555555555555), np.float64(0.7471910112359551), np.float64(0.75), np.float64(0.7888198757763976)]\n",
            "ID_TARGET: 241.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7647058823529411), np.float64(0.7452229299363057), np.float64(0.7806451612903226), np.float64(0.7677419354838709), np.float64(0.7806451612903226), np.float64(0.7701863354037267), np.float64(0.7793103448275862)]\n",
            "ID_TARGET: 214.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9166 | Fold Accuracies: [np.float64(0.8083832335329342), np.float64(0.8292682926829268), np.float64(0.8343949044585988), np.float64(0.8148148148148148), np.float64(0.813953488372093), np.float64(0.7559523809523809), np.float64(0.7215909090909091)]\n",
            "ID_TARGET: 102.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7770700636942676), np.float64(0.7341772151898734), np.float64(0.78125), np.float64(0.8516129032258064), np.float64(0.8104575163398693), np.float64(0.7469135802469136), np.float64(0.7692307692307693)]\n",
            "ID_TARGET: 145.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7559523809523809), np.float64(0.7960526315789473), np.float64(0.7261904761904762), np.float64(0.7421383647798742), np.float64(0.7848101265822784), np.float64(0.8113207547169812), np.float64(0.7362637362637363)]\n",
            "ID_TARGET: 155.0 | Best Params: {'bagging_fraction': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.001, 'min_child_samples': 10, 'min_gain_to_split': 0.0, 'num_leaves': 15, 'reg_alpha': 0.0, 'reg_lambda': 0.0} | Mean Accuracy: 0.9713 | Fold Accuracies: [np.float64(0.8142076502732241), np.float64(0.7468354430379747), np.float64(0.8563218390804598), np.float64(0.8166666666666667), np.float64(0.8148148148148148), np.float64(0.8011363636363636), np.float64(0.7707006369426752)]\n",
            "ID_TARGET: nan | Best Params: {} | Mean Accuracy: 0.0000 | Fold Accuracies: []\n",
            "\n",
            "Training XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "XGBoost Targets: 100%|| 101/101 [2:42:45<00:00, 96.69s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Weighted Accuracy: 1.0000\n",
            "\n",
            "XGBoost Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 129.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 136.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 161.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 217.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 91.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 137.0 | Best Params: {'colsample_bylevel': 0.8, 'gamma': 0.2, 'learning_rate': 0.005, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 8.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 3.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6986301369863014), np.float64(0.71875), np.float64(0.7421383647798742), np.float64(0.6685393258426966), np.float64(0.6423841059602649), np.float64(0.7152317880794702), np.float64(0.7261146496815286)]\n",
            "ID_TARGET: 9.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 131.0 | Best Params: {'colsample_bylevel': 0.8, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.5, 'reg_lambda': 1.5, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6171428571428571), np.float64(0.6835443037974683), np.float64(0.7142857142857143), np.float64(0.6647727272727273), np.float64(0.7197452229299363), np.float64(0.6597222222222222), np.float64(0.7278481012658228)]\n",
            "ID_TARGET: 21.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 54.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7770700636942676), np.float64(0.8741721854304636), np.float64(0.8457142857142858), np.float64(0.7125748502994012), np.float64(0.7151515151515152), np.float64(0.8641304347826086), np.float64(0.710691823899371)]\n",
            "ID_TARGET: 130.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7925531914893617), np.float64(0.8490566037735849), np.float64(0.8285714285714286), np.float64(0.7692307692307693), np.float64(0.6982248520710059), np.float64(0.7414965986394558), np.float64(0.7803468208092486)]\n",
            "ID_TARGET: 269.0 | Best Params: {'colsample_bylevel': 0.8, 'gamma': 0.2, 'learning_rate': 0.03, 'max_depth': 7, 'min_child_weight': 5, 'n_estimators': 300, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.75} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6408450704225352), np.float64(0.6451612903225806), np.float64(0.6558441558441559), np.float64(0.6089743589743589), np.float64(0.6601307189542484), np.float64(0.6797385620915033), np.float64(0.6556291390728477)]\n",
            "ID_TARGET: 157.0 | Best Params: {'colsample_bylevel': 0.8, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.5, 'reg_lambda': 1.5, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7225806451612903), np.float64(0.7328767123287672), np.float64(0.8490566037735849), np.float64(0.8211920529801324), np.float64(0.7070063694267515), np.float64(0.6948051948051948), np.float64(0.7167630057803468)]\n",
            "ID_TARGET: 249.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6936416184971098), np.float64(0.6783625730994152), np.float64(0.6410256410256411), np.float64(0.6686390532544378), np.float64(0.593103448275862), np.float64(0.7329192546583851), np.float64(0.7142857142857143)]\n",
            "ID_TARGET: 22.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 202.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 132.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 96.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 7.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 178.0 | Best Params: {'colsample_bylevel': 0.9, 'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 68.0 | Best Params: {'colsample_bylevel': 0.9, 'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 44.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 196.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 292.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 239.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 279.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 38.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 209.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 207.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 98.0 | Best Params: {'colsample_bylevel': 0.9, 'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 65.0 | Best Params: {'colsample_bylevel': 0.9, 'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 51.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 78.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 177.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 231.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 119.0 | Best Params: {'colsample_bylevel': 0.9, 'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 158.0 | Best Params: {'colsample_bylevel': 0.9, 'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 80.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 25.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 175.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 151.0 | Best Params: {'colsample_bylevel': 0.9, 'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 257.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 75.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 244.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 149.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 85.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 190.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 13.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 228.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 144.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 290.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 114.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 166.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 234.0 | Best Params: {'colsample_bylevel': 0.9, 'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 34.0 | Best Params: {'colsample_bylevel': 0.9, 'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 154.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 225.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 185.0 | Best Params: {'colsample_bylevel': 0.9, 'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 39.0 | Best Params: {'colsample_bylevel': 0.8, 'gamma': 0.2, 'learning_rate': 0.005, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 272.0 | Best Params: {'colsample_bylevel': 0.8, 'gamma': 0.2, 'learning_rate': 0.005, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 282.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 90.0 | Best Params: {'colsample_bylevel': 0.9, 'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 52.0 | Best Params: {'colsample_bylevel': 0.9, 'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 258.0 | Best Params: {'colsample_bylevel': 0.9, 'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 291.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 152.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 133.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 29.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 274.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 106.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 173.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 33.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 69.0 | Best Params: {'colsample_bylevel': 0.9, 'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 17.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 189.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 284.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 218.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 183.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 206.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 93.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 16.0 | Best Params: {'colsample_bylevel': 0.9, 'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 246.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 167.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 1.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 289.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 141.0 | Best Params: {'colsample_bylevel': 0.9, 'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 109.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 19.0 | Best Params: {'colsample_bylevel': 0.9, 'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 28.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 251.0 | Best Params: {'colsample_bylevel': 0.9, 'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 278.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 76.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 241.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 214.0 | Best Params: {'colsample_bylevel': 0.9, 'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 102.0 | Best Params: {'colsample_bylevel': 0.9, 'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 250, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.65} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 145.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 155.0 | Best Params: {'colsample_bylevel': 0.6, 'gamma': 0.0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: nan | Best Params: {} | Mean Accuracy: 0.0000 | Fold Accuracies: []\n",
            "\n",
            "Performing second-pass training with top 30 features...\n",
            "\n",
            "Second-pass LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rLightGBM Targets:   0%|          | 0/101 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   1%|          | 1/101 [00:02<03:36,  2.16s/it]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   2%|         | 2/101 [00:02<02:09,  1.30s/it]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   3%|         | 3/101 [00:03<01:40,  1.02s/it]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   4%|         | 4/101 [00:04<01:26,  1.12it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   5%|         | 5/101 [00:04<01:18,  1.23it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   6%|         | 6/101 [00:05<01:10,  1.35it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   7%|         | 7/101 [00:06<01:04,  1.45it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   8%|         | 8/101 [00:06<01:05,  1.42it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   9%|         | 9/101 [00:07<01:05,  1.41it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  10%|         | 10/101 [00:08<01:02,  1.46it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  11%|         | 11/101 [00:08<01:03,  1.43it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  12%|        | 12/101 [00:09<00:56,  1.58it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  13%|        | 13/101 [00:10<00:58,  1.51it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  14%|        | 14/101 [00:10<00:59,  1.46it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  15%|        | 15/101 [00:11<00:58,  1.46it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  16%|        | 16/101 [00:12<01:04,  1.32it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  17%|        | 17/101 [00:13<01:11,  1.17it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  18%|        | 18/101 [00:14<01:05,  1.27it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  19%|        | 19/101 [00:15<01:09,  1.18it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  20%|        | 20/101 [00:15<01:03,  1.28it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  21%|        | 21/101 [00:16<00:59,  1.34it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  22%|       | 22/101 [00:17<00:57,  1.38it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  23%|       | 23/101 [00:17<00:54,  1.42it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  24%|       | 24/101 [00:18<00:53,  1.45it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  25%|       | 25/101 [00:19<00:51,  1.48it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  26%|       | 26/101 [00:19<00:50,  1.47it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  27%|       | 27/101 [00:20<00:50,  1.46it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  28%|       | 28/101 [00:21<00:48,  1.52it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  29%|       | 29/101 [00:21<00:47,  1.51it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  30%|       | 30/101 [00:22<00:47,  1.50it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  31%|       | 31/101 [00:23<00:44,  1.56it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  32%|      | 32/101 [00:23<00:44,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  33%|      | 33/101 [00:24<00:43,  1.57it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  34%|      | 34/101 [00:24<00:42,  1.59it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  35%|      | 35/101 [00:25<00:48,  1.35it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  36%|      | 36/101 [00:26<00:46,  1.40it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  37%|      | 37/101 [00:27<00:50,  1.26it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  38%|      | 38/101 [00:28<00:51,  1.23it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  39%|      | 39/101 [00:28<00:44,  1.39it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  40%|      | 40/101 [00:29<00:42,  1.42it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  41%|      | 41/101 [00:30<00:38,  1.56it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  42%|     | 42/101 [00:30<00:37,  1.58it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  43%|     | 43/101 [00:31<00:36,  1.59it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  44%|     | 44/101 [00:31<00:33,  1.70it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  45%|     | 45/101 [00:32<00:33,  1.67it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  46%|     | 46/101 [00:33<00:33,  1.62it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  47%|     | 47/101 [00:33<00:34,  1.58it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  48%|     | 48/101 [00:34<00:31,  1.70it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  49%|     | 49/101 [00:34<00:30,  1.70it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  50%|     | 50/101 [00:35<00:28,  1.79it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  50%|     | 51/101 [00:35<00:28,  1.76it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  51%|    | 52/101 [00:36<00:26,  1.86it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  52%|    | 53/101 [00:36<00:26,  1.78it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  53%|    | 54/101 [00:37<00:27,  1.69it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  54%|    | 55/101 [00:38<00:28,  1.63it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  55%|    | 56/101 [00:39<00:32,  1.40it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  56%|    | 57/101 [00:40<00:33,  1.30it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  57%|    | 58/101 [00:40<00:32,  1.31it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  58%|    | 59/101 [00:41<00:30,  1.36it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  59%|    | 60/101 [00:42<00:29,  1.40it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  60%|    | 61/101 [00:42<00:27,  1.44it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  61%|   | 62/101 [00:43<00:24,  1.61it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  62%|   | 63/101 [00:43<00:22,  1.65it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  63%|   | 64/101 [00:44<00:22,  1.64it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  64%|   | 65/101 [00:45<00:22,  1.61it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  65%|   | 66/101 [00:45<00:21,  1.62it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  66%|   | 67/101 [00:46<00:19,  1.77it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  67%|   | 68/101 [00:46<00:19,  1.70it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  68%|   | 69/101 [00:47<00:19,  1.68it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  69%|   | 70/101 [00:48<00:18,  1.68it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  70%|   | 71/101 [00:48<00:18,  1.64it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  71%|  | 72/101 [00:49<00:17,  1.62it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  72%|  | 73/101 [00:49<00:16,  1.65it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  73%|  | 74/101 [00:50<00:16,  1.66it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  74%|  | 75/101 [00:51<00:16,  1.62it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  75%|  | 76/101 [00:51<00:15,  1.63it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  76%|  | 77/101 [00:52<00:14,  1.61it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  77%|  | 78/101 [00:53<00:16,  1.40it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  78%|  | 79/101 [00:54<00:18,  1.21it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  79%|  | 80/101 [00:55<00:16,  1.27it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  80%|  | 81/101 [00:55<00:15,  1.33it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  81%|  | 82/101 [00:56<00:12,  1.49it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  82%| | 83/101 [00:56<00:11,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  83%| | 84/101 [00:57<00:10,  1.67it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  84%| | 85/101 [00:57<00:08,  1.81it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  85%| | 86/101 [00:58<00:08,  1.73it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  86%| | 87/101 [00:59<00:08,  1.67it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  87%| | 88/101 [00:59<00:07,  1.68it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  88%| | 89/101 [01:00<00:07,  1.62it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  89%| | 90/101 [01:01<00:06,  1.60it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  90%| | 91/101 [01:01<00:06,  1.59it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  91%| | 92/101 [01:02<00:05,  1.72it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  92%|| 93/101 [01:02<00:04,  1.68it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  93%|| 94/101 [01:03<00:04,  1.66it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  94%|| 95/101 [01:03<00:03,  1.80it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  95%|| 96/101 [01:04<00:02,  1.76it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  96%|| 97/101 [01:05<00:02,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  97%|| 98/101 [01:06<00:02,  1.39it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  98%|| 99/101 [01:07<00:01,  1.23it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets: 100%|| 101/101 [01:08<00:00,  1.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: No features for ID_TARGET nan. Skipping.\n",
            "\n",
            "Second-pass XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Targets: 100%|| 101/101 [01:27<00:00,  1.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: No features for ID_TARGET nan. Skipping.\n",
            "\n",
            "Performing third-pass training for low-performing targets...\n",
            "\n",
            "Third-pass LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "LightGBM Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 54215.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Third-pass XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 54024.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Performing fourth-pass training for very low-performing targets...\n",
            "\n",
            "Fourth-pass LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "LightGBM Very Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 52488.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fourth-pass XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Very Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 125033.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved hyperparameter log to: /content/hyperparameters.json\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_12e04146-1999-437e-8c61-528ae5edc89e\", \"hyperparameters.json\", 4223252)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved predictions to: /content/predictions_ensemble.csv\n",
            "Output CSV shape: (114468, 2)\n",
            "Output CSV ID range: 0 to 114467\n",
            "Unique RET_TARGET values: [ 1 -1]\n",
            "Missing values: 0\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_0cc17f60-9865-4ab8-b543-09b541543e71\", \"predictions_ensemble.csv\", 940568)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Results:\n",
            "LightGBM: 0.9858\n",
            "XGBoost: 1.0000\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost\n",
        "from sklearn.decomposition import PCA\n",
        "from joblib import Parallel, delayed\n",
        "import json\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# Check xgboost version for compatibility\n",
        "print(f\"XGBoost version: {xgboost.__version__}\")\n",
        "if int(xgboost.__version__.split('.')[0]) < 1:\n",
        "    print(\"Warning: XGBoost version < 1.0.0 detected. Ensure compatibility with eval_metric in constructor.\")\n",
        "\n",
        "# Set up data directory\n",
        "DATA_DIR = '/content'\n",
        "\n",
        "# Load datasets\n",
        "try:\n",
        "    X_train = pd.read_csv(os.path.join(DATA_DIR, 'X_train_itDkypA.csv'), index_col='ID', dtype=np.float32)\n",
        "    y_train = pd.read_csv(os.path.join(DATA_DIR, 'y_train_3LeeT2g.csv'), index_col='ID', dtype=np.float32)\n",
        "    X_test = pd.read_csv(os.path.join(DATA_DIR, 'X_test_Beg4ey3.csv'), index_col='ID', dtype=np.float32)\n",
        "    supplementary = pd.read_csv(os.path.join(DATA_DIR, 'supplementary_data_Vkoyn8z.csv'))\n",
        "except FileNotFoundError as e:\n",
        "    raise FileNotFoundError(f\"Dataset not found: {e}. Please ensure files are uploaded to {DATA_DIR}.\")\n",
        "\n",
        "# Custom weighted accuracy metric\n",
        "def weighted_accuracy(y_true, y_pred, weights):\n",
        "    y_pred_mapped = np.where(y_pred == 1, 1, -1)\n",
        "    correct = (y_pred_mapped == np.sign(y_true)).astype(float)\n",
        "    return np.sum(np.abs(y_true) * correct) / np.sum(np.abs(y_true))\n",
        "\n",
        "# Preprocess data with enhanced feature selection\n",
        "def preprocess_data(X, y=None, supplementary=None, is_train=True, top_cols=None):\n",
        "    ret_cols = [col for col in X.columns if col.startswith('RET_')]\n",
        "\n",
        "    # Dynamic feature selection with minimum variance threshold\n",
        "    if is_train and top_cols is None:\n",
        "        if len(ret_cols) > 15:\n",
        "            variances = X[ret_cols].var()\n",
        "            corr_sum = X[ret_cols].corr().abs().sum()\n",
        "            combined_score = variances * corr_sum\n",
        "            valid_cols = variances[variances > 1e-5].index\n",
        "            if len(valid_cols) < 15:\n",
        "                top_cols = valid_cols.tolist()\n",
        "            else:\n",
        "                top_cols = combined_score.loc[valid_cols].sort_values(ascending=False).head(15).index.tolist()\n",
        "        else:\n",
        "            top_cols = ret_cols\n",
        "        print(f\"Selected top return columns: {top_cols}\")\n",
        "    elif top_cols is not None:\n",
        "        ret_cols = [col for col in ret_cols if col in top_cols]\n",
        "        if not ret_cols:\n",
        "            raise ValueError(\"No return columns selected. Check top_cols consistency.\")\n",
        "\n",
        "    # Cache sector-based medians\n",
        "    sector_medians = {}\n",
        "    if supplementary is not None:\n",
        "        sector_map = supplementary.set_index('ID_asset')['CLASS_LEVEL_1']\n",
        "        for col in ret_cols:\n",
        "            asset_id = int(col.replace('RET_', ''))\n",
        "            sector = sector_map.get(asset_id, np.nan)\n",
        "            if pd.notna(sector):\n",
        "                sector_assets = supplementary[supplementary['CLASS_LEVEL_1'] == sector]['ID_asset']\n",
        "                sector_cols = [f'RET_{a}' for a in sector_assets if f'RET_{a}' in X.columns]\n",
        "                if sector_cols:\n",
        "                    sector_medians[col] = X[sector_cols].median(axis=1)\n",
        "            if col in sector_medians:\n",
        "                X[col] = X[col].fillna(sector_medians[col])\n",
        "            else:\n",
        "                X[col] = X[col].fillna(X[col].median())\n",
        "\n",
        "    # Sector-based features\n",
        "    new_cols = {}\n",
        "    if supplementary is not None:\n",
        "        level = 'CLASS_LEVEL_1'\n",
        "        sector_groups = supplementary.groupby(level)['ID_asset'].apply(list).to_dict()\n",
        "        for sector, assets in sector_groups.items():\n",
        "            asset_cols = [f'RET_{asset}' for asset in assets if f'RET_{asset}' in ret_cols]\n",
        "            if asset_cols:\n",
        "                new_cols[f'SECTOR_AVG_{level}_{sector}'] = X[asset_cols].mean(axis=1).replace([np.inf, -np.inf], 0).fillna(0)\n",
        "        X = X.merge(supplementary[['ID_asset', level]].rename(columns={'ID_asset': 'ID_TARGET', level: f'TARGET_{level}'}),\n",
        "                    on='ID_TARGET', how='left')\n",
        "        X = pd.concat([X, pd.get_dummies(X[f'TARGET_{level}'], prefix=f'TARGET_{level}', dummy_na=True)], axis=1)\n",
        "        X = X.drop(f'TARGET_{level}', axis=1)\n",
        "\n",
        "    # Cross-sectional features\n",
        "    new_cols['MEAN_RET'] = X[ret_cols].mean(axis=1)\n",
        "    new_cols['STD_RET'] = X[ret_cols].std(axis=1)\n",
        "    new_cols.update({f'CS_RANK_{col}': X.groupby('ID_DAY')[col].rank(pct=True).replace([np.inf, -np.inf], 0).fillna(0) for col in ret_cols})\n",
        "\n",
        "    # Correlation-based features (top 5 pairs)\n",
        "    if is_train:\n",
        "        corr_matrix = X[ret_cols].corr()\n",
        "        corr_pairs = corr_matrix.unstack().sort_values(ascending=False)\n",
        "        top_pairs = [(i, j) for i, j in corr_pairs.index if i < j][:5]\n",
        "        for i, j in top_pairs:\n",
        "            new_cols[f'CORR_{i}_{j}'] = X[i] * X[j]\n",
        "\n",
        "    # PCA features (2 components)\n",
        "    if ret_cols:\n",
        "        pca = PCA(n_components=min(2, len(ret_cols)), random_state=42)\n",
        "        pca_features = pca.fit_transform(X[ret_cols].fillna(0))\n",
        "        for i in range(pca_features.shape[1]):\n",
        "            new_cols[f'PCA_{i}'] = pca_features[:, i]\n",
        "\n",
        "    # Add new features to DataFrame\n",
        "    new_cols_df = pd.DataFrame(new_cols, index=X.index, dtype=np.float32)\n",
        "    X = pd.concat([X, new_cols_df], axis=1)\n",
        "\n",
        "    # Standardize numerical features\n",
        "    feature_cols = [col for col in X.columns if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "    scaler = StandardScaler()\n",
        "    X[feature_cols] = scaler.fit_transform(X[feature_cols].replace([np.inf, -np.inf], 0).fillna(0))\n",
        "\n",
        "    if is_train:\n",
        "        y['SIGN_TARGET'] = np.where(y['RET_TARGET'] > 0, 1, 0).astype(np.int32)\n",
        "        return X, y, feature_cols, top_cols\n",
        "    return X, None, feature_cols, top_cols\n",
        "\n",
        "# Preprocess data\n",
        "try:\n",
        "    X_train, y_train, feature_cols, top_cols = preprocess_data(X_train, y_train, supplementary, is_train=True)\n",
        "    X_test, _, test_feature_cols, _ = preprocess_data(X_test, supplementary=supplementary, is_train=False, top_cols=top_cols)\n",
        "except ValueError as e:\n",
        "    print(f\"Preprocessing error: {e}\")\n",
        "    raise\n",
        "\n",
        "# Align columns\n",
        "common_cols = X_train.columns.intersection(X_test.columns)\n",
        "X_train = X_train[common_cols]\n",
        "X_test = X_test[common_cols]\n",
        "feature_cols = [col for col in common_cols if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "\n",
        "# Align y_train\n",
        "y_train = y_train.loc[X_train.index]\n",
        "\n",
        "# Define models with further expanded hyperparameter grids\n",
        "models = {\n",
        "    'LightGBM': {\n",
        "        'model': LGBMClassifier(num_leaves=31, min_child_samples=15, lambda_l1=0.3, lambda_l2=0.3,\n",
        "                                subsample=0.7, colsample_bytree=0.8, bagging_freq=5, bagging_fraction=0.7,\n",
        "                                random_state=42, n_jobs=1, verbosity=-1, class_weight='balanced', force_row_wise=True),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.001], 'num_leaves': [15], 'min_child_samples': [10], 'bagging_fraction': [0.6], 'reg_alpha': [0.0], 'reg_lambda': [0.0], 'colsample_bytree': [0.6], 'min_gain_to_split': [0.0]},\n",
        "            {'learning_rate': [0.003], 'num_leaves': [31], 'min_child_samples': [15], 'bagging_fraction': [0.7], 'reg_alpha': [0.1], 'reg_lambda': [0.1], 'colsample_bytree': [0.7], 'min_gain_to_split': [0.1]},\n",
        "            {'learning_rate': [0.005], 'num_leaves': [47], 'min_child_samples': [20], 'bagging_fraction': [0.8], 'reg_alpha': [0.2], 'reg_lambda': [0.2], 'colsample_bytree': [0.8], 'min_gain_to_split': [0.0]},\n",
        "            {'learning_rate': [0.01], 'num_leaves': [63], 'min_child_samples': [12], 'bagging_fraction': [0.65], 'reg_alpha': [0.3], 'reg_lambda': [0.3], 'colsample_bytree': [0.9], 'min_gain_to_split': [0.1]},\n",
        "            {'learning_rate': [0.03], 'num_leaves': [79], 'min_child_samples': [30], 'bagging_fraction': [0.75], 'reg_alpha': [0.4], 'reg_lambda': [0.4], 'colsample_bytree': [0.6], 'min_gain_to_split': [0.2]},\n",
        "            {'learning_rate': [0.05], 'num_leaves': [15], 'min_child_samples': [10], 'bagging_fraction': [0.6], 'reg_alpha': [0.0], 'reg_lambda': [0.1], 'colsample_bytree': [0.7], 'min_gain_to_split': [0.0]},\n",
        "            {'learning_rate': [0.07], 'num_leaves': [31], 'min_child_samples': [15], 'bagging_fraction': [0.7], 'reg_alpha': [0.2], 'reg_lambda': [0.0], 'colsample_bytree': [0.8], 'min_gain_to_split': [0.1]},\n",
        "            {'learning_rate': [0.1], 'num_leaves': [47], 'min_child_samples': [20], 'bagging_fraction': [0.8], 'reg_alpha': [0.1], 'reg_lambda': [0.3], 'colsample_bytree': [0.9], 'min_gain_to_split': [0.2]},\n",
        "            {'learning_rate': [0.15], 'num_leaves': [63], 'min_child_samples': [12], 'bagging_fraction': [0.65], 'reg_alpha': [0.3], 'reg_lambda': [0.2], 'colsample_bytree': [0.6], 'min_gain_to_split': [0.0]},\n",
        "            {'learning_rate': [0.2], 'num_leaves': [79], 'min_child_samples': [30], 'bagging_fraction': [0.75], 'reg_alpha': [0.4], 'reg_lambda': [0.1], 'colsample_bytree': [0.7], 'min_gain_to_split': [0.1]},\n",
        "            {'learning_rate': [0.001], 'num_leaves': [15], 'min_child_samples': [10], 'bagging_fraction': [0.6], 'reg_alpha': [0.5], 'reg_lambda': [0.5], 'colsample_bytree': [0.8], 'min_gain_to_split': [0.2]},\n",
        "            {'learning_rate': [0.003], 'num_leaves': [31], 'min_child_samples': [15], 'bagging_fraction': [0.7], 'reg_alpha': [0.0], 'reg_lambda': [0.0], 'colsample_bytree': [0.9], 'min_gain_to_split': [0.0]},\n",
        "            {'learning_rate': [0.005], 'num_leaves': [47], 'min_child_samples': [20], 'bagging_fraction': [0.8], 'reg_alpha': [0.2], 'reg_lambda': [0.2], 'colsample_bytree': [0.6], 'min_gain_to_split': [0.1]},\n",
        "            {'learning_rate': [0.01], 'num_leaves': [63], 'min_child_samples': [12], 'bagging_fraction': [0.65], 'reg_alpha': [0.1], 'reg_lambda': [0.3], 'colsample_bytree': [0.7], 'min_gain_to_split': [0.2]},\n",
        "            {'learning_rate': [0.03], 'num_leaves': [79], 'min_child_samples': [30], 'bagging_fraction': [0.75], 'reg_alpha': [0.3], 'reg_lambda': [0.4], 'colsample_bytree': [0.8], 'min_gain_to_split': [0.0]},\n",
        "            {'learning_rate': [0.05], 'num_leaves': [15], 'min_child_samples': [10], 'bagging_fraction': [0.6], 'reg_alpha': [0.4], 'reg_lambda': [0.1], 'colsample_bytree': [0.9], 'min_gain_to_split': [0.1]},\n",
        "            {'learning_rate': [0.07], 'num_leaves': [31], 'min_child_samples': [15], 'bagging_fraction': [0.7], 'reg_alpha': [0.5], 'reg_lambda': [0.5], 'colsample_bytree': [0.6], 'min_gain_to_split': [0.2]},\n",
        "            {'learning_rate': [0.1], 'num_leaves': [47], 'min_child_samples': [20], 'bagging_fraction': [0.8], 'reg_alpha': [0.0], 'reg_lambda': [0.0], 'colsample_bytree': [0.7], 'min_gain_to_split': [0.0]},\n",
        "            {'learning_rate': [0.15], 'num_leaves': [63], 'min_child_samples': [12], 'bagging_fraction': [0.65], 'reg_alpha': [0.2], 'reg_lambda': [0.2], 'colsample_bytree': [0.8], 'min_gain_to_split': [0.1]},\n",
        "            {'learning_rate': [0.2], 'num_leaves': [79], 'min_child_samples': [30], 'bagging_fraction': [0.75], 'reg_alpha': [0.1], 'reg_lambda': [0.3], 'colsample_bytree': [0.9], 'min_gain_to_split': [0.2]},\n",
        "            {'learning_rate': [0.001], 'num_leaves': [15], 'min_child_samples': [10], 'bagging_fraction': [0.6], 'reg_alpha': [0.3], 'reg_lambda': [0.4], 'colsample_bytree': [0.6], 'min_gain_to_split': [0.0]},\n",
        "            {'learning_rate': [0.003], 'num_leaves': [31], 'min_child_samples': [15], 'bagging_fraction': [0.7], 'reg_alpha': [0.4], 'reg_lambda': [0.1], 'colsample_bytree': [0.7], 'min_gain_to_split': [0.1]},\n",
        "            {'learning_rate': [0.005], 'num_leaves': [47], 'min_child_samples': [20], 'bagging_fraction': [0.8], 'reg_alpha': [0.5], 'reg_lambda': [0.5], 'colsample_bytree': [0.8], 'min_gain_to_split': [0.2]},\n",
        "            {'learning_rate': [0.01], 'num_leaves': [63], 'min_child_samples': [12], 'bagging_fraction': [0.65], 'reg_alpha': [0.0], 'reg_lambda': [0.0], 'colsample_bytree': [0.9], 'min_gain_to_split': [0.0]}\n",
        "        ],\n",
        "        'callbacks': [lightgbm.early_stopping(stopping_rounds=15, verbose=False)]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'model': XGBClassifier(max_depth=4, min_child_weight=2, subsample=0.8, colsample_bytree=0.8,\n",
        "                               random_state=42, n_jobs=1, eval_metric='logloss', verbosity=0,\n",
        "                               scale_pos_weight=len(y_train[y_train['SIGN_TARGET'] == 0]) / len(y_train[y_train['SIGN_TARGET'] == 1])),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.001], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [100], 'reg_alpha': [0.0], 'reg_lambda': [1.0], 'gamma': [0.0], 'colsample_bylevel': [0.6]},\n",
        "            {'learning_rate': [0.003], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [150], 'reg_alpha': [0.5], 'reg_lambda': [1.5], 'gamma': [0.1], 'colsample_bylevel': [0.7]},\n",
        "            {'learning_rate': [0.005], 'max_depth': [5], 'min_child_weight': [3], 'subsample': [0.8], 'n_estimators': [200], 'reg_alpha': [1.0], 'reg_lambda': [2.0], 'gamma': [0.2], 'colsample_bylevel': [0.8]},\n",
        "            {'learning_rate': [0.01], 'max_depth': [6], 'min_child_weight': [4], 'subsample': [0.65], 'n_estimators': [250], 'reg_alpha': [0.0], 'reg_lambda': [1.0], 'gamma': [0.0], 'colsample_bylevel': [0.9]},\n",
        "            {'learning_rate': [0.03], 'max_depth': [7], 'min_child_weight': [5], 'subsample': [0.75], 'n_estimators': [300], 'reg_alpha': [0.5], 'reg_lambda': [1.5], 'gamma': [0.1], 'colsample_bylevel': [0.6]},\n",
        "            {'learning_rate': [0.05], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [100], 'reg_alpha': [1.0], 'reg_lambda': [2.0], 'gamma': [0.2], 'colsample_bylevel': [0.7]},\n",
        "            {'learning_rate': [0.07], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [150], 'reg_alpha': [0.0], 'reg_lambda': [1.0], 'gamma': [0.0], 'colsample_bylevel': [0.8]},\n",
        "            {'learning_rate': [0.1], 'max_depth': [5], 'min_child_weight': [3], 'subsample': [0.8], 'n_estimators': [200], 'reg_alpha': [0.5], 'reg_lambda': [1.5], 'gamma': [0.1], 'colsample_bylevel': [0.9]},\n",
        "            {'learning_rate': [0.15], 'max_depth': [6], 'min_child_weight': [4], 'subsample': [0.65], 'n_estimators': [250], 'reg_alpha': [1.0], 'reg_lambda': [2.0], 'gamma': [0.2], 'colsample_bylevel': [0.6]},\n",
        "            {'learning_rate': [0.2], 'max_depth': [7], 'min_child_weight': [5], 'subsample': [0.75], 'n_estimators': [300], 'reg_alpha': [0.0], 'reg_lambda': [1.0], 'gamma': [0.0], 'colsample_bylevel': [0.7]},\n",
        "            {'learning_rate': [0.001], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [100], 'reg_alpha': [0.5], 'reg_lambda': [1.5], 'gamma': [0.1], 'colsample_bylevel': [0.8]},\n",
        "            {'learning_rate': [0.003], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [150], 'reg_alpha': [1.0], 'reg_lambda': [2.0], 'gamma': [0.2], 'colsample_bylevel': [0.9]},\n",
        "            {'learning_rate': [0.005], 'max_depth': [5], 'min_child_weight': [3], 'subsample': [0.8], 'n_estimators': [200], 'reg_alpha': [0.0], 'reg_lambda': [1.0], 'gamma': [0.0], 'colsample_bylevel': [0.6]},\n",
        "            {'learning_rate': [0.01], 'max_depth': [6], 'min_child_weight': [4], 'subsample': [0.65], 'n_estimators': [250], 'reg_alpha': [0.5], 'reg_lambda': [1.5], 'gamma': [0.1], 'colsample_bylevel': [0.7]},\n",
        "            {'learning_rate': [0.03], 'max_depth': [7], 'min_child_weight': [5], 'subsample': [0.75], 'n_estimators': [300], 'reg_alpha': [1.0], 'reg_lambda': [2.0], 'gamma': [0.2], 'colsample_bylevel': [0.8]},\n",
        "            {'learning_rate': [0.05], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [100], 'reg_alpha': [0.0], 'reg_lambda': [1.0], 'gamma': [0.0], 'colsample_bylevel': [0.9]},\n",
        "            {'learning_rate': [0.07], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [150], 'reg_alpha': [0.5], 'reg_lambda': [1.5], 'gamma': [0.1], 'colsample_bylevel': [0.6]},\n",
        "            {'learning_rate': [0.1], 'max_depth': [5], 'min_child_weight': [3], 'subsample': [0.8], 'n_estimators': [200], 'reg_alpha': [1.0], 'reg_lambda': [2.0], 'gamma': [0.2], 'colsample_bylevel': [0.7]},\n",
        "            {'learning_rate': [0.15], 'max_depth': [6], 'min_child_weight': [4], 'subsample': [0.65], 'n_estimators': [250], 'reg_alpha': [0.0], 'reg_lambda': [1.0], 'gamma': [0.0], 'colsample_bylevel': [0.8]},\n",
        "            {'learning_rate': [0.2], 'max_depth': [7], 'min_child_weight': [5], 'subsample': [0.75], 'n_estimators': [300], 'reg_alpha': [0.5], 'reg_lambda': [1.5], 'gamma': [0.1], 'colsample_bylevel': [0.9]},\n",
        "            {'learning_rate': [0.001], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [100], 'reg_alpha': [1.0], 'reg_lambda': [2.0], 'gamma': [0.2], 'colsample_bylevel': [0.6]},\n",
        "            {'learning_rate': [0.003], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [150], 'reg_alpha': [0.0], 'reg_lambda': [1.0], 'gamma': [0.0], 'colsample_bylevel': [0.7]},\n",
        "            {'learning_rate': [0.005], 'max_depth': [5], 'min_child_weight': [3], 'subsample': [0.8], 'n_estimators': [200], 'reg_alpha': [0.5], 'reg_lambda': [1.5], 'gamma': [0.1], 'colsample_bylevel': [0.8]},\n",
        "            {'learning_rate': [0.01], 'max_depth': [6], 'min_child_weight': [4], 'subsample': [0.65], 'n_estimators': [250], 'reg_alpha': [1.0], 'reg_lambda': [2.0], 'gamma': [0.2], 'colsample_bylevel': [0.9]}\n",
        "        ],\n",
        "        'callbacks': [xgboost.callback.EarlyStopping(rounds=15, metric_name='logloss', save_best=True)]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to train and predict for a single target\n",
        "def train_target(target, X_train, y_train, X_test, feature_cols, model, model_name, kf, param_grid, callbacks):\n",
        "    X_target = X_train[X_train['ID_TARGET'] == target][feature_cols]\n",
        "    y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "    weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "    low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "    # Dynamic weight scaling based on sample size\n",
        "    weight_scale = 2.0 if target in low_performing_targets else 1.0\n",
        "    if len(X_target) < 500:\n",
        "        weight_scale *= 1.5  # Boost weights for small targets\n",
        "    weights = weights * weight_scale\n",
        "    groups = X_train[X_train['ID_TARGET'] == target]['ID_DAY']\n",
        "    X_test_target = X_test[X_test['ID_TARGET'] == target][feature_cols]\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "    # Check for sufficient data\n",
        "    if len(X_target) < 100 or len(X_test_target) == 0:\n",
        "        print(f\"Warning: Insufficient data for ID_TARGET {target} (train: {len(X_target)}, test: {len(X_test_target)}). Skipping.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    param_results = []\n",
        "    best_params = None\n",
        "    best_score = 0\n",
        "    best_model = None\n",
        "\n",
        "    # First-pass grid search with sample weights\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        print(f\"Testing params for {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "        try:\n",
        "            model.set_params(**params)\n",
        "        except ValueError as e:\n",
        "            print(f\"Invalid params for {model_name} ID_TARGET {target}: {e}\")\n",
        "            continue\n",
        "        fold_accuracies = []\n",
        "        for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "            X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "            y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "            w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "\n",
        "            if model_name == 'LightGBM' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=callbacks)\n",
        "            elif model_name == 'XGBoost' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "            else:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "            y_pred = model.predict(X_val)\n",
        "            acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "            fold_accuracies.append(acc)\n",
        "\n",
        "        mean_acc = np.mean(fold_accuracies)\n",
        "        print(f\"{model_name} | ID_TARGET: {target} | Params: {params} | Mean Accuracy: {mean_acc:.4f} | Fold Accuracies: {fold_accuracies}\", flush=True)\n",
        "        param_results.append({\n",
        "            'params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': fold_accuracies\n",
        "        })\n",
        "        if mean_acc > best_score:\n",
        "            best_score = mean_acc\n",
        "            best_params = params\n",
        "            best_model = type(model)(**model.get_params())\n",
        "\n",
        "    # Train with best parameters\n",
        "    if best_model is None:\n",
        "        print(f\"No valid model for {model_name} ID_TARGET {target}. Using default.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    best_model.set_params(**best_params)\n",
        "    if model_name == 'LightGBM' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=callbacks)\n",
        "    elif model_name == 'XGBoost' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "    else:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights)\n",
        "\n",
        "    # Predict\n",
        "    preds = best_model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "\n",
        "    # Feature importance\n",
        "    importance = best_model.feature_importances_\n",
        "    feature_importance = dict(zip(feature_cols, importance))\n",
        "    top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:30]\n",
        "\n",
        "    # Clean up memory\n",
        "    gc.collect()\n",
        "\n",
        "    return str(target), best_params, best_score, param_results, test_ids, preds, top_features\n",
        "\n",
        "# Cross-validation and training\n",
        "kf = GroupKFold(n_splits=7)  # Increased to 7 folds\n",
        "results = {}\n",
        "predictions = {}\n",
        "ensemble_weights = {'LightGBM': 0.7, 'XGBoost': 0.3}\n",
        "param_log = {}\n",
        "top_features_all = {}\n",
        "param_summary = []\n",
        "low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\", flush=True)\n",
        "    param_log[model_name] = {}\n",
        "    top_features_all[model_name] = {}\n",
        "\n",
        "    # First-pass training\n",
        "    results_parallel = Parallel(n_jobs=-1)(\n",
        "        delayed(train_target)(target, X_train, y_train, X_test, feature_cols, model_info['model'], model_name, kf,\n",
        "                             model_info['param_grid'], model_info['callbacks'])\n",
        "        for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\")\n",
        "    )\n",
        "\n",
        "    # Collect results\n",
        "    accuracies = []\n",
        "    for target, params, mean_acc, param_results, test_ids, preds, top_features in results_parallel:\n",
        "        param_log[model_name][target] = {\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'all_params': param_results\n",
        "        }\n",
        "        top_features_all[model_name][target] = top_features\n",
        "        accuracies.append(mean_acc)\n",
        "        predictions.setdefault(target, {})[model_name] = dict(zip(test_ids, preds))\n",
        "        param_summary.append({\n",
        "            'model': model_name,\n",
        "            'ID_TARGET': target,\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': param_results[-1]['fold_accuracies'] if param_results else []\n",
        "        })\n",
        "\n",
        "    results[model_name] = np.mean([acc for acc in accuracies if acc > 0])  # Exclude skipped targets\n",
        "    print(f\"{model_name} Weighted Accuracy: {results[model_name]:.4f}\", flush=True)\n",
        "\n",
        "    # Print parameter summary\n",
        "    print(f\"\\n{model_name} Parameter Summary:\", flush=True)\n",
        "    for summary in param_summary:\n",
        "        if summary['model'] == model_name:\n",
        "            print(f\"ID_TARGET: {summary['ID_TARGET']} | Best Params: {summary['best_params']} | Mean Accuracy: {summary['mean_accuracy']:.4f} | Fold Accuracies: {summary['fold_accuracies']}\", flush=True)\n",
        "\n",
        "# Second-pass training with top 30 features\n",
        "print(\"\\nPerforming second-pass training with top 30 features...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nSecond-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\"):\n",
        "        target_str = str(target)\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "        weight_scale = 2.0 if target in low_performing_targets else 1.0\n",
        "        if len(X_target) < 500:\n",
        "            weight_scale *= 1.5\n",
        "        weights = weights * weight_scale\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        best_params['n_estimators'] = 300  # Use integer instead of list\n",
        "        model.set_params(**best_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Third-pass training for low-performing targets\n",
        "print(\"\\nPerforming third-pass training for low-performing targets...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nThird-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(low_performing_targets, desc=f\"{model_name} Low-Performing Targets\"):\n",
        "        target_str = str(target)\n",
        "        if target_str not in param_log[model_name] or param_log[model_name][target_str]['mean_accuracy'] >= 0.75:\n",
        "            continue  # Skip if already performing well\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs() * 3.0  # Increase weight\n",
        "        if len(X_target) < 500:\n",
        "            weights = weights * 1.5\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        # Further expanded fine-tuning grid for low-performing targets\n",
        "        fine_tune_grid = [\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.2, 'n_estimators': 400, 'reg_alpha': best_params['reg_alpha'][0] + 0.4, 'reg_lambda': best_params['reg_lambda'][0] + 0.4},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.3, 'n_estimators': 450, 'reg_alpha': best_params['reg_alpha'][0] + 0.3, 'reg_lambda': best_params['reg_lambda'][0] + 0.3},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.5, 'n_estimators': 500, 'reg_alpha': best_params['reg_alpha'][0] + 0.2, 'reg_lambda': best_params['reg_lambda'][0] + 0.2},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.7, 'n_estimators': 550, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.0, 'n_estimators': 400, 'reg_alpha': best_params['reg_alpha'][0], 'reg_lambda': best_params['reg_lambda'][0]},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.2, 'n_estimators': 450, 'reg_alpha': best_params['reg_alpha'][0] + 0.15, 'reg_lambda': best_params['reg_lambda'][0] + 0.15},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.5, 'n_estimators': 500, 'reg_alpha': best_params['reg_alpha'][0] + 0.25, 'reg_lambda': best_params['reg_lambda'][0] + 0.25},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.7, 'n_estimators': 550, 'reg_alpha': best_params['reg_alpha'][0] + 0.3, 'reg_lambda': best_params['reg_lambda'][0] + 0.3},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 2.0, 'n_estimators': 600, 'reg_alpha': best_params['reg_alpha'][0] + 0.2, 'reg_lambda': best_params['reg_lambda'][0] + 0.2},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.4, 'n_estimators': 650, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.8, 'n_estimators': 700, 'reg_alpha': best_params['reg_alpha'][0] + 0.15, 'reg_lambda': best_params['reg_lambda'][0] + 0.15},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.3, 'n_estimators': 450, 'reg_alpha': best_params['reg_alpha'][0] + 0.3, 'reg_lambda': best_params['reg_lambda'][0] + 0.3}\n",
        "        ]\n",
        "        best_score = param_log[model_name][target_str]['mean_accuracy']\n",
        "        best_fine_params = best_params\n",
        "\n",
        "        for params in ParameterGrid(fine_tune_grid):\n",
        "            print(f\"Fine-tuning {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "            model.set_params(**params)\n",
        "            fold_accuracies = []\n",
        "            for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "                X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "                y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "                w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "                if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "                elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "                else:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "                y_pred = model.predict(X_val)\n",
        "                acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "                fold_accuracies.append(acc)\n",
        "            mean_acc = np.mean(fold_accuracies)\n",
        "            print(f\"{model_name} | ID_TARGET: {target} | Fine-tune Params: {params} | Mean Accuracy: {mean_acc:.4f}\", flush=True)\n",
        "            if mean_acc > best_score:\n",
        "                best_score = mean_acc\n",
        "                best_fine_params = params\n",
        "                param_log[model_name][target_str]['best_params'] = best_fine_params\n",
        "                param_log[model_name][target_str]['mean_accuracy'] = best_score\n",
        "                param_summary.append({\n",
        "                    'model': model_name,\n",
        "                    'ID_TARGET': target_str,\n",
        "                    'best_params': best_fine_params,\n",
        "                    'mean_accuracy': best_score,\n",
        "                    'fold_accuracies': fold_accuracies\n",
        "                })\n",
        "\n",
        "        # Retrain with fine-tuned parameters\n",
        "        model.set_params(**best_fine_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Fourth-pass training for very low-performing targets\n",
        "print(\"\\nPerforming fourth-pass training for very low-performing targets...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nFourth-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(low_performing_targets, desc=f\"{model_name} Very Low-Performing Targets\"):\n",
        "        target_str = str(target)\n",
        "        if target_str not in param_log[model_name] or param_log[model_name][target_str]['mean_accuracy'] >= 0.70:\n",
        "            continue  # Skip if accuracy >= 0.70\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs() * 3.0  # High weight\n",
        "        if len(X_target) < 500:\n",
        "            weights = weights * 1.5\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        # Further expanded fine-tuning grid for very low-performing targets\n",
        "        fine_tune_grid = [\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.1, 'n_estimators': 400, 'reg_alpha': best_params['reg_alpha'][0] + 0.5, 'reg_lambda': best_params['reg_lambda'][0] + 0.5},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.2, 'n_estimators': 450, 'reg_alpha': best_params['reg_alpha'][0] + 0.4, 'reg_lambda': best_params['reg_lambda'][0] + 0.4},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.4, 'n_estimators': 500, 'reg_alpha': best_params['reg_alpha'][0] + 0.3, 'reg_lambda': best_params['reg_lambda'][0] + 0.3},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.6, 'n_estimators': 550, 'reg_alpha': best_params['reg_alpha'][0] + 0.2, 'reg_lambda': best_params['reg_lambda'][0] + 0.2},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.8, 'n_estimators': 600, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.0, 'n_estimators': 400, 'reg_alpha': best_params['reg_alpha'][0], 'reg_lambda': best_params['reg_lambda'][0]},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.2, 'n_estimators': 450, 'reg_alpha': best_params['reg_alpha'][0] + 0.15, 'reg_lambda': best_params['reg_lambda'][0] + 0.15},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.5, 'n_estimators': 500, 'reg_alpha': best_params['reg_alpha'][0] + 0.25, 'reg_lambda': best_params['reg_lambda'][0] + 0.25},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.7, 'n_estimators': 550, 'reg_alpha': best_params['reg_alpha'][0] + 0.3, 'reg_lambda': best_params['reg_lambda'][0] + 0.3},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 2.0, 'n_estimators': 600, 'reg_alpha': best_params['reg_alpha'][0] + 0.2, 'reg_lambda': best_params['reg_lambda'][0] + 0.2},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.3, 'n_estimators': 650, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.5, 'n_estimators': 700, 'reg_alpha': best_params['reg_alpha'][0] + 0.15, 'reg_lambda': best_params['reg_lambda'][0] + 0.15}\n",
        "        ]\n",
        "        best_score = param_log[model_name][target_str]['mean_accuracy']\n",
        "        best_fine_params = best_params\n",
        "\n",
        "        for params in ParameterGrid(fine_tune_grid):\n",
        "            print(f\"Fine-tuning {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "            model.set_params(**params)\n",
        "            fold_accuracies = []\n",
        "            for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "                X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "                y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "                w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "                if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "                elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "                else:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "                y_pred = model.predict(X_val)\n",
        "                acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "                fold_accuracies.append(acc)\n",
        "            mean_acc = np.mean(fold_accuracies)\n",
        "            print(f\"{model_name} | ID_TARGET: {target} | Fine-tune Params: {params} | Mean Accuracy: {mean_acc:.4f}\", flush=True)\n",
        "            if mean_acc > best_score:\n",
        "                best_score = mean_acc\n",
        "                best_fine_params = params\n",
        "                param_log[model_name][target_str]['best_params'] = best_fine_params\n",
        "                param_log[model_name][target_str]['mean_accuracy'] = best_score\n",
        "                param_summary.append({\n",
        "                    'model': model_name,\n",
        "                    'ID_TARGET': target_str,\n",
        "                    'best_params': best_fine_params,\n",
        "                    'mean_accuracy': best_score,\n",
        "                    'fold_accuracies': fold_accuracies\n",
        "                })\n",
        "\n",
        "        # Retrain with fine-tuned parameters\n",
        "        model.set_params(**best_fine_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Save parameter log\n",
        "param_log_path = os.path.join(DATA_DIR, 'hyperparameters.json')\n",
        "with open(param_log_path, 'w') as f:\n",
        "    json.dump(param_log, f, indent=4)\n",
        "print(f\"Saved hyperparameter log to: {param_log_path}\", flush=True)\n",
        "files.download(param_log_path)\n",
        "\n",
        "# Ensemble predictions\n",
        "final_predictions = {}\n",
        "missing_day_targets = []\n",
        "for target in X_test['ID_TARGET'].unique():\n",
        "    target_str = str(target)\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "    for day in X_test[X_test['ID_TARGET'] == target]['ID_DAY'].unique():\n",
        "        day_idx = (X_test['ID_TARGET'] == target) & (X_test['ID_DAY'] == day)\n",
        "        day_test_ids = X_test[day_idx].index\n",
        "        if len(day_test_ids) == 0:\n",
        "            print(f\"Warning: No test samples for ID_TARGET {target} on ID_DAY {day}. Using default prediction.\")\n",
        "            missing_day_targets.append((target, day))\n",
        "            for idx in test_ids:\n",
        "                final_predictions[idx] = -1\n",
        "            continue\n",
        "        lgbm_preds = np.array([predictions[target_str].get('LightGBM', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        xgb_preds = np.array([predictions[target_str].get('XGBoost', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        ensemble_preds = ensemble_weights['LightGBM'] * lgbm_preds + ensemble_weights['XGBoost'] * xgb_preds\n",
        "        # Apply exponential moving average for smoothing\n",
        "        smoothed_preds = pd.Series(ensemble_preds).ewm(span=3).mean().values[-1] if len(ensemble_preds) > 0 else 0.5\n",
        "        for idx in day_test_ids:\n",
        "            final_predictions[idx] = 1 if smoothed_preds >= 0.5 else -1\n",
        "\n",
        "if missing_day_targets:\n",
        "    print(f\"Missing day-target pairs: {missing_day_targets}\")\n",
        "\n",
        "# Create output CSV\n",
        "output_df = pd.DataFrame.from_dict(final_predictions, orient='index', columns=['RET_TARGET']).reset_index()\n",
        "output_df.columns = ['ID', 'RET_TARGET']\n",
        "output_df = output_df.sort_values('ID')\n",
        "expected_ids = set(X_test.index)\n",
        "submission_ids = set(output_df['ID'])\n",
        "if expected_ids != submission_ids:\n",
        "    missing_ids = expected_ids - submission_ids\n",
        "    print(f\"Warning: Submission missing {len(missing_ids)} IDs: {missing_ids}\")\n",
        "    missing_df = pd.DataFrame({'ID': list(missing_ids), 'RET_TARGET': -1})\n",
        "    output_df = pd.concat([output_df, missing_df], ignore_index=True).sort_values('ID')\n",
        "output_path = os.path.join(DATA_DIR, 'predictions_ensemble.csv')\n",
        "output_df.to_csv(output_path, index=False)\n",
        "print(f\"Saved predictions to: {output_path}\", flush=True)\n",
        "\n",
        "# Validate output\n",
        "test_csv = pd.read_csv(output_path)\n",
        "print(f\"Output CSV shape: {test_csv.shape}\", flush=True)\n",
        "print(f\"Output CSV ID range: {test_csv['ID'].min()} to {test_csv['ID'].max()}\", flush=True)\n",
        "print(f\"Unique RET_TARGET values: {test_csv['RET_TARGET'].unique()}\", flush=True)\n",
        "print(f\"Missing values: {test_csv.isna().sum().sum()}\", flush=True)\n",
        "\n",
        "# Download the file\n",
        "files.download(output_path)\n",
        "\n",
        "# Print final results\n",
        "print(\"\\nValidation Results:\", flush=True)\n",
        "for model_name, acc in results.items():\n",
        "    print(f\"{model_name}: {acc:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3Ei9bbl0oG7"
      },
      "source": [
        "New method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW9BAzmO2cto",
        "outputId": "3f26c6e1-46f8-4409-8ad8-a1c46f3012db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting arch\n",
            "  Downloading arch-7.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from arch) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.11/dist-packages (from arch) (1.15.3)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.11/dist-packages (from arch) (2.2.2)\n",
            "Requirement already satisfied: statsmodels>=0.12 in /usr/local/lib/python3.11/dist-packages (from arch) (0.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->arch) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->arch) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->arch) (2025.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.12->arch) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.12->arch) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4->arch) (1.17.0)\n",
            "Downloading arch-7.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (985 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m985.3/985.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: arch\n",
            "Successfully installed arch-7.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install arch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "KoLhXBbm0pN0",
        "outputId": "ae059bd4-97c4-45be-c965-04786c50d494"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost version: 2.1.4\n",
            "Selected top return columns: ['RET_262', 'RET_88', 'RET_172', 'RET_259', 'RET_150', 'RET_118', 'RET_216', 'RET_268']\n",
            "\n",
            "Training LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "LightGBM Targets:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-1665543012.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;31m# First-pass training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m     results_parallel = Parallel(n_jobs=-1)(\n\u001b[0m\u001b[1;32m    309\u001b[0m         delayed(train_target)(target, X_train_inner, y_train_inner, X_test, feature_cols, model_info['model'], model_name, kf,\n\u001b[1;32m    310\u001b[0m                              model_info['param_grid'], model_info['callbacks'], batch_size=500)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost\n",
        "from sklearn.decomposition import PCA\n",
        "from joblib import Parallel, delayed\n",
        "import json\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# Check xgboost version for compatibility\n",
        "print(f\"XGBoost version: {xgboost.__version__}\")\n",
        "if int(xgboost.__version__.split('.')[0]) < 1:\n",
        "    print(\"Warning: XGBoost version < 1.0.0 detected. Ensure compatibility with eval_metric in constructor.\")\n",
        "\n",
        "# Set up data directory\n",
        "DATA_DIR = '/content'\n",
        "\n",
        "# Load datasets with minimal memory\n",
        "try:\n",
        "    X_train = pd.read_csv(os.path.join(DATA_DIR, 'X_train_itDkypA.csv'), index_col='ID', dtype=np.float32)\n",
        "    y_train = pd.read_csv(os.path.join(DATA_DIR, 'y_train_3LeeT2g.csv'), index_col='ID', dtype=np.float32)\n",
        "    X_test = pd.read_csv(os.path.join(DATA_DIR, 'X_test_Beg4ey3.csv'), index_col='ID', dtype=np.float32)\n",
        "    supplementary = pd.read_csv(os.path.join(DATA_DIR, 'supplementary_data_Vkoyn8z.csv'), dtype={'ID_asset': np.int32, 'CLASS_LEVEL_1': 'category'})\n",
        "except FileNotFoundError as e:\n",
        "    raise FileNotFoundError(f\"Dataset not found: {e}. Please ensure files are uploaded to {DATA_DIR}.\")\n",
        "\n",
        "# Custom weighted accuracy metric\n",
        "def weighted_accuracy(y_true, y_pred, weights):\n",
        "    y_pred_mapped = np.where(y_pred == 1, 1, -1)\n",
        "    correct = (y_pred_mapped == np.sign(y_true)).astype(np.float32)\n",
        "    return np.sum(np.abs(y_true) * correct) / np.sum(np.abs(y_true))\n",
        "\n",
        "# Preprocess data with reduced feature set\n",
        "def preprocess_data(X, y=None, supplementary=None, is_train=True, top_cols=None):\n",
        "    ret_cols = [col for col in X.columns if col.startswith('RET_')]\n",
        "\n",
        "    # Dynamic feature selection (top 8)\n",
        "    if is_train and top_cols is None:\n",
        "        if len(ret_cols) > 8:\n",
        "            variances = X[ret_cols].var()\n",
        "            corr_sum = X[ret_cols].corr().abs().sum()\n",
        "            combined_score = variances * corr_sum\n",
        "            valid_cols = variances[variances > 1e-5].index\n",
        "            top_cols = combined_score.loc[valid_cols].sort_values(ascending=False).head(8).index.tolist()\n",
        "        else:\n",
        "            top_cols = ret_cols\n",
        "        print(f\"Selected top return columns: {top_cols}\")\n",
        "    elif top_cols is not None:\n",
        "        ret_cols = [col for col in ret_cols if col in top_cols]\n",
        "        if not ret_cols:\n",
        "            raise ValueError(\"No return columns selected. Check top_cols consistency.\")\n",
        "\n",
        "    # Cache sector-based medians\n",
        "    sector_medians = {}\n",
        "    if supplementary is not None:\n",
        "        sector_map = supplementary.set_index('ID_asset')['CLASS_LEVEL_1']\n",
        "        for col in ret_cols:\n",
        "            asset_id = int(col.replace('RET_', ''))\n",
        "            sector = sector_map.get(asset_id, np.nan)\n",
        "            if pd.notna(sector):\n",
        "                sector_assets = supplementary[supplementary['CLASS_LEVEL_1'] == sector]['ID_asset']\n",
        "                sector_cols = [f'RET_{a}' for a in sector_assets if f'RET_{a}' in X.columns]\n",
        "                if sector_cols:\n",
        "                    sector_medians[col] = X[sector_cols].median(axis=1)\n",
        "            if col in sector_medians:\n",
        "                X[col] = X[col].fillna(sector_medians[col])\n",
        "            else:\n",
        "                X[col] = X[col].fillna(X[col].median())\n",
        "        gc.collect()\n",
        "\n",
        "    # New columns dictionary\n",
        "    new_cols = {}\n",
        "\n",
        "    # Sector-based features (top 5 categories)\n",
        "    if supplementary is not None:\n",
        "        level = 'CLASS_LEVEL_1'\n",
        "        top_sectors = supplementary[level].value_counts().head(5).index\n",
        "        sector_groups = supplementary[supplementary[level].isin(top_sectors)].groupby(level, observed=True)['ID_asset'].apply(list).to_dict()\n",
        "        for sector, assets in sector_groups.items():\n",
        "            asset_cols = [f'RET_{asset}' for asset in assets if f'RET_{asset}' in ret_cols]\n",
        "            if asset_cols:\n",
        "                new_cols[f'SECTOR_AVG_{level}_{sector}'] = X[asset_cols].mean(axis=1).replace([np.inf, -np.inf], 0).fillna(0)\n",
        "        X = X.merge(supplementary[['ID_asset', level]].rename(columns={'ID_asset': 'ID_TARGET', level: f'TARGET_{level}'}),\n",
        "                    on='ID_TARGET', how='left')\n",
        "        X = pd.concat([X, pd.get_dummies(X[f'TARGET_{level}'], prefix=f'TARGET_{level}', dummy_na=True)], axis=1)\n",
        "        X = X.drop(f'TARGET_{level}', axis=1)\n",
        "        gc.collect()\n",
        "\n",
        "    # Cross-sectional features\n",
        "    new_cols['MEAN_RET'] = X[ret_cols].mean(axis=1)\n",
        "    new_cols['STD_RET'] = X[ret_cols].std(axis=1)\n",
        "    new_cols.update({f'CS_RANK_{col}': X.groupby('ID_DAY')[col].rank(pct=True).replace([np.inf, -np.inf], 0).fillna(0) for col in ret_cols})\n",
        "\n",
        "    # Correlation-based features (top 3 pairs)\n",
        "    if is_train:\n",
        "        corr_matrix = X[ret_cols].corr()\n",
        "        corr_pairs = corr_matrix.unstack().sort_values(ascending=False)\n",
        "        top_pairs = [(i, j) for i, j in corr_pairs.index if i < j][:3]\n",
        "        for i, j in top_pairs:\n",
        "            new_cols[f'CORR_{i}_{j}'] = X[i] * X[j]\n",
        "\n",
        "    # PCA features (1 component)\n",
        "    if ret_cols:\n",
        "        pca = PCA(n_components=1, random_state=42)\n",
        "        pca_features = pca.fit_transform(X[ret_cols].fillna(0))\n",
        "        new_cols['PCA_0'] = pca_features[:, 0]\n",
        "        gc.collect()\n",
        "\n",
        "    # Temporal features: Momentum and Volatility\n",
        "    for col in ret_cols:\n",
        "        new_cols[f'MOMENTUM_7D_{col}'] = X[col].groupby(X['ID_TARGET']).rolling(7, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "        new_cols[f'VOLATILITY_3D_{col}'] = X[col].groupby(X['ID_TARGET']).rolling(3, min_periods=1).std().reset_index(level=0, drop=True)\n",
        "        gc.collect()\n",
        "\n",
        "    # Add new features to DataFrame\n",
        "    new_cols_df = pd.DataFrame(new_cols, index=X.index, dtype=np.float32)\n",
        "    X = pd.concat([X, new_cols_df], axis=1)\n",
        "    del new_cols_df\n",
        "    gc.collect()\n",
        "\n",
        "    # Standardize numerical features\n",
        "    feature_cols = [col for col in X.columns if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "    scaler = StandardScaler()\n",
        "    X[feature_cols] = scaler.fit_transform(X[feature_cols].replace([np.inf, -np.inf], 0).fillna(0))\n",
        "    gc.collect()\n",
        "\n",
        "    if is_train:\n",
        "        y['SIGN_TARGET'] = np.where(y['RET_TARGET'] > 0, 1, 0).astype(np.int32)\n",
        "        return X, y, feature_cols, top_cols\n",
        "    return X, None, feature_cols, top_cols\n",
        "\n",
        "# Preprocess data\n",
        "try:\n",
        "    X_train, y_train, feature_cols, top_cols = preprocess_data(X_train, y_train, supplementary, is_train=True)\n",
        "    X_test, _, test_feature_cols, _ = preprocess_data(X_test, supplementary=supplementary, is_train=False, top_cols=top_cols)\n",
        "except ValueError as e:\n",
        "    print(f\"Preprocessing error: {e}\")\n",
        "    raise\n",
        "\n",
        "# Align columns\n",
        "common_cols = X_train.columns.intersection(X_test.columns)\n",
        "X_train = X_train[common_cols]\n",
        "X_test = X_test[common_cols]\n",
        "feature_cols = [col for col in common_cols if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "y_train = y_train.loc[X_train.index]\n",
        "gc.collect()\n",
        "\n",
        "# Create holdout set (20% of training data)\n",
        "outer_kf = GroupKFold(n_splits=4)\n",
        "train_idx, holdout_idx = next(outer_kf.split(X_train, y_train, groups=X_train['ID_DAY']))\n",
        "X_train_inner, X_holdout = X_train.iloc[train_idx], X_train.iloc[holdout_idx]\n",
        "y_train_inner, y_holdout = y_train.iloc[train_idx], y_train.iloc[holdout_idx]\n",
        "del X_train, y_train\n",
        "gc.collect()\n",
        "\n",
        "# Define models with fixed hyperparameter grids\n",
        "models = {\n",
        "    'LightGBM': {\n",
        "        'model': LGBMClassifier(num_leaves=31, min_child_samples=15, lambda_l1=0.3, lambda_l2=0.3,\n",
        "                                subsample=0.7, colsample_bytree=0.8, bagging_freq=5, bagging_fraction=0.7,\n",
        "                                random_state=42, n_jobs=1, verbosity=-1, class_weight='balanced', force_row_wise=True),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.01], 'num_leaves': [15], 'min_child_samples': [10], 'bagging_fraction': [0.6], 'reg_alpha': [0.0], 'reg_lambda': [0.0]},\n",
        "            {'learning_rate': [0.03], 'num_leaves': [31], 'min_child_samples': [15], 'bagging_fraction': [0.7], 'reg_alpha': [0.1], 'reg_lambda': [0.1]},\n",
        "            {'learning_rate': [0.05], 'num_leaves': [47], 'min_child_samples': [20], 'bagging_fraction': [0.8], 'reg_alpha': [0.2], 'reg_lambda': [0.2]},\n",
        "            {'learning_rate': [0.1], 'num_leaves': [31], 'min_child_samples': [15], 'bagging_fraction': [0.7], 'reg_alpha': [0.2], 'reg_lambda': [0.1]}\n",
        "        ],\n",
        "        'callbacks': [lightgbm.early_stopping(stopping_rounds=15, verbose=False)]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'model': XGBClassifier(max_depth=4, min_child_weight=2, subsample=0.8, colsample_bytree=0.8,\n",
        "                               random_state=42, n_jobs=1, eval_metric='logloss', verbosity=0,\n",
        "                               scale_pos_weight=len(y_train_inner[y_train_inner['SIGN_TARGET'] == 0]) / len(y_train_inner[y_train_inner['SIGN_TARGET'] == 1])),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.01], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [100], 'reg_alpha': [0.0], 'reg_lambda': [1.0]},\n",
        "            {'learning_rate': [0.03], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [150], 'reg_alpha': [0.5], 'reg_lambda': [1.5]},\n",
        "            {'learning_rate': [0.05], 'max_depth': [5], 'min_child_weight': [3], 'subsample': [0.8], 'n_estimators': [200], 'reg_alpha': [1.0], 'reg_lambda': [2.0]},\n",
        "            {'learning_rate': [0.1], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [150], 'reg_alpha': [0.5], 'reg_lambda': [1.5]}\n",
        "        ],\n",
        "        'callbacks': [xgboost.callback.EarlyStopping(rounds=15, metric_name='logloss', save_best=True)]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to train and predict with batch processing\n",
        "def train_target(target, X_train, y_train, X_test, feature_cols, model, model_name, kf, param_grid, callbacks, batch_size=500):\n",
        "    X_target = X_train[X_train['ID_TARGET'] == target][feature_cols]\n",
        "    y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "    weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "    low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "    weight_scale = 2.0 if target in low_performing_targets else 1.0\n",
        "    if len(X_target) < 500:\n",
        "        weight_scale *= 1.5\n",
        "    weights = weights * weight_scale\n",
        "    groups = X_train[X_train['ID_TARGET'] == target]['ID_DAY']\n",
        "    X_test_target = X_test[X_test['ID_TARGET'] == target][feature_cols]\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "    if len(X_target) < 100 or len(X_test_target) == 0:\n",
        "        print(f\"Warning: Insufficient data for ID_TARGET {target} (train: {len(X_target)}, test: {len(X_test_target)}). Skipping.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    param_results = []\n",
        "    best_params = None\n",
        "    best_score = 0\n",
        "    best_model = None\n",
        "\n",
        "    # Grid search with RFE and batch processing\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        print(f\"Testing params for {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "        try:\n",
        "            model.set_params(**params)\n",
        "        except ValueError as e:\n",
        "            print(f\"Invalid params for {model_name} ID_TARGET {target}: {e}\")\n",
        "            continue\n",
        "        rfe = RFE(estimator=model, n_features_to_select=10)\n",
        "        fold_accuracies = []\n",
        "        for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "            for batch_start in range(0, len(train_idx), batch_size):\n",
        "                batch_train_idx = train_idx[batch_start:batch_start + batch_size]\n",
        "                X_tr = X_target.iloc[batch_train_idx]\n",
        "                y_tr = y_target.iloc[batch_train_idx]\n",
        "                w_tr = weights.iloc[batch_train_idx]\n",
        "                X_val = X_target.iloc[val_idx]\n",
        "                y_val = y_target.iloc[val_idx]\n",
        "                w_val = weights.iloc[val_idx]\n",
        "                rfe.fit(X_tr, y_tr)\n",
        "                selected_features = X_tr.columns[rfe.support_].tolist()\n",
        "                X_tr_rfe, X_val_rfe = X_tr[selected_features], X_val[selected_features]\n",
        "                if model_name == 'LightGBM' and callbacks:\n",
        "                    model.fit(X_tr_rfe, y_tr, sample_weight=w_tr, eval_set=[(X_val_rfe, y_val)], eval_metric='logloss', callbacks=callbacks)\n",
        "                elif model_name == 'XGBoost' and callbacks:\n",
        "                    model.fit(X_tr_rfe, y_tr, sample_weight=w_tr, eval_set=[(X_val_rfe, y_val)], verbose=False)\n",
        "                else:\n",
        "                    model.fit(X_tr_rfe, y_tr, sample_weight=w_tr)\n",
        "                y_pred = model.predict(X_val_rfe)\n",
        "                acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "                fold_accuracies.append(acc)\n",
        "                del X_tr_rfe, X_val_rfe, X_tr, X_val, y_tr, y_val, w_tr, w_val\n",
        "                gc.collect()\n",
        "        mean_acc = np.mean(fold_accuracies)\n",
        "        print(f\"{model_name} | ID_TARGET: {target} | Params: {params} | Mean Accuracy: {mean_acc:.4f}\", flush=True)\n",
        "        param_results.append({\n",
        "            'params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': fold_accuracies,\n",
        "            'selected_features': selected_features\n",
        "        })\n",
        "        if mean_acc > best_score:\n",
        "            best_score = mean_acc\n",
        "            best_params = params\n",
        "            best_model = type(model)(**model.get_params())\n",
        "            best_features = selected_features\n",
        "        del rfe\n",
        "        gc.collect()\n",
        "\n",
        "    if best_model is None:\n",
        "        print(f\"No valid model for {model_name} ID_TARGET {target}. Using default.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    best_model.set_params(**best_params)\n",
        "    X_target_rfe = X_target[best_features]\n",
        "    X_test_target_rfe = X_test_target[best_features]\n",
        "    for batch_start in range(0, len(X_target), batch_size):\n",
        "        batch_idx = X_target.index[batch_start:batch_start + batch_size]\n",
        "        X_batch = X_target_rfe.loc[batch_idx]\n",
        "        y_batch = y_target.loc[batch_idx]\n",
        "        w_batch = weights.loc[batch_idx]\n",
        "        if model_name == 'LightGBM' and callbacks:\n",
        "            best_model.fit(X_batch, y_batch, sample_weight=w_batch, eval_set=[(X_batch, y_batch)], eval_metric='logloss', callbacks=callbacks)\n",
        "        elif model_name == 'XGBoost' and callbacks:\n",
        "            best_model.fit(X_batch, y_batch, sample_weight=w_batch, eval_set=[(X_batch, y_batch)], verbose=False)\n",
        "        else:\n",
        "            best_model.fit(X_batch, y_batch, sample_weight=w_batch)\n",
        "        del X_batch, y_batch, w_batch\n",
        "        gc.collect()\n",
        "    preds = best_model.predict_proba(X_test_target_rfe)[:, 1].astype(np.float32)\n",
        "    importance = best_model.feature_importances_\n",
        "    feature_importance = dict(zip(best_features, importance))\n",
        "    top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
        "    del X_target, y_target, weights, X_test_target, X_target_rfe, X_test_target_rfe\n",
        "    gc.collect()\n",
        "    return str(target), best_params, best_score, param_results, test_ids, preds, top_features\n",
        "\n",
        "# Cross-validation and training\n",
        "kf = GroupKFold(n_splits=5)\n",
        "results = {}\n",
        "predictions = {}\n",
        "param_log = {}\n",
        "top_features_all = {}\n",
        "param_summary = []\n",
        "low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\", flush=True)\n",
        "    param_log[model_name] = {}\n",
        "    top_features_all[model_name] = {}\n",
        "\n",
        "    # First-pass training\n",
        "    results_parallel = Parallel(n_jobs=-1)(\n",
        "        delayed(train_target)(target, X_train_inner, y_train_inner, X_test, feature_cols, model_info['model'], model_name, kf,\n",
        "                             model_info['param_grid'], model_info['callbacks'], batch_size=500)\n",
        "        for target in tqdm(X_train_inner['ID_TARGET'].unique(), desc=f\"{model_name} Targets\")\n",
        "    )\n",
        "\n",
        "    # Collect results\n",
        "    accuracies = []\n",
        "    for target, params, mean_acc, param_results, test_ids, preds, top_features in results_parallel:\n",
        "        param_log[model_name][target] = {\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'all_params': param_results\n",
        "        }\n",
        "        top_features_all[model_name][target] = top_features\n",
        "        accuracies.append(mean_acc)\n",
        "        predictions.setdefault(target, {})[model_name] = dict(zip(test_ids, preds))\n",
        "        param_summary.append({\n",
        "            'model': model_name,\n",
        "            'ID_TARGET': target,\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': param_results[-1]['fold_accuracies'] if param_results else []\n",
        "        })\n",
        "    results[model_name] = np.mean([acc for acc in accuracies if acc > 0])\n",
        "    print(f\"{model_name} Weighted Accuracy: {results[model_name]:.4f}\", flush=True)\n",
        "\n",
        "    # Second-pass training with top features\n",
        "    print(f\"\\nSecond-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(X_train_inner['ID_TARGET'].unique(), desc=f\"{model_name} Targets\"):\n",
        "        target_str = str(target)\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train_inner[X_train_inner['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train_inner.loc[X_train_inner['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train_inner.loc[X_train_inner['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "        weight_scale = 2.0 if target in low_performing_targets else 1.0\n",
        "        if len(X_target) < 500:\n",
        "            weight_scale *= 1.5\n",
        "        weights = weights * weight_scale\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        best_params['n_estimators'] = 200\n",
        "        model.set_params(**best_params)\n",
        "        for batch_start in range(0, len(X_target), 500):\n",
        "            batch_idx = X_target.index[batch_start:batch_start + 500]\n",
        "            X_batch = X_target.loc[batch_idx]\n",
        "            y_batch = y_target.loc[batch_idx]\n",
        "            w_batch = weights.loc[batch_idx]\n",
        "            if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "                model.fit(X_batch, y_batch, sample_weight=w_batch, eval_set=[(X_batch, y_batch)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "            elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "                model.fit(X_batch, y_batch, sample_weight=w_batch, eval_set=[(X_batch, y_batch)], verbose=False)\n",
        "            else:\n",
        "                model.fit(X_batch, y_batch, sample_weight=w_batch)\n",
        "            del X_batch, y_batch, w_batch\n",
        "            gc.collect()\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        del X_target, y_target, weights, X_test_target\n",
        "        gc.collect()\n",
        "\n",
        "    # Third-pass training for low-performing targets\n",
        "    print(f\"\\nThird-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(low_performing_targets, desc=f\"{model_name} Low-Performing Targets\"):\n",
        "        target_str = str(target)\n",
        "        if target_str not in param_log[model_name] or param_log[model_name][target_str]['mean_accuracy'] >= 0.75:\n",
        "            continue\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train_inner[X_train_inner['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train_inner.loc[X_train_inner['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train_inner.loc[X_train_inner['ID_TARGET'] == target, 'RET_TARGET'].abs() * 2.0\n",
        "        if len(X_target) < 500:\n",
        "            weights = weights * 1.5\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        fine_tune_grid = [\n",
        "            {'learning_rate': [best_params['learning_rate'][0] * 0.5], 'n_estimators': [300], 'reg_alpha': [best_params['reg_alpha'][0] + 0.2], 'reg_lambda': [best_params['reg_lambda'][0] + 0.2]},\n",
        "            {'learning_rate': [best_params['learning_rate'][0] * 1.0], 'n_estimators': [300], 'reg_alpha': [best_params['reg_alpha'][0]], 'reg_lambda': [best_params['reg_lambda'][0]]},\n",
        "            {'learning_rate': [best_params['learning_rate'][0] * 1.2], 'n_estimators': [350], 'reg_alpha': [best_params['reg_alpha'][0] + 0.15], 'reg_lambda': [best_params['reg_lambda'][0] + 0.15]},\n",
        "            {'learning_rate': [best_params['learning_rate'][0] * 0.7], 'n_estimators': [350], 'reg_alpha': [best_params['reg_alpha'][0] + 0.1], 'reg_lambda': [best_params['reg_lambda'][0] + 0.1]}\n",
        "        ]\n",
        "        best_score = param_log[model_name][target_str]['mean_accuracy']\n",
        "        best_fine_params = best_params\n",
        "\n",
        "        for params in ParameterGrid(fine_tune_grid):\n",
        "            print(f\"Fine-tuning {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "            model.set_params(**params)\n",
        "            fold_accuracies = []\n",
        "            for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "                for batch_start in range(0, len(train_idx), 500):\n",
        "                    batch_train_idx = train_idx[batch_start:batch_start + 500]\n",
        "                    X_tr = X_target.iloc[batch_train_idx]\n",
        "                    y_tr = y_target.iloc[batch_train_idx]\n",
        "                    w_tr = weights.iloc[batch_train_idx]\n",
        "                    X_val = X_target.iloc[val_idx]\n",
        "                    y_val = y_target.iloc[val_idx]\n",
        "                    w_val = weights.iloc[val_idx]\n",
        "                    if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "                        model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "                    elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "                        model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "                    else:\n",
        "                        model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "                    y_pred = model.predict(X_val)\n",
        "                    acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "                    fold_accuracies.append(acc)\n",
        "                    del X_tr, X_val, y_tr, y_val, w_tr, w_val\n",
        "                    gc.collect()\n",
        "            mean_acc = np.mean(fold_accuracies)\n",
        "            print(f\"{model_name} | ID_TARGET: {target} | Fine-tune Params: {params} | Mean Accuracy: {mean_acc:.4f}\", flush=True)\n",
        "            if mean_acc > best_score:\n",
        "                best_score = mean_acc\n",
        "                best_fine_params = params\n",
        "                param_log[model_name][target_str]['best_params'] = best_fine_params\n",
        "                param_log[model_name][target_str]['mean_accuracy'] = best_score\n",
        "                param_summary.append({\n",
        "                    'model': model_name,\n",
        "                    'ID_TARGET': target_str,\n",
        "                    'best_params': best_fine_params,\n",
        "                    'mean_accuracy': best_score,\n",
        "                    'fold_accuracies': fold_accuracies\n",
        "                })\n",
        "            gc.collect()\n",
        "\n",
        "        model.set_params(**best_fine_params)\n",
        "        for batch_start in range(0, len(X_target), 500):\n",
        "            batch_idx = X_target.index[batch_start:batch_start + 500]\n",
        "            X_batch = X_target.loc[batch_idx]\n",
        "            y_batch = y_target.loc[batch_idx]\n",
        "            w_batch = weights.loc[batch_idx]\n",
        "            if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "                model.fit(X_batch, y_batch, sample_weight=w_batch, eval_set=[(X_batch, y_batch)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "            elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "                model.fit(X_batch, y_batch, sample_weight=w_batch, eval_set=[(X_batch, y_batch)], verbose=False)\n",
        "            else:\n",
        "                model.fit(X_batch, y_batch, sample_weight=w_batch)\n",
        "            del X_batch, y_batch, w_batch\n",
        "            gc.collect()\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        del X_target, y_target, weights, X_test_target\n",
        "        gc.collect()\n",
        "\n",
        "# Validate on holdout set\n",
        "holdout_predictions = {}\n",
        "for model_name, model_info in models.items():\n",
        "    for target in X_holdout['ID_TARGET'].unique():\n",
        "        target_str = str(target)\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            continue\n",
        "        X_target = X_holdout[X_holdout['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_holdout.loc[X_holdout['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_holdout.loc[X_holdout['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "        weight_scale = 2.0 if target in low_performing_targets else 1.0\n",
        "        if len(X_target) < 500:\n",
        "            weight_scale *= 1.5\n",
        "        weights = weights * weight_scale\n",
        "        if len(X_target) < 100:\n",
        "            continue\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        model.set_params(**best_params)\n",
        "        for batch_start in range(0, len(X_target), 500):\n",
        "            batch_idx = X_target.index[batch_start:batch_start + 500]\n",
        "            X_batch = X_target.loc[batch_idx]\n",
        "            y_batch = y_target.loc[batch_idx]\n",
        "            w_batch = weights.loc[batch_idx]\n",
        "            model.fit(X_train_inner[X_train_inner['ID_TARGET'] == target][top_features].loc[batch_idx.intersection(X_train_inner.index)],\n",
        "                      y_train_inner.loc[X_train_inner['ID_TARGET'] == target].loc[batch_idx.intersection(X_train_inner.index), 'SIGN_TARGET'],\n",
        "                      sample_weight=y_train_inner.loc[X_train_inner['ID_TARGET'] == target].loc[batch_idx.intersection(X_train_inner.index), 'RET_TARGET'].abs() * weight_scale)\n",
        "            del X_batch, y_batch, w_batch\n",
        "            gc.collect()\n",
        "        preds = model.predict_proba(X_target)[:, 1].astype(np.float32)\n",
        "        holdout_predictions.setdefault(target_str, {})[model_name] = dict(zip(X_target.index, preds))\n",
        "        del X_target, y_target, weights\n",
        "        gc.collect()\n",
        "\n",
        "# Compute holdout accuracy\n",
        "holdout_final = {}\n",
        "for target in X_holdout['ID_TARGET'].unique():\n",
        "    target_str = str(target)\n",
        "    if target_str not in holdout_predictions:\n",
        "        continue\n",
        "    target_idx = X_holdout[X_holdout['ID_TARGET'] == target].index\n",
        "    weights = y_holdout.loc[target_idx, 'RET_TARGET'].abs()\n",
        "    ensemble_weights = {\n",
        "        'LightGBM': param_log['LightGBM'].get(target_str, {}).get('mean_accuracy', 0.5),\n",
        "        'XGBoost': param_log['XGBoost'].get(target_str, {}).get('mean_accuracy', 0.5)\n",
        "    }\n",
        "    total = ensemble_weights['LightGBM'] + ensemble_weights['XGBoost']\n",
        "    if total == 0:\n",
        "        ensemble_weights = {'LightGBM': 0.5, 'XGBoost': 0.5}\n",
        "    else:\n",
        "        ensemble_weights = {k: v / total for k, v in ensemble_weights.items()}\n",
        "    for day in X_holdout[X_holdout['ID_TARGET'] == target]['ID_DAY'].unique():\n",
        "        day_idx = (X_holdout['ID_TARGET'] == target) & (X_holdout['ID_DAY'] == day)\n",
        "        day_test_ids = X_holdout[day_idx].index\n",
        "        lgbm_preds = np.array([holdout_predictions[target_str].get('LightGBM', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        xgb_preds = np.array([holdout_predictions[target_str].get('XGBoost', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        ensemble_preds = ensemble_weights['LightGBM'] * lgbm_preds + ensemble_weights['XGBoost'] * xgb_preds\n",
        "        smoothed_preds = pd.Series(ensemble_preds).ewm(span=3).mean().values[-1] if len(ensemble_preds) > 0 else 0.5\n",
        "        for idx in day_test_ids:\n",
        "            holdout_final[idx] = 1 if smoothed_preds >= 0.5 else -1\n",
        "        del lgbm_preds, xgb_preds, ensemble_preds\n",
        "        gc.collect()\n",
        "holdout_df = pd.DataFrame.from_dict(holdout_final, orient='index', columns=['PRED']).reset_index()\n",
        "holdout_df = holdout_df.merge(y_holdout[['SIGN_TARGET', 'RET_TARGET']], left_on='index', right_index=True)\n",
        "holdout_acc = weighted_accuracy(holdout_df['SIGN_TARGET'], np.where(holdout_df['PRED'] == 1, 1, -1), holdout_df['RET_TARGET'].abs())\n",
        "print(f\"Holdout Weighted Accuracy: {holdout_acc:.4f}\", flush=True)\n",
        "del holdout_predictions, holdout_df, X_holdout, y_holdout\n",
        "gc.collect()\n",
        "\n",
        "# Save parameter log\n",
        "param_log_path = os.path.join(DATA_DIR, 'hyperparameters.json')\n",
        "with open(param_log_path, 'w') as f:\n",
        "    json.dump(param_log, f, indent=4)\n",
        "print(f\"Saved hyperparameter log to: {param_log_path}\", flush=True)\n",
        "files.download(param_log_path)\n",
        "\n",
        "# Ensemble predictions for test set\n",
        "final_predictions = {}\n",
        "missing_day_targets = []\n",
        "for target in X_test['ID_TARGET'].unique():\n",
        "    target_str = str(target)\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "    ensemble_weights = {\n",
        "        'LightGBM': param_log['LightGBM'].get(target_str, {}).get('mean_accuracy', 0.5),\n",
        "        'XGBoost': param_log['XGBoost'].get(target_str, {}).get('mean_accuracy', 0.5)\n",
        "    }\n",
        "    total = ensemble_weights['LightGBM'] + ensemble_weights['XGBoost']\n",
        "    if total == 0:\n",
        "        ensemble_weights = {'LightGBM': 0.5, 'XGBoost': 0.5}\n",
        "    else:\n",
        "        ensemble_weights = {k: v / total for k, v in ensemble_weights.items()}\n",
        "    for day in X_test[X_test['ID_TARGET'] == target]['ID_DAY'].unique():\n",
        "        day_idx = (X_test['ID_TARGET'] == target) & (X_test['ID_DAY'] == day)\n",
        "        day_test_ids = X_test[day_idx].index\n",
        "        if len(day_test_ids) == 0:\n",
        "            print(f\"Warning: No test samples for ID_TARGET {target} on ID_DAY {day}. Using default prediction.\")\n",
        "            missing_day_targets.append((target, day))\n",
        "            for idx in test_ids:\n",
        "                final_predictions[idx] = -1\n",
        "            continue\n",
        "        lgbm_preds = np.array([predictions[target_str].get('LightGBM', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        xgb_preds = np.array([predictions[target_str].get('XGBoost', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        ensemble_preds = ensemble_weights['LightGBM'] * lgbm_preds + ensemble_weights['XGBoost'] * xgb_preds\n",
        "        smoothed_preds = pd.Series(ensemble_preds).ewm(span=3).mean().values[-1] if len(ensemble_preds) > 0 else 0.5\n",
        "        for idx in day_test_ids:\n",
        "            final_predictions[idx] = 1 if smoothed_preds >= 0.5 else -1\n",
        "        del lgbm_preds, xgb_preds, ensemble_preds\n",
        "        gc.collect()\n",
        "\n",
        "if missing_day_targets:\n",
        "    print(f\"Missing day-target pairs: {missing_day_targets}\")\n",
        "\n",
        "# Create output CSV\n",
        "output_df = pd.DataFrame.from_dict(final_predictions, orient='index', columns=['RET_TARGET']).reset_index()\n",
        "output_df.columns = ['ID', 'RET_TARGET']\n",
        "output_df = output_df.sort_values('ID')\n",
        "expected_ids = set(X_test.index)\n",
        "submission_ids = set(output_df['ID'])\n",
        "if expected_ids != submission_ids:\n",
        "    missing_ids = expected_ids - submission_ids\n",
        "    print(f\"Warning: Submission missing {len(missing_ids)} IDs: {missing_ids}\")\n",
        "    missing_df = pd.DataFrame({'ID': list(missing_ids), 'RET_TARGET': -1})\n",
        "    output_df = pd.concat([output_df, missing_df], ignore_index=True).sort_values('ID')\n",
        "output_path = os.path.join(DATA_DIR, 'predictions_ensemble.csv')\n",
        "output_df.to_csv(output_path, index=False)\n",
        "print(f\"Saved predictions to: {output_path}\", flush=True)\n",
        "\n",
        "# Validate output\n",
        "test_csv = pd.read_csv(output_path)\n",
        "print(f\"Output CSV shape: {test_csv.shape}\", flush=True)\n",
        "print(f\"Output CSV ID range: {test_csv['ID'].min()} to {test_csv['ID'].max()}\", flush=True)\n",
        "print(f\"Unique RET_TARGET values: {test_csv['RET_TARGET'].unique()}\", flush=True)\n",
        "print(f\"Missing values: {test_csv.isna().sum().sum()}\", flush=True)\n",
        "\n",
        "# Download the file\n",
        "files.download(output_path)\n",
        "\n",
        "# Print final results\n",
        "print(\"\\nValidation Results:\", flush=True)\n",
        "for model_name, acc in results.items():\n",
        "    print(f\"{model_name}: {acc:.4f}\", flush=True)\n",
        "print(f\"Holdout Weighted Accuracy: {holdout_acc:.4f}\", flush=True)\n",
        "del X_test, test_csv, output_df\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpw5iss4GuCA"
      },
      "source": [
        "new mth -- 73.7%"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost\n",
        "from sklearn.decomposition import PCA\n",
        "from joblib import Parallel, delayed\n",
        "import json\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# Check xgboost version for compatibility\n",
        "print(f\"XGBoost version: {xgboost.__version__}\")\n",
        "if int(xgboost.__version__.split('.')[0]) < 1:\n",
        "    print(\"Warning: XGBoost version < 1.0.0 detected. Ensure compatibility with eval_metric in constructor.\")\n",
        "\n",
        "# Set up data directory\n",
        "DATA_DIR = '/content'\n",
        "\n",
        "# Load datasets\n",
        "try:\n",
        "    X_train = pd.read_csv(os.path.join(DATA_DIR, 'X_train_itDkypA.csv'), index_col='ID', dtype=np.float32)\n",
        "    y_train = pd.read_csv(os.path.join(DATA_DIR, 'y_train_3LeeT2g.csv'), index_col='ID', dtype=np.float32)\n",
        "    X_test = pd.read_csv(os.path.join(DATA_DIR, 'X_test_Beg4ey3.csv'), index_col='ID', dtype=np.float32)\n",
        "    supplementary = pd.read_csv(os.path.join(DATA_DIR, 'supplementary_data_Vkoyn8z.csv'))\n",
        "except FileNotFoundError as e:\n",
        "    raise FileNotFoundError(f\"Dataset not found: {e}. Please ensure files are uploaded to {DATA_DIR}.\")\n",
        "\n",
        "# Custom weighted accuracy metric\n",
        "def weighted_accuracy(y_true, y_pred, weights):\n",
        "    y_pred_mapped = np.where(y_pred == 1, 1, -1)\n",
        "    correct = (y_pred_mapped == np.sign(y_true)).astype(float)\n",
        "    return np.sum(np.abs(y_true) * correct) / np.sum(np.abs(y_true))\n",
        "\n",
        "# Preprocess data with enhanced feature selection\n",
        "def preprocess_data(X, y=None, supplementary=None, is_train=True, top_cols=None):\n",
        "    ret_cols = [col for col in X.columns if col.startswith('RET_')]\n",
        "    if is_train and top_cols is None:\n",
        "        if len(ret_cols) > 15:\n",
        "            variances = X[ret_cols].var()\n",
        "            corr_sum = X[ret_cols].corr().abs().sum()\n",
        "            combined_score = variances * corr_sum\n",
        "            valid_cols = variances[variances > 1e-5].index\n",
        "            if len(valid_cols) < 15:\n",
        "                top_cols = valid_cols.tolist()\n",
        "            else:\n",
        "                top_cols = combined_score.loc[valid_cols].sort_values(ascending=False).head(15).index.tolist()\n",
        "        else:\n",
        "            top_cols = ret_cols\n",
        "        print(f\"Selected top return columns: {top_cols}\")\n",
        "    elif top_cols is not None:\n",
        "        ret_cols = [col for col in ret_cols if col in top_cols]\n",
        "        if not ret_cols:\n",
        "            raise ValueError(\"No return columns selected. Check top_cols consistency.\")\n",
        "\n",
        "    sector_medians = {}\n",
        "    if supplementary is not None:\n",
        "        sector_map = supplementary.set_index('ID_asset')['CLASS_LEVEL_1']\n",
        "        for col in ret_cols:\n",
        "            asset_id = int(col.replace('RET_', ''))\n",
        "            sector = sector_map.get(asset_id, np.nan)\n",
        "            if pd.notna(sector):\n",
        "                sector_assets = supplementary[supplementary['CLASS_LEVEL_1'] == sector]['ID_asset']\n",
        "                sector_cols = [f'RET_{a}' for a in sector_assets if f'RET_{a}' in X.columns]\n",
        "                if sector_cols:\n",
        "                    sector_medians[col] = X[sector_cols].median(axis=1)\n",
        "            if col in sector_medians:\n",
        "                X[col] = X[col].fillna(sector_medians[col])\n",
        "            else:\n",
        "                X[col] = X[col].fillna(X[col].median())\n",
        "\n",
        "    new_cols = {}\n",
        "    if supplementary is not None:\n",
        "        level = 'CLASS_LEVEL_1'\n",
        "        sector_groups = supplementary.groupby(level)['ID_asset'].apply(list).to_dict()\n",
        "        for sector, assets in sector_groups.items():\n",
        "            asset_cols = [f'RET_{asset}' for asset in assets if f'RET_{asset}' in ret_cols]\n",
        "            if asset_cols:\n",
        "                new_cols[f'SECTOR_AVG_{level}_{sector}'] = X[asset_cols].mean(axis=1).replace([np.inf, -np.inf], 0).fillna(0)\n",
        "        X = X.merge(supplementary[['ID_asset', level]].rename(columns={'ID_asset': 'ID_TARGET', level: f'TARGET_{level}'}),\n",
        "                    on='ID_TARGET', how='left')\n",
        "        X = pd.concat([X, pd.get_dummies(X[f'TARGET_{level}'], prefix=f'TARGET_{level}', dummy_na=True)], axis=1)\n",
        "        X = X.drop(f'TARGET_{level}', axis=1)\n",
        "\n",
        "    new_cols['MEAN_RET'] = X[ret_cols].mean(axis=1)\n",
        "    new_cols['STD_RET'] = X[ret_cols].std(axis=1)\n",
        "    new_cols.update({f'CS_RANK_{col}': X.groupby('ID_DAY')[col].rank(pct=True).replace([np.inf, -np.inf], 0).fillna(0) for col in ret_cols})\n",
        "\n",
        "    if is_train:\n",
        "        corr_matrix = X[ret_cols].corr()\n",
        "        corr_pairs = corr_matrix.unstack().sort_values(ascending=False)\n",
        "        top_pairs = [(i, j) for i, j in corr_pairs.index if i < j][:5]\n",
        "        for i, j in top_pairs:\n",
        "            new_cols[f'CORR_{i}_{j}'] = X[i] * X[j]\n",
        "\n",
        "    if ret_cols:\n",
        "        pca = PCA(n_components=min(2, len(ret_cols)), random_state=42)\n",
        "        pca_features = pca.fit_transform(X[ret_cols].fillna(0))\n",
        "        for i in range(pca_features.shape[1]):\n",
        "            new_cols[f'PCA_{i}'] = pca_features[:, i]\n",
        "\n",
        "    new_cols_df = pd.DataFrame(new_cols, index=X.index, dtype=np.float32)\n",
        "    X = pd.concat([X, new_cols_df], axis=1)\n",
        "\n",
        "    feature_cols = [col for col in X.columns if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "    scaler = StandardScaler()\n",
        "    X[feature_cols] = scaler.fit_transform(X[feature_cols].replace([np.inf, -np.inf], 0).fillna(0))\n",
        "\n",
        "    if is_train:\n",
        "        y['SIGN_TARGET'] = np.where(y['RET_TARGET'] > 0, 1, 0).astype(np.int32)\n",
        "        return X, y, feature_cols, top_cols\n",
        "    return X, None, feature_cols, top_cols\n",
        "\n",
        "# Preprocess data\n",
        "try:\n",
        "    X_train, y_train, feature_cols, top_cols = preprocess_data(X_train, y_train, supplementary, is_train=True)\n",
        "    X_test, _, test_feature_cols, _ = preprocess_data(X_test, supplementary=supplementary, is_train=False, top_cols=top_cols)\n",
        "except ValueError as e:\n",
        "    print(f\"Preprocessing error: {e}\")\n",
        "    raise\n",
        "\n",
        "# Align columns\n",
        "common_cols = X_train.columns.intersection(X_test.columns)\n",
        "X_train = X_train[common_cols]\n",
        "X_test = X_test[common_cols]\n",
        "feature_cols = [col for col in common_cols if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "\n",
        "# Align y_train\n",
        "y_train = y_train.loc[X_train.index]\n",
        "\n",
        "# Define models with updated LightGBM hyperparameter grid\n",
        "models = {\n",
        "    'LightGBM': {\n",
        "        'model': LGBMClassifier(num_leaves=31, min_child_samples=15, lambda_l1=0.3, lambda_l2=0.3,\n",
        "                                subsample=0.7, colsample_bytree=0.8, bagging_freq=5, bagging_fraction=0.7,\n",
        "                                random_state=42, n_jobs=1, verbosity=-1, class_weight='balanced', force_row_wise=True),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.01], 'num_leaves': [10], 'min_child_samples': [25], 'bagging_fraction': [0.5], 'reg_alpha': [0.05], 'reg_lambda': [0.05]},\n",
        "            {'learning_rate': [0.02], 'num_leaves': [15], 'min_child_samples': [20], 'bagging_fraction': [0.6], 'reg_alpha': [0.1], 'reg_lambda': [0.1]},\n",
        "            {'learning_rate': [0.05], 'num_leaves': [31], 'min_child_samples': [10], 'bagging_fraction': [0.7], 'reg_alpha': [0.2], 'reg_lambda': [0.2]},\n",
        "            {'learning_rate': [0.07], 'num_leaves': [47], 'min_child_samples': [15], 'bagging_fraction': [0.8], 'reg_alpha': [0.3], 'reg_lambda': [0.3]},\n",
        "            {'learning_rate': [0.03], 'num_leaves': [25], 'min_child_samples': [15], 'bagging_fraction': [0.65], 'reg_alpha': [0.15], 'reg_lambda': [0.15]}\n",
        "        ],\n",
        "        'callbacks': [lightgbm.early_stopping(stopping_rounds=10, verbose=False)]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'model': XGBClassifier(max_depth=4, min_child_weight=2, subsample=0.8, colsample_bytree=0.8,\n",
        "                               random_state=42, n_jobs=1, eval_metric='logloss', verbosity=0,\n",
        "                               scale_pos_weight=len(y_train[y_train['SIGN_TARGET'] == 0]) / len(y_train[y_train['SIGN_TARGET'] == 1])),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.03], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [150], 'reg_alpha': [0.1], 'reg_lambda': [1.0]},\n",
        "            {'learning_rate': [0.05], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [200], 'reg_alpha': [0.2], 'reg_lambda': [1.5]},\n",
        "            {'learning_rate': [0.07], 'max_depth': [5], 'min_child_weight': [3], 'subsample': [0.8], 'n_estimators': [150], 'reg_alpha': [0.3], 'reg_lambda': [1.0]}\n",
        "        ],\n",
        "        'callbacks': [xgboost.callback.EarlyStopping(rounds=10, metric_name='logloss', save_best=True)]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to train and predict for a single target\n",
        "def train_target(target, X_train, y_train, X_test, feature_cols, model, model_name, kf, param_grid, callbacks):\n",
        "    X_target = X_train[X_train['ID_TARGET'] == target][feature_cols]\n",
        "    y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "    weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "    low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "    weight_scale = 1.5 if target in low_performing_targets else 1.0\n",
        "    if len(X_target) < 500:\n",
        "        weight_scale *= 1.5\n",
        "    weights = weights * weight_scale\n",
        "    groups = X_train[X_train['ID_TARGET'] == target]['ID_DAY']\n",
        "    X_test_target = X_test[X_test['ID_TARGET'] == target][feature_cols]\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "    if len(X_target) < 100 or len(X_test_target) == 0:\n",
        "        print(f\"Warning: Insufficient data for ID_TARGET {target} (train: {len(X_target)}, test: {len(X_test_target)}). Skipping.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    param_results = []\n",
        "    best_params = None\n",
        "    best_score = 0\n",
        "    best_model = None\n",
        "\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        print(f\"Testing params for {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "        try:\n",
        "            model.set_params(**params)\n",
        "        except ValueError as e:\n",
        "            print(f\"Invalid params for {model_name} ID_TARGET {target}: {e}\")\n",
        "            continue\n",
        "        fold_accuracies = []\n",
        "        for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "            X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "            y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "            w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "            if model_name == 'LightGBM' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=callbacks)\n",
        "            elif model_name == 'XGBoost' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "            else:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "            y_pred = model.predict(X_val)\n",
        "            acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "            fold_accuracies.append(acc)\n",
        "        mean_acc = np.mean(fold_accuracies)\n",
        "        print(f\"{model_name} | ID_TARGET: {target} | Params: {params} | Mean Accuracy: {mean_acc:.4f} | Fold Accuracies: {fold_accuracies}\", flush=True)\n",
        "        param_results.append({\n",
        "            'params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': fold_accuracies\n",
        "        })\n",
        "        if mean_acc > best_score:\n",
        "            best_score = mean_acc\n",
        "            best_params = params\n",
        "            best_model = type(model)(**model.get_params())\n",
        "\n",
        "    if best_model is None:\n",
        "        print(f\"No valid model for {model_name} ID_TARGET {target}. Using default.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    best_model.set_params(**best_params)\n",
        "    if model_name == 'LightGBM' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=callbacks)\n",
        "    elif model_name == 'XGBoost' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "    else:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights)\n",
        "    preds = best_model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "    importance = best_model.feature_importances_\n",
        "    feature_importance = dict(zip(feature_cols, importance))\n",
        "    top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:30]\n",
        "    gc.collect()\n",
        "    return str(target), best_params, best_score, param_results, test_ids, preds, top_features\n",
        "\n",
        "# Cross-validation and training\n",
        "kf = GroupKFold(n_splits=5)\n",
        "results = {}\n",
        "predictions = {}\n",
        "ensemble_weights = {'LightGBM': 0.7, 'XGBoost': 0.3}\n",
        "param_log = {}\n",
        "top_features_all = {}\n",
        "param_summary = []\n",
        "low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\", flush=True)\n",
        "    param_log[model_name] = {}\n",
        "    top_features_all[model_name] = {}\n",
        "    results_parallel = Parallel(n_jobs=-1)(\n",
        "        delayed(train_target)(target, X_train, y_train, X_test, feature_cols, model_info['model'], model_name, kf,\n",
        "                             model_info['param_grid'], model_info['callbacks'])\n",
        "        for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\")\n",
        "    )\n",
        "    accuracies = []\n",
        "    for target, params, mean_acc, param_results, test_ids, preds, top_features in results_parallel:\n",
        "        param_log[model_name][target] = {\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'all_params': param_results\n",
        "        }\n",
        "        top_features_all[model_name][target] = top_features\n",
        "        accuracies.append(mean_acc)\n",
        "        predictions.setdefault(target, {})[model_name] = dict(zip(test_ids, preds))\n",
        "        param_summary.append({\n",
        "            'model': model_name,\n",
        "            'ID_TARGET': target,\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': param_results[-1]['fold_accuracies'] if param_results else []\n",
        "        })\n",
        "    results[model_name] = np.mean([acc for acc in accuracies if acc > 0])\n",
        "    print(f\"{model_name} Weighted Accuracy: {results[model_name]:.4f}\", flush=True)\n",
        "    print(f\"\\n{model_name} Parameter Summary:\", flush=True)\n",
        "    for summary in param_summary:\n",
        "        if summary['model'] == model_name:\n",
        "            print(f\"ID_TARGET: {summary['ID_TARGET']} | Best Params: {summary['best_params']} | Mean Accuracy: {summary['mean_accuracy']:.4f} | Fold Accuracies: {summary['fold_accuracies']}\", flush=True)\n",
        "\n",
        "# Second-pass training with top 30 features\n",
        "print(\"\\nPerforming second-pass training with top 30 features...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nSecond-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\"):\n",
        "        target_str = str(target)\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "        weight_scale = 1.5 if target in low_performing_targets else 1.0\n",
        "        if len(X_target) < 500:\n",
        "            weight_scale *= 1.5\n",
        "        weights = weights * weight_scale\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        best_params['n_estimators'] = 200\n",
        "        model.set_params(**best_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Third-pass training for low-performing targets\n",
        "print(\"\\nPerforming third-pass training for low-performing targets...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nThird-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(low_performing_targets, desc=f\"{model_name} Low-Performing Targets\"):\n",
        "        target_str = str(target)\n",
        "        if target_str not in param_log[model_name] or param_log[model_name][target_str]['mean_accuracy'] >= 0.75:\n",
        "            continue\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs() * 1.5\n",
        "        if len(X_target) < 500:\n",
        "            weights = weights * 1.5\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        fine_tune_grid = [\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.8, 'n_estimators': 200, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.0, 'n_estimators': 250, 'reg_alpha': best_params['reg_alpha'][0], 'reg_lambda': best_params['reg_lambda'][0]},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.2, 'n_estimators': 200, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1}\n",
        "        ]\n",
        "        best_score = param_log[model_name][target_str]['mean_accuracy']\n",
        "        best_fine_params = best_params\n",
        "        for params in ParameterGrid(fine_tune_grid):\n",
        "            print(f\"Fine-tuning {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "            model.set_params(**params)\n",
        "            fold_accuracies = []\n",
        "            for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "                X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "                y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "                w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "                if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "                elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "                else:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "                y_pred = model.predict(X_val)\n",
        "                acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "                fold_accuracies.append(acc)\n",
        "            mean_acc = np.mean(fold_accuracies)\n",
        "            print(f\"{model_name} | ID_TARGET: {target} | Fine-tune Params: {params} | Mean Accuracy: {mean_acc:.4f}\", flush=True)\n",
        "            if mean_acc > best_score:\n",
        "                best_score = mean_acc\n",
        "                best_fine_params = params\n",
        "                param_log[model_name][target_str]['best_params'] = best_fine_params\n",
        "                param_log[model_name][target_str]['mean_accuracy'] = best_score\n",
        "                param_summary.append({\n",
        "                    'model': model_name,\n",
        "                    'ID_TARGET': target_str,\n",
        "                    'best_params': best_fine_params,\n",
        "                    'mean_accuracy': best_score,\n",
        "                    'fold_accuracies': fold_accuracies\n",
        "                })\n",
        "        model.set_params(**best_fine_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Save parameter log\n",
        "param_log_path = os.path.join(DATA_DIR, 'hyperparameters.json')\n",
        "with open(param_log_path, 'w') as f:\n",
        "    json.dump(param_log, f, indent=4)\n",
        "print(f\"Saved hyperparameter log to: {param_log_path}\", flush=True)\n",
        "files.download(param_log_path)\n",
        "\n",
        "# Ensemble predictions\n",
        "final_predictions = {}\n",
        "missing_day_targets = []\n",
        "for target in X_test['ID_TARGET'].unique():\n",
        "    target_str = str(target)\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "    for day in X_test[X_test['ID_TARGET'] == target]['ID_DAY'].unique():\n",
        "        day_idx = (X_test['ID_TARGET'] == target) & (X_test['ID_DAY'] == day)\n",
        "        day_test_ids = X_test[day_idx].index\n",
        "        if len(day_test_ids) == 0:\n",
        "            print(f\"Warning: No test samples for ID_TARGET {target} on ID_DAY {day}. Using default prediction.\")\n",
        "            missing_day_targets.append((target, day))\n",
        "            for idx in test_ids:\n",
        "                final_predictions[idx] = -1\n",
        "            continue\n",
        "        lgbm_preds = np.array([predictions[target_str].get('LightGBM', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        xgb_preds = np.array([predictions[target_str].get('XGBoost', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        ensemble_preds = ensemble_weights['LightGBM'] * lgbm_preds + ensemble_weights['XGBoost'] * xgb_preds\n",
        "        smoothed_preds = pd.Series(ensemble_preds).ewm(span=3).mean().values[-1] if len(ensemble_preds) > 0 else 0.5\n",
        "        for idx in day_test_ids:\n",
        "            final_predictions[idx] = 1 if smoothed_preds >= 0.5 else -1\n",
        "\n",
        "if missing_day_targets:\n",
        "    print(f\"Missing day-target pairs: {missing_day_targets}\")\n",
        "\n",
        "# Create output CSV\n",
        "output_df = pd.DataFrame.from_dict(final_predictions, orient='index', columns=['RET_TARGET']).reset_index()\n",
        "output_df.columns = ['ID', 'RET_TARGET']\n",
        "output_df = output_df.sort_values('ID')\n",
        "expected_ids = set(X_test.index)\n",
        "submission_ids = set(output_df['ID'])\n",
        "if expected_ids != submission_ids:\n",
        "    missing_ids = expected_ids - submission_ids\n",
        "    print(f\"Warning: Submission missing {len(missing_ids)} IDs: {missing_ids}\")\n",
        "    missing_df = pd.DataFrame({'ID': list(missing_ids), 'RET_TARGET': -1})\n",
        "    output_df = pd.concat([output_df, missing_df], ignore_index=True).sort_values('ID')\n",
        "output_path = os.path.join(DATA_DIR, 'predictions_ensemble.csv')\n",
        "output_df.to_csv(output_path, index=False)\n",
        "print(f\"Saved predictions to: {output_path}\", flush=True)\n",
        "\n",
        "# Validate output\n",
        "test_csv = pd.read_csv(output_path)\n",
        "print(f\"Output CSV shape: {test_csv.shape}\", flush=True)\n",
        "print(f\"Output CSV ID range: {test_csv['ID'].min()} to {test_csv['ID'].max()}\", flush=True)\n",
        "print(f\"Unique RET_TARGET values: {test_csv['RET_TARGET'].unique()}\", flush=True)\n",
        "print(f\"Missing values: {test_csv.isna().sum().sum()}\", flush=True)\n",
        "\n",
        "# Download the file\n",
        "files.download(output_path)\n",
        "\n",
        "# Print final results\n",
        "print(\"\\nValidation Results:\", flush=True)\n",
        "for model_name, acc in results.items():\n",
        "    print(f\"{model_name}: {acc:.4f}\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u9_wjUUNETLn",
        "outputId": "1f57face-2ac1-4fb3-c0e3-c789c21bd7c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost version: 3.0.2\n",
            "Selected top return columns: ['RET_262', 'RET_88', 'RET_172', 'RET_259', 'RET_150', 'RET_118', 'RET_216', 'RET_268', 'RET_115', 'RET_261', 'RET_59', 'RET_238', 'RET_121', 'RET_97', 'RET_30']\n",
            "\n",
            "Training LightGBM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LightGBM Targets: 100%|| 100/100 [16:39<00:00,  9.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LightGBM Weighted Accuracy: 0.7572\n",
            "\n",
            "LightGBM Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.9697 | Fold Accuracies: [np.float64(0.8340425531914893), np.float64(0.9375), np.float64(0.7250996015936255), np.float64(0.9069767441860465), np.float64(0.8433734939759037)]\n",
            "ID_TARGET: 129.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.6779 | Fold Accuracies: [np.float64(0.6040816326530613), np.float64(0.6219512195121951), np.float64(0.6174242424242424), np.float64(0.5949367088607594), np.float64(0.7127272727272728)]\n",
            "ID_TARGET: 136.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.6441 | Fold Accuracies: [np.float64(0.640926640926641), np.float64(0.6136363636363636), np.float64(0.6218181818181818), np.float64(0.60546875), np.float64(0.6194331983805668)]\n",
            "ID_TARGET: 161.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7014 | Fold Accuracies: [np.float64(0.6048387096774194), np.float64(0.6439393939393939), np.float64(0.6564885496183206), np.float64(0.7104247104247104), np.float64(0.6896551724137931)]\n",
            "ID_TARGET: 217.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7118 | Fold Accuracies: [np.float64(0.7181467181467182), np.float64(0.6844106463878327), np.float64(0.671280276816609), np.float64(0.663003663003663), np.float64(0.7056737588652482)]\n",
            "ID_TARGET: 91.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7451 | Fold Accuracies: [np.float64(0.6793893129770993), np.float64(0.6788617886178862), np.float64(0.688212927756654), np.float64(0.6900826446280992), np.float64(0.7078651685393258)]\n",
            "ID_TARGET: 137.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.6801 | Fold Accuracies: [np.float64(0.6074380165289256), np.float64(0.6331877729257642), np.float64(0.6538461538461539), np.float64(0.73046875), np.float64(0.6296296296296297)]\n",
            "ID_TARGET: 8.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.8686 | Fold Accuracies: [np.float64(0.7470817120622568), np.float64(0.6265060240963856), np.float64(0.7131474103585658), np.float64(0.668), np.float64(0.984251968503937)]\n",
            "ID_TARGET: 3.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7387 | Fold Accuracies: [np.float64(0.6931818181818182), np.float64(0.6557377049180327), np.float64(0.7171314741035857), np.float64(0.711864406779661), np.float64(0.6768558951965066)]\n",
            "ID_TARGET: 9.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7291 | Fold Accuracies: [np.float64(0.6553191489361702), np.float64(0.684), np.float64(0.6615384615384615), np.float64(0.6735537190082644), np.float64(0.6666666666666666)]\n",
            "ID_TARGET: 131.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7135 | Fold Accuracies: [np.float64(0.7204724409448819), np.float64(0.676923076923077), np.float64(0.6330645161290323), np.float64(0.6286919831223629), np.float64(0.6038461538461538)]\n",
            "ID_TARGET: 21.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.6858 | Fold Accuracies: [np.float64(0.7394366197183099), np.float64(0.648854961832061), np.float64(0.6556776556776557), np.float64(0.625), np.float64(0.6303501945525292)]\n",
            "ID_TARGET: 54.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.8229 | Fold Accuracies: [np.float64(0.7674418604651163), np.float64(0.7265917602996255), np.float64(0.8458149779735683), np.float64(0.6942446043165468), np.float64(0.8156862745098039)]\n",
            "ID_TARGET: 130.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7879 | Fold Accuracies: [np.float64(0.7445887445887446), np.float64(0.7453874538745388), np.float64(0.6953405017921147), np.float64(0.6958174904942965), np.float64(0.7737226277372263)]\n",
            "ID_TARGET: 269.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7352 | Fold Accuracies: [np.float64(0.704), np.float64(0.7030567685589519), np.float64(0.7044534412955465), np.float64(0.5914893617021276), np.float64(0.670995670995671)]\n",
            "ID_TARGET: 157.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.8073 | Fold Accuracies: [np.float64(0.7217391304347827), np.float64(0.8025210084033614), np.float64(0.7701612903225806), np.float64(0.756), np.float64(0.7827868852459017)]\n",
            "ID_TARGET: 249.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7580 | Fold Accuracies: [np.float64(0.748062015503876), np.float64(0.7034220532319392), np.float64(0.7654320987654321), np.float64(0.710204081632653), np.float64(0.6984732824427481)]\n",
            "ID_TARGET: 22.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.6821 | Fold Accuracies: [np.float64(0.6630434782608695), np.float64(0.6616541353383458), np.float64(0.6929133858267716), np.float64(0.6590038314176245), np.float64(0.6614785992217899)]\n",
            "ID_TARGET: 202.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.6716 | Fold Accuracies: [np.float64(0.6235294117647059), np.float64(0.6940298507462687), np.float64(0.6475095785440613), np.float64(0.6678700361010831), np.float64(0.6515151515151515)]\n",
            "ID_TARGET: 132.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7737 | Fold Accuracies: [np.float64(0.728448275862069), np.float64(0.7068273092369478), np.float64(0.7283464566929134), np.float64(0.7178423236514523), np.float64(0.7983870967741935)]\n",
            "ID_TARGET: 96.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.8273 | Fold Accuracies: [np.float64(0.7012987012987013), np.float64(0.6952789699570815), np.float64(0.6653846153846154), np.float64(0.7351598173515982), np.float64(0.905982905982906)]\n",
            "ID_TARGET: 7.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7657 | Fold Accuracies: [np.float64(0.6875), np.float64(0.7027027027027027), np.float64(0.7116788321167883), np.float64(0.7430830039525692), np.float64(0.7945736434108527)]\n",
            "ID_TARGET: 178.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7355 | Fold Accuracies: [np.float64(0.7235772357723578), np.float64(0.7186311787072244), np.float64(0.7351778656126482), np.float64(0.6816326530612244), np.float64(0.70703125)]\n",
            "ID_TARGET: 68.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7851 | Fold Accuracies: [np.float64(0.735632183908046), np.float64(0.7935222672064778), np.float64(0.7692307692307693), np.float64(0.7959183673469388), np.float64(0.7540983606557377)]\n",
            "ID_TARGET: 44.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7366 | Fold Accuracies: [np.float64(0.7433962264150943), np.float64(0.7362204724409449), np.float64(0.7086330935251799), np.float64(0.6923076923076923), np.float64(0.7222222222222222)]\n",
            "ID_TARGET: 196.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7501 | Fold Accuracies: [np.float64(0.6466666666666666), np.float64(0.7601351351351351), np.float64(0.6992753623188406), np.float64(0.734375), np.float64(0.7269503546099291)]\n",
            "ID_TARGET: 292.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7590 | Fold Accuracies: [np.float64(0.6823104693140795), np.float64(0.6944444444444444), np.float64(0.7132352941176471), np.float64(0.6796875), np.float64(0.7164750957854407)]\n",
            "ID_TARGET: 239.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7668 | Fold Accuracies: [np.float64(0.7076923076923077), np.float64(0.7096774193548387), np.float64(0.711864406779661), np.float64(0.7936507936507936), np.float64(0.78125)]\n",
            "ID_TARGET: 279.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7378 | Fold Accuracies: [np.float64(0.6867924528301886), np.float64(0.7125984251968503), np.float64(0.669260700389105), np.float64(0.6833333333333333), np.float64(0.6771653543307087)]\n",
            "ID_TARGET: 38.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7846 | Fold Accuracies: [np.float64(0.6717557251908397), np.float64(0.691699604743083), np.float64(0.6910569105691057), np.float64(0.6973180076628352), np.float64(0.7092511013215859)]\n",
            "ID_TARGET: 209.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7618 | Fold Accuracies: [np.float64(0.7686274509803922), np.float64(0.6937984496124031), np.float64(0.7120622568093385), np.float64(0.7), np.float64(0.7042801556420234)]\n",
            "ID_TARGET: 207.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.6959 | Fold Accuracies: [np.float64(0.6964980544747081), np.float64(0.6431372549019608), np.float64(0.7108433734939759), np.float64(0.6377358490566037), np.float64(0.6589147286821705)]\n",
            "ID_TARGET: 98.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7328 | Fold Accuracies: [np.float64(0.6447876447876448), np.float64(0.746938775510204), np.float64(0.7613168724279835), np.float64(0.7583333333333333), np.float64(0.6539923954372624)]\n",
            "ID_TARGET: 65.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7431 | Fold Accuracies: [np.float64(0.7330827067669173), np.float64(0.7272727272727273), np.float64(0.6944444444444444), np.float64(0.7420634920634921), np.float64(0.7393162393162394)]\n",
            "ID_TARGET: 51.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7746 | Fold Accuracies: [np.float64(0.7458333333333333), np.float64(0.7327935222672065), np.float64(0.7543103448275862), np.float64(0.7439024390243902), np.float64(0.7519685039370079)]\n",
            "ID_TARGET: 78.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7507 | Fold Accuracies: [np.float64(0.7196652719665272), np.float64(0.748), np.float64(0.7125), np.float64(0.6666666666666666), np.float64(0.7193675889328063)]\n",
            "ID_TARGET: 177.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7548 | Fold Accuracies: [np.float64(0.72), np.float64(0.7397769516728625), np.float64(0.7198581560283688), np.float64(0.7377622377622378), np.float64(0.6988416988416989)]\n",
            "ID_TARGET: 231.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.8079 | Fold Accuracies: [np.float64(0.779467680608365), np.float64(0.7388059701492538), np.float64(0.748), np.float64(0.8), np.float64(0.7756653992395437)]\n",
            "ID_TARGET: 119.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7795 | Fold Accuracies: [np.float64(0.7198443579766537), np.float64(0.7689243027888446), np.float64(0.810077519379845), np.float64(0.7510548523206751), np.float64(0.7418032786885246)]\n",
            "ID_TARGET: 158.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.8084 | Fold Accuracies: [np.float64(0.7759336099585062), np.float64(0.8467741935483871), np.float64(0.7824427480916031), np.float64(0.7944664031620553), np.float64(0.7695167286245354)]\n",
            "ID_TARGET: 80.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.6982 | Fold Accuracies: [np.float64(0.692), np.float64(0.691699604743083), np.float64(0.636), np.float64(0.6938775510204082), np.float64(0.7123893805309734)]\n",
            "ID_TARGET: 25.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7537 | Fold Accuracies: [np.float64(0.7154471544715447), np.float64(0.7076271186440678), np.float64(0.7352941176470589), np.float64(0.7276119402985075), np.float64(0.71484375)]\n",
            "ID_TARGET: 175.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7507 | Fold Accuracies: [np.float64(0.72265625), np.float64(0.712), np.float64(0.6854838709677419), np.float64(0.7729083665338645), np.float64(0.7392996108949417)]\n",
            "ID_TARGET: 151.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7796 | Fold Accuracies: [np.float64(0.7638376383763837), np.float64(0.7573529411764706), np.float64(0.7692307692307693), np.float64(0.7347826086956522), np.float64(0.8016528925619835)]\n",
            "ID_TARGET: 257.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7364 | Fold Accuracies: [np.float64(0.6837944664031621), np.float64(0.7245283018867924), np.float64(0.7116788321167883), np.float64(0.6937269372693727), np.float64(0.7672727272727272)]\n",
            "ID_TARGET: 75.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7836 | Fold Accuracies: [np.float64(0.7868852459016393), np.float64(0.7530364372469636), np.float64(0.7649253731343284), np.float64(0.7482758620689656), np.float64(0.7902621722846442)]\n",
            "ID_TARGET: 244.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7017 | Fold Accuracies: [np.float64(0.6853932584269663), np.float64(0.7137254901960784), np.float64(0.6679245283018868), np.float64(0.6857142857142857), np.float64(0.6568265682656826)]\n",
            "ID_TARGET: 149.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7792 | Fold Accuracies: [np.float64(0.6804511278195489), np.float64(0.7176470588235294), np.float64(0.7846153846153846), np.float64(0.7204724409448819), np.float64(0.7440944881889764)]\n",
            "ID_TARGET: 85.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.8035 | Fold Accuracies: [np.float64(0.8048780487804879), np.float64(0.7704918032786885), np.float64(0.78), np.float64(0.7436974789915967), np.float64(0.7203065134099617)]\n",
            "ID_TARGET: 190.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7519 | Fold Accuracies: [np.float64(0.7556390977443609), np.float64(0.7453183520599251), np.float64(0.7327935222672065), np.float64(0.7213740458015268), np.float64(0.7728937728937729)]\n",
            "ID_TARGET: 13.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7509 | Fold Accuracies: [np.float64(0.7159533073929961), np.float64(0.7436823104693141), np.float64(0.7269372693726938), np.float64(0.743801652892562), np.float64(0.7322834645669292)]\n",
            "ID_TARGET: 228.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7202 | Fold Accuracies: [np.float64(0.7406015037593985), np.float64(0.7170542635658915), np.float64(0.7142857142857143), np.float64(0.6626016260162602), np.float64(0.6413043478260869)]\n",
            "ID_TARGET: 144.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.8027 | Fold Accuracies: [np.float64(0.7923728813559322), np.float64(0.8403361344537815), np.float64(0.7963636363636364), np.float64(0.7182539682539683), np.float64(0.7542372881355932)]\n",
            "ID_TARGET: 290.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7681 | Fold Accuracies: [np.float64(0.7312252964426877), np.float64(0.7107438016528925), np.float64(0.7272727272727273), np.float64(0.6951219512195121), np.float64(0.7261904761904762)]\n",
            "ID_TARGET: 114.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.6967 | Fold Accuracies: [np.float64(0.6475095785440613), np.float64(0.7142857142857143), np.float64(0.7234848484848485), np.float64(0.6852589641434262), np.float64(0.6791044776119403)]\n",
            "ID_TARGET: 166.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7581 | Fold Accuracies: [np.float64(0.7804878048780488), np.float64(0.7582417582417582), np.float64(0.7663934426229508), np.float64(0.7340823970037453), np.float64(0.7131147540983607)]\n",
            "ID_TARGET: 234.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7703 | Fold Accuracies: [np.float64(0.7622950819672131), np.float64(0.7580645161290323), np.float64(0.7394957983193278), np.float64(0.7705627705627706), np.float64(0.7042801556420234)]\n",
            "ID_TARGET: 34.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7834 | Fold Accuracies: [np.float64(0.7228464419475655), np.float64(0.7748091603053435), np.float64(0.768), np.float64(0.7682926829268293), np.float64(0.735632183908046)]\n",
            "ID_TARGET: 154.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7625 | Fold Accuracies: [np.float64(0.7716535433070866), np.float64(0.7744360902255639), np.float64(0.678030303030303), np.float64(0.7228464419475655), np.float64(0.7717842323651453)]\n",
            "ID_TARGET: 225.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7236 | Fold Accuracies: [np.float64(0.6654929577464789), np.float64(0.7105263157894737), np.float64(0.6950354609929078), np.float64(0.6976744186046512), np.float64(0.7355072463768116)]\n",
            "ID_TARGET: 185.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.8280 | Fold Accuracies: [np.float64(0.7828054298642534), np.float64(0.7947598253275109), np.float64(0.7619047619047619), np.float64(0.7729257641921398), np.float64(0.847457627118644)]\n",
            "ID_TARGET: 39.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7647 | Fold Accuracies: [np.float64(0.7235772357723578), np.float64(0.7137254901960784), np.float64(0.7587548638132295), np.float64(0.7330677290836654), np.float64(0.7075098814229249)]\n",
            "ID_TARGET: 272.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7650 | Fold Accuracies: [np.float64(0.7447698744769874), np.float64(0.8083333333333333), np.float64(0.7003891050583657), np.float64(0.7931034482758621), np.float64(0.7253521126760564)]\n",
            "ID_TARGET: 282.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7649 | Fold Accuracies: [np.float64(0.7109375), np.float64(0.7104247104247104), np.float64(0.704), np.float64(0.7480916030534351), np.float64(0.7178423236514523)]\n",
            "ID_TARGET: 90.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7603 | Fold Accuracies: [np.float64(0.75390625), np.float64(0.7547892720306514), np.float64(0.74), np.float64(0.7759336099585062), np.float64(0.746031746031746)]\n",
            "ID_TARGET: 52.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7547 | Fold Accuracies: [np.float64(0.7318840579710145), np.float64(0.7623318385650224), np.float64(0.7364016736401674), np.float64(0.7301587301587301), np.float64(0.6788617886178862)]\n",
            "ID_TARGET: 258.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7403 | Fold Accuracies: [np.float64(0.7191489361702128), np.float64(0.717391304347826), np.float64(0.6956521739130435), np.float64(0.76171875), np.float64(0.6589147286821705)]\n",
            "ID_TARGET: 291.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7898 | Fold Accuracies: [np.float64(0.7510729613733905), np.float64(0.7451737451737451), np.float64(0.717948717948718), np.float64(0.7647058823529411), np.float64(0.7182539682539683)]\n",
            "ID_TARGET: 152.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7680 | Fold Accuracies: [np.float64(0.775), np.float64(0.76), np.float64(0.7348484848484849), np.float64(0.7463768115942029), np.float64(0.7344398340248963)]\n",
            "ID_TARGET: 133.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7819 | Fold Accuracies: [np.float64(0.8141263940520446), np.float64(0.7330677290836654), np.float64(0.7747035573122529), np.float64(0.7310606060606061), np.float64(0.7713178294573644)]\n",
            "ID_TARGET: 29.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7559 | Fold Accuracies: [np.float64(0.6573705179282868), np.float64(0.7180616740088106), np.float64(0.7049808429118773), np.float64(0.7557251908396947), np.float64(0.7241379310344828)]\n",
            "ID_TARGET: 274.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7463 | Fold Accuracies: [np.float64(0.7666666666666667), np.float64(0.7517985611510791), np.float64(0.7297297297297297), np.float64(0.7096774193548387), np.float64(0.7106227106227107)]\n",
            "ID_TARGET: 106.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7929 | Fold Accuracies: [np.float64(0.7662337662337663), np.float64(0.7375565610859729), np.float64(0.7488372093023256), np.float64(0.7511520737327189), np.float64(0.7916666666666666)]\n",
            "ID_TARGET: 173.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7955 | Fold Accuracies: [np.float64(0.7692307692307693), np.float64(0.744), np.float64(0.7459016393442623), np.float64(0.8148148148148148), np.float64(0.7362204724409449)]\n",
            "ID_TARGET: 33.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7781 | Fold Accuracies: [np.float64(0.7136929460580913), np.float64(0.722007722007722), np.float64(0.7098039215686275), np.float64(0.7392996108949417), np.float64(0.7323420074349443)]\n",
            "ID_TARGET: 69.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7334 | Fold Accuracies: [np.float64(0.7130434782608696), np.float64(0.7341772151898734), np.float64(0.6730769230769231), np.float64(0.7245283018867924), np.float64(0.7162162162162162)]\n",
            "ID_TARGET: 17.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7018 | Fold Accuracies: [np.float64(0.6937984496124031), np.float64(0.7218045112781954), np.float64(0.6953125), np.float64(0.671875), np.float64(0.667953667953668)]\n",
            "ID_TARGET: 189.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7789 | Fold Accuracies: [np.float64(0.7430830039525692), np.float64(0.694980694980695), np.float64(0.6818181818181818), np.float64(0.758893280632411), np.float64(0.7333333333333333)]\n",
            "ID_TARGET: 284.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7338 | Fold Accuracies: [np.float64(0.6945454545454546), np.float64(0.7104247104247104), np.float64(0.7377049180327869), np.float64(0.724907063197026), np.float64(0.7333333333333333)]\n",
            "ID_TARGET: 218.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7152 | Fold Accuracies: [np.float64(0.6806083650190115), np.float64(0.6705882352941176), np.float64(0.6407407407407407), np.float64(0.7651821862348178), np.float64(0.697841726618705)]\n",
            "ID_TARGET: 183.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7898 | Fold Accuracies: [np.float64(0.7753623188405797), np.float64(0.7851239669421488), np.float64(0.7603305785123967), np.float64(0.6946564885496184), np.float64(0.7840909090909091)]\n",
            "ID_TARGET: 206.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7564 | Fold Accuracies: [np.float64(0.7051792828685259), np.float64(0.7509578544061303), np.float64(0.7786561264822134), np.float64(0.7510729613733905), np.float64(0.7824427480916031)]\n",
            "ID_TARGET: 93.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7354 | Fold Accuracies: [np.float64(0.6861924686192469), np.float64(0.6826568265682657), np.float64(0.6752136752136753), np.float64(0.7303370786516854), np.float64(0.7126436781609196)]\n",
            "ID_TARGET: 16.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7404 | Fold Accuracies: [np.float64(0.7425373134328358), np.float64(0.6935483870967742), np.float64(0.7078651685393258), np.float64(0.7255639097744361), np.float64(0.7310924369747899)]\n",
            "ID_TARGET: 246.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7614 | Fold Accuracies: [np.float64(0.7049808429118773), np.float64(0.7272727272727273), np.float64(0.779467680608365), np.float64(0.7886792452830189), np.float64(0.7490196078431373)]\n",
            "ID_TARGET: 167.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7682 | Fold Accuracies: [np.float64(0.7450199203187251), np.float64(0.7451737451737451), np.float64(0.75), np.float64(0.6885245901639344), np.float64(0.7950819672131147)]\n",
            "ID_TARGET: 1.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7451 | Fold Accuracies: [np.float64(0.7456140350877193), np.float64(0.7521367521367521), np.float64(0.708502024291498), np.float64(0.6984126984126984), np.float64(0.7551867219917012)]\n",
            "ID_TARGET: 289.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7537 | Fold Accuracies: [np.float64(0.7307692307692307), np.float64(0.7574626865671642), np.float64(0.75), np.float64(0.7201492537313433), np.float64(0.7030075187969925)]\n",
            "ID_TARGET: 141.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.8059 | Fold Accuracies: [np.float64(0.775), np.float64(0.7835497835497836), np.float64(0.789272030651341), np.float64(0.8053435114503816), np.float64(0.7439024390243902)]\n",
            "ID_TARGET: 109.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7203 | Fold Accuracies: [np.float64(0.7166666666666667), np.float64(0.6882591093117408), np.float64(0.6872427983539094), np.float64(0.6363636363636364), np.float64(0.7122302158273381)]\n",
            "ID_TARGET: 19.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7695 | Fold Accuracies: [np.float64(0.7727272727272727), np.float64(0.7172131147540983), np.float64(0.71484375), np.float64(0.7811320754716982), np.float64(0.7557251908396947)]\n",
            "ID_TARGET: 28.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7142 | Fold Accuracies: [np.float64(0.7196969696969697), np.float64(0.6778242677824268), np.float64(0.701195219123506), np.float64(0.7195571955719557), np.float64(0.6949152542372882)]\n",
            "ID_TARGET: 251.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7230 | Fold Accuracies: [np.float64(0.6814516129032258), np.float64(0.6940298507462687), np.float64(0.7222222222222222), np.float64(0.7804878048780488), np.float64(0.7125)]\n",
            "ID_TARGET: 278.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7848 | Fold Accuracies: [np.float64(0.6984126984126984), np.float64(0.7782101167315175), np.float64(0.7385892116182573), np.float64(0.8095238095238095), np.float64(0.7639484978540773)]\n",
            "ID_TARGET: 76.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7406 | Fold Accuracies: [np.float64(0.7258687258687259), np.float64(0.7238805970149254), np.float64(0.7431906614785992), np.float64(0.697841726618705), np.float64(0.782608695652174)]\n",
            "ID_TARGET: 241.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7658 | Fold Accuracies: [np.float64(0.7569721115537849), np.float64(0.7252252252252253), np.float64(0.6861924686192469), np.float64(0.7777777777777778), np.float64(0.7375)]\n",
            "ID_TARGET: 214.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7959 | Fold Accuracies: [np.float64(0.7660377358490567), np.float64(0.6941176470588235), np.float64(0.8070866141732284), np.float64(0.8222222222222222), np.float64(0.7325581395348837)]\n",
            "ID_TARGET: 102.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.8107 | Fold Accuracies: [np.float64(0.7709923664122137), np.float64(0.7217391304347827), np.float64(0.7603305785123967), np.float64(0.8146551724137931), np.float64(0.7576923076923077)]\n",
            "ID_TARGET: 145.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.7528 | Fold Accuracies: [np.float64(0.7142857142857143), np.float64(0.6703703703703704), np.float64(0.689795918367347), np.float64(0.6996197718631179), np.float64(0.7119341563786008)]\n",
            "ID_TARGET: 155.0 | Best Params: {'bagging_fraction': 0.5, 'learning_rate': 0.01, 'min_child_samples': 25, 'num_leaves': 10, 'reg_alpha': 0.05, 'reg_lambda': 0.05} | Mean Accuracy: 0.8016 | Fold Accuracies: [np.float64(0.7638888888888888), np.float64(0.8161764705882353), np.float64(0.8024691358024691), np.float64(0.7392996108949417), np.float64(0.7904411764705882)]\n",
            "\n",
            "Training XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "XGBoost Targets: 100%|| 100/100 [13:51<00:00,  8.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Weighted Accuracy: 0.7645\n",
            "\n",
            "XGBoost Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7133 | Fold Accuracies: [np.float64(0.7574468085106383), np.float64(0.67578125), np.float64(0.7729083665338645), np.float64(0.6937984496124031), np.float64(0.6666666666666666)]\n",
            "ID_TARGET: 129.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6275 | Fold Accuracies: [np.float64(0.6040816326530613), np.float64(0.6869918699186992), np.float64(0.6060606060606061), np.float64(0.6075949367088608), np.float64(0.6327272727272727)]\n",
            "ID_TARGET: 136.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 161.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.6710 | Fold Accuracies: [np.float64(0.5887096774193549), np.float64(0.6742424242424242), np.float64(0.6183206106870229), np.float64(0.667953667953668), np.float64(0.6743295019157088)]\n",
            "ID_TARGET: 217.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 91.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7799 | Fold Accuracies: [np.float64(0.8282442748091603), np.float64(0.8089430894308943), np.float64(0.6996197718631179), np.float64(0.8099173553719008), np.float64(0.7528089887640449)]\n",
            "ID_TARGET: 137.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0)]\n",
            "ID_TARGET: 8.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6083 | Fold Accuracies: [np.float64(0.5797665369649806), np.float64(0.5582329317269076), np.float64(0.6374501992031872), np.float64(0.616), np.float64(0.6181102362204725)]\n",
            "ID_TARGET: 3.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6825 | Fold Accuracies: [np.float64(0.678030303030303), np.float64(0.6639344262295082), np.float64(0.7131474103585658), np.float64(0.7330508474576272), np.float64(0.6244541484716157)]\n",
            "ID_TARGET: 9.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8953 | Fold Accuracies: [np.float64(1.0), np.float64(0.828), np.float64(0.8384615384615385), np.float64(1.0), np.float64(0.810077519379845)]\n",
            "ID_TARGET: 131.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6427 | Fold Accuracies: [np.float64(0.6968503937007874), np.float64(0.6538461538461539), np.float64(0.6532258064516129), np.float64(0.5864978902953587), np.float64(0.6230769230769231)]\n",
            "ID_TARGET: 21.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6880 | Fold Accuracies: [np.float64(0.7183098591549296), np.float64(0.6679389312977099), np.float64(0.6886446886446886), np.float64(0.66015625), np.float64(0.5914396887159533)]\n",
            "ID_TARGET: 54.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7428 | Fold Accuracies: [np.float64(0.7403100775193798), np.float64(0.7116104868913857), np.float64(0.775330396475771), np.float64(0.6474820143884892), np.float64(0.7686274509803922)]\n",
            "ID_TARGET: 130.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7001 | Fold Accuracies: [np.float64(0.7229437229437229), np.float64(0.6900369003690037), np.float64(0.7204301075268817), np.float64(0.6768060836501901), np.float64(0.635036496350365)]\n",
            "ID_TARGET: 269.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6456 | Fold Accuracies: [np.float64(0.676), np.float64(0.6812227074235808), np.float64(0.6639676113360324), np.float64(0.5531914893617021), np.float64(0.6536796536796536)]\n",
            "ID_TARGET: 157.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7185 | Fold Accuracies: [np.float64(0.7130434782608696), np.float64(0.7689075630252101), np.float64(0.7137096774193549), np.float64(0.708), np.float64(0.6762295081967213)]\n",
            "ID_TARGET: 249.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6977 | Fold Accuracies: [np.float64(0.686046511627907), np.float64(0.6730038022813688), np.float64(0.7325102880658436), np.float64(0.6693877551020408), np.float64(0.6412213740458015)]\n",
            "ID_TARGET: 22.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.6951 | Fold Accuracies: [np.float64(0.6847826086956522), np.float64(0.650375939849624), np.float64(0.7086614173228346), np.float64(0.685823754789272), np.float64(0.7042801556420234)]\n",
            "ID_TARGET: 202.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6943 | Fold Accuracies: [np.float64(0.6588235294117647), np.float64(0.7164179104477612), np.float64(0.6666666666666666), np.float64(0.7111913357400722), np.float64(0.6818181818181818)]\n",
            "ID_TARGET: 132.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7437 | Fold Accuracies: [np.float64(0.7543103448275862), np.float64(0.7068273092369478), np.float64(0.7244094488188977), np.float64(0.7427385892116183), np.float64(0.7903225806451613)]\n",
            "ID_TARGET: 96.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.9823 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(0.9115384615384615), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 7.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7419 | Fold Accuracies: [np.float64(0.7109375), np.float64(0.694980694980695), np.float64(0.6970802919708029), np.float64(0.7233201581027668), np.float64(0.7906976744186046)]\n",
            "ID_TARGET: 178.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7174 | Fold Accuracies: [np.float64(0.7357723577235772), np.float64(0.7110266159695817), np.float64(0.758893280632411), np.float64(0.689795918367347), np.float64(0.69140625)]\n",
            "ID_TARGET: 68.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7428 | Fold Accuracies: [np.float64(0.6973180076628352), np.float64(0.7489878542510121), np.float64(0.7521367521367521), np.float64(0.7755102040816326), np.float64(0.7090163934426229)]\n",
            "ID_TARGET: 44.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7481 | Fold Accuracies: [np.float64(0.7924528301886793), np.float64(0.7677165354330708), np.float64(0.7517985611510791), np.float64(0.7136752136752137), np.float64(0.7148148148148148)]\n",
            "ID_TARGET: 196.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7447 | Fold Accuracies: [np.float64(0.69), np.float64(0.7972972972972973), np.float64(0.7789855072463768), np.float64(0.69140625), np.float64(0.7659574468085106)]\n",
            "ID_TARGET: 292.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7031 | Fold Accuracies: [np.float64(0.6642599277978339), np.float64(0.7023809523809523), np.float64(0.6801470588235294), np.float64(0.67578125), np.float64(0.7126436781609196)]\n",
            "ID_TARGET: 239.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7428 | Fold Accuracies: [np.float64(0.6730769230769231), np.float64(0.6854838709677419), np.float64(0.7330508474576272), np.float64(0.753968253968254), np.float64(0.7366071428571429)]\n",
            "ID_TARGET: 279.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6781 | Fold Accuracies: [np.float64(0.6075471698113207), np.float64(0.7322834645669292), np.float64(0.6809338521400778), np.float64(0.7083333333333334), np.float64(0.6614173228346457)]\n",
            "ID_TARGET: 38.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7325 | Fold Accuracies: [np.float64(0.6870229007633588), np.float64(0.7233201581027668), np.float64(0.7601626016260162), np.float64(0.7164750957854407), np.float64(0.775330396475771)]\n",
            "ID_TARGET: 209.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 207.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6802 | Fold Accuracies: [np.float64(0.6809338521400778), np.float64(0.6666666666666666), np.float64(0.7188755020080321), np.float64(0.6792452830188679), np.float64(0.6550387596899225)]\n",
            "ID_TARGET: 98.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7322 | Fold Accuracies: [np.float64(0.6872586872586872), np.float64(0.7795918367346939), np.float64(0.7860082304526749), np.float64(0.7541666666666667), np.float64(0.6539923954372624)]\n",
            "ID_TARGET: 65.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8022 | Fold Accuracies: [np.float64(0.7443609022556391), np.float64(0.740909090909091), np.float64(1.0), np.float64(0.7777777777777778), np.float64(0.7478632478632479)]\n",
            "ID_TARGET: 51.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7318 | Fold Accuracies: [np.float64(0.7291666666666666), np.float64(0.708502024291498), np.float64(0.7241379310344828), np.float64(0.7235772357723578), np.float64(0.6929133858267716)]\n",
            "ID_TARGET: 78.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7317 | Fold Accuracies: [np.float64(0.7196652719665272), np.float64(0.78), np.float64(0.6958333333333333), np.float64(0.6962025316455697), np.float64(0.766798418972332)]\n",
            "ID_TARGET: 177.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7548 | Fold Accuracies: [np.float64(0.7454545454545455), np.float64(0.7695167286245354), np.float64(0.723404255319149), np.float64(0.7622377622377622), np.float64(0.7142857142857143)]\n",
            "ID_TARGET: 231.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 119.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7668 | Fold Accuracies: [np.float64(0.7159533073929961), np.float64(0.7370517928286853), np.float64(0.8372093023255814), np.float64(0.7172995780590717), np.float64(0.7622950819672131)]\n",
            "ID_TARGET: 158.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7908 | Fold Accuracies: [np.float64(0.7634854771784232), np.float64(0.8225806451612904), np.float64(0.7709923664122137), np.float64(0.7984189723320159), np.float64(0.7397769516728625)]\n",
            "ID_TARGET: 80.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7180 | Fold Accuracies: [np.float64(0.672), np.float64(0.7114624505928854), np.float64(0.668), np.float64(0.7061224489795919), np.float64(0.7433628318584071)]\n",
            "ID_TARGET: 25.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7408 | Fold Accuracies: [np.float64(0.7723577235772358), np.float64(0.7457627118644068), np.float64(0.7095588235294118), np.float64(0.7574626865671642), np.float64(0.71875)]\n",
            "ID_TARGET: 175.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 151.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7736 | Fold Accuracies: [np.float64(0.7601476014760148), np.float64(0.7536764705882353), np.float64(0.7649572649572649), np.float64(0.7347826086956522), np.float64(0.7975206611570248)]\n",
            "ID_TARGET: 257.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7382 | Fold Accuracies: [np.float64(0.7154150197628458), np.float64(0.6867924528301886), np.float64(0.7408759124087592), np.float64(0.7084870848708487), np.float64(0.7018181818181818)]\n",
            "ID_TARGET: 75.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7849 | Fold Accuracies: [np.float64(0.8032786885245902), np.float64(0.7530364372469636), np.float64(0.7873134328358209), np.float64(0.7551724137931034), np.float64(0.797752808988764)]\n",
            "ID_TARGET: 244.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.6760 | Fold Accuracies: [np.float64(0.704119850187266), np.float64(0.6823529411764706), np.float64(0.6754716981132075), np.float64(0.673469387755102), np.float64(0.6088560885608856)]\n",
            "ID_TARGET: 149.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7248 | Fold Accuracies: [np.float64(0.6353383458646616), np.float64(0.7176470588235294), np.float64(0.7307692307692307), np.float64(0.7283464566929134), np.float64(0.7007874015748031)]\n",
            "ID_TARGET: 85.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8157 | Fold Accuracies: [np.float64(0.8414634146341463), np.float64(0.8114754098360656), np.float64(0.816), np.float64(0.8739495798319328), np.float64(0.735632183908046)]\n",
            "ID_TARGET: 190.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7512 | Fold Accuracies: [np.float64(0.7631578947368421), np.float64(0.7228464419475655), np.float64(0.7692307692307693), np.float64(0.7213740458015268), np.float64(0.7655677655677655)]\n",
            "ID_TARGET: 13.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 228.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7756 | Fold Accuracies: [np.float64(0.7969924812030075), np.float64(0.7868217054263565), np.float64(0.735191637630662), np.float64(0.8414634146341463), np.float64(0.717391304347826)]\n",
            "ID_TARGET: 144.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7567 | Fold Accuracies: [np.float64(0.7457627118644068), np.float64(0.8277310924369747), np.float64(0.7672727272727272), np.float64(0.6785714285714286), np.float64(0.7161016949152542)]\n",
            "ID_TARGET: 290.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 114.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7208 | Fold Accuracies: [np.float64(0.6628352490421456), np.float64(0.7420634920634921), np.float64(0.7234848484848485), np.float64(0.7370517928286853), np.float64(0.7052238805970149)]\n",
            "ID_TARGET: 166.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7561 | Fold Accuracies: [np.float64(0.7439024390243902), np.float64(0.7435897435897436), np.float64(0.7459016393442623), np.float64(0.7340823970037453), np.float64(0.6967213114754098)]\n",
            "ID_TARGET: 234.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7604 | Fold Accuracies: [np.float64(0.7540983606557377), np.float64(0.7943548387096774), np.float64(0.7605042016806722), np.float64(0.7965367965367965), np.float64(0.6964980544747081)]\n",
            "ID_TARGET: 34.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7765 | Fold Accuracies: [np.float64(0.7415730337078652), np.float64(0.8053435114503816), np.float64(0.796), np.float64(0.7845528455284553), np.float64(0.7547892720306514)]\n",
            "ID_TARGET: 154.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7678 | Fold Accuracies: [np.float64(0.7677165354330708), np.float64(0.7857142857142857), np.float64(0.6893939393939394), np.float64(0.7078651685393258), np.float64(0.8008298755186722)]\n",
            "ID_TARGET: 225.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7313 | Fold Accuracies: [np.float64(0.6936619718309859), np.float64(0.7218045112781954), np.float64(0.7269503546099291), np.float64(0.7248062015503876), np.float64(0.7318840579710145)]\n",
            "ID_TARGET: 185.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7310 | Fold Accuracies: [np.float64(0.7013574660633484), np.float64(0.7074235807860262), np.float64(0.683982683982684), np.float64(0.7117903930131004), np.float64(0.7033898305084746)]\n",
            "ID_TARGET: 39.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 272.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7795 | Fold Accuracies: [np.float64(0.7615062761506276), np.float64(0.8416666666666667), np.float64(0.7120622568093385), np.float64(0.7701149425287356), np.float64(0.7852112676056338)]\n",
            "ID_TARGET: 282.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7396 | Fold Accuracies: [np.float64(0.70703125), np.float64(0.7451737451737451), np.float64(0.72), np.float64(0.7595419847328244), np.float64(0.7385892116182573)]\n",
            "ID_TARGET: 90.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7747 | Fold Accuracies: [np.float64(0.75), np.float64(0.7701149425287356), np.float64(0.724), np.float64(0.7800829875518672), np.float64(0.7936507936507936)]\n",
            "ID_TARGET: 52.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7410 | Fold Accuracies: [np.float64(0.717391304347826), np.float64(0.7713004484304933), np.float64(0.6694560669456067), np.float64(0.7142857142857143), np.float64(0.7154471544715447)]\n",
            "ID_TARGET: 258.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7263 | Fold Accuracies: [np.float64(0.6978723404255319), np.float64(0.7521739130434782), np.float64(0.7193675889328063), np.float64(0.75390625), np.float64(0.6589147286821705)]\n",
            "ID_TARGET: 291.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7596 | Fold Accuracies: [np.float64(0.7553648068669528), np.float64(0.7683397683397684), np.float64(0.73992673992674), np.float64(0.7683823529411765), np.float64(0.7658730158730159)]\n",
            "ID_TARGET: 152.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7523 | Fold Accuracies: [np.float64(0.6958333333333333), np.float64(0.744), np.float64(0.7310606060606061), np.float64(0.6884057971014492), np.float64(0.7593360995850622)]\n",
            "ID_TARGET: 133.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7715 | Fold Accuracies: [np.float64(0.7732342007434945), np.float64(0.7410358565737052), np.float64(0.7944664031620553), np.float64(0.7083333333333334), np.float64(0.8023255813953488)]\n",
            "ID_TARGET: 29.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7074 | Fold Accuracies: [np.float64(0.6613545816733067), np.float64(0.7665198237885462), np.float64(0.6781609195402298), np.float64(0.7022900763358778), np.float64(0.6973180076628352)]\n",
            "ID_TARGET: 274.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7475 | Fold Accuracies: [np.float64(0.7407407407407407), np.float64(0.7697841726618705), np.float64(0.7335907335907336), np.float64(0.7275985663082437), np.float64(0.6923076923076923)]\n",
            "ID_TARGET: 106.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.9610 | Fold Accuracies: [np.float64(0.8051948051948052), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 173.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7626 | Fold Accuracies: [np.float64(0.7875457875457875), np.float64(0.752), np.float64(0.75), np.float64(0.7777777777777778), np.float64(0.7086614173228346)]\n",
            "ID_TARGET: 33.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7340 | Fold Accuracies: [np.float64(0.7676348547717843), np.float64(0.722007722007722), np.float64(0.6941176470588235), np.float64(0.7354085603112841), np.float64(0.7509293680297398)]\n",
            "ID_TARGET: 69.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7338 | Fold Accuracies: [np.float64(0.7434782608695653), np.float64(0.7257383966244726), np.float64(0.6846153846153846), np.float64(0.7358490566037735), np.float64(0.7477477477477478)]\n",
            "ID_TARGET: 17.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7002 | Fold Accuracies: [np.float64(0.7170542635658915), np.float64(0.7180451127819549), np.float64(0.6953125), np.float64(0.6796875), np.float64(0.667953667953668)]\n",
            "ID_TARGET: 189.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7320 | Fold Accuracies: [np.float64(0.7272727272727273), np.float64(0.6833976833976834), np.float64(0.7851239669421488), np.float64(0.7391304347826086), np.float64(0.725)]\n",
            "ID_TARGET: 284.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7287 | Fold Accuracies: [np.float64(0.6618181818181819), np.float64(0.7065637065637066), np.float64(0.7581967213114754), np.float64(0.7211895910780669), np.float64(0.7333333333333333)]\n",
            "ID_TARGET: 218.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7126 | Fold Accuracies: [np.float64(0.6844106463878327), np.float64(0.7019607843137254), np.float64(0.6703703703703704), np.float64(0.8016194331983806), np.float64(0.6798561151079137)]\n",
            "ID_TARGET: 183.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7483 | Fold Accuracies: [np.float64(0.7246376811594203), np.float64(0.7644628099173554), np.float64(0.7396694214876033), np.float64(0.6946564885496184), np.float64(0.8181818181818182)]\n",
            "ID_TARGET: 206.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7602 | Fold Accuracies: [np.float64(0.7091633466135459), np.float64(0.7279693486590039), np.float64(0.782608695652174), np.float64(0.7510729613733905), np.float64(0.767175572519084)]\n",
            "ID_TARGET: 93.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7047 | Fold Accuracies: [np.float64(0.6694560669456067), np.float64(0.6383763837638377), np.float64(0.7136752136752137), np.float64(0.6966292134831461), np.float64(0.7011494252873564)]\n",
            "ID_TARGET: 16.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7130 | Fold Accuracies: [np.float64(0.6902985074626866), np.float64(0.6774193548387096), np.float64(0.6779026217228464), np.float64(0.7330827067669173), np.float64(0.6974789915966386)]\n",
            "ID_TARGET: 246.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7454 | Fold Accuracies: [np.float64(0.6628352490421456), np.float64(0.7121212121212122), np.float64(0.7338403041825095), np.float64(0.7132075471698113), np.float64(0.7137254901960784)]\n",
            "ID_TARGET: 167.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.9602 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(0.8008474576271186), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 1.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7377 | Fold Accuracies: [np.float64(0.7719298245614035), np.float64(0.7478632478632479), np.float64(0.7246963562753036), np.float64(0.6944444444444444), np.float64(0.7261410788381742)]\n",
            "ID_TARGET: 289.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7539 | Fold Accuracies: [np.float64(0.7521367521367521), np.float64(0.7761194029850746), np.float64(0.765625), np.float64(0.7649253731343284), np.float64(0.7105263157894737)]\n",
            "ID_TARGET: 141.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7918 | Fold Accuracies: [np.float64(0.7916666666666666), np.float64(0.8051948051948052), np.float64(0.7931034482758621), np.float64(0.816793893129771), np.float64(0.7520325203252033)]\n",
            "ID_TARGET: 109.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7265 | Fold Accuracies: [np.float64(0.7), np.float64(0.7530364372469636), np.float64(0.6995884773662552), np.float64(0.6679841897233202), np.float64(0.7446043165467626)]\n",
            "ID_TARGET: 19.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7719 | Fold Accuracies: [np.float64(0.7765151515151515), np.float64(0.7704918032786885), np.float64(0.73046875), np.float64(0.8150943396226416), np.float64(0.767175572519084)]\n",
            "ID_TARGET: 28.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7113 | Fold Accuracies: [np.float64(0.696969696969697), np.float64(0.6778242677824268), np.float64(0.7091633466135459), np.float64(0.7343173431734318), np.float64(0.690677966101695)]\n",
            "ID_TARGET: 251.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7186 | Fold Accuracies: [np.float64(0.6612903225806451), np.float64(0.6791044776119403), np.float64(0.725925925925926), np.float64(0.7073170731707317), np.float64(0.725)]\n",
            "ID_TARGET: 278.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7499 | Fold Accuracies: [np.float64(0.6587301587301587), np.float64(0.7509727626459144), np.float64(0.7219917012448133), np.float64(0.8095238095238095), np.float64(0.7467811158798283)]\n",
            "ID_TARGET: 76.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7491 | Fold Accuracies: [np.float64(0.6911196911196911), np.float64(0.7238805970149254), np.float64(0.7042801556420234), np.float64(0.7302158273381295), np.float64(0.7312252964426877)]\n",
            "ID_TARGET: 241.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7444 | Fold Accuracies: [np.float64(0.7051792828685259), np.float64(0.7522522522522522), np.float64(0.6652719665271967), np.float64(0.7860082304526749), np.float64(0.7166666666666667)]\n",
            "ID_TARGET: 214.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7816 | Fold Accuracies: [np.float64(0.7320754716981132), np.float64(0.6823529411764706), np.float64(0.7755905511811023), np.float64(0.7888888888888889), np.float64(0.7248062015503876)]\n",
            "ID_TARGET: 102.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7621 | Fold Accuracies: [np.float64(0.7862595419847328), np.float64(0.717391304347826), np.float64(0.7396694214876033), np.float64(0.8103448275862069), np.float64(0.7153846153846154)]\n",
            "ID_TARGET: 145.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6891 | Fold Accuracies: [np.float64(0.6640926640926641), np.float64(0.6370370370370371), np.float64(0.6816326530612244), np.float64(0.6539923954372624), np.float64(0.6954732510288066)]\n",
            "ID_TARGET: 155.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7950 | Fold Accuracies: [np.float64(0.7777777777777778), np.float64(0.8382352941176471), np.float64(0.7901234567901234), np.float64(0.7704280155642024), np.float64(0.7830882352941176)]\n",
            "\n",
            "Performing second-pass training with top 30 features...\n",
            "\n",
            "Second-pass LightGBM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rLightGBM Targets:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   1%|          | 1/100 [00:00<01:04,  1.52it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   2%|         | 2/100 [00:01<00:57,  1.71it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   3%|         | 3/100 [00:01<00:53,  1.80it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   4%|         | 4/100 [00:02<00:51,  1.86it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   5%|         | 5/100 [00:02<00:48,  1.94it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   6%|         | 6/100 [00:03<00:46,  2.04it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   7%|         | 7/100 [00:03<00:43,  2.12it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   8%|         | 8/100 [00:04<00:45,  2.04it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   9%|         | 9/100 [00:04<00:46,  1.95it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  10%|         | 10/100 [00:05<00:45,  1.99it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  11%|         | 11/100 [00:05<00:46,  1.93it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  12%|        | 12/100 [00:06<00:46,  1.89it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  13%|        | 13/100 [00:07<00:53,  1.64it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  14%|        | 14/100 [00:07<00:56,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  15%|        | 15/100 [00:08<00:57,  1.49it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  16%|        | 16/100 [00:09<00:58,  1.43it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  17%|        | 17/100 [00:09<00:53,  1.56it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  18%|        | 18/100 [00:10<00:47,  1.71it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  19%|        | 19/100 [00:10<00:46,  1.73it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  20%|        | 20/100 [00:11<00:43,  1.85it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  21%|        | 21/100 [00:11<00:40,  1.93it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  22%|       | 22/100 [00:12<00:39,  1.97it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  23%|       | 23/100 [00:12<00:38,  2.01it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  24%|       | 24/100 [00:13<00:37,  2.05it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  25%|       | 25/100 [00:13<00:36,  2.04it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  26%|       | 26/100 [00:14<00:35,  2.06it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  27%|       | 27/100 [00:14<00:36,  2.02it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  28%|       | 28/100 [00:15<00:36,  1.99it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  29%|       | 29/100 [00:15<00:36,  1.95it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  30%|       | 30/100 [00:16<00:37,  1.89it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  31%|       | 31/100 [00:16<00:38,  1.80it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  32%|      | 32/100 [00:17<00:41,  1.65it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  33%|      | 33/100 [00:18<00:41,  1.62it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  34%|      | 34/100 [00:18<00:41,  1.58it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  35%|      | 35/100 [00:19<00:43,  1.50it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  36%|      | 36/100 [00:20<00:43,  1.46it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  37%|      | 37/100 [00:21<00:42,  1.47it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  38%|      | 38/100 [00:21<00:41,  1.48it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  39%|      | 39/100 [00:22<00:41,  1.46it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  40%|      | 40/100 [00:23<00:39,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  41%|      | 41/100 [00:23<00:35,  1.67it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  42%|     | 42/100 [00:23<00:32,  1.81it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  43%|     | 43/100 [00:24<00:29,  1.91it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  44%|     | 44/100 [00:24<00:30,  1.85it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  45%|     | 45/100 [00:25<00:30,  1.80it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  46%|     | 46/100 [00:26<00:29,  1.82it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  47%|     | 47/100 [00:26<00:29,  1.81it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  48%|     | 48/100 [00:27<00:28,  1.80it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  49%|     | 49/100 [00:27<00:27,  1.89it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  50%|     | 50/100 [00:28<00:25,  1.94it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  51%|     | 51/100 [00:28<00:24,  1.98it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  52%|    | 52/100 [00:29<00:24,  1.99it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  53%|    | 53/100 [00:29<00:22,  2.05it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  54%|    | 54/100 [00:30<00:22,  2.06it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  55%|    | 55/100 [00:30<00:22,  2.00it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  56%|    | 56/100 [00:31<00:22,  1.96it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  57%|    | 57/100 [00:31<00:22,  1.94it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  58%|    | 58/100 [00:32<00:22,  1.89it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  59%|    | 59/100 [00:32<00:21,  1.87it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  60%|    | 60/100 [00:33<00:24,  1.64it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  61%|    | 61/100 [00:34<00:25,  1.55it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  62%|   | 62/100 [00:34<00:25,  1.51it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  63%|   | 63/100 [00:35<00:24,  1.48it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  64%|   | 64/100 [00:36<00:23,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  65%|   | 65/100 [00:36<00:21,  1.64it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  66%|   | 66/100 [00:37<00:19,  1.77it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  67%|   | 67/100 [00:37<00:17,  1.87it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  68%|   | 68/100 [00:38<00:17,  1.87it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  69%|   | 69/100 [00:38<00:16,  1.87it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  70%|   | 70/100 [00:39<00:16,  1.85it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  71%|   | 71/100 [00:39<00:15,  1.86it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  72%|  | 72/100 [00:40<00:14,  1.89it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  73%|  | 73/100 [00:40<00:13,  2.00it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  74%|  | 74/100 [00:41<00:12,  2.05it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  75%|  | 75/100 [00:41<00:12,  2.07it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  76%|  | 76/100 [00:42<00:11,  2.04it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  77%|  | 77/100 [00:42<00:11,  2.08it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  78%|  | 78/100 [00:43<00:10,  2.12it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  79%|  | 79/100 [00:43<00:10,  2.09it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  80%|  | 80/100 [00:44<00:09,  2.10it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  81%|  | 81/100 [00:44<00:09,  2.10it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  82%| | 82/100 [00:45<00:08,  2.05it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  83%| | 83/100 [00:45<00:08,  2.08it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  84%| | 84/100 [00:46<00:07,  2.01it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  85%| | 85/100 [00:46<00:08,  1.78it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  86%| | 86/100 [00:47<00:08,  1.65it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  87%| | 87/100 [00:48<00:08,  1.56it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  88%| | 88/100 [00:48<00:07,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  89%| | 89/100 [00:49<00:06,  1.68it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  90%| | 90/100 [00:49<00:05,  1.77it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  91%| | 91/100 [00:50<00:04,  1.88it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  92%|| 92/100 [00:50<00:04,  1.93it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  93%|| 93/100 [00:51<00:03,  1.99it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  94%|| 94/100 [00:51<00:02,  2.03it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  95%|| 95/100 [00:52<00:02,  2.07it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  96%|| 96/100 [00:52<00:01,  2.14it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  97%|| 97/100 [00:53<00:01,  2.16it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  98%|| 98/100 [00:53<00:00,  2.12it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  99%|| 99/100 [00:54<00:00,  2.01it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets: 100%|| 100/100 [00:54<00:00,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Second-pass XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "XGBoost Targets: 100%|| 100/100 [00:53<00:00,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performing third-pass training for low-performing targets...\n",
            "\n",
            "Third-pass LightGBM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "LightGBM Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 44150.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Third-pass XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "XGBoost Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 57888.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved hyperparameter log to: /content/hyperparameters.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5c6ab69e-79cd-4975-a0bc-7a9d6ae51452\", \"hyperparameters.json\", 655243)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved predictions to: /content/predictions_ensemble.csv\n",
            "Output CSV shape: (114468, 2)\n",
            "Output CSV ID range: 0 to 114467\n",
            "Unique RET_TARGET values: [ 1 -1]\n",
            "Missing values: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7a7aeff3-5be2-48a2-9387-2fa741c51cfa\", \"predictions_ensemble.csv\", 968188)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation Results:\n",
            "LightGBM: 0.7572\n",
            "XGBoost: 0.7645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "new mtd, lee[ 74.22 lightbm but improve XGBoost -- 74.219"
      ],
      "metadata": {
        "id": "8PKMrCQ-T487"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost\n",
        "from sklearn.decomposition import PCA\n",
        "from joblib import Parallel, delayed\n",
        "import json\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# Check xgboost version for compatibility\n",
        "print(f\"XGBoost version: {xgboost.__version__}\")\n",
        "if int(xgboost.__version__.split('.')[0]) < 1:\n",
        "    print(\"Warning: XGBoost version < 1.0.0 detected. Ensure compatibility with eval_metric in constructor.\")\n",
        "\n",
        "# Set up data directory\n",
        "DATA_DIR = '/content'\n",
        "\n",
        "# Load datasets\n",
        "try:\n",
        "    X_train = pd.read_csv(os.path.join(DATA_DIR, 'X_train_itDkypA.csv'), index_col='ID', dtype=np.float32)\n",
        "    y_train = pd.read_csv(os.path.join(DATA_DIR, 'y_train_3LeeT2g.csv'), index_col='ID', dtype=np.float32)\n",
        "    X_test = pd.read_csv(os.path.join(DATA_DIR, 'X_test_Beg4ey3.csv'), index_col='ID', dtype=np.float32)\n",
        "    supplementary = pd.read_csv(os.path.join(DATA_DIR, 'supplementary_data_Vkoyn8z.csv'))\n",
        "except FileNotFoundError as e:\n",
        "    raise FileNotFoundError(f\"Dataset not found: {e}. Please ensure files are uploaded to {DATA_DIR}.\")\n",
        "\n",
        "# Custom weighted accuracy metric\n",
        "def weighted_accuracy(y_true, y_pred, weights):\n",
        "    y_pred_mapped = np.where(y_pred == 1, 1, -1)\n",
        "    correct = (y_pred_mapped == np.sign(y_true)).astype(float)\n",
        "    return np.sum(np.abs(y_true) * correct) / np.sum(np.abs(y_true))\n",
        "\n",
        "# Preprocess data with enhanced feature selection\n",
        "def preprocess_data(X, y=None, supplementary=None, is_train=True, top_cols=None):\n",
        "    ret_cols = [col for col in X.columns if col.startswith('RET_')]\n",
        "    if is_train and top_cols is None:\n",
        "        if len(ret_cols) > 15:\n",
        "            variances = X[ret_cols].var()\n",
        "            corr_sum = X[ret_cols].corr().abs().sum()\n",
        "            combined_score = variances * corr_sum\n",
        "            valid_cols = variances[variances > 1e-5].index\n",
        "            if len(valid_cols) < 15:\n",
        "                top_cols = valid_cols.tolist()\n",
        "            else:\n",
        "                top_cols = combined_score.loc[valid_cols].sort_values(ascending=False).head(15).index.tolist()\n",
        "        else:\n",
        "            top_cols = ret_cols\n",
        "        print(f\"Selected top return columns: {top_cols}\")\n",
        "    elif top_cols is not None:\n",
        "        ret_cols = [col for col in ret_cols if col in top_cols]\n",
        "        if not ret_cols:\n",
        "            raise ValueError(\"No return columns selected. Check top_cols consistency.\")\n",
        "\n",
        "    sector_medians = {}\n",
        "    if supplementary is not None:\n",
        "        sector_map = supplementary.set_index('ID_asset')['CLASS_LEVEL_1']\n",
        "        for col in ret_cols:\n",
        "            asset_id = int(col.replace('RET_', ''))\n",
        "            sector = sector_map.get(asset_id, np.nan)\n",
        "            if pd.notna(sector):\n",
        "                sector_assets = supplementary[supplementary['CLASS_LEVEL_1'] == sector]['ID_asset']\n",
        "                sector_cols = [f'RET_{a}' for a in sector_assets if f'RET_{a}' in X.columns]\n",
        "                if sector_cols:\n",
        "                    sector_medians[col] = X[sector_cols].median(axis=1)\n",
        "            if col in sector_medians:\n",
        "                X[col] = X[col].fillna(sector_medians[col])\n",
        "            else:\n",
        "                X[col] = X[col].fillna(X[col].median())\n",
        "\n",
        "    new_cols = {}\n",
        "    if supplementary is not None:\n",
        "        level = 'CLASS_LEVEL_1'\n",
        "        sector_groups = supplementary.groupby(level)['ID_asset'].apply(list).to_dict()\n",
        "        for sector, assets in sector_groups.items():\n",
        "            asset_cols = [f'RET_{asset}' for asset in assets if f'RET_{asset}' in ret_cols]\n",
        "            if asset_cols:\n",
        "                new_cols[f'SECTOR_AVG_{level}_{sector}'] = X[asset_cols].mean(axis=1).replace([np.inf, -np.inf], 0).fillna(0)\n",
        "        X = X.merge(supplementary[['ID_asset', level]].rename(columns={'ID_asset': 'ID_TARGET', level: f'TARGET_{level}'}),\n",
        "                    on='ID_TARGET', how='left')\n",
        "        X = pd.concat([X, pd.get_dummies(X[f'TARGET_{level}'], prefix=f'TARGET_{level}', dummy_na=True)], axis=1)\n",
        "        X = X.drop(f'TARGET_{level}', axis=1)\n",
        "\n",
        "    new_cols['MEAN_RET'] = X[ret_cols].mean(axis=1)\n",
        "    new_cols['STD_RET'] = X[ret_cols].std(axis=1)\n",
        "    new_cols.update({f'CS_RANK_{col}': X.groupby('ID_DAY')[col].rank(pct=True).replace([np.inf, -np.inf], 0).fillna(0) for col in ret_cols})\n",
        "\n",
        "    if is_train:\n",
        "        corr_matrix = X[ret_cols].corr()\n",
        "        corr_pairs = corr_matrix.unstack().sort_values(ascending=False)\n",
        "        top_pairs = [(i, j) for i, j in corr_pairs.index if i < j][:5]\n",
        "        for i, j in top_pairs:\n",
        "            new_cols[f'CORR_{i}_{j}'] = X[i] * X[j]\n",
        "\n",
        "    if ret_cols:\n",
        "        pca = PCA(n_components=min(2, len(ret_cols)), random_state=42)\n",
        "        pca_features = pca.fit_transform(X[ret_cols].fillna(0))\n",
        "        for i in range(pca_features.shape[1]):\n",
        "            new_cols[f'PCA_{i}'] = pca_features[:, i]\n",
        "\n",
        "    new_cols_df = pd.DataFrame(new_cols, index=X.index, dtype=np.float32)\n",
        "    X = pd.concat([X, new_cols_df], axis=1)\n",
        "\n",
        "    feature_cols = [col for col in X.columns if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "    scaler = StandardScaler()\n",
        "    X[feature_cols] = scaler.fit_transform(X[feature_cols].replace([np.inf, -np.inf], 0).fillna(0))\n",
        "\n",
        "    if is_train:\n",
        "        y['SIGN_TARGET'] = np.where(y['RET_TARGET'] > 0, 1, 0).astype(np.int32)\n",
        "        return X, y, feature_cols, top_cols\n",
        "    return X, None, feature_cols, top_cols\n",
        "\n",
        "# Preprocess data\n",
        "try:\n",
        "    X_train, y_train, feature_cols, top_cols = preprocess_data(X_train, y_train, supplementary, is_train=True)\n",
        "    X_test, _, test_feature_cols, _ = preprocess_data(X_test, supplementary=supplementary, is_train=False, top_cols=top_cols)\n",
        "except ValueError as e:\n",
        "    print(f\"Preprocessing error: {e}\")\n",
        "    raise\n",
        "\n",
        "# Align columns\n",
        "common_cols = X_train.columns.intersection(X_test.columns)\n",
        "X_train = X_train[common_cols]\n",
        "X_test = X_test[common_cols]\n",
        "feature_cols = [col for col in common_cols if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "\n",
        "# Align y_train\n",
        "y_train = y_train.loc[X_train.index]\n",
        "\n",
        "# Define models with updated XGBoost hyperparameter grid\n",
        "models = {\n",
        "    'LightGBM': {\n",
        "        'model': LGBMClassifier(num_leaves=31, min_child_samples=15, lambda_l1=0.3, lambda_l2=0.3,\n",
        "                                subsample=0.7, colsample_bytree=0.8, bagging_freq=5, bagging_fraction=0.7,\n",
        "                                random_state=42, n_jobs=1, verbosity=-1, class_weight='balanced', force_row_wise=True),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.02], 'num_leaves': [15], 'min_child_samples': [20], 'bagging_fraction': [0.6], 'reg_alpha': [0.1], 'reg_lambda': [0.1]},\n",
        "            {'learning_rate': [0.05], 'num_leaves': [31], 'min_child_samples': [10], 'bagging_fraction': [0.7], 'reg_alpha': [0.2], 'reg_lambda': [0.2]},\n",
        "            {'learning_rate': [0.07], 'num_leaves': [47], 'min_child_samples': [15], 'bagging_fraction': [0.8], 'reg_alpha': [0.3], 'reg_lambda': [0.3]}\n",
        "        ],\n",
        "        'callbacks': [lightgbm.early_stopping(stopping_rounds=10, verbose=False)]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'model': XGBClassifier(max_depth=4, min_child_weight=2, subsample=0.8, colsample_bytree=0.8,\n",
        "                               random_state=42, n_jobs=1, eval_metric='logloss', verbosity=0,\n",
        "                               scale_pos_weight=len(y_train[y_train['SIGN_TARGET'] == 0]) / len(y_train[y_train['SIGN_TARGET'] == 1])),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.02], 'max_depth': [2], 'min_child_weight': [1], 'subsample': [0.5], 'n_estimators': [150], 'reg_alpha': [0.05], 'reg_lambda': [0.5]},\n",
        "            {'learning_rate': [0.03], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [150], 'reg_alpha': [0.1], 'reg_lambda': [1.0]},\n",
        "            {'learning_rate': [0.05], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [200], 'reg_alpha': [0.2], 'reg_lambda': [1.5]},\n",
        "            {'learning_rate': [0.07], 'max_depth': [5], 'min_child_weight': [3], 'subsample': [0.8], 'n_estimators': [150], 'reg_alpha': [0.3], 'reg_lambda': [1.0]},\n",
        "            {'learning_rate': [0.04], 'max_depth': [3], 'min_child_weight': [2], 'subsample': [0.65], 'n_estimators': [175], 'reg_alpha': [0.15], 'reg_lambda': [1.2]}\n",
        "        ],\n",
        "        'callbacks': [xgboost.callback.EarlyStopping(rounds=10, metric_name='logloss', save_best=True)]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to train and predict for a single target\n",
        "def train_target(target, X_train, y_train, X_test, feature_cols, model, model_name, kf, param_grid, callbacks):\n",
        "    X_target = X_train[X_train['ID_TARGET'] == target][feature_cols]\n",
        "    y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "    weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "    low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "    weight_scale = 1.5 if target in low_performing_targets else 1.0\n",
        "    if len(X_target) < 500:\n",
        "        weight_scale *= 1.5\n",
        "    weights = weights * weight_scale\n",
        "    groups = X_train[X_train['ID_TARGET'] == target]['ID_DAY']\n",
        "    X_test_target = X_test[X_test['ID_TARGET'] == target][feature_cols]\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "    if len(X_target) < 100 or len(X_test_target) == 0:\n",
        "        print(f\"Warning: Insufficient data for ID_TARGET {target} (train: {len(X_target)}, test: {len(X_test_target)}). Skipping.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    param_results = []\n",
        "    best_params = None\n",
        "    best_score = 0\n",
        "    best_model = None\n",
        "\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        print(f\"Testing params for {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "        try:\n",
        "            model.set_params(**params)\n",
        "        except ValueError as e:\n",
        "            print(f\"Invalid params for {model_name} ID_TARGET {target}: {e}\")\n",
        "            continue\n",
        "        fold_accuracies = []\n",
        "        for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "            X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "            y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "            w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "            if model_name == 'LightGBM' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=callbacks)\n",
        "            elif model_name == 'XGBoost' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "            else:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "            y_pred = model.predict(X_val)\n",
        "            acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "            fold_accuracies.append(acc)\n",
        "        mean_acc = np.mean(fold_accuracies)\n",
        "        print(f\"{model_name} | ID_TARGET: {target} | Params: {params} | Mean Accuracy: {mean_acc:.4f} | Fold Accuracies: {fold_accuracies}\", flush=True)\n",
        "        param_results.append({\n",
        "            'params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': fold_accuracies\n",
        "        })\n",
        "        if mean_acc > best_score:\n",
        "            best_score = mean_acc\n",
        "            best_params = params\n",
        "            best_model = type(model)(**model.get_params())\n",
        "\n",
        "    if best_model is None:\n",
        "        print(f\"No valid model for {model_name} ID_TARGET {target}. Using default.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    best_model.set_params(**best_params)\n",
        "    if model_name == 'LightGBM' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=callbacks)\n",
        "    elif model_name == 'XGBoost' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "    else:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights)\n",
        "    preds = best_model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "    importance = best_model.feature_importances_\n",
        "    feature_importance = dict(zip(feature_cols, importance))\n",
        "    top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:30]\n",
        "    gc.collect()\n",
        "    return str(target), best_params, best_score, param_results, test_ids, preds, top_features\n",
        "\n",
        "# Cross-validation and training\n",
        "kf = GroupKFold(n_splits=5)\n",
        "results = {}\n",
        "predictions = {}\n",
        "ensemble_weights = {'LightGBM': 0.7, 'XGBoost': 0.3}\n",
        "param_log = {}\n",
        "top_features_all = {}\n",
        "param_summary = []\n",
        "low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\", flush=True)\n",
        "    param_log[model_name] = {}\n",
        "    top_features_all[model_name] = {}\n",
        "    results_parallel = Parallel(n_jobs=-1)(\n",
        "        delayed(train_target)(target, X_train, y_train, X_test, feature_cols, model_info['model'], model_name, kf,\n",
        "                             model_info['param_grid'], model_info['callbacks'])\n",
        "        for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\")\n",
        "    )\n",
        "    accuracies = []\n",
        "    for target, params, mean_acc, param_results, test_ids, preds, top_features in results_parallel:\n",
        "        param_log[model_name][target] = {\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'all_params': param_results\n",
        "        }\n",
        "        top_features_all[model_name][target] = top_features\n",
        "        accuracies.append(mean_acc)\n",
        "        predictions.setdefault(target, {})[model_name] = dict(zip(test_ids, preds))\n",
        "        param_summary.append({\n",
        "            'model': model_name,\n",
        "            'ID_TARGET': target,\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': param_results[-1]['fold_accuracies'] if param_results else []\n",
        "        })\n",
        "    results[model_name] = np.mean([acc for acc in accuracies if acc > 0])\n",
        "    print(f\"{model_name} Weighted Accuracy: {results[model_name]:.4f}\", flush=True)\n",
        "    print(f\"\\n{model_name} Parameter Summary:\", flush=True)\n",
        "    for summary in param_summary:\n",
        "        if summary['model'] == model_name:\n",
        "            print(f\"ID_TARGET: {summary['ID_TARGET']} | Best Params: {summary['best_params']} | Mean Accuracy: {summary['mean_accuracy']:.4f} | Fold Accuracies: {summary['fold_accuracies']}\", flush=True)\n",
        "\n",
        "# Second-pass training with top 30 features\n",
        "print(\"\\nPerforming second-pass training with top 30 features...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nSecond-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\"):\n",
        "        target_str = str(target)\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "        weight_scale = 1.5 if target in low_performing_targets else 1.0\n",
        "        if len(X_target) < 500:\n",
        "            weight_scale *= 1.5\n",
        "        weights = weights * weight_scale\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        best_params['n_estimators'] = 200\n",
        "        model.set_params(**best_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Third-pass training for low-performing targets\n",
        "print(\"\\nPerforming third-pass training for low-performing targets...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nThird-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(low_performing_targets, desc=f\"{model_name} Low-Performing Targets\"):\n",
        "        target_str = str(target)\n",
        "        if target_str not in param_log[model_name] or param_log[model_name][target_str]['mean_accuracy'] >= 0.75:\n",
        "            continue\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs() * 1.5\n",
        "        if len(X_target) < 500:\n",
        "            weights = weights * 1.5\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        fine_tune_grid = [\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.8, 'n_estimators': 200, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.0, 'n_estimators': 250, 'reg_alpha': best_params['reg_alpha'][0], 'reg_lambda': best_params['reg_lambda'][0]},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.2, 'n_estimators': 200, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1}\n",
        "        ]\n",
        "        best_score = param_log[model_name][target_str]['mean_accuracy']\n",
        "        best_fine_params = best_params\n",
        "        for params in ParameterGrid(fine_tune_grid):\n",
        "            print(f\"Fine-tuning {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "            model.set_params(**params)\n",
        "            fold_accuracies = []\n",
        "            for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "                X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "                y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "                w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "                if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "                elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "                else:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "                y_pred = model.predict(X_val)\n",
        "                acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "                fold_accuracies.append(acc)\n",
        "            mean_acc = np.mean(fold_accuracies)\n",
        "            print(f\"{model_name} | ID_TARGET: {target} | Fine-tune Params: {params} | Mean Accuracy: {mean_acc:.4f}\", flush=True)\n",
        "            if mean_acc > best_score:\n",
        "                best_score = mean_acc\n",
        "                best_fine_params = params\n",
        "                param_log[model_name][target_str]['best_params'] = best_fine_params\n",
        "                param_log[model_name][target_str]['mean_accuracy'] = best_score\n",
        "                param_summary.append({\n",
        "                    'model': model_name,\n",
        "                    'ID_TARGET': target_str,\n",
        "                    'best_params': best_fine_params,\n",
        "                    'mean_accuracy': best_score,\n",
        "                    'fold_accuracies': fold_accuracies\n",
        "                })\n",
        "        model.set_params(**best_fine_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Save parameter log\n",
        "param_log_path = os.path.join(DATA_DIR, 'hyperparameters.json')\n",
        "with open(param_log_path, 'w') as f:\n",
        "    json.dump(param_log, f, indent=4)\n",
        "print(f\"Saved hyperparameter log to: {param_log_path}\", flush=True)\n",
        "files.download(param_log_path)\n",
        "\n",
        "# Ensemble predictions\n",
        "final_predictions = {}\n",
        "missing_day_targets = []\n",
        "for target in X_test['ID_TARGET'].unique():\n",
        "    target_str = str(target)\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "    for day in X_test[X_test['ID_TARGET'] == target]['ID_DAY'].unique():\n",
        "        day_idx = (X_test['ID_TARGET'] == target) & (X_test['ID_DAY'] == day)\n",
        "        day_test_ids = X_test[day_idx].index\n",
        "        if len(day_test_ids) == 0:\n",
        "            print(f\"Warning: No test samples for ID_TARGET {target} on ID_DAY {day}. Using default prediction.\")\n",
        "            missing_day_targets.append((target, day))\n",
        "            for idx in test_ids:\n",
        "                final_predictions[idx] = -1\n",
        "            continue\n",
        "        lgbm_preds = np.array([predictions[target_str].get('LightGBM', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        xgb_preds = np.array([predictions[target_str].get('XGBoost', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        ensemble_preds = ensemble_weights['LightGBM'] * lgbm_preds + ensemble_weights['XGBoost'] * xgb_preds\n",
        "        smoothed_preds = pd.Series(ensemble_preds).ewm(span=3).mean().values[-1] if len(ensemble_preds) > 0 else 0.5\n",
        "        for idx in day_test_ids:\n",
        "            final_predictions[idx] = 1 if smoothed_preds >= 0.5 else -1\n",
        "\n",
        "if missing_day_targets:\n",
        "    print(f\"Missing day-target pairs: {missing_day_targets}\")\n",
        "\n",
        "# Create output CSV\n",
        "output_df = pd.DataFrame.from_dict(final_predictions, orient='index', columns=['RET_TARGET']).reset_index()\n",
        "output_df.columns = ['ID', 'RET_TARGET']\n",
        "output_df = output_df.sort_values('ID')\n",
        "expected_ids = set(X_test.index)\n",
        "submission_ids = set(output_df['ID'])\n",
        "if expected_ids != submission_ids:\n",
        "    missing_ids = expected_ids - submission_ids\n",
        "    print(f\"Warning: Submission missing {len(missing_ids)} IDs: {missing_ids}\")\n",
        "    missing_df = pd.DataFrame({'ID': list(missing_ids), 'RET_TARGET': -1})\n",
        "    output_df = pd.concat([output_df, missing_df], ignore_index=True).sort_values('ID')\n",
        "output_path = os.path.join(DATA_DIR, 'predictions_ensemble.csv')\n",
        "output_df.to_csv(output_path, index=False)\n",
        "print(f\"Saved predictions to: {output_path}\", flush=True)\n",
        "\n",
        "# Validate output\n",
        "test_csv = pd.read_csv(output_path)\n",
        "print(f\"Output CSV shape: {test_csv.shape}\", flush=True)\n",
        "print(f\"Output CSV ID range: {test_csv['ID'].min()} to {test_csv['ID'].max()}\", flush=True)\n",
        "print(f\"Unique RET_TARGET values: {test_csv['RET_TARGET'].unique()}\", flush=True)\n",
        "print(f\"Missing values: {test_csv.isna().sum().sum()}\", flush=True)\n",
        "\n",
        "# Download the file\n",
        "files.download(output_path)\n",
        "\n",
        "# Print final results\n",
        "print(\"\\nValidation Results:\", flush=True)\n",
        "for model_name, acc in results.items():\n",
        "    print(f\"{model_name}: {acc:.4f}\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aku4zBe-T99C",
        "outputId": "8778f977-7590-483b-974b-621199d7c115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost version: 3.0.2\n",
            "Selected top return columns: ['RET_262', 'RET_88', 'RET_172', 'RET_259', 'RET_150', 'RET_118', 'RET_216', 'RET_268', 'RET_115', 'RET_261', 'RET_59', 'RET_238', 'RET_121', 'RET_97', 'RET_30']\n",
            "\n",
            "Training LightGBM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LightGBM Targets: 100%|| 100/100 [10:32<00:00,  6.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LightGBM Weighted Accuracy: 0.7327\n",
            "\n",
            "LightGBM Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.9173 | Fold Accuracies: [np.float64(0.7531914893617021), np.float64(0.83203125), np.float64(0.7330677290836654), np.float64(0.8255813953488372), np.float64(0.8112449799196787)]\n",
            "ID_TARGET: 129.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6481 | Fold Accuracies: [np.float64(0.5959183673469388), np.float64(0.6504065040650406), np.float64(0.6363636363636364), np.float64(0.6118143459915611), np.float64(0.7090909090909091)]\n",
            "ID_TARGET: 136.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.6080 | Fold Accuracies: [np.float64(0.6138996138996139), np.float64(0.6060606060606061), np.float64(0.610909090909091), np.float64(0.59765625), np.float64(0.611336032388664)]\n",
            "ID_TARGET: 161.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6911 | Fold Accuracies: [np.float64(0.6532258064516129), np.float64(0.6704545454545454), np.float64(0.6908396946564885), np.float64(0.7258687258687259), np.float64(0.6704980842911877)]\n",
            "ID_TARGET: 217.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6876 | Fold Accuracies: [np.float64(0.6795366795366795), np.float64(0.6844106463878327), np.float64(0.671280276816609), np.float64(0.6666666666666666), np.float64(0.6808510638297872)]\n",
            "ID_TARGET: 91.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6982 | Fold Accuracies: [np.float64(0.6603053435114504), np.float64(0.6788617886178862), np.float64(0.6920152091254753), np.float64(0.6900826446280992), np.float64(0.7191011235955056)]\n",
            "ID_TARGET: 137.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6451 | Fold Accuracies: [np.float64(0.5909090909090909), np.float64(0.6200873362445415), np.float64(0.6282051282051282), np.float64(0.71484375), np.float64(0.6185185185185185)]\n",
            "ID_TARGET: 8.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7665 | Fold Accuracies: [np.float64(0.7042801556420234), np.float64(0.6506024096385542), np.float64(0.6693227091633466), np.float64(0.68), np.float64(0.9015748031496063)]\n",
            "ID_TARGET: 3.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7112 | Fold Accuracies: [np.float64(0.6818181818181818), np.float64(0.6598360655737705), np.float64(0.6932270916334662), np.float64(0.7330508474576272), np.float64(0.6593886462882096)]\n",
            "ID_TARGET: 9.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6752 | Fold Accuracies: [np.float64(0.6553191489361702), np.float64(0.708), np.float64(0.65), np.float64(0.6776859504132231), np.float64(0.6627906976744186)]\n",
            "ID_TARGET: 131.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6581 | Fold Accuracies: [np.float64(0.6889763779527559), np.float64(0.6692307692307692), np.float64(0.6733870967741935), np.float64(0.5822784810126582), np.float64(0.6307692307692307)]\n",
            "ID_TARGET: 21.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6770 | Fold Accuracies: [np.float64(0.7323943661971831), np.float64(0.6755725190839694), np.float64(0.663003663003663), np.float64(0.63671875), np.float64(0.6264591439688716)]\n",
            "ID_TARGET: 54.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7675 | Fold Accuracies: [np.float64(0.7829457364341085), np.float64(0.7640449438202247), np.float64(0.7577092511013216), np.float64(0.6834532374100719), np.float64(0.788235294117647)]\n",
            "ID_TARGET: 130.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7486 | Fold Accuracies: [np.float64(0.7012987012987013), np.float64(0.7453874538745388), np.float64(0.6738351254480287), np.float64(0.6958174904942965), np.float64(0.6715328467153284)]\n",
            "ID_TARGET: 269.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6907 | Fold Accuracies: [np.float64(0.708), np.float64(0.6899563318777293), np.float64(0.7044534412955465), np.float64(0.5957446808510638), np.float64(0.658008658008658)]\n",
            "ID_TARGET: 157.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7842 | Fold Accuracies: [np.float64(0.7652173913043478), np.float64(0.8361344537815126), np.float64(0.7620967741935484), np.float64(0.76), np.float64(0.7827868852459017)]\n",
            "ID_TARGET: 249.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7234 | Fold Accuracies: [np.float64(0.7558139534883721), np.float64(0.6806083650190115), np.float64(0.7654320987654321), np.float64(0.673469387755102), np.float64(0.6870229007633588)]\n",
            "ID_TARGET: 22.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6774 | Fold Accuracies: [np.float64(0.6666666666666666), np.float64(0.650375939849624), np.float64(0.6732283464566929), np.float64(0.6513409961685823), np.float64(0.688715953307393)]\n",
            "ID_TARGET: 202.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.6716 | Fold Accuracies: [np.float64(0.6235294117647059), np.float64(0.7089552238805971), np.float64(0.6283524904214559), np.float64(0.7003610108303249), np.float64(0.696969696969697)]\n",
            "ID_TARGET: 132.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7474 | Fold Accuracies: [np.float64(0.7586206896551724), np.float64(0.714859437751004), np.float64(0.7362204724409449), np.float64(0.7219917012448133), np.float64(0.7862903225806451)]\n",
            "ID_TARGET: 96.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7597 | Fold Accuracies: [np.float64(0.6926406926406926), np.float64(0.6566523605150214), np.float64(0.6423076923076924), np.float64(0.7397260273972602), np.float64(0.8034188034188035)]\n",
            "ID_TARGET: 7.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7348 | Fold Accuracies: [np.float64(0.71484375), np.float64(0.694980694980695), np.float64(0.7153284671532847), np.float64(0.7312252964426877), np.float64(0.8178294573643411)]\n",
            "ID_TARGET: 178.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7171 | Fold Accuracies: [np.float64(0.7154471544715447), np.float64(0.7110266159695817), np.float64(0.7272727272727273), np.float64(0.6612244897959184), np.float64(0.71875)]\n",
            "ID_TARGET: 68.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7697 | Fold Accuracies: [np.float64(0.7394636015325671), np.float64(0.7651821862348178), np.float64(0.7692307692307693), np.float64(0.7755102040816326), np.float64(0.75)]\n",
            "ID_TARGET: 44.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7190 | Fold Accuracies: [np.float64(0.7433962264150943), np.float64(0.7165354330708661), np.float64(0.7050359712230215), np.float64(0.7008547008547008), np.float64(0.7074074074074074)]\n",
            "ID_TARGET: 196.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7216 | Fold Accuracies: [np.float64(0.6933333333333334), np.float64(0.7364864864864865), np.float64(0.7282608695652174), np.float64(0.73046875), np.float64(0.7127659574468085)]\n",
            "ID_TARGET: 292.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7064 | Fold Accuracies: [np.float64(0.6425992779783394), np.float64(0.6349206349206349), np.float64(0.7058823529411765), np.float64(0.671875), np.float64(0.7394636015325671)]\n",
            "ID_TARGET: 239.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7517 | Fold Accuracies: [np.float64(0.7076923076923077), np.float64(0.7096774193548387), np.float64(0.711864406779661), np.float64(0.7936507936507936), np.float64(0.7678571428571429)]\n",
            "ID_TARGET: 279.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6957 | Fold Accuracies: [np.float64(0.6943396226415094), np.float64(0.7007874015748031), np.float64(0.6498054474708171), np.float64(0.6833333333333333), np.float64(0.6456692913385826)]\n",
            "ID_TARGET: 38.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7154 | Fold Accuracies: [np.float64(0.6641221374045801), np.float64(0.6837944664031621), np.float64(0.6626016260162602), np.float64(0.7049808429118773), np.float64(0.6828193832599119)]\n",
            "ID_TARGET: 209.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7241 | Fold Accuracies: [np.float64(0.7725490196078432), np.float64(0.6821705426356589), np.float64(0.7003891050583657), np.float64(0.6851851851851852), np.float64(0.6809338521400778)]\n",
            "ID_TARGET: 207.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6671 | Fold Accuracies: [np.float64(0.6653696498054474), np.float64(0.6313725490196078), np.float64(0.7108433734939759), np.float64(0.6377358490566037), np.float64(0.6550387596899225)]\n",
            "ID_TARGET: 98.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7187 | Fold Accuracies: [np.float64(0.6486486486486487), np.float64(0.7428571428571429), np.float64(0.7654320987654321), np.float64(0.7416666666666667), np.float64(0.6387832699619772)]\n",
            "ID_TARGET: 65.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7317 | Fold Accuracies: [np.float64(0.7443609022556391), np.float64(0.7227272727272728), np.float64(0.7142857142857143), np.float64(0.7222222222222222), np.float64(0.7350427350427351)]\n",
            "ID_TARGET: 51.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7547 | Fold Accuracies: [np.float64(0.7541666666666667), np.float64(0.757085020242915), np.float64(0.7586206896551724), np.float64(0.7439024390243902), np.float64(0.7598425196850394)]\n",
            "ID_TARGET: 78.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7117 | Fold Accuracies: [np.float64(0.7322175732217573), np.float64(0.732), np.float64(0.7), np.float64(0.6540084388185654), np.float64(0.6956521739130435)]\n",
            "ID_TARGET: 177.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7318 | Fold Accuracies: [np.float64(0.7418181818181818), np.float64(0.7211895910780669), np.float64(0.7269503546099291), np.float64(0.7342657342657343), np.float64(0.7181467181467182)]\n",
            "ID_TARGET: 231.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7775 | Fold Accuracies: [np.float64(0.7680608365019012), np.float64(0.7388059701492538), np.float64(0.756), np.float64(0.8081632653061225), np.float64(0.752851711026616)]\n",
            "ID_TARGET: 119.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7598 | Fold Accuracies: [np.float64(0.7159533073929961), np.float64(0.7569721115537849), np.float64(0.7790697674418605), np.float64(0.7172995780590717), np.float64(0.7622950819672131)]\n",
            "ID_TARGET: 158.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7916 | Fold Accuracies: [np.float64(0.7842323651452282), np.float64(0.8306451612903226), np.float64(0.7748091603053435), np.float64(0.8023715415019763), np.float64(0.7620817843866171)]\n",
            "ID_TARGET: 80.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6956 | Fold Accuracies: [np.float64(0.672), np.float64(0.7075098814229249), np.float64(0.668), np.float64(0.6938775510204082), np.float64(0.7123893805309734)]\n",
            "ID_TARGET: 25.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7211 | Fold Accuracies: [np.float64(0.7195121951219512), np.float64(0.6864406779661016), np.float64(0.6985294117647058), np.float64(0.7276119402985075), np.float64(0.73046875)]\n",
            "ID_TARGET: 175.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7280 | Fold Accuracies: [np.float64(0.71484375), np.float64(0.68), np.float64(0.6814516129032258), np.float64(0.7729083665338645), np.float64(0.6964980544747081)]\n",
            "ID_TARGET: 151.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7705 | Fold Accuracies: [np.float64(0.7749077490774908), np.float64(0.7647058823529411), np.float64(0.7692307692307693), np.float64(0.7304347826086957), np.float64(0.7892561983471075)]\n",
            "ID_TARGET: 257.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7166 | Fold Accuracies: [np.float64(0.691699604743083), np.float64(0.720754716981132), np.float64(0.7116788321167883), np.float64(0.6974169741697417), np.float64(0.7345454545454545)]\n",
            "ID_TARGET: 75.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7677 | Fold Accuracies: [np.float64(0.7704918032786885), np.float64(0.7327935222672065), np.float64(0.7649253731343284), np.float64(0.7517241379310344), np.float64(0.7827715355805244)]\n",
            "ID_TARGET: 244.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6957 | Fold Accuracies: [np.float64(0.6816479400749064), np.float64(0.7333333333333333), np.float64(0.6867924528301886), np.float64(0.6857142857142857), np.float64(0.6236162361623616)]\n",
            "ID_TARGET: 149.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7443 | Fold Accuracies: [np.float64(0.6917293233082706), np.float64(0.7294117647058823), np.float64(0.7461538461538462), np.float64(0.7322834645669292), np.float64(0.7165354330708661)]\n",
            "ID_TARGET: 85.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7712 | Fold Accuracies: [np.float64(0.8089430894308943), np.float64(0.7540983606557377), np.float64(0.78), np.float64(0.7563025210084033), np.float64(0.7318007662835249)]\n",
            "ID_TARGET: 190.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7397 | Fold Accuracies: [np.float64(0.7481203007518797), np.float64(0.7265917602996255), np.float64(0.7408906882591093), np.float64(0.7213740458015268), np.float64(0.7582417582417582)]\n",
            "ID_TARGET: 13.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7416 | Fold Accuracies: [np.float64(0.7354085603112841), np.float64(0.7364620938628159), np.float64(0.7195571955719557), np.float64(0.7148760330578512), np.float64(0.7519685039370079)]\n",
            "ID_TARGET: 228.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.6944 | Fold Accuracies: [np.float64(0.7142857142857143), np.float64(0.7209302325581395), np.float64(0.6933797909407665), np.float64(0.6829268292682927), np.float64(0.644927536231884)]\n",
            "ID_TARGET: 144.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7785 | Fold Accuracies: [np.float64(0.7669491525423728), np.float64(0.8235294117647058), np.float64(0.7963636363636364), np.float64(0.7103174603174603), np.float64(0.7415254237288136)]\n",
            "ID_TARGET: 290.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7138 | Fold Accuracies: [np.float64(0.7312252964426877), np.float64(0.6652892561983471), np.float64(0.7310606060606061), np.float64(0.6747967479674797), np.float64(0.6706349206349206)]\n",
            "ID_TARGET: 114.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.6967 | Fold Accuracies: [np.float64(0.6743295019157088), np.float64(0.7182539682539683), np.float64(0.7121212121212122), np.float64(0.6812749003984063), np.float64(0.6977611940298507)]\n",
            "ID_TARGET: 166.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7523 | Fold Accuracies: [np.float64(0.7642276422764228), np.float64(0.7619047619047619), np.float64(0.7827868852459017), np.float64(0.7340823970037453), np.float64(0.7131147540983607)]\n",
            "ID_TARGET: 234.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7609 | Fold Accuracies: [np.float64(0.7459016393442623), np.float64(0.7701612903225806), np.float64(0.7521008403361344), np.float64(0.7662337662337663), np.float64(0.7237354085603113)]\n",
            "ID_TARGET: 34.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7563 | Fold Accuracies: [np.float64(0.7116104868913857), np.float64(0.7480916030534351), np.float64(0.764), np.float64(0.7520325203252033), np.float64(0.7471264367816092)]\n",
            "ID_TARGET: 154.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7532 | Fold Accuracies: [np.float64(0.7795275590551181), np.float64(0.7669172932330827), np.float64(0.696969696969697), np.float64(0.700374531835206), np.float64(0.7800829875518672)]\n",
            "ID_TARGET: 225.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7136 | Fold Accuracies: [np.float64(0.6549295774647887), np.float64(0.7142857142857143), np.float64(0.7021276595744681), np.float64(0.7131782945736435), np.float64(0.7355072463768116)]\n",
            "ID_TARGET: 185.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.8007 | Fold Accuracies: [np.float64(0.7828054298642534), np.float64(0.7903930131004366), np.float64(0.7186147186147186), np.float64(0.7292576419213974), np.float64(0.8389830508474576)]\n",
            "ID_TARGET: 39.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7360 | Fold Accuracies: [np.float64(0.7073170731707317), np.float64(0.6862745098039216), np.float64(0.7431906614785992), np.float64(0.7211155378486056), np.float64(0.7154150197628458)]\n",
            "ID_TARGET: 272.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7528 | Fold Accuracies: [np.float64(0.7447698744769874), np.float64(0.7958333333333333), np.float64(0.7198443579766537), np.float64(0.789272030651341), np.float64(0.704225352112676)]\n",
            "ID_TARGET: 282.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7332 | Fold Accuracies: [np.float64(0.71484375), np.float64(0.7181467181467182), np.float64(0.7), np.float64(0.7519083969465649), np.float64(0.7219917012448133)]\n",
            "ID_TARGET: 90.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7507 | Fold Accuracies: [np.float64(0.7421875), np.float64(0.7509578544061303), np.float64(0.712), np.float64(0.7634854771784232), np.float64(0.7619047619047619)]\n",
            "ID_TARGET: 52.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7405 | Fold Accuracies: [np.float64(0.75), np.float64(0.7309417040358744), np.float64(0.7322175732217573), np.float64(0.7261904761904762), np.float64(0.6991869918699187)]\n",
            "ID_TARGET: 258.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7202 | Fold Accuracies: [np.float64(0.7319148936170212), np.float64(0.717391304347826), np.float64(0.7154150197628458), np.float64(0.77734375), np.float64(0.6589147286821705)]\n",
            "ID_TARGET: 291.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7525 | Fold Accuracies: [np.float64(0.7639484978540773), np.float64(0.7374517374517374), np.float64(0.7289377289377289), np.float64(0.7610294117647058), np.float64(0.7341269841269841)]\n",
            "ID_TARGET: 152.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7570 | Fold Accuracies: [np.float64(0.7666666666666667), np.float64(0.772), np.float64(0.7386363636363636), np.float64(0.7608695652173914), np.float64(0.7385892116182573)]\n",
            "ID_TARGET: 133.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7649 | Fold Accuracies: [np.float64(0.79182156133829), np.float64(0.7370517928286853), np.float64(0.7747035573122529), np.float64(0.7310606060606061), np.float64(0.7829457364341085)]\n",
            "ID_TARGET: 29.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7151 | Fold Accuracies: [np.float64(0.6812749003984063), np.float64(0.7092511013215859), np.float64(0.7011494252873564), np.float64(0.7480916030534351), np.float64(0.7241379310344828)]\n",
            "ID_TARGET: 274.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7397 | Fold Accuracies: [np.float64(0.762962962962963), np.float64(0.7661870503597122), np.float64(0.749034749034749), np.float64(0.7096774193548387), np.float64(0.7106227106227107)]\n",
            "ID_TARGET: 106.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7634 | Fold Accuracies: [np.float64(0.7705627705627706), np.float64(0.755656108597285), np.float64(0.7255813953488373), np.float64(0.7373271889400922), np.float64(0.7875)]\n",
            "ID_TARGET: 173.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7719 | Fold Accuracies: [np.float64(0.7765567765567766), np.float64(0.752), np.float64(0.7336065573770492), np.float64(0.8148148148148148), np.float64(0.7362204724409449)]\n",
            "ID_TARGET: 33.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7343 | Fold Accuracies: [np.float64(0.7219917012448133), np.float64(0.7065637065637066), np.float64(0.6980392156862745), np.float64(0.7431906614785992), np.float64(0.7360594795539034)]\n",
            "ID_TARGET: 69.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7188 | Fold Accuracies: [np.float64(0.7130434782608696), np.float64(0.729957805907173), np.float64(0.6692307692307692), np.float64(0.7018867924528301), np.float64(0.7072072072072072)]\n",
            "ID_TARGET: 17.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6870 | Fold Accuracies: [np.float64(0.7286821705426356), np.float64(0.706766917293233), np.float64(0.66796875), np.float64(0.64453125), np.float64(0.6525096525096525)]\n",
            "ID_TARGET: 189.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7351 | Fold Accuracies: [np.float64(0.7628458498023716), np.float64(0.6872586872586872), np.float64(0.6776859504132231), np.float64(0.758893280632411), np.float64(0.75)]\n",
            "ID_TARGET: 284.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7283 | Fold Accuracies: [np.float64(0.6981818181818182), np.float64(0.7104247104247104), np.float64(0.7581967213114754), np.float64(0.7100371747211895), np.float64(0.7416666666666667)]\n",
            "ID_TARGET: 218.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6929 | Fold Accuracies: [np.float64(0.6806083650190115), np.float64(0.6745098039215687), np.float64(0.6518518518518519), np.float64(0.757085020242915), np.float64(0.697841726618705)]\n",
            "ID_TARGET: 183.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7584 | Fold Accuracies: [np.float64(0.75), np.float64(0.756198347107438), np.float64(0.7355371900826446), np.float64(0.6908396946564885), np.float64(0.7954545454545454)]\n",
            "ID_TARGET: 206.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7564 | Fold Accuracies: [np.float64(0.6932270916334662), np.float64(0.7624521072796935), np.float64(0.7549407114624506), np.float64(0.7510729613733905), np.float64(0.7938931297709924)]\n",
            "ID_TARGET: 93.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7229 | Fold Accuracies: [np.float64(0.7615062761506276), np.float64(0.7416974169741697), np.float64(0.6794871794871795), np.float64(0.7228464419475655), np.float64(0.7088122605363985)]\n",
            "ID_TARGET: 16.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7182 | Fold Accuracies: [np.float64(0.7201492537313433), np.float64(0.6935483870967742), np.float64(0.6891385767790262), np.float64(0.706766917293233), np.float64(0.7184873949579832)]\n",
            "ID_TARGET: 246.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7500 | Fold Accuracies: [np.float64(0.7049808429118773), np.float64(0.7386363636363636), np.float64(0.7376425855513308), np.float64(0.769811320754717), np.float64(0.7764705882352941)]\n",
            "ID_TARGET: 167.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7443 | Fold Accuracies: [np.float64(0.7171314741035857), np.float64(0.7644787644787645), np.float64(0.7076271186440678), np.float64(0.7090163934426229), np.float64(0.7786885245901639)]\n",
            "ID_TARGET: 1.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7424 | Fold Accuracies: [np.float64(0.7412280701754386), np.float64(0.7649572649572649), np.float64(0.7165991902834008), np.float64(0.7182539682539683), np.float64(0.7593360995850622)]\n",
            "ID_TARGET: 289.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7311 | Fold Accuracies: [np.float64(0.7136752136752137), np.float64(0.746268656716418), np.float64(0.7421875), np.float64(0.7238805970149254), np.float64(0.7293233082706767)]\n",
            "ID_TARGET: 141.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7909 | Fold Accuracies: [np.float64(0.7375), np.float64(0.7705627705627706), np.float64(0.789272030651341), np.float64(0.8015267175572519), np.float64(0.7235772357723578)]\n",
            "ID_TARGET: 109.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.6993 | Fold Accuracies: [np.float64(0.6933333333333334), np.float64(0.708502024291498), np.float64(0.6707818930041153), np.float64(0.6679841897233202), np.float64(0.697841726618705)]\n",
            "ID_TARGET: 19.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7570 | Fold Accuracies: [np.float64(0.7651515151515151), np.float64(0.7377049180327869), np.float64(0.72265625), np.float64(0.7924528301886793), np.float64(0.767175572519084)]\n",
            "ID_TARGET: 28.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.6971 | Fold Accuracies: [np.float64(0.7196969696969697), np.float64(0.6317991631799164), np.float64(0.7091633466135459), np.float64(0.7343173431734318), np.float64(0.690677966101695)]\n",
            "ID_TARGET: 251.0 | Best Params: {'bagging_fraction': 0.7, 'learning_rate': 0.05, 'min_child_samples': 10, 'num_leaves': 31, 'reg_alpha': 0.2, 'reg_lambda': 0.2} | Mean Accuracy: 0.7211 | Fold Accuracies: [np.float64(0.6653225806451613), np.float64(0.7014925373134329), np.float64(0.7185185185185186), np.float64(0.7804878048780488), np.float64(0.7083333333333334)]\n",
            "ID_TARGET: 278.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7686 | Fold Accuracies: [np.float64(0.7142857142857143), np.float64(0.7626459143968871), np.float64(0.7593360995850622), np.float64(0.8268398268398268), np.float64(0.7553648068669528)]\n",
            "ID_TARGET: 76.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7339 | Fold Accuracies: [np.float64(0.7335907335907336), np.float64(0.6940298507462687), np.float64(0.7470817120622568), np.float64(0.7158273381294964), np.float64(0.766798418972332)]\n",
            "ID_TARGET: 241.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7443 | Fold Accuracies: [np.float64(0.7649402390438247), np.float64(0.7342342342342343), np.float64(0.7154811715481172), np.float64(0.7736625514403292), np.float64(0.7333333333333333)]\n",
            "ID_TARGET: 214.0 | Best Params: {'bagging_fraction': 0.8, 'learning_rate': 0.07, 'min_child_samples': 15, 'num_leaves': 47, 'reg_alpha': 0.3, 'reg_lambda': 0.3} | Mean Accuracy: 0.7762 | Fold Accuracies: [np.float64(0.7584905660377359), np.float64(0.7058823529411765), np.float64(0.8307086614173228), np.float64(0.8185185185185185), np.float64(0.7674418604651163)]\n",
            "ID_TARGET: 102.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7796 | Fold Accuracies: [np.float64(0.767175572519084), np.float64(0.7130434782608696), np.float64(0.7892561983471075), np.float64(0.8103448275862069), np.float64(0.7423076923076923)]\n",
            "ID_TARGET: 145.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7225 | Fold Accuracies: [np.float64(0.7413127413127413), np.float64(0.6555555555555556), np.float64(0.6775510204081633), np.float64(0.6958174904942965), np.float64(0.7530864197530864)]\n",
            "ID_TARGET: 155.0 | Best Params: {'bagging_fraction': 0.6, 'learning_rate': 0.02, 'min_child_samples': 20, 'num_leaves': 15, 'reg_alpha': 0.1, 'reg_lambda': 0.1} | Mean Accuracy: 0.7905 | Fold Accuracies: [np.float64(0.7638888888888888), np.float64(0.8014705882352942), np.float64(0.7942386831275721), np.float64(0.7470817120622568), np.float64(0.7757352941176471)]\n",
            "\n",
            "Training XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "XGBoost Targets: 100%|| 100/100 [21:42<00:00, 13.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Weighted Accuracy: 0.7672\n",
            "\n",
            "XGBoost Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'learning_rate': 0.04, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 175, 'reg_alpha': 0.15, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.7161 | Fold Accuracies: [np.float64(0.7914893617021277), np.float64(0.70703125), np.float64(0.7649402390438247), np.float64(0.6705426356589147), np.float64(0.6465863453815262)]\n",
            "ID_TARGET: 129.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6275 | Fold Accuracies: [np.float64(0.6163265306122448), np.float64(0.6260162601626016), np.float64(0.5909090909090909), np.float64(0.5780590717299579), np.float64(0.5854545454545454)]\n",
            "ID_TARGET: 136.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6293436293436293), np.float64(0.5568181818181818), np.float64(0.5818181818181818), np.float64(0.56640625), np.float64(0.5748987854251012)]\n",
            "ID_TARGET: 161.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.6710 | Fold Accuracies: [np.float64(0.6088709677419355), np.float64(0.6856060606060606), np.float64(0.6450381679389313), np.float64(0.7065637065637066), np.float64(0.6896551724137931)]\n",
            "ID_TARGET: 217.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7644787644787645), np.float64(0.7262357414448669), np.float64(0.7474048442906575), np.float64(0.7252747252747253), np.float64(0.723404255319149)]\n",
            "ID_TARGET: 91.0 | Best Params: {'learning_rate': 0.04, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 175, 'reg_alpha': 0.15, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.7862 | Fold Accuracies: [np.float64(0.8015267175572519), np.float64(0.8089430894308943), np.float64(0.7604562737642585), np.float64(0.78099173553719), np.float64(0.7790262172284644)]\n",
            "ID_TARGET: 137.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8000 | Fold Accuracies: [np.float64(0.6983471074380165), np.float64(0.7117903930131004), np.float64(0.688034188034188), np.float64(0.65234375), np.float64(0.6444444444444445)]\n",
            "ID_TARGET: 8.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.6146 | Fold Accuracies: [np.float64(0.5953307392996109), np.float64(0.5542168674698795), np.float64(0.6613545816733067), np.float64(0.596), np.float64(0.6417322834645669)]\n",
            "ID_TARGET: 3.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6825 | Fold Accuracies: [np.float64(0.6590909090909091), np.float64(0.6434426229508197), np.float64(0.7131474103585658), np.float64(0.7161016949152542), np.float64(0.6244541484716157)]\n",
            "ID_TARGET: 9.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8953 | Fold Accuracies: [np.float64(0.676595744680851), np.float64(0.7), np.float64(0.6807692307692308), np.float64(0.6818181818181818), np.float64(0.6627906976744186)]\n",
            "ID_TARGET: 131.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6427 | Fold Accuracies: [np.float64(0.6889763779527559), np.float64(0.6384615384615384), np.float64(0.6370967741935484), np.float64(0.5991561181434599), np.float64(0.6192307692307693)]\n",
            "ID_TARGET: 21.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.6971 | Fold Accuracies: [np.float64(0.75), np.float64(0.6984732824427481), np.float64(0.6996336996336996), np.float64(0.69140625), np.float64(0.6147859922178989)]\n",
            "ID_TARGET: 54.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7731 | Fold Accuracies: [np.float64(0.7441860465116279), np.float64(0.7116104868913857), np.float64(0.7929515418502202), np.float64(0.6294964028776978), np.float64(0.7529411764705882)]\n",
            "ID_TARGET: 130.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7114 | Fold Accuracies: [np.float64(0.7316017316017316), np.float64(0.7084870848708487), np.float64(0.7311827956989247), np.float64(0.6768060836501901), np.float64(0.6423357664233577)]\n",
            "ID_TARGET: 269.0 | Best Params: {'learning_rate': 0.04, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 175, 'reg_alpha': 0.15, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.6524 | Fold Accuracies: [np.float64(0.692), np.float64(0.7030567685589519), np.float64(0.6558704453441295), np.float64(0.5702127659574469), np.float64(0.6406926406926406)]\n",
            "ID_TARGET: 157.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7409 | Fold Accuracies: [np.float64(0.717391304347826), np.float64(0.7815126050420168), np.float64(0.6854838709677419), np.float64(0.716), np.float64(0.6967213114754098)]\n",
            "ID_TARGET: 249.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7175 | Fold Accuracies: [np.float64(0.6976744186046512), np.float64(0.6806083650190115), np.float64(0.7613168724279835), np.float64(0.6857142857142857), np.float64(0.6374045801526718)]\n",
            "ID_TARGET: 22.0 | Best Params: {'learning_rate': 0.04, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 175, 'reg_alpha': 0.15, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.6989 | Fold Accuracies: [np.float64(0.6992753623188406), np.float64(0.6578947368421053), np.float64(0.7125984251968503), np.float64(0.7011494252873564), np.float64(0.7237354085603113)]\n",
            "ID_TARGET: 202.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7003 | Fold Accuracies: [np.float64(0.6470588235294118), np.float64(0.7238805970149254), np.float64(0.685823754789272), np.float64(0.6967509025270758), np.float64(0.6893939393939394)]\n",
            "ID_TARGET: 132.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7437 | Fold Accuracies: [np.float64(0.7327586206896551), np.float64(0.7068273092369478), np.float64(0.7322834645669292), np.float64(0.7178423236514523), np.float64(0.7943548387096774)]\n",
            "ID_TARGET: 96.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.9823 | Fold Accuracies: [np.float64(0.7142857142857143), np.float64(0.721030042918455), np.float64(0.7), np.float64(0.771689497716895), np.float64(0.7051282051282052)]\n",
            "ID_TARGET: 7.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7419 | Fold Accuracies: [np.float64(0.69921875), np.float64(0.7181467181467182), np.float64(0.6788321167883211), np.float64(0.7351778656126482), np.float64(0.7829457364341085)]\n",
            "ID_TARGET: 178.0 | Best Params: {'learning_rate': 0.04, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 175, 'reg_alpha': 0.15, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.7223 | Fold Accuracies: [np.float64(0.7560975609756098), np.float64(0.7034220532319392), np.float64(0.7549407114624506), np.float64(0.689795918367347), np.float64(0.70703125)]\n",
            "ID_TARGET: 68.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7455 | Fold Accuracies: [np.float64(0.7011494252873564), np.float64(0.7530364372469636), np.float64(0.7606837606837606), np.float64(0.7755102040816326), np.float64(0.7131147540983607)]\n",
            "ID_TARGET: 44.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7481 | Fold Accuracies: [np.float64(0.7811320754716982), np.float64(0.7559055118110236), np.float64(0.7338129496402878), np.float64(0.7051282051282052), np.float64(0.7074074074074074)]\n",
            "ID_TARGET: 196.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7505 | Fold Accuracies: [np.float64(0.6933333333333334), np.float64(0.7972972972972973), np.float64(0.7681159420289855), np.float64(0.70703125), np.float64(0.7588652482269503)]\n",
            "ID_TARGET: 292.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7122 | Fold Accuracies: [np.float64(0.6678700361010831), np.float64(0.7222222222222222), np.float64(0.6838235294117647), np.float64(0.70703125), np.float64(0.7279693486590039)]\n",
            "ID_TARGET: 239.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7428 | Fold Accuracies: [np.float64(0.6961538461538461), np.float64(0.7298387096774194), np.float64(0.7330508474576272), np.float64(0.7619047619047619), np.float64(0.7678571428571429)]\n",
            "ID_TARGET: 279.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6781 | Fold Accuracies: [np.float64(0.5622641509433962), np.float64(0.7362204724409449), np.float64(0.688715953307393), np.float64(0.7), np.float64(0.6692913385826772)]\n",
            "ID_TARGET: 38.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7325 | Fold Accuracies: [np.float64(0.6679389312977099), np.float64(0.6798418972332015), np.float64(0.6991869918699187), np.float64(0.6973180076628352), np.float64(0.7577092511013216)]\n",
            "ID_TARGET: 209.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 207.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6802 | Fold Accuracies: [np.float64(0.6614785992217899), np.float64(0.6666666666666666), np.float64(0.714859437751004), np.float64(0.6415094339622641), np.float64(0.6511627906976745)]\n",
            "ID_TARGET: 98.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7322 | Fold Accuracies: [np.float64(0.637065637065637), np.float64(0.7591836734693878), np.float64(0.757201646090535), np.float64(0.7333333333333333), np.float64(0.6349809885931559)]\n",
            "ID_TARGET: 65.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8022 | Fold Accuracies: [np.float64(0.7443609022556391), np.float64(0.740909090909091), np.float64(0.6785714285714286), np.float64(0.7380952380952381), np.float64(0.7435897435897436)]\n",
            "ID_TARGET: 51.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7318 | Fold Accuracies: [np.float64(0.7208333333333333), np.float64(0.708502024291498), np.float64(0.728448275862069), np.float64(0.7235772357723578), np.float64(0.6732283464566929)]\n",
            "ID_TARGET: 78.0 | Best Params: {'learning_rate': 0.04, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 175, 'reg_alpha': 0.15, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.7320 | Fold Accuracies: [np.float64(0.7364016736401674), np.float64(0.78), np.float64(0.7083333333333334), np.float64(0.6919831223628692), np.float64(0.7430830039525692)]\n",
            "ID_TARGET: 177.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7548 | Fold Accuracies: [np.float64(0.7418181818181818), np.float64(0.7769516728624535), np.float64(0.7269503546099291), np.float64(0.7727272727272727), np.float64(0.7297297297297297)]\n",
            "ID_TARGET: 231.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8250950570342205), np.float64(0.6604477611940298), np.float64(0.752), np.float64(1.0), np.float64(0.7908745247148289)]\n",
            "ID_TARGET: 119.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7685 | Fold Accuracies: [np.float64(0.7237354085603113), np.float64(0.7768924302788844), np.float64(0.8333333333333334), np.float64(0.7383966244725738), np.float64(0.7663934426229508)]\n",
            "ID_TARGET: 158.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7948 | Fold Accuracies: [np.float64(0.7676348547717843), np.float64(0.8225806451612904), np.float64(0.767175572519084), np.float64(0.8063241106719368), np.float64(0.7509293680297398)]\n",
            "ID_TARGET: 80.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7202 | Fold Accuracies: [np.float64(0.704), np.float64(0.7233201581027668), np.float64(0.676), np.float64(0.7183673469387755), np.float64(0.7477876106194691)]\n",
            "ID_TARGET: 25.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7408 | Fold Accuracies: [np.float64(0.7398373983739838), np.float64(0.711864406779661), np.float64(0.6985294117647058), np.float64(0.7313432835820896), np.float64(0.75)]\n",
            "ID_TARGET: 175.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.66796875), np.float64(0.652), np.float64(0.6330645161290323), np.float64(0.7290836653386454), np.float64(0.6731517509727627)]\n",
            "ID_TARGET: 151.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7736 | Fold Accuracies: [np.float64(0.7527675276752768), np.float64(0.7463235294117647), np.float64(0.7649572649572649), np.float64(0.7304347826086957), np.float64(0.7975206611570248)]\n",
            "ID_TARGET: 257.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7382 | Fold Accuracies: [np.float64(0.7114624505928854), np.float64(0.6943396226415094), np.float64(0.708029197080292), np.float64(0.6937269372693727), np.float64(0.7090909090909091)]\n",
            "ID_TARGET: 75.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7923 | Fold Accuracies: [np.float64(0.8032786885245902), np.float64(0.7651821862348178), np.float64(0.7873134328358209), np.float64(0.7551724137931034), np.float64(0.8089887640449438)]\n",
            "ID_TARGET: 244.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.6760 | Fold Accuracies: [np.float64(0.6816479400749064), np.float64(0.6941176470588235), np.float64(0.6792452830188679), np.float64(0.6938775510204082), np.float64(0.6273062730627307)]\n",
            "ID_TARGET: 149.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7248 | Fold Accuracies: [np.float64(0.6278195488721805), np.float64(0.7019607843137254), np.float64(0.7384615384615385), np.float64(0.7322834645669292), np.float64(0.7007874015748031)]\n",
            "ID_TARGET: 85.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8157 | Fold Accuracies: [np.float64(0.7967479674796748), np.float64(0.7540983606557377), np.float64(0.788), np.float64(0.7436974789915967), np.float64(0.685823754789272)]\n",
            "ID_TARGET: 190.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7528 | Fold Accuracies: [np.float64(0.7631578947368421), np.float64(0.7265917602996255), np.float64(0.7692307692307693), np.float64(0.7137404580152672), np.float64(0.7692307692307693)]\n",
            "ID_TARGET: 13.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6926070038910506), np.float64(0.7509025270758123), np.float64(0.7232472324723247), np.float64(0.7644628099173554), np.float64(0.7362204724409449)]\n",
            "ID_TARGET: 228.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7756 | Fold Accuracies: [np.float64(0.7781954887218046), np.float64(0.7170542635658915), np.float64(0.7073170731707317), np.float64(0.7113821138211383), np.float64(0.6811594202898551)]\n",
            "ID_TARGET: 144.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7603 | Fold Accuracies: [np.float64(0.7584745762711864), np.float64(0.8403361344537815), np.float64(0.7745454545454545), np.float64(0.6785714285714286), np.float64(0.7245762711864406)]\n",
            "ID_TARGET: 290.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7154150197628458), np.float64(0.7066115702479339), np.float64(0.7159090909090909), np.float64(0.6951219512195121), np.float64(0.6904761904761905)]\n",
            "ID_TARGET: 114.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7216 | Fold Accuracies: [np.float64(0.6704980842911877), np.float64(0.7420634920634921), np.float64(0.7234848484848485), np.float64(0.7290836653386454), np.float64(0.6977611940298507)]\n",
            "ID_TARGET: 166.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7561 | Fold Accuracies: [np.float64(0.7723577235772358), np.float64(0.7472527472527473), np.float64(0.7827868852459017), np.float64(0.7528089887640449), np.float64(0.7172131147540983)]\n",
            "ID_TARGET: 234.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7604 | Fold Accuracies: [np.float64(0.7540983606557377), np.float64(0.7943548387096774), np.float64(0.7521008403361344), np.float64(0.7878787878787878), np.float64(0.7042801556420234)]\n",
            "ID_TARGET: 34.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7765 | Fold Accuracies: [np.float64(0.7340823970037453), np.float64(0.7938931297709924), np.float64(0.796), np.float64(0.7601626016260162), np.float64(0.7318007662835249)]\n",
            "ID_TARGET: 154.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7680 | Fold Accuracies: [np.float64(0.7874015748031497), np.float64(0.8045112781954887), np.float64(0.7121212121212122), np.float64(0.7303370786516854), np.float64(0.8008298755186722)]\n",
            "ID_TARGET: 225.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7350 | Fold Accuracies: [np.float64(0.6866197183098591), np.float64(0.7218045112781954), np.float64(0.7269503546099291), np.float64(0.7325581395348837), np.float64(0.7427536231884058)]\n",
            "ID_TARGET: 185.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7310 | Fold Accuracies: [np.float64(0.7194570135746606), np.float64(0.7554585152838428), np.float64(0.6753246753246753), np.float64(0.7205240174672489), np.float64(0.7330508474576272)]\n",
            "ID_TARGET: 39.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7520325203252033), np.float64(0.7372549019607844), np.float64(0.7665369649805448), np.float64(0.7649402390438247), np.float64(0.7312252964426877)]\n",
            "ID_TARGET: 272.0 | Best Params: {'learning_rate': 0.04, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 175, 'reg_alpha': 0.15, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.7840 | Fold Accuracies: [np.float64(0.7907949790794979), np.float64(0.85), np.float64(0.7276264591439688), np.float64(0.8084291187739464), np.float64(0.7429577464788732)]\n",
            "ID_TARGET: 282.0 | Best Params: {'learning_rate': 0.04, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 175, 'reg_alpha': 0.15, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.7420 | Fold Accuracies: [np.float64(0.7109375), np.float64(0.7374517374517374), np.float64(0.736), np.float64(0.7748091603053435), np.float64(0.7510373443983402)]\n",
            "ID_TARGET: 90.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7753 | Fold Accuracies: [np.float64(0.75), np.float64(0.789272030651341), np.float64(0.744), np.float64(0.7842323651452282), np.float64(0.7857142857142857)]\n",
            "ID_TARGET: 52.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7410 | Fold Accuracies: [np.float64(0.717391304347826), np.float64(0.757847533632287), np.float64(0.7196652719665272), np.float64(0.75), np.float64(0.7113821138211383)]\n",
            "ID_TARGET: 258.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7263 | Fold Accuracies: [np.float64(0.7191489361702128), np.float64(0.7478260869565218), np.float64(0.7035573122529645), np.float64(0.76953125), np.float64(0.6589147286821705)]\n",
            "ID_TARGET: 291.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7596 | Fold Accuracies: [np.float64(0.759656652360515), np.float64(0.7644787644787645), np.float64(0.7509157509157509), np.float64(0.7720588235294118), np.float64(0.7420634920634921)]\n",
            "ID_TARGET: 152.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7523 | Fold Accuracies: [np.float64(0.725), np.float64(0.768), np.float64(0.7045454545454546), np.float64(0.7065217391304348), np.float64(0.7344398340248963)]\n",
            "ID_TARGET: 133.0 | Best Params: {'learning_rate': 0.04, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 175, 'reg_alpha': 0.15, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.7746 | Fold Accuracies: [np.float64(0.7881040892193308), np.float64(0.7609561752988048), np.float64(0.7905138339920948), np.float64(0.7386363636363636), np.float64(0.7945736434108527)]\n",
            "ID_TARGET: 29.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7074 | Fold Accuracies: [np.float64(0.6374501992031872), np.float64(0.7268722466960352), np.float64(0.6819923371647509), np.float64(0.7213740458015268), np.float64(0.7241379310344828)]\n",
            "ID_TARGET: 274.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7475 | Fold Accuracies: [np.float64(0.7592592592592593), np.float64(0.7733812949640287), np.float64(0.7413127413127413), np.float64(0.7347670250896058), np.float64(0.706959706959707)]\n",
            "ID_TARGET: 106.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.9610 | Fold Accuracies: [np.float64(0.7359307359307359), np.float64(0.7375565610859729), np.float64(0.7302325581395349), np.float64(0.728110599078341), np.float64(0.7416666666666667)]\n",
            "ID_TARGET: 173.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7702 | Fold Accuracies: [np.float64(0.7582417582417582), np.float64(0.728), np.float64(0.7459016393442623), np.float64(0.7814814814814814), np.float64(0.7007874015748031)]\n",
            "ID_TARGET: 33.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7340 | Fold Accuracies: [np.float64(0.7427385892116183), np.float64(0.6911196911196911), np.float64(0.7137254901960784), np.float64(0.7431906614785992), np.float64(0.7472118959107806)]\n",
            "ID_TARGET: 69.0 | Best Params: {'learning_rate': 0.04, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 175, 'reg_alpha': 0.15, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.7391 | Fold Accuracies: [np.float64(0.7739130434782608), np.float64(0.7468354430379747), np.float64(0.6807692307692308), np.float64(0.7283018867924528), np.float64(0.7657657657657657)]\n",
            "ID_TARGET: 17.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7055 | Fold Accuracies: [np.float64(0.7170542635658915), np.float64(0.7330827067669173), np.float64(0.703125), np.float64(0.6875), np.float64(0.6602316602316602)]\n",
            "ID_TARGET: 189.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7320 | Fold Accuracies: [np.float64(0.6956521739130435), np.float64(0.7104247104247104), np.float64(0.7024793388429752), np.float64(0.7509881422924901), np.float64(0.7083333333333334)]\n",
            "ID_TARGET: 284.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7287 | Fold Accuracies: [np.float64(0.6872727272727273), np.float64(0.7065637065637066), np.float64(0.7704918032786885), np.float64(0.7211895910780669), np.float64(0.7458333333333333)]\n",
            "ID_TARGET: 218.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7211 | Fold Accuracies: [np.float64(0.688212927756654), np.float64(0.7058823529411765), np.float64(0.6666666666666666), np.float64(0.7935222672064778), np.float64(0.6906474820143885)]\n",
            "ID_TARGET: 183.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7502 | Fold Accuracies: [np.float64(0.7210144927536232), np.float64(0.7644628099173554), np.float64(0.743801652892562), np.float64(0.6946564885496184), np.float64(0.8106060606060606)]\n",
            "ID_TARGET: 206.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7632 | Fold Accuracies: [np.float64(0.7171314741035857), np.float64(0.7432950191570882), np.float64(0.8063241106719368), np.float64(0.7467811158798283), np.float64(0.767175572519084)]\n",
            "ID_TARGET: 93.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7098 | Fold Accuracies: [np.float64(0.6820083682008368), np.float64(0.6605166051660517), np.float64(0.7136752136752137), np.float64(0.704119850187266), np.float64(0.7088122605363985)]\n",
            "ID_TARGET: 16.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7130 | Fold Accuracies: [np.float64(0.7201492537313433), np.float64(0.6854838709677419), np.float64(0.6853932584269663), np.float64(0.7481203007518797), np.float64(0.7142857142857143)]\n",
            "ID_TARGET: 246.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7522 | Fold Accuracies: [np.float64(0.7049808429118773), np.float64(0.7348484848484849), np.float64(0.7566539923954373), np.float64(0.7396226415094339), np.float64(0.7333333333333333)]\n",
            "ID_TARGET: 167.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.9602 | Fold Accuracies: [np.float64(0.7330677290836654), np.float64(0.7451737451737451), np.float64(0.7457627118644068), np.float64(0.7254098360655737), np.float64(0.7909836065573771)]\n",
            "ID_TARGET: 1.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7462 | Fold Accuracies: [np.float64(0.7675438596491229), np.float64(0.7564102564102564), np.float64(0.7327935222672065), np.float64(0.7063492063492064), np.float64(0.7302904564315352)]\n",
            "ID_TARGET: 289.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7539 | Fold Accuracies: [np.float64(0.7393162393162394), np.float64(0.7574626865671642), np.float64(0.7578125), np.float64(0.7388059701492538), np.float64(0.6954887218045113)]\n",
            "ID_TARGET: 141.0 | Best Params: {'learning_rate': 0.04, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 175, 'reg_alpha': 0.15, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.7921 | Fold Accuracies: [np.float64(0.8), np.float64(0.8181818181818182), np.float64(0.789272030651341), np.float64(0.8091603053435115), np.float64(0.7439024390243902)]\n",
            "ID_TARGET: 109.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7298 | Fold Accuracies: [np.float64(0.71), np.float64(0.7489878542510121), np.float64(0.720164609053498), np.float64(0.6719367588932806), np.float64(0.7661870503597122)]\n",
            "ID_TARGET: 19.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7719 | Fold Accuracies: [np.float64(0.7727272727272727), np.float64(0.7704918032786885), np.float64(0.7421875), np.float64(0.7886792452830189), np.float64(0.7786259541984732)]\n",
            "ID_TARGET: 28.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7113 | Fold Accuracies: [np.float64(0.7083333333333334), np.float64(0.6736401673640168), np.float64(0.7051792828685259), np.float64(0.7380073800738007), np.float64(0.6949152542372882)]\n",
            "ID_TARGET: 251.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7186 | Fold Accuracies: [np.float64(0.6733870967741935), np.float64(0.7164179104477612), np.float64(0.7111111111111111), np.float64(0.7398373983739838), np.float64(0.6916666666666667)]\n",
            "ID_TARGET: 278.0 | Best Params: {'learning_rate': 0.04, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 175, 'reg_alpha': 0.15, 'reg_lambda': 1.2, 'subsample': 0.65} | Mean Accuracy: 0.7523 | Fold Accuracies: [np.float64(0.6944444444444444), np.float64(0.754863813229572), np.float64(0.7427385892116183), np.float64(0.8181818181818182), np.float64(0.7510729613733905)]\n",
            "ID_TARGET: 76.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7491 | Fold Accuracies: [np.float64(0.7374517374517374), np.float64(0.7313432835820896), np.float64(0.7392996108949417), np.float64(0.7230215827338129), np.float64(0.7865612648221344)]\n",
            "ID_TARGET: 241.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7519 | Fold Accuracies: [np.float64(0.7330677290836654), np.float64(0.7117117117117117), np.float64(0.7071129707112971), np.float64(0.7860082304526749), np.float64(0.7208333333333333)]\n",
            "ID_TARGET: 214.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7831 | Fold Accuracies: [np.float64(0.7396226415094339), np.float64(0.6941176470588235), np.float64(0.8110236220472441), np.float64(0.8), np.float64(0.751937984496124)]\n",
            "ID_TARGET: 102.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.7720 | Fold Accuracies: [np.float64(0.7862595419847328), np.float64(0.7304347826086957), np.float64(0.7727272727272727), np.float64(0.8060344827586207), np.float64(0.7269230769230769)]\n",
            "ID_TARGET: 145.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.6932 | Fold Accuracies: [np.float64(0.6718146718146718), np.float64(0.6296296296296297), np.float64(0.6857142857142857), np.float64(0.6730038022813688), np.float64(0.7078189300411523)]\n",
            "ID_TARGET: 155.0 | Best Params: {'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.05, 'reg_lambda': 0.5, 'subsample': 0.5} | Mean Accuracy: 0.8019 | Fold Accuracies: [np.float64(0.7777777777777778), np.float64(0.8161764705882353), np.float64(0.7983539094650206), np.float64(0.754863813229572), np.float64(0.7867647058823529)]\n",
            "\n",
            "Performing second-pass training with top 30 features...\n",
            "\n",
            "Second-pass LightGBM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rLightGBM Targets:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   1%|          | 1/100 [00:00<01:19,  1.25it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   2%|         | 2/100 [00:01<01:09,  1.41it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   3%|         | 3/100 [00:02<01:07,  1.44it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   4%|         | 4/100 [00:02<01:05,  1.47it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   5%|         | 5/100 [00:03<01:00,  1.56it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   6%|         | 6/100 [00:03<00:55,  1.70it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   7%|         | 7/100 [00:04<00:50,  1.83it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   8%|         | 8/100 [00:05<00:58,  1.57it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:   9%|         | 9/100 [00:05<00:58,  1.56it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  10%|         | 10/100 [00:06<00:55,  1.62it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  11%|         | 11/100 [00:07<01:00,  1.47it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  12%|        | 12/100 [00:07<00:58,  1.52it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  13%|        | 13/100 [00:08<00:55,  1.56it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  14%|        | 14/100 [00:08<00:54,  1.57it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  15%|        | 15/100 [00:09<00:56,  1.50it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  16%|        | 16/100 [00:10<01:01,  1.37it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  17%|        | 17/100 [00:11<01:10,  1.17it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  18%|        | 18/100 [00:12<01:07,  1.22it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  19%|        | 19/100 [00:13<01:00,  1.34it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  20%|        | 20/100 [00:13<00:53,  1.49it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  21%|        | 21/100 [00:14<00:49,  1.61it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  22%|       | 22/100 [00:14<00:46,  1.67it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  23%|       | 23/100 [00:15<00:44,  1.72it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  24%|       | 24/100 [00:15<00:43,  1.76it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  25%|       | 25/100 [00:16<00:41,  1.80it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  26%|       | 26/100 [00:16<00:40,  1.81it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  27%|       | 27/100 [00:17<00:40,  1.80it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  28%|       | 28/100 [00:17<00:38,  1.88it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  29%|       | 29/100 [00:18<00:37,  1.89it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  30%|       | 30/100 [00:18<00:36,  1.90it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  31%|       | 31/100 [00:19<00:35,  1.96it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  32%|      | 32/100 [00:19<00:35,  1.93it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  33%|      | 33/100 [00:20<00:33,  1.98it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  34%|      | 34/100 [00:20<00:32,  2.05it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  35%|      | 35/100 [00:21<00:31,  2.05it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  36%|      | 36/100 [00:21<00:32,  1.98it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  37%|      | 37/100 [00:22<00:33,  1.87it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  38%|      | 38/100 [00:23<00:36,  1.68it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  39%|      | 39/100 [00:23<00:40,  1.50it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  40%|      | 40/100 [00:24<00:44,  1.35it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  41%|      | 41/100 [00:25<00:45,  1.29it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  42%|     | 42/100 [00:26<00:39,  1.46it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  43%|     | 43/100 [00:26<00:35,  1.60it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  44%|     | 44/100 [00:27<00:32,  1.71it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  45%|     | 45/100 [00:27<00:31,  1.76it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  46%|     | 46/100 [00:28<00:30,  1.80it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  47%|     | 47/100 [00:28<00:29,  1.77it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  48%|     | 48/100 [00:29<00:29,  1.79it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  49%|     | 49/100 [00:29<00:27,  1.85it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  50%|     | 50/100 [00:30<00:28,  1.77it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  51%|     | 51/100 [00:31<00:26,  1.82it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  52%|    | 52/100 [00:31<00:26,  1.78it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  53%|    | 53/100 [00:32<00:26,  1.75it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  54%|    | 54/100 [00:32<00:26,  1.74it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  55%|    | 55/100 [00:33<00:26,  1.73it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  56%|    | 56/100 [00:33<00:25,  1.72it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  57%|    | 57/100 [00:34<00:25,  1.71it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  58%|    | 58/100 [00:35<00:25,  1.68it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  59%|    | 59/100 [00:35<00:26,  1.56it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  60%|    | 60/100 [00:36<00:28,  1.42it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  61%|    | 61/100 [00:37<00:28,  1.39it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  62%|   | 62/100 [00:38<00:27,  1.37it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  63%|   | 63/100 [00:38<00:25,  1.46it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  64%|   | 64/100 [00:39<00:23,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  65%|   | 65/100 [00:40<00:22,  1.55it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  66%|   | 66/100 [00:40<00:21,  1.60it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  67%|   | 67/100 [00:41<00:20,  1.59it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  68%|   | 68/100 [00:41<00:19,  1.62it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  69%|   | 69/100 [00:42<00:18,  1.64it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  70%|   | 70/100 [00:43<00:17,  1.68it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  71%|   | 71/100 [00:43<00:17,  1.69it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  72%|  | 72/100 [00:44<00:16,  1.66it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  73%|  | 73/100 [00:44<00:15,  1.74it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  74%|  | 74/100 [00:45<00:14,  1.79it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  75%|  | 75/100 [00:45<00:13,  1.79it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  76%|  | 76/100 [00:46<00:13,  1.82it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  77%|  | 77/100 [00:47<00:13,  1.68it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  78%|  | 78/100 [00:47<00:12,  1.71it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  79%|  | 79/100 [00:48<00:12,  1.69it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  80%|  | 80/100 [00:49<00:13,  1.47it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  81%|  | 81/100 [00:49<00:13,  1.41it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  82%| | 82/100 [00:50<00:13,  1.38it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  83%| | 83/100 [00:51<00:12,  1.31it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  84%| | 84/100 [00:52<00:11,  1.35it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  85%| | 85/100 [00:52<00:10,  1.43it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  86%| | 86/100 [00:53<00:09,  1.53it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  87%| | 87/100 [00:54<00:08,  1.48it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  88%| | 88/100 [00:54<00:07,  1.55it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  89%| | 89/100 [00:55<00:06,  1.58it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  90%| | 90/100 [00:55<00:06,  1.54it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  91%| | 91/100 [00:56<00:05,  1.62it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  92%|| 92/100 [00:57<00:04,  1.61it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  93%|| 93/100 [00:57<00:04,  1.67it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  94%|| 94/100 [00:58<00:03,  1.71it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  95%|| 95/100 [00:58<00:02,  1.77it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  96%|| 96/100 [00:59<00:02,  1.77it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  97%|| 97/100 [00:59<00:01,  1.73it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  98%|| 98/100 [01:00<00:01,  1.73it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets:  99%|| 99/100 [01:01<00:00,  1.69it/s]/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "LightGBM Targets: 100%|| 100/100 [01:01<00:00,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Second-pass XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "XGBoost Targets: 100%|| 100/100 [00:54<00:00,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performing third-pass training for low-performing targets...\n",
            "\n",
            "Third-pass LightGBM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "LightGBM Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 55721.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Third-pass XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "XGBoost Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 55320.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved hyperparameter log to: /content/hyperparameters.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a981f02c-f8fe-490e-b061-7abc83c3b013\", \"hyperparameters.json\", 661728)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved predictions to: /content/predictions_ensemble.csv\n",
            "Output CSV shape: (114468, 2)\n",
            "Output CSV ID range: 0 to 114467\n",
            "Unique RET_TARGET values: [ 1 -1]\n",
            "Missing values: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fb1f78cb-c06b-48dd-9b4a-159f749658cd\", \"predictions_ensemble.csv\", 970513)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation Results:\n",
            "LightGBM: 0.7327\n",
            "XGBoost: 0.7672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "keep xgboost orginal, but tune down lightgbm"
      ],
      "metadata": {
        "id": "4UCUGVxJgZM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost\n",
        "from sklearn.decomposition import PCA\n",
        "from joblib import Parallel, delayed\n",
        "import json\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# Check xgboost version for compatibility\n",
        "print(f\"XGBoost version: {xgboost.__version__}\")\n",
        "if int(xgboost.__version__.split('.')[0]) < 1:\n",
        "    print(\"Warning: XGBoost version < 1.0.0 detected. Ensure compatibility with eval_metric in constructor.\")\n",
        "\n",
        "# Set up data directory\n",
        "DATA_DIR = '/content'\n",
        "\n",
        "# Load datasets\n",
        "try:\n",
        "    X_train = pd.read_csv(os.path.join(DATA_DIR, 'X_train_itDkypA.csv'), index_col='ID', dtype=np.float32)\n",
        "    y_train = pd.read_csv(os.path.join(DATA_DIR, 'y_train_3LeeT2g.csv'), index_col='ID', dtype=np.float32)\n",
        "    X_test = pd.read_csv(os.path.join(DATA_DIR, 'X_test_Beg4ey3.csv'), index_col='ID', dtype=np.float32)\n",
        "    supplementary = pd.read_csv(os.path.join(DATA_DIR, 'supplementary_data_Vkoyn8z.csv'))\n",
        "except FileNotFoundError as e:\n",
        "    raise FileNotFoundError(f\"Dataset not found: {e}. Please ensure files are uploaded to {DATA_DIR}.\")\n",
        "\n",
        "# Custom weighted accuracy metric\n",
        "def weighted_accuracy(y_true, y_pred, weights):\n",
        "    y_pred_mapped = np.where(y_pred == 1, 1, -1)\n",
        "    correct = (y_pred_mapped == np.sign(y_true)).astype(float)\n",
        "    return np.sum(np.abs(y_true) * correct) / np.sum(np.abs(y_true))\n",
        "\n",
        "# Preprocess data with enhanced feature selection\n",
        "def preprocess_data(X, y=None, supplementary=None, is_train=True, top_cols=None):\n",
        "    ret_cols = [col for col in X.columns if col.startswith('RET_')]\n",
        "    if is_train and top_cols is None:\n",
        "        if len(ret_cols) > 15:\n",
        "            variances = X[ret_cols].var()\n",
        "            corr_sum = X[ret_cols].corr().abs().sum()\n",
        "            combined_score = variances * corr_sum\n",
        "            valid_cols = variances[variances > 1e-5].index\n",
        "            if len(valid_cols) < 15:\n",
        "                top_cols = valid_cols.tolist()\n",
        "            else:\n",
        "                top_cols = combined_score.loc[valid_cols].sort_values(ascending=False).head(15).index.tolist()\n",
        "        else:\n",
        "            top_cols = ret_cols\n",
        "        print(f\"Selected top return columns: {top_cols}\")\n",
        "    elif top_cols is not None:\n",
        "        ret_cols = [col for col in ret_cols if col in top_cols]\n",
        "        if not ret_cols:\n",
        "            raise ValueError(\"No return columns selected. Check top_cols consistency.\")\n",
        "\n",
        "    sector_medians = {}\n",
        "    if supplementary is not None:\n",
        "        sector_map = supplementary.set_index('ID_asset')['CLASS_LEVEL_1']\n",
        "        for col in ret_cols:\n",
        "            asset_id = int(col.replace('RET_', ''))\n",
        "            sector = sector_map.get(asset_id, np.nan)\n",
        "            if pd.notna(sector):\n",
        "                sector_assets = supplementary[supplementary['CLASS_LEVEL_1'] == sector]['ID_asset']\n",
        "                sector_cols = [f'RET_{a}' for a in sector_assets if f'RET_{a}' in X.columns]\n",
        "                if sector_cols:\n",
        "                    sector_medians[col] = X[sector_cols].median(axis=1)\n",
        "            if col in sector_medians:\n",
        "                X[col] = X[col].fillna(sector_medians[col])\n",
        "            else:\n",
        "                X[col] = X[col].fillna(X[col].median())\n",
        "\n",
        "    new_cols = {}\n",
        "    if supplementary is not None:\n",
        "        level = 'CLASS_LEVEL_1'\n",
        "        sector_groups = supplementary.groupby(level)['ID_asset'].apply(list).to_dict()\n",
        "        for sector, assets in sector_groups.items():\n",
        "            asset_cols = [f'RET_{asset}' for asset in assets if f'RET_{asset}' in ret_cols]\n",
        "            if asset_cols:\n",
        "                new_cols[f'SECTOR_AVG_{level}_{sector}'] = X[asset_cols].mean(axis=1).replace([np.inf, -np.inf], 0).fillna(0)\n",
        "        X = X.merge(supplementary[['ID_asset', level]].rename(columns={'ID_asset': 'ID_TARGET', level: f'TARGET_{level}'}),\n",
        "                    on='ID_TARGET', how='left')\n",
        "        X = pd.concat([X, pd.get_dummies(X[f'TARGET_{level}'], prefix=f'TARGET_{level}', dummy_na=True)], axis=1)\n",
        "        X = X.drop(f'TARGET_{level}', axis=1)\n",
        "\n",
        "    new_cols['MEAN_RET'] = X[ret_cols].mean(axis=1)\n",
        "    new_cols['STD_RET'] = X[ret_cols].std(axis=1)\n",
        "    new_cols.update({f'CS_RANK_{col}': X.groupby('ID_DAY')[col].rank(pct=True).replace([np.inf, -np.inf], 0).fillna(0) for col in ret_cols})\n",
        "\n",
        "    if is_train:\n",
        "        corr_matrix = X[ret_cols].corr()\n",
        "        corr_pairs = corr_matrix.unstack().sort_values(ascending=False)\n",
        "        top_pairs = [(i, j) for i, j in corr_pairs.index if i < j][:5]\n",
        "        for i, j in top_pairs:\n",
        "            new_cols[f'CORR_{i}_{j}'] = X[i] * X[j]\n",
        "\n",
        "    if ret_cols:\n",
        "        pca = PCA(n_components=min(2, len(ret_cols)), random_state=42)\n",
        "        pca_features = pca.fit_transform(X[ret_cols].fillna(0))\n",
        "        for i in range(pca_features.shape[1]):\n",
        "            new_cols[f'PCA_{i}'] = pca_features[:, i]\n",
        "\n",
        "    new_cols_df = pd.DataFrame(new_cols, index=X.index, dtype=np.float32)\n",
        "    X = pd.concat([X, new_cols_df], axis=1)\n",
        "\n",
        "    feature_cols = [col for col in X.columns if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "    scaler = StandardScaler()\n",
        "    X[feature_cols] = scaler.fit_transform(X[feature_cols].replace([np.inf, -np.inf], 0).fillna(0))\n",
        "\n",
        "    if is_train:\n",
        "        y['SIGN_TARGET'] = np.where(y['RET_TARGET'] > 0, 1, 0).astype(np.int32)\n",
        "        return X, y, feature_cols, top_cols\n",
        "    return X, None, feature_cols, top_cols\n",
        "\n",
        "# Preprocess data\n",
        "try:\n",
        "    X_train, y_train, feature_cols, top_cols = preprocess_data(X_train, y_train, supplementary, is_train=True)\n",
        "    X_test, _, test_feature_cols, _ = preprocess_data(X_test, supplementary=supplementary, is_train=False, top_cols=top_cols)\n",
        "except ValueError as e:\n",
        "    print(f\"Preprocessing error: {e}\")\n",
        "    raise\n",
        "\n",
        "# Align columns\n",
        "common_cols = X_train.columns.intersection(X_test.columns)\n",
        "X_train = X_train[common_cols]\n",
        "X_test = X_test[common_cols]\n",
        "feature_cols = [col for col in common_cols if col not in ['ID_DAY', 'ID_TARGET']]\n",
        "\n",
        "# Align y_train\n",
        "y_train = y_train.loc[X_train.index]\n",
        "\n",
        "# Define models with aggressively tuned-down LightGBM hyperparameter grid and original XGBoost\n",
        "models = {\n",
        "    'LightGBM': {\n",
        "        'model': LGBMClassifier(num_leaves=31, min_child_samples=15, lambda_l1=0.3, lambda_l2=0.3,\n",
        "                                subsample=0.7, colsample_bytree=0.8, bagging_freq=5, bagging_fraction=0.7,\n",
        "                                random_state=42, n_jobs=1, verbosity=-1, force_row_wise=True),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.001], 'num_leaves': [3], 'min_child_samples': [100], 'bagging_fraction': [0.3], 'colsample_bytree': [0.5], 'reg_alpha': [3.0], 'reg_lambda': [3.0], 'n_estimators': [20]},\n",
        "            {'learning_rate': [0.005], 'num_leaves': [5], 'min_child_samples': [75], 'bagging_fraction': [0.4], 'colsample_bytree': [0.6], 'reg_alpha': [2.0], 'reg_lambda': [2.0], 'n_estimators': [30]},\n",
        "            {'learning_rate': [0.007], 'num_leaves': [6], 'min_child_samples': [60], 'bagging_fraction': [0.3], 'colsample_bytree': [0.5], 'reg_alpha': [1.5], 'reg_lambda': [1.5], 'n_estimators': [40]},\n",
        "            {'learning_rate': [0.01], 'num_leaves': [8], 'min_child_samples': [50], 'bagging_fraction': [0.4], 'colsample_bytree': [0.6], 'reg_alpha': [1.0], 'reg_lambda': [1.0], 'n_estimators': [50]}\n",
        "        ],\n",
        "        'callbacks': [lightgbm.early_stopping(stopping_rounds=5, verbose=False)]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'model': XGBClassifier(max_depth=4, min_child_weight=2, subsample=0.8, colsample_bytree=0.8,\n",
        "                               random_state=42, n_jobs=1, eval_metric='logloss', verbosity=0,\n",
        "                               scale_pos_weight=len(y_train[y_train['SIGN_TARGET'] == 0]) / len(y_train[y_train['SIGN_TARGET'] == 1])),\n",
        "        'param_grid': [\n",
        "            {'learning_rate': [0.03], 'max_depth': [3], 'min_child_weight': [1], 'subsample': [0.6], 'n_estimators': [150], 'reg_alpha': [0.1], 'reg_lambda': [1.0]},\n",
        "            {'learning_rate': [0.05], 'max_depth': [4], 'min_child_weight': [2], 'subsample': [0.7], 'n_estimators': [200], 'reg_alpha': [0.2], 'reg_lambda': [1.5]},\n",
        "            {'learning_rate': [0.07], 'max_depth': [5], 'min_child_weight': [3], 'subsample': [0.8], 'n_estimators': [150], 'reg_alpha': [0.3], 'reg_lambda': [1.0]}\n",
        "        ],\n",
        "        'callbacks': [xgboost.callback.EarlyStopping(rounds=10, metric_name='logloss', save_best=True)]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to train and predict for a single target\n",
        "def train_target(target, X_train, y_train, X_test, feature_cols, model, model_name, kf, param_grid, callbacks):\n",
        "    X_target = X_train[X_train['ID_TARGET'] == target][feature_cols]\n",
        "    y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "    weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "    low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "    weight_scale = 1.5 if target in low_performing_targets else 1.0\n",
        "    if len(X_target) < 500:\n",
        "        weight_scale *= 1.5\n",
        "    weights = weights * weight_scale\n",
        "    groups = X_train[X_train['ID_TARGET'] == target]['ID_DAY']\n",
        "    X_test_target = X_test[X_test['ID_TARGET'] == target][feature_cols]\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "\n",
        "    if len(X_target) < 100 or len(X_test_target) == 0:\n",
        "        print(f\"Warning: Insufficient data for ID_TARGET {target} (train: {len(X_target)}, test: {len(X_test_target)}). Skipping.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    param_results = []\n",
        "    best_params = None\n",
        "    best_score = 0\n",
        "    best_model = None\n",
        "\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        print(f\"Testing params for {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "        try:\n",
        "            model.set_params(**params)\n",
        "        except ValueError as e:\n",
        "            print(f\"Invalid params for {model_name} ID_TARGET {target}: {e}\")\n",
        "            continue\n",
        "        fold_accuracies = []\n",
        "        for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "            X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "            y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "            w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "            if model_name == 'LightGBM' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=callbacks)\n",
        "            elif model_name == 'XGBoost' and callbacks:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "            else:\n",
        "                model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "            y_pred = model.predict(X_val)\n",
        "            acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "            fold_accuracies.append(acc)\n",
        "        mean_acc = np.mean(fold_accuracies)\n",
        "        print(f\"{model_name} | ID_TARGET: {target} | Params: {params} | Mean Accuracy: {mean_acc:.4f} | Fold Accuracies: {fold_accuracies}\", flush=True)\n",
        "        param_results.append({\n",
        "            'params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': fold_accuracies\n",
        "        })\n",
        "        if mean_acc > best_score:\n",
        "            best_score = mean_acc\n",
        "            best_params = params\n",
        "            best_model = type(model)(**model.get_params())\n",
        "\n",
        "    if best_model is None:\n",
        "        print(f\"No valid model for {model_name} ID_TARGET {target}. Using default.\")\n",
        "        return str(target), {}, 0, [], test_ids, np.zeros(len(test_ids), dtype=np.float32), []\n",
        "\n",
        "    best_model.set_params(**best_params)\n",
        "    if model_name == 'LightGBM' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=callbacks)\n",
        "    elif model_name == 'XGBoost' and callbacks:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "    else:\n",
        "        best_model.fit(X_target, y_target, sample_weight=weights)\n",
        "    preds = best_model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "    importance = best_model.feature_importances_\n",
        "    feature_importance = dict(zip(feature_cols, importance))\n",
        "    top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:30]\n",
        "    gc.collect()\n",
        "    return str(target), best_params, best_score, param_results, test_ids, preds, top_features\n",
        "\n",
        "# Cross-validation and training\n",
        "kf = GroupKFold(n_splits=5)\n",
        "results = {}\n",
        "predictions = {}\n",
        "ensemble_weights = {'LightGBM': 0.7, 'XGBoost': 0.3}\n",
        "param_log = {}\n",
        "top_features_all = {}\n",
        "param_summary = []\n",
        "low_performing_targets = [139, 8, 131, 269, 157, 249, 54, 130, 136, 3, 129]\n",
        "\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\", flush=True)\n",
        "    param_log[model_name] = {}\n",
        "    top_features_all[model_name] = {}\n",
        "    results_parallel = Parallel(n_jobs=-1)(\n",
        "        delayed(train_target)(target, X_train, y_train, X_test, feature_cols, model_info['model'], model_name, kf,\n",
        "                             model_info['param_grid'], model_info['callbacks'])\n",
        "        for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\")\n",
        "    )\n",
        "    accuracies = []\n",
        "    for target, params, mean_acc, param_results, test_ids, preds, top_features in results_parallel:\n",
        "        param_log[model_name][target] = {\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'all_params': param_results\n",
        "        }\n",
        "        top_features_all[model_name][target] = top_features\n",
        "        accuracies.append(mean_acc)\n",
        "        predictions.setdefault(target, {})[model_name] = dict(zip(test_ids, preds))\n",
        "        param_summary.append({\n",
        "            'model': model_name,\n",
        "            'ID_TARGET': target,\n",
        "            'best_params': params,\n",
        "            'mean_accuracy': mean_acc,\n",
        "            'fold_accuracies': param_results[-1]['fold_accuracies'] if param_results else []\n",
        "        })\n",
        "    results[model_name] = np.mean([acc for acc in accuracies if acc > 0])\n",
        "    print(f\"{model_name} Weighted Accuracy: {results[model_name]:.4f}\", flush=True)\n",
        "    print(f\"\\n{model_name} Parameter Summary:\", flush=True)\n",
        "    for summary in param_summary:\n",
        "        if summary['model'] == model_name:\n",
        "            print(f\"ID_TARGET: {summary['ID_TARGET']} | Best Params: {summary['best_params']} | Mean Accuracy: {summary['mean_accuracy']:.4f} | Fold Accuracies: {summary['fold_accuracies']}\", flush=True)\n",
        "\n",
        "# Second-pass training with top 30 features\n",
        "print(\"\\nPerforming second-pass training with top 30 features...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nSecond-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(X_train['ID_TARGET'].unique(), desc=f\"{model_name} Targets\"):\n",
        "        target_str = str(target)\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs()\n",
        "        weight_scale = 1.5 if target in low_performing_targets else 1.0\n",
        "        if len(X_target) < 500:\n",
        "            weight_scale *= 1.5\n",
        "        weights = weights * weight_scale\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        best_params['n_estimators'] = 200\n",
        "        model.set_params(**best_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Third-pass training for low-performing targets\n",
        "print(\"\\nPerforming third-pass training for low-performing targets...\", flush=True)\n",
        "for model_name, model_info in models.items():\n",
        "    print(f\"\\nThird-pass {model_name}...\", flush=True)\n",
        "    for target in tqdm(low_performing_targets, desc=f\"{model_name} Low-Performing Targets\"):\n",
        "        target_str = str(target)\n",
        "        if target_str not in param_log[model_name] or param_log[model_name][target_str]['mean_accuracy'] >= 0.75:\n",
        "            continue\n",
        "        top_features = [f[0] for f in top_features_all[model_name][target_str]]\n",
        "        if not top_features:\n",
        "            print(f\"Warning: No features for ID_TARGET {target}. Skipping.\")\n",
        "            continue\n",
        "        X_target = X_train[X_train['ID_TARGET'] == target][top_features]\n",
        "        y_target = y_train.loc[X_train['ID_TARGET'] == target, 'SIGN_TARGET']\n",
        "        weights = y_train.loc[X_train['ID_TARGET'] == target, 'RET_TARGET'].abs() * 1.5\n",
        "        if len(X_target) < 500:\n",
        "            weights = weights * 1.5\n",
        "        X_test_target = X_test[X_test['ID_TARGET'] == target][top_features]\n",
        "        test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "        if len(X_target) < 100:\n",
        "            print(f\"Warning: Insufficient training data for ID_TARGET {target} ({len(X_target)} samples). Skipping.\")\n",
        "            continue\n",
        "        model = model_info['model']\n",
        "        best_params = param_log[model_name][target_str]['best_params']\n",
        "        fine_tune_grid = [\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 0.8, 'n_estimators': 200, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.0, 'n_estimators': 250, 'reg_alpha': best_params['reg_alpha'][0], 'reg_lambda': best_params['reg_lambda'][0]},\n",
        "            {'learning_rate': best_params['learning_rate'][0] * 1.2, 'n_estimators': 200, 'reg_alpha': best_params['reg_alpha'][0] + 0.1, 'reg_lambda': best_params['reg_lambda'][0] + 0.1}\n",
        "        ]\n",
        "        best_score = param_log[model_name][target_str]['mean_accuracy']\n",
        "        best_fine_params = best_params\n",
        "        for params in ParameterGrid(fine_tune_grid):\n",
        "            print(f\"Fine-tuning {model_name} ID_TARGET {target}: {params}\", flush=True)\n",
        "            model.set_params(**params)\n",
        "            fold_accuracies = []\n",
        "            for train_idx, val_idx in kf.split(X_target, y_target, groups):\n",
        "                X_tr, X_val = X_target.iloc[train_idx], X_target.iloc[val_idx]\n",
        "                y_tr, y_val = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "                w_tr, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "                if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "                elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "                else:\n",
        "                    model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "                y_pred = model.predict(X_val)\n",
        "                acc = weighted_accuracy(y_val, y_pred, w_val)\n",
        "                fold_accuracies.append(acc)\n",
        "            mean_acc = np.mean(fold_accuracies)\n",
        "            print(f\"{model_name} | ID_TARGET: {target} | Fine-tune Params: {params} | Mean Accuracy: {mean_acc:.4f}\", flush=True)\n",
        "            if mean_acc > best_score:\n",
        "                best_score = mean_acc\n",
        "                best_fine_params = params\n",
        "                param_log[model_name][target_str]['best_params'] = best_fine_params\n",
        "                param_log[model_name][target_str]['mean_accuracy'] = best_score\n",
        "                param_summary.append({\n",
        "                    'model': model_name,\n",
        "                    'ID_TARGET': target_str,\n",
        "                    'best_params': best_fine_params,\n",
        "                    'mean_accuracy': best_score,\n",
        "                    'fold_accuracies': fold_accuracies\n",
        "                })\n",
        "        model.set_params(**best_fine_params)\n",
        "        if model_name == 'LightGBM' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], eval_metric='logloss', callbacks=model_info['callbacks'])\n",
        "        elif model_name == 'XGBoost' and model_info['callbacks']:\n",
        "            model.fit(X_target, y_target, sample_weight=weights, eval_set=[(X_target, y_target)], verbose=False)\n",
        "        else:\n",
        "            model.fit(X_target, y_target, sample_weight=weights)\n",
        "        preds = model.predict_proba(X_test_target)[:, 1].astype(np.float32)\n",
        "        predictions[target_str][model_name] = dict(zip(test_ids, preds))\n",
        "        gc.collect()\n",
        "\n",
        "# Save parameter log\n",
        "param_log_path = os.path.join(DATA_DIR, 'hyperparameters.json')\n",
        "with open(param_log_path, 'w') as f:\n",
        "    json.dump(param_log, f, indent=4)\n",
        "print(f\"Saved hyperparameter log to: {param_log_path}\", flush=True)\n",
        "files.download(param_log_path)\n",
        "\n",
        "# Ensemble predictions\n",
        "final_predictions = {}\n",
        "missing_day_targets = []\n",
        "for target in X_test['ID_TARGET'].unique():\n",
        "    target_str = str(target)\n",
        "    test_ids = X_test[X_test['ID_TARGET'] == target].index\n",
        "    for day in X_test[X_test['ID_TARGET'] == target]['ID_DAY'].unique():\n",
        "        day_idx = (X_test['ID_TARGET'] == target) & (X_test['ID_DAY'] == day)\n",
        "        day_test_ids = X_test[day_idx].index\n",
        "        if len(day_test_ids) == 0:\n",
        "            print(f\"Warning: No test samples for ID_TARGET {target} on ID_DAY {day}. Using default prediction.\")\n",
        "            missing_day_targets.append((target, day))\n",
        "            for idx in test_ids:\n",
        "                final_predictions[idx] = -1\n",
        "            continue\n",
        "        lgbm_preds = np.array([predictions[target_str].get('LightGBM', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        xgb_preds = np.array([predictions[target_str].get('XGBoost', {}).get(idx, 0.5) for idx in day_test_ids], dtype=np.float32)\n",
        "        ensemble_preds = ensemble_weights['LightGBM'] * lgbm_preds + ensemble_weights['XGBoost'] * xgb_preds\n",
        "        smoothed_preds = pd.Series(ensemble_preds).ewm(span=3).mean().values[-1] if len(ensemble_preds) > 0 else 0.5\n",
        "        for idx in day_test_ids:\n",
        "            final_predictions[idx] = 1 if smoothed_preds >= 0.5 else -1\n",
        "\n",
        "if missing_day_targets:\n",
        "    print(f\"Missing day-target pairs: {missing_day_targets}\")\n",
        "\n",
        "# Create output CSV\n",
        "output_df = pd.DataFrame.from_dict(final_predictions, orient='index', columns=['RET_TARGET']).reset_index()\n",
        "output_df.columns = ['ID', 'RET_TARGET']\n",
        "output_df = output_df.sort_values('ID')\n",
        "expected_ids = set(X_test.index)\n",
        "submission_ids = set(output_df['ID'])\n",
        "if expected_ids != submission_ids:\n",
        "    missing_ids = expected_ids - submission_ids\n",
        "    print(f\"Warning: Submission missing {len(missing_ids)} IDs: {missing_ids}\")\n",
        "    missing_df = pd.DataFrame({'ID': list(missing_ids), 'RET_TARGET': -1})\n",
        "    output_df = pd.concat([output_df, missing_df], ignore_index=True).sort_values('ID')\n",
        "output_path = os.path.join(DATA_DIR, 'predictions_ensemble.csv')\n",
        "output_df.to_csv(output_path, index=False)\n",
        "print(f\"Saved predictions to: {output_path}\", flush=True)\n",
        "\n",
        "# Validate output\n",
        "test_csv = pd.read_csv(output_path)\n",
        "print(f\"Output CSV shape: {test_csv.shape}\", flush=True)\n",
        "print(f\"Output CSV ID range: {test_csv['ID'].min()} to {test_csv['ID'].max()}\", flush=True)\n",
        "print(f\"Unique RET_TARGET values: {test_csv['RET_TARGET'].unique()}\", flush=True)\n",
        "print(f\"Missing values: {test_csv.isna().sum().sum()}\", flush=True)\n",
        "\n",
        "# Download the file\n",
        "files.download(output_path)\n",
        "\n",
        "# Print final results\n",
        "print(\"\\nValidation Results:\", flush=True)\n",
        "for model_name, acc in results.items():\n",
        "    print(f\"{model_name}: {acc:.4f}\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u7_i5qYqgY3_",
        "outputId": "2b8bf907-352a-45f3-ed49-d06e881a3ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost version: 3.0.2\n",
            "Selected top return columns: ['RET_262', 'RET_88', 'RET_172', 'RET_259', 'RET_150', 'RET_118', 'RET_216', 'RET_268', 'RET_115', 'RET_261', 'RET_59', 'RET_238', 'RET_121', 'RET_97', 'RET_30']\n",
            "\n",
            "Training LightGBM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "LightGBM Targets:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:   4%|         | 4/100 [00:12<05:04,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:   6%|         | 6/100 [00:19<05:03,  3.23s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:   8%|         | 8/100 [00:26<05:10,  3.38s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  10%|         | 10/100 [00:32<04:50,  3.22s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  12%|        | 12/100 [00:40<05:04,  3.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  14%|        | 14/100 [00:46<04:47,  3.34s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  16%|        | 16/100 [00:54<04:56,  3.53s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  18%|        | 18/100 [01:00<04:36,  3.37s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  20%|        | 20/100 [01:08<04:40,  3.51s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  22%|       | 22/100 [01:15<04:44,  3.64s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  24%|       | 24/100 [01:22<04:32,  3.59s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  26%|       | 26/100 [01:28<04:13,  3.43s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  28%|       | 28/100 [01:36<04:17,  3.58s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  30%|       | 30/100 [01:43<04:01,  3.45s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  32%|      | 32/100 [01:50<04:02,  3.56s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  34%|      | 34/100 [01:56<03:41,  3.36s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  36%|      | 36/100 [02:04<03:43,  3.49s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  38%|      | 38/100 [02:10<03:26,  3.32s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  40%|      | 40/100 [02:17<03:28,  3.48s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  42%|     | 42/100 [02:23<03:12,  3.32s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  44%|     | 44/100 [02:31<03:12,  3.45s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  46%|     | 46/100 [02:37<02:58,  3.31s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  48%|     | 48/100 [02:44<02:59,  3.45s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  50%|     | 50/100 [02:50<02:45,  3.30s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  52%|    | 52/100 [02:57<02:39,  3.32s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  54%|    | 54/100 [03:03<02:31,  3.30s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  56%|    | 56/100 [03:10<02:26,  3.34s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  58%|    | 58/100 [03:17<02:22,  3.39s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  60%|    | 60/100 [03:24<02:13,  3.34s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  62%|   | 62/100 [03:31<02:09,  3.41s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  64%|   | 64/100 [03:37<01:59,  3.32s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  66%|   | 66/100 [03:45<01:58,  3.48s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  68%|   | 68/100 [03:51<01:47,  3.37s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  70%|   | 70/100 [03:59<01:45,  3.51s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  72%|  | 72/100 [04:05<01:33,  3.35s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  74%|  | 74/100 [04:12<01:31,  3.53s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  76%|  | 76/100 [04:18<01:20,  3.33s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  78%|  | 78/100 [04:26<01:17,  3.54s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  80%|  | 80/100 [04:32<01:07,  3.40s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  82%| | 82/100 [04:40<01:04,  3.56s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  84%| | 84/100 [04:46<00:54,  3.40s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  86%| | 86/100 [04:54<00:49,  3.53s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  88%| | 88/100 [05:00<00:40,  3.37s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  90%| | 90/100 [05:08<00:34,  3.50s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  92%|| 92/100 [05:14<00:26,  3.36s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  94%|| 94/100 [05:22<00:21,  3.55s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  96%|| 96/100 [05:28<00:13,  3.40s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets:  98%|| 98/100 [05:35<00:07,  3.51s/it]\u001b[A\u001b[A\n",
            "\n",
            "LightGBM Targets: 100%|| 100/100 [05:41<00:00,  3.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LightGBM Weighted Accuracy: 0.9045\n",
            "\n",
            "LightGBM Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8808510638297873), np.float64(1.0), np.float64(0.9482071713147411), np.float64(1.0), np.float64(0.4738955823293173)]\n",
            "ID_TARGET: 129.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.673469387755102), np.float64(0.6178861788617886), np.float64(0.6477272727272727), np.float64(0.5991561181434599), np.float64(0.6509090909090909)]\n",
            "ID_TARGET: 136.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.7326 | Fold Accuracies: [np.float64(0.5868725868725869), np.float64(0.5), np.float64(0.52), np.float64(0.515625), np.float64(0.631578947368421)]\n",
            "ID_TARGET: 161.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6774193548387096), np.float64(0.696969696969697), np.float64(0.6374045801526718), np.float64(0.6718146718146718), np.float64(0.6704980842911877)]\n",
            "ID_TARGET: 217.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.888030888030888), np.float64(0.8365019011406845), np.float64(0.8408304498269896), np.float64(0.8608058608058609), np.float64(0.8546099290780141)]\n",
            "ID_TARGET: 91.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7977099236641222), np.float64(0.8008130081300813), np.float64(0.7338403041825095), np.float64(0.8057851239669421), np.float64(0.7715355805243446)]\n",
            "ID_TARGET: 137.0 | Best Params: {'bagging_fraction': 0.4, 'colsample_bytree': 0.6, 'learning_rate': 0.01, 'min_child_samples': 50, 'n_estimators': 50, 'num_leaves': 8, 'reg_alpha': 1.0, 'reg_lambda': 1.0} | Mean Accuracy: 0.5588 | Fold Accuracies: [np.float64(0.5537190082644629), np.float64(0.5676855895196506), np.float64(0.6025641025641025), np.float64(0.63671875), np.float64(0.43333333333333335)]\n",
            "ID_TARGET: 8.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6070038910505836), np.float64(0.6224899598393574), np.float64(0.6254980079681275), np.float64(0.908), np.float64(1.0)]\n",
            "ID_TARGET: 3.0 | Best Params: {'bagging_fraction': 0.4, 'colsample_bytree': 0.6, 'learning_rate': 0.01, 'min_child_samples': 50, 'n_estimators': 50, 'num_leaves': 8, 'reg_alpha': 1.0, 'reg_lambda': 1.0} | Mean Accuracy: 0.5916 | Fold Accuracies: [np.float64(0.5568181818181818), np.float64(0.569672131147541), np.float64(0.601593625498008), np.float64(0.6271186440677966), np.float64(0.6026200873362445)]\n",
            "ID_TARGET: 9.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7531914893617021), np.float64(0.756), np.float64(0.7153846153846154), np.float64(0.756198347107438), np.float64(0.7093023255813954)]\n",
            "ID_TARGET: 131.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.7430 | Fold Accuracies: [np.float64(0.515748031496063), np.float64(0.5576923076923077), np.float64(0.657258064516129), np.float64(0.5316455696202531), np.float64(0.5615384615384615)]\n",
            "ID_TARGET: 21.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7535211267605634), np.float64(0.6984732824427481), np.float64(0.7252747252747253), np.float64(0.734375), np.float64(0.669260700389105)]\n",
            "ID_TARGET: 54.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.9031007751937985), np.float64(0.8576779026217228), np.float64(0.9911894273127754), np.float64(0.6906474820143885), np.float64(0.8823529411764706)]\n",
            "ID_TARGET: 130.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.9090909090909091), np.float64(0.6974169741697417), np.float64(0.7132616487455197), np.float64(0.7338403041825095), np.float64(0.6240875912408759)]\n",
            "ID_TARGET: 269.0 | Best Params: {'bagging_fraction': 0.4, 'colsample_bytree': 0.6, 'learning_rate': 0.01, 'min_child_samples': 50, 'n_estimators': 50, 'num_leaves': 8, 'reg_alpha': 1.0, 'reg_lambda': 1.0} | Mean Accuracy: 0.5982 | Fold Accuracies: [np.float64(0.632), np.float64(0.6986899563318777), np.float64(0.5870445344129555), np.float64(0.5319148936170213), np.float64(0.5411255411255411)]\n",
            "ID_TARGET: 157.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.7311 | Fold Accuracies: [np.float64(0.7043478260869566), np.float64(0.7352941176470589), np.float64(0.7419354838709677), np.float64(0.64), np.float64(0.6065573770491803)]\n",
            "ID_TARGET: 249.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.748062015503876), np.float64(0.6996197718631179), np.float64(0.8436213991769548), np.float64(0.7346938775510204), np.float64(0.6297709923664122)]\n",
            "ID_TARGET: 22.0 | Best Params: {'bagging_fraction': 0.4, 'colsample_bytree': 0.6, 'learning_rate': 0.005, 'min_child_samples': 75, 'n_estimators': 30, 'num_leaves': 5, 'reg_alpha': 2.0, 'reg_lambda': 2.0} | Mean Accuracy: 0.7727 | Fold Accuracies: [np.float64(0.5978260869565217), np.float64(0.6390977443609023), np.float64(0.7244094488188977), np.float64(0.7318007662835249), np.float64(0.7431906614785992)]\n",
            "ID_TARGET: 202.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6745098039215687), np.float64(0.7276119402985075), np.float64(0.7471264367816092), np.float64(0.7328519855595668), np.float64(0.6931818181818182)]\n",
            "ID_TARGET: 132.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.9716 | Fold Accuracies: [np.float64(0.7068965517241379), np.float64(0.714859437751004), np.float64(0.6929133858267716), np.float64(0.7136929460580913), np.float64(0.7862903225806451)]\n",
            "ID_TARGET: 96.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.9090909090909091), np.float64(0.9742489270386266), np.float64(0.8269230769230769), np.float64(0.9497716894977168), np.float64(0.9786324786324786)]\n",
            "ID_TARGET: 7.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.73828125), np.float64(0.7876447876447876), np.float64(0.708029197080292), np.float64(0.766798418972332), np.float64(0.872093023255814)]\n",
            "ID_TARGET: 178.0 | Best Params: {'bagging_fraction': 0.4, 'colsample_bytree': 0.6, 'learning_rate': 0.01, 'min_child_samples': 50, 'n_estimators': 50, 'num_leaves': 8, 'reg_alpha': 1.0, 'reg_lambda': 1.0} | Mean Accuracy: 0.6419 | Fold Accuracies: [np.float64(0.6300813008130082), np.float64(0.6425855513307985), np.float64(0.6719367588932806), np.float64(0.6163265306122448), np.float64(0.6484375)]\n",
            "ID_TARGET: 68.0 | Best Params: {'bagging_fraction': 0.4, 'colsample_bytree': 0.6, 'learning_rate': 0.01, 'min_child_samples': 50, 'n_estimators': 50, 'num_leaves': 8, 'reg_alpha': 1.0, 'reg_lambda': 1.0} | Mean Accuracy: 0.7148 | Fold Accuracies: [np.float64(0.6896551724137931), np.float64(0.708502024291498), np.float64(0.7606837606837606), np.float64(0.7306122448979592), np.float64(0.6844262295081968)]\n",
            "ID_TARGET: 44.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7169811320754716), np.float64(0.7716535433070866), np.float64(0.7194244604316546), np.float64(0.7991452991452992), np.float64(0.7814814814814814)]\n",
            "ID_TARGET: 196.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8733333333333333), np.float64(0.9290540540540541), np.float64(0.967391304347826), np.float64(0.94921875), np.float64(0.925531914893617)]\n",
            "ID_TARGET: 292.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6606498194945848), np.float64(0.7777777777777778), np.float64(0.7867647058823529), np.float64(0.82421875), np.float64(0.896551724137931)]\n",
            "ID_TARGET: 239.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6692307692307692), np.float64(0.7661290322580645), np.float64(0.7627118644067796), np.float64(0.8095238095238095), np.float64(0.8526785714285714)]\n",
            "ID_TARGET: 279.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6377358490566037), np.float64(0.7165354330708661), np.float64(0.7276264591439688), np.float64(0.725), np.float64(0.6771653543307087)]\n",
            "ID_TARGET: 38.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6984732824427481), np.float64(0.7470355731225297), np.float64(0.8089430894308943), np.float64(0.7509578544061303), np.float64(0.8414096916299559)]\n",
            "ID_TARGET: 209.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.803921568627451), np.float64(0.7364341085271318), np.float64(0.7315175097276264), np.float64(0.7185185185185186), np.float64(0.7587548638132295)]\n",
            "ID_TARGET: 207.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7042801556420234), np.float64(0.6627450980392157), np.float64(0.7349397590361446), np.float64(0.6113207547169811), np.float64(0.6976744186046512)]\n",
            "ID_TARGET: 98.0 | Best Params: {'bagging_fraction': 0.4, 'colsample_bytree': 0.6, 'learning_rate': 0.01, 'min_child_samples': 50, 'n_estimators': 50, 'num_leaves': 8, 'reg_alpha': 1.0, 'reg_lambda': 1.0} | Mean Accuracy: 0.6243 | Fold Accuracies: [np.float64(0.5366795366795367), np.float64(0.6530612244897959), np.float64(0.691358024691358), np.float64(0.6625), np.float64(0.5779467680608364)]\n",
            "ID_TARGET: 65.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.007, 'min_child_samples': 60, 'n_estimators': 40, 'num_leaves': 6, 'reg_alpha': 1.5, 'reg_lambda': 1.5} | Mean Accuracy: 0.6957 | Fold Accuracies: [np.float64(0.6879699248120301), np.float64(0.7090909090909091), np.float64(0.6428571428571429), np.float64(0.6944444444444444), np.float64(0.7094017094017094)]\n",
            "ID_TARGET: 51.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7541666666666667), np.float64(0.7368421052631579), np.float64(0.8275862068965517), np.float64(0.7276422764227642), np.float64(0.7047244094488189)]\n",
            "ID_TARGET: 78.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7531380753138075), np.float64(0.768), np.float64(0.7375), np.float64(0.7257383966244726), np.float64(0.7628458498023716)]\n",
            "ID_TARGET: 177.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8145454545454546), np.float64(0.8141263940520446), np.float64(0.7659574468085106), np.float64(0.8041958041958042), np.float64(0.7451737451737451)]\n",
            "ID_TARGET: 231.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.8000 | Fold Accuracies: [np.float64(0.7604562737642585), np.float64(0.6380597014925373), np.float64(0.74), np.float64(0.8081632653061225), np.float64(0.779467680608365)]\n",
            "ID_TARGET: 119.0 | Best Params: {'bagging_fraction': 0.4, 'colsample_bytree': 0.6, 'learning_rate': 0.005, 'min_child_samples': 75, 'n_estimators': 30, 'num_leaves': 5, 'reg_alpha': 2.0, 'reg_lambda': 2.0} | Mean Accuracy: 0.7750 | Fold Accuracies: [np.float64(0.7276264591439688), np.float64(0.7569721115537849), np.float64(0.7713178294573644), np.float64(0.759493670886076), np.float64(0.7663934426229508)]\n",
            "ID_TARGET: 158.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.9398 | Fold Accuracies: [np.float64(0.7925311203319502), np.float64(0.8266129032258065), np.float64(0.7977099236641222), np.float64(0.8102766798418972), np.float64(0.7100371747211895)]\n",
            "ID_TARGET: 80.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.668), np.float64(0.7114624505928854), np.float64(0.648), np.float64(0.7020408163265306), np.float64(0.7920353982300885)]\n",
            "ID_TARGET: 25.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.9412 | Fold Accuracies: [np.float64(0.7886178861788617), np.float64(0.7627118644067796), np.float64(0.6764705882352942), np.float64(0.75), np.float64(0.75)]\n",
            "ID_TARGET: 175.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.67578125), np.float64(0.712), np.float64(0.6733870967741935), np.float64(0.7569721115537849), np.float64(0.7042801556420234)]\n",
            "ID_TARGET: 151.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.7735 | Fold Accuracies: [np.float64(0.6937269372693727), np.float64(0.7647058823529411), np.float64(0.7606837606837606), np.float64(0.7260869565217392), np.float64(0.8057851239669421)]\n",
            "ID_TARGET: 257.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8102766798418972), np.float64(0.7358490566037735), np.float64(0.8357664233576643), np.float64(0.7601476014760148), np.float64(0.7781818181818182)]\n",
            "ID_TARGET: 75.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8483606557377049), np.float64(0.8097165991902834), np.float64(0.8208955223880597), np.float64(0.7758620689655172), np.float64(0.8202247191011236)]\n",
            "ID_TARGET: 244.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.704119850187266), np.float64(0.7411764705882353), np.float64(0.6641509433962264), np.float64(0.7551020408163265), np.float64(0.6383763837638377)]\n",
            "ID_TARGET: 149.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6390977443609023), np.float64(0.6509803921568628), np.float64(0.7384615384615385), np.float64(0.7598425196850394), np.float64(0.7283464566929134)]\n",
            "ID_TARGET: 85.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.8000 | Fold Accuracies: [np.float64(0.7804878048780488), np.float64(0.7868852459016393), np.float64(0.772), np.float64(0.7521008403361344), np.float64(0.6360153256704981)]\n",
            "ID_TARGET: 190.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.7962 | Fold Accuracies: [np.float64(0.706766917293233), np.float64(0.7378277153558053), np.float64(0.7489878542510121), np.float64(0.6870229007633588), np.float64(0.7252747252747253)]\n",
            "ID_TARGET: 13.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.8914 | Fold Accuracies: [np.float64(0.7042801556420234), np.float64(0.7256317689530686), np.float64(0.7158671586715867), np.float64(0.7603305785123967), np.float64(0.7244094488188977)]\n",
            "ID_TARGET: 228.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8157894736842105), np.float64(0.810077519379845), np.float64(0.6794425087108014), np.float64(0.8373983739837398), np.float64(0.6702898550724637)]\n",
            "ID_TARGET: 144.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.788135593220339), np.float64(0.8403361344537815), np.float64(0.76), np.float64(0.6825396825396826), np.float64(0.7415254237288136)]\n",
            "ID_TARGET: 290.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7786561264822134), np.float64(0.8016528925619835), np.float64(0.7083333333333334), np.float64(0.7154471544715447), np.float64(0.7142857142857143)]\n",
            "ID_TARGET: 114.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6513409961685823), np.float64(0.7182539682539683), np.float64(0.696969696969697), np.float64(0.7808764940239044), np.float64(0.6902985074626866)]\n",
            "ID_TARGET: 166.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8292682926829268), np.float64(0.7802197802197802), np.float64(0.8360655737704918), np.float64(0.8014981273408239), np.float64(0.7745901639344263)]\n",
            "ID_TARGET: 234.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.8949 | Fold Accuracies: [np.float64(0.7909836065573771), np.float64(0.7661290322580645), np.float64(0.7773109243697479), np.float64(0.8095238095238095), np.float64(0.6964980544747081)]\n",
            "ID_TARGET: 34.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7490636704119851), np.float64(0.7938931297709924), np.float64(0.78), np.float64(0.7804878048780488), np.float64(0.7509578544061303)]\n",
            "ID_TARGET: 154.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8070866141732284), np.float64(0.8157894736842105), np.float64(0.7045454545454546), np.float64(0.7490636704119851), np.float64(0.8174273858921162)]\n",
            "ID_TARGET: 225.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7077464788732394), np.float64(0.7819548872180451), np.float64(0.74822695035461), np.float64(0.7790697674418605), np.float64(0.7644927536231884)]\n",
            "ID_TARGET: 185.0 | Best Params: {'bagging_fraction': 0.4, 'colsample_bytree': 0.6, 'learning_rate': 0.01, 'min_child_samples': 50, 'n_estimators': 50, 'num_leaves': 8, 'reg_alpha': 1.0, 'reg_lambda': 1.0} | Mean Accuracy: 0.6928 | Fold Accuracies: [np.float64(0.7601809954751131), np.float64(0.7117903930131004), np.float64(0.6190476190476191), np.float64(0.7161572052401747), np.float64(0.6567796610169492)]\n",
            "ID_TARGET: 39.0 | Best Params: {'bagging_fraction': 0.4, 'colsample_bytree': 0.6, 'learning_rate': 0.005, 'min_child_samples': 75, 'n_estimators': 30, 'num_leaves': 5, 'reg_alpha': 2.0, 'reg_lambda': 2.0} | Mean Accuracy: 0.7337 | Fold Accuracies: [np.float64(0.7439024390243902), np.float64(0.6431372549019608), np.float64(0.7042801556420234), np.float64(0.7450199203187251), np.float64(0.7193675889328063)]\n",
            "ID_TARGET: 272.0 | Best Params: {'bagging_fraction': 0.4, 'colsample_bytree': 0.6, 'learning_rate': 0.01, 'min_child_samples': 50, 'n_estimators': 50, 'num_leaves': 8, 'reg_alpha': 1.0, 'reg_lambda': 1.0} | Mean Accuracy: 0.7251 | Fold Accuracies: [np.float64(0.7280334728033473), np.float64(0.8), np.float64(0.7003891050583657), np.float64(0.7318007662835249), np.float64(0.6654929577464789)]\n",
            "ID_TARGET: 282.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.734375), np.float64(0.7683397683397684), np.float64(0.752), np.float64(0.7786259541984732), np.float64(0.7759336099585062)]\n",
            "ID_TARGET: 90.0 | Best Params: {'bagging_fraction': 0.4, 'colsample_bytree': 0.6, 'learning_rate': 0.01, 'min_child_samples': 50, 'n_estimators': 50, 'num_leaves': 8, 'reg_alpha': 1.0, 'reg_lambda': 1.0} | Mean Accuracy: 0.7161 | Fold Accuracies: [np.float64(0.734375), np.float64(0.7049808429118773), np.float64(0.672), np.float64(0.7468879668049793), np.float64(0.7222222222222222)]\n",
            "ID_TARGET: 52.0 | Best Params: {'bagging_fraction': 0.4, 'colsample_bytree': 0.6, 'learning_rate': 0.01, 'min_child_samples': 50, 'n_estimators': 50, 'num_leaves': 8, 'reg_alpha': 1.0, 'reg_lambda': 1.0} | Mean Accuracy: 0.7190 | Fold Accuracies: [np.float64(0.644927536231884), np.float64(0.7892376681614349), np.float64(0.7280334728033473), np.float64(0.75), np.float64(0.6829268292682927)]\n",
            "ID_TARGET: 258.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.007, 'min_child_samples': 60, 'n_estimators': 40, 'num_leaves': 6, 'reg_alpha': 1.5, 'reg_lambda': 1.5} | Mean Accuracy: 0.6707 | Fold Accuracies: [np.float64(0.6638297872340425), np.float64(0.7217391304347827), np.float64(0.6482213438735178), np.float64(0.69921875), np.float64(0.5968992248062015)]\n",
            "ID_TARGET: 291.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.9801 | Fold Accuracies: [np.float64(0.7982832618025751), np.float64(0.7335907335907336), np.float64(0.7326007326007326), np.float64(0.7426470588235294), np.float64(0.7698412698412699)]\n",
            "ID_TARGET: 152.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.9101 | Fold Accuracies: [np.float64(0.7416666666666667), np.float64(0.728), np.float64(0.6704545454545454), np.float64(0.6811594202898551), np.float64(0.6929460580912863)]\n",
            "ID_TARGET: 133.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8141263940520446), np.float64(0.7410358565737052), np.float64(0.7984189723320159), np.float64(0.7083333333333334), np.float64(0.7713178294573644)]\n",
            "ID_TARGET: 29.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.007, 'min_child_samples': 60, 'n_estimators': 40, 'num_leaves': 6, 'reg_alpha': 1.5, 'reg_lambda': 1.5} | Mean Accuracy: 0.7166 | Fold Accuracies: [np.float64(0.6254980079681275), np.float64(0.762114537444934), np.float64(0.6283524904214559), np.float64(0.7442748091603053), np.float64(0.6436781609195402)]\n",
            "ID_TARGET: 274.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7814814814814814), np.float64(0.7841726618705036), np.float64(0.7992277992277992), np.float64(0.7956989247311828), np.float64(0.7362637362637363)]\n",
            "ID_TARGET: 106.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7489177489177489), np.float64(0.7601809954751131), np.float64(0.7116279069767442), np.float64(0.7649769585253456), np.float64(0.75)]\n",
            "ID_TARGET: 173.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7582417582417582), np.float64(0.78), np.float64(0.8237704918032787), np.float64(0.8296296296296296), np.float64(0.7283464566929134)]\n",
            "ID_TARGET: 33.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7634854771784232), np.float64(0.749034749034749), np.float64(0.7764705882352941), np.float64(0.7782101167315175), np.float64(0.7397769516728625)]\n",
            "ID_TARGET: 69.0 | Best Params: {'bagging_fraction': 0.4, 'colsample_bytree': 0.6, 'learning_rate': 0.01, 'min_child_samples': 50, 'n_estimators': 50, 'num_leaves': 8, 'reg_alpha': 1.0, 'reg_lambda': 1.0} | Mean Accuracy: 0.6755 | Fold Accuracies: [np.float64(0.7217391304347827), np.float64(0.7215189873417721), np.float64(0.55), np.float64(0.6679245283018868), np.float64(0.7162162162162162)]\n",
            "ID_TARGET: 17.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7209302325581395), np.float64(0.7293233082706767), np.float64(0.734375), np.float64(0.66015625), np.float64(0.6756756756756757)]\n",
            "ID_TARGET: 189.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.9019 | Fold Accuracies: [np.float64(0.7312252964426877), np.float64(0.640926640926641), np.float64(0.7272727272727273), np.float64(0.758893280632411), np.float64(0.6958333333333333)]\n",
            "ID_TARGET: 284.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.8379 | Fold Accuracies: [np.float64(0.6581818181818182), np.float64(0.7297297297297297), np.float64(0.75), np.float64(0.7026022304832714), np.float64(0.7166666666666667)]\n",
            "ID_TARGET: 218.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.8000 | Fold Accuracies: [np.float64(0.6768060836501901), np.float64(0.6980392156862745), np.float64(0.6037037037037037), np.float64(0.8016194331983806), np.float64(0.697841726618705)]\n",
            "ID_TARGET: 183.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7282608695652174), np.float64(0.8347107438016529), np.float64(0.8223140495867769), np.float64(0.6870229007633588), np.float64(0.8371212121212122)]\n",
            "ID_TARGET: 206.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.6852589641434262), np.float64(0.6781609195402298), np.float64(0.7786561264822134), np.float64(0.8197424892703863), np.float64(0.7442748091603053)]\n",
            "ID_TARGET: 93.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7949790794979079), np.float64(0.6789667896678967), np.float64(0.8418803418803419), np.float64(0.7153558052434457), np.float64(0.7586206896551724)]\n",
            "ID_TARGET: 16.0 | Best Params: {'bagging_fraction': 0.4, 'colsample_bytree': 0.6, 'learning_rate': 0.005, 'min_child_samples': 75, 'n_estimators': 30, 'num_leaves': 5, 'reg_alpha': 2.0, 'reg_lambda': 2.0} | Mean Accuracy: 0.7140 | Fold Accuracies: [np.float64(0.6716417910447762), np.float64(0.6935483870967742), np.float64(0.6367041198501873), np.float64(0.7030075187969925), np.float64(0.7142857142857143)]\n",
            "ID_TARGET: 246.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7471264367816092), np.float64(0.7310606060606061), np.float64(0.7908745247148289), np.float64(0.7773584905660378), np.float64(0.7803921568627451)]\n",
            "ID_TARGET: 167.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8247011952191236), np.float64(0.8378378378378378), np.float64(0.8050847457627118), np.float64(0.8073770491803278), np.float64(0.8278688524590164)]\n",
            "ID_TARGET: 1.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7719298245614035), np.float64(0.7478632478632479), np.float64(0.7368421052631579), np.float64(0.7182539682539683), np.float64(0.7717842323651453)]\n",
            "ID_TARGET: 289.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.9147 | Fold Accuracies: [np.float64(0.7649572649572649), np.float64(0.667910447761194), np.float64(0.73828125), np.float64(0.7238805970149254), np.float64(0.6541353383458647)]\n",
            "ID_TARGET: 141.0 | Best Params: {'bagging_fraction': 0.4, 'colsample_bytree': 0.6, 'learning_rate': 0.005, 'min_child_samples': 75, 'n_estimators': 30, 'num_leaves': 5, 'reg_alpha': 2.0, 'reg_lambda': 2.0} | Mean Accuracy: 0.8041 | Fold Accuracies: [np.float64(0.7958333333333333), np.float64(0.8225108225108225), np.float64(0.7969348659003831), np.float64(0.7404580152671756), np.float64(0.7520325203252033)]\n",
            "ID_TARGET: 109.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.69), np.float64(0.8340080971659919), np.float64(0.7901234567901234), np.float64(0.8102766798418972), np.float64(0.7589928057553957)]\n",
            "ID_TARGET: 19.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.8669 | Fold Accuracies: [np.float64(0.7575757575757576), np.float64(0.7540983606557377), np.float64(0.734375), np.float64(0.7962264150943397), np.float64(0.7595419847328244)]\n",
            "ID_TARGET: 28.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.8915 | Fold Accuracies: [np.float64(0.6628787878787878), np.float64(0.6652719665271967), np.float64(0.6772908366533864), np.float64(0.6568265682656826), np.float64(0.6779661016949152)]\n",
            "ID_TARGET: 251.0 | Best Params: {'bagging_fraction': 0.4, 'colsample_bytree': 0.6, 'learning_rate': 0.005, 'min_child_samples': 75, 'n_estimators': 30, 'num_leaves': 5, 'reg_alpha': 2.0, 'reg_lambda': 2.0} | Mean Accuracy: 0.6913 | Fold Accuracies: [np.float64(0.6733870967741935), np.float64(0.6604477611940298), np.float64(0.6111111111111112), np.float64(0.7601626016260162), np.float64(0.6875)]\n",
            "ID_TARGET: 278.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.8395 | Fold Accuracies: [np.float64(0.6349206349206349), np.float64(0.7276264591439688), np.float64(0.7261410788381742), np.float64(0.7835497835497836), np.float64(0.7167381974248928)]\n",
            "ID_TARGET: 76.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.752895752895753), np.float64(0.7238805970149254), np.float64(0.7470817120622568), np.float64(0.7050359712230215), np.float64(0.8102766798418972)]\n",
            "ID_TARGET: 241.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.8007968127490039), np.float64(0.8108108108108109), np.float64(0.7740585774058577), np.float64(0.7942386831275721), np.float64(0.7541666666666667)]\n",
            "ID_TARGET: 214.0 | Best Params: {'bagging_fraction': 0.4, 'colsample_bytree': 0.6, 'learning_rate': 0.01, 'min_child_samples': 50, 'n_estimators': 50, 'num_leaves': 8, 'reg_alpha': 1.0, 'reg_lambda': 1.0} | Mean Accuracy: 0.7619 | Fold Accuracies: [np.float64(0.7396226415094339), np.float64(0.7411764705882353), np.float64(0.8110236220472441), np.float64(0.7888888888888889), np.float64(0.7286821705426356)]\n",
            "ID_TARGET: 102.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.9149 | Fold Accuracies: [np.float64(0.7480916030534351), np.float64(0.7521739130434782), np.float64(0.756198347107438), np.float64(0.8448275862068966), np.float64(0.7307692307692307)]\n",
            "ID_TARGET: 145.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(0.7104247104247104), np.float64(0.6111111111111112), np.float64(0.7183673469387755), np.float64(0.7224334600760456), np.float64(0.8024691358024691)]\n",
            "ID_TARGET: 155.0 | Best Params: {'bagging_fraction': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.001, 'min_child_samples': 100, 'n_estimators': 20, 'num_leaves': 3, 'reg_alpha': 3.0, 'reg_lambda': 3.0} | Mean Accuracy: 0.9854 | Fold Accuracies: [np.float64(0.7430555555555556), np.float64(0.8602941176470589), np.float64(0.8436213991769548), np.float64(0.7665369649805448), np.float64(0.8419117647058824)]\n",
            "\n",
            "Training XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "XGBoost Targets:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:   4%|         | 4/100 [00:18<07:12,  4.51s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:   6%|         | 6/100 [00:34<09:36,  6.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:   8%|         | 8/100 [00:51<10:35,  6.90s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  10%|         | 10/100 [01:06<10:42,  7.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  12%|        | 12/100 [01:26<11:55,  8.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  14%|        | 14/100 [01:46<12:22,  8.64s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  16%|        | 16/100 [02:08<13:08,  9.38s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  18%|        | 18/100 [02:26<12:38,  9.25s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  20%|        | 20/100 [02:45<12:35,  9.44s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  22%|       | 22/100 [03:04<12:19,  9.48s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  24%|       | 24/100 [03:20<11:20,  8.96s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  26%|       | 26/100 [03:39<11:17,  9.15s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  28%|       | 28/100 [04:00<11:23,  9.49s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  30%|       | 30/100 [04:18<10:59,  9.42s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  32%|      | 32/100 [04:37<10:44,  9.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  34%|      | 34/100 [04:52<09:40,  8.80s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  36%|      | 36/100 [05:09<09:23,  8.80s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  38%|      | 38/100 [05:28<09:14,  8.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  40%|      | 40/100 [05:44<08:36,  8.61s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  42%|     | 42/100 [06:02<08:26,  8.74s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  44%|     | 44/100 [06:19<08:11,  8.78s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  46%|     | 46/100 [06:36<07:43,  8.58s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  48%|     | 48/100 [06:53<07:27,  8.60s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  50%|     | 50/100 [07:10<07:09,  8.59s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  52%|    | 52/100 [07:26<06:39,  8.32s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  54%|    | 54/100 [07:42<06:24,  8.36s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  56%|    | 56/100 [08:03<06:33,  8.94s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  58%|    | 58/100 [08:21<06:15,  8.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  60%|    | 60/100 [08:38<05:54,  8.85s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  62%|   | 62/100 [09:00<05:58,  9.44s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  64%|   | 64/100 [09:17<05:31,  9.21s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  66%|   | 66/100 [09:34<05:02,  8.90s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  68%|   | 68/100 [09:52<04:48,  9.02s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  70%|   | 70/100 [10:11<04:35,  9.19s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  72%|  | 72/100 [10:28<04:10,  8.94s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  74%|  | 74/100 [10:46<03:52,  8.92s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  76%|  | 76/100 [11:02<03:28,  8.68s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  78%|  | 78/100 [11:22<03:19,  9.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  80%|  | 80/100 [11:41<03:05,  9.27s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  82%| | 82/100 [12:02<02:52,  9.56s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  84%| | 84/100 [12:21<02:32,  9.55s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  86%| | 86/100 [12:41<02:14,  9.61s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  88%| | 88/100 [13:03<02:00, 10.06s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  90%| | 90/100 [13:27<01:46, 10.64s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  92%|| 92/100 [13:47<01:23, 10.46s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  94%|| 94/100 [14:07<01:02, 10.36s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  96%|| 96/100 [14:27<00:41, 10.32s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  98%|| 98/100 [14:46<00:20, 10.07s/it]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets: 100%|| 100/100 [15:07<00:00,  9.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Weighted Accuracy: 0.7645\n",
            "\n",
            "XGBoost Parameter Summary:\n",
            "ID_TARGET: 139.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7133 | Fold Accuracies: [np.float64(0.7574468085106383), np.float64(0.67578125), np.float64(0.7729083665338645), np.float64(0.6937984496124031), np.float64(0.6666666666666666)]\n",
            "ID_TARGET: 129.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6275 | Fold Accuracies: [np.float64(0.6040816326530613), np.float64(0.6869918699186992), np.float64(0.6060606060606061), np.float64(0.6075949367088608), np.float64(0.6327272727272727)]\n",
            "ID_TARGET: 136.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 161.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.6710 | Fold Accuracies: [np.float64(0.5887096774193549), np.float64(0.6742424242424242), np.float64(0.6183206106870229), np.float64(0.667953667953668), np.float64(0.6743295019157088)]\n",
            "ID_TARGET: 217.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 91.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7799 | Fold Accuracies: [np.float64(0.8282442748091603), np.float64(0.8089430894308943), np.float64(0.6996197718631179), np.float64(0.8099173553719008), np.float64(0.7528089887640449)]\n",
            "ID_TARGET: 137.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0)]\n",
            "ID_TARGET: 8.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6083 | Fold Accuracies: [np.float64(0.5797665369649806), np.float64(0.5582329317269076), np.float64(0.6374501992031872), np.float64(0.616), np.float64(0.6181102362204725)]\n",
            "ID_TARGET: 3.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6825 | Fold Accuracies: [np.float64(0.678030303030303), np.float64(0.6639344262295082), np.float64(0.7131474103585658), np.float64(0.7330508474576272), np.float64(0.6244541484716157)]\n",
            "ID_TARGET: 9.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8953 | Fold Accuracies: [np.float64(1.0), np.float64(0.828), np.float64(0.8384615384615385), np.float64(1.0), np.float64(0.810077519379845)]\n",
            "ID_TARGET: 131.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6427 | Fold Accuracies: [np.float64(0.6968503937007874), np.float64(0.6538461538461539), np.float64(0.6532258064516129), np.float64(0.5864978902953587), np.float64(0.6230769230769231)]\n",
            "ID_TARGET: 21.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6880 | Fold Accuracies: [np.float64(0.7183098591549296), np.float64(0.6679389312977099), np.float64(0.6886446886446886), np.float64(0.66015625), np.float64(0.5914396887159533)]\n",
            "ID_TARGET: 54.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7428 | Fold Accuracies: [np.float64(0.7403100775193798), np.float64(0.7116104868913857), np.float64(0.775330396475771), np.float64(0.6474820143884892), np.float64(0.7686274509803922)]\n",
            "ID_TARGET: 130.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7001 | Fold Accuracies: [np.float64(0.7229437229437229), np.float64(0.6900369003690037), np.float64(0.7204301075268817), np.float64(0.6768060836501901), np.float64(0.635036496350365)]\n",
            "ID_TARGET: 269.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6456 | Fold Accuracies: [np.float64(0.676), np.float64(0.6812227074235808), np.float64(0.6639676113360324), np.float64(0.5531914893617021), np.float64(0.6536796536796536)]\n",
            "ID_TARGET: 157.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7185 | Fold Accuracies: [np.float64(0.7130434782608696), np.float64(0.7689075630252101), np.float64(0.7137096774193549), np.float64(0.708), np.float64(0.6762295081967213)]\n",
            "ID_TARGET: 249.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6977 | Fold Accuracies: [np.float64(0.686046511627907), np.float64(0.6730038022813688), np.float64(0.7325102880658436), np.float64(0.6693877551020408), np.float64(0.6412213740458015)]\n",
            "ID_TARGET: 22.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.6951 | Fold Accuracies: [np.float64(0.6847826086956522), np.float64(0.650375939849624), np.float64(0.7086614173228346), np.float64(0.685823754789272), np.float64(0.7042801556420234)]\n",
            "ID_TARGET: 202.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6943 | Fold Accuracies: [np.float64(0.6588235294117647), np.float64(0.7164179104477612), np.float64(0.6666666666666666), np.float64(0.7111913357400722), np.float64(0.6818181818181818)]\n",
            "ID_TARGET: 132.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7437 | Fold Accuracies: [np.float64(0.7543103448275862), np.float64(0.7068273092369478), np.float64(0.7244094488188977), np.float64(0.7427385892116183), np.float64(0.7903225806451613)]\n",
            "ID_TARGET: 96.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.9823 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(0.9115384615384615), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 7.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7419 | Fold Accuracies: [np.float64(0.7109375), np.float64(0.694980694980695), np.float64(0.6970802919708029), np.float64(0.7233201581027668), np.float64(0.7906976744186046)]\n",
            "ID_TARGET: 178.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7174 | Fold Accuracies: [np.float64(0.7357723577235772), np.float64(0.7110266159695817), np.float64(0.758893280632411), np.float64(0.689795918367347), np.float64(0.69140625)]\n",
            "ID_TARGET: 68.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7428 | Fold Accuracies: [np.float64(0.6973180076628352), np.float64(0.7489878542510121), np.float64(0.7521367521367521), np.float64(0.7755102040816326), np.float64(0.7090163934426229)]\n",
            "ID_TARGET: 44.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7481 | Fold Accuracies: [np.float64(0.7924528301886793), np.float64(0.7677165354330708), np.float64(0.7517985611510791), np.float64(0.7136752136752137), np.float64(0.7148148148148148)]\n",
            "ID_TARGET: 196.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7447 | Fold Accuracies: [np.float64(0.69), np.float64(0.7972972972972973), np.float64(0.7789855072463768), np.float64(0.69140625), np.float64(0.7659574468085106)]\n",
            "ID_TARGET: 292.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7031 | Fold Accuracies: [np.float64(0.6642599277978339), np.float64(0.7023809523809523), np.float64(0.6801470588235294), np.float64(0.67578125), np.float64(0.7126436781609196)]\n",
            "ID_TARGET: 239.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7428 | Fold Accuracies: [np.float64(0.6730769230769231), np.float64(0.6854838709677419), np.float64(0.7330508474576272), np.float64(0.753968253968254), np.float64(0.7366071428571429)]\n",
            "ID_TARGET: 279.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6781 | Fold Accuracies: [np.float64(0.6075471698113207), np.float64(0.7322834645669292), np.float64(0.6809338521400778), np.float64(0.7083333333333334), np.float64(0.6614173228346457)]\n",
            "ID_TARGET: 38.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7325 | Fold Accuracies: [np.float64(0.6870229007633588), np.float64(0.7233201581027668), np.float64(0.7601626016260162), np.float64(0.7164750957854407), np.float64(0.775330396475771)]\n",
            "ID_TARGET: 209.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 207.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.6802 | Fold Accuracies: [np.float64(0.6809338521400778), np.float64(0.6666666666666666), np.float64(0.7188755020080321), np.float64(0.6792452830188679), np.float64(0.6550387596899225)]\n",
            "ID_TARGET: 98.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7322 | Fold Accuracies: [np.float64(0.6872586872586872), np.float64(0.7795918367346939), np.float64(0.7860082304526749), np.float64(0.7541666666666667), np.float64(0.6539923954372624)]\n",
            "ID_TARGET: 65.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8022 | Fold Accuracies: [np.float64(0.7443609022556391), np.float64(0.740909090909091), np.float64(1.0), np.float64(0.7777777777777778), np.float64(0.7478632478632479)]\n",
            "ID_TARGET: 51.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7318 | Fold Accuracies: [np.float64(0.7291666666666666), np.float64(0.708502024291498), np.float64(0.7241379310344828), np.float64(0.7235772357723578), np.float64(0.6929133858267716)]\n",
            "ID_TARGET: 78.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7317 | Fold Accuracies: [np.float64(0.7196652719665272), np.float64(0.78), np.float64(0.6958333333333333), np.float64(0.6962025316455697), np.float64(0.766798418972332)]\n",
            "ID_TARGET: 177.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7548 | Fold Accuracies: [np.float64(0.7454545454545455), np.float64(0.7695167286245354), np.float64(0.723404255319149), np.float64(0.7622377622377622), np.float64(0.7142857142857143)]\n",
            "ID_TARGET: 231.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 119.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7668 | Fold Accuracies: [np.float64(0.7159533073929961), np.float64(0.7370517928286853), np.float64(0.8372093023255814), np.float64(0.7172995780590717), np.float64(0.7622950819672131)]\n",
            "ID_TARGET: 158.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7908 | Fold Accuracies: [np.float64(0.7634854771784232), np.float64(0.8225806451612904), np.float64(0.7709923664122137), np.float64(0.7984189723320159), np.float64(0.7397769516728625)]\n",
            "ID_TARGET: 80.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7180 | Fold Accuracies: [np.float64(0.672), np.float64(0.7114624505928854), np.float64(0.668), np.float64(0.7061224489795919), np.float64(0.7433628318584071)]\n",
            "ID_TARGET: 25.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7408 | Fold Accuracies: [np.float64(0.7723577235772358), np.float64(0.7457627118644068), np.float64(0.7095588235294118), np.float64(0.7574626865671642), np.float64(0.71875)]\n",
            "ID_TARGET: 175.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 151.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7736 | Fold Accuracies: [np.float64(0.7601476014760148), np.float64(0.7536764705882353), np.float64(0.7649572649572649), np.float64(0.7347826086956522), np.float64(0.7975206611570248)]\n",
            "ID_TARGET: 257.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7382 | Fold Accuracies: [np.float64(0.7154150197628458), np.float64(0.6867924528301886), np.float64(0.7408759124087592), np.float64(0.7084870848708487), np.float64(0.7018181818181818)]\n",
            "ID_TARGET: 75.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7849 | Fold Accuracies: [np.float64(0.8032786885245902), np.float64(0.7530364372469636), np.float64(0.7873134328358209), np.float64(0.7551724137931034), np.float64(0.797752808988764)]\n",
            "ID_TARGET: 244.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.6760 | Fold Accuracies: [np.float64(0.704119850187266), np.float64(0.6823529411764706), np.float64(0.6754716981132075), np.float64(0.673469387755102), np.float64(0.6088560885608856)]\n",
            "ID_TARGET: 149.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7248 | Fold Accuracies: [np.float64(0.6353383458646616), np.float64(0.7176470588235294), np.float64(0.7307692307692307), np.float64(0.7283464566929134), np.float64(0.7007874015748031)]\n",
            "ID_TARGET: 85.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.8157 | Fold Accuracies: [np.float64(0.8414634146341463), np.float64(0.8114754098360656), np.float64(0.816), np.float64(0.8739495798319328), np.float64(0.735632183908046)]\n",
            "ID_TARGET: 190.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7512 | Fold Accuracies: [np.float64(0.7631578947368421), np.float64(0.7228464419475655), np.float64(0.7692307692307693), np.float64(0.7213740458015268), np.float64(0.7655677655677655)]\n",
            "ID_TARGET: 13.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 228.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7756 | Fold Accuracies: [np.float64(0.7969924812030075), np.float64(0.7868217054263565), np.float64(0.735191637630662), np.float64(0.8414634146341463), np.float64(0.717391304347826)]\n",
            "ID_TARGET: 144.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7567 | Fold Accuracies: [np.float64(0.7457627118644068), np.float64(0.8277310924369747), np.float64(0.7672727272727272), np.float64(0.6785714285714286), np.float64(0.7161016949152542)]\n",
            "ID_TARGET: 290.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 114.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7208 | Fold Accuracies: [np.float64(0.6628352490421456), np.float64(0.7420634920634921), np.float64(0.7234848484848485), np.float64(0.7370517928286853), np.float64(0.7052238805970149)]\n",
            "ID_TARGET: 166.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7561 | Fold Accuracies: [np.float64(0.7439024390243902), np.float64(0.7435897435897436), np.float64(0.7459016393442623), np.float64(0.7340823970037453), np.float64(0.6967213114754098)]\n",
            "ID_TARGET: 234.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7604 | Fold Accuracies: [np.float64(0.7540983606557377), np.float64(0.7943548387096774), np.float64(0.7605042016806722), np.float64(0.7965367965367965), np.float64(0.6964980544747081)]\n",
            "ID_TARGET: 34.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7765 | Fold Accuracies: [np.float64(0.7415730337078652), np.float64(0.8053435114503816), np.float64(0.796), np.float64(0.7845528455284553), np.float64(0.7547892720306514)]\n",
            "ID_TARGET: 154.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7678 | Fold Accuracies: [np.float64(0.7677165354330708), np.float64(0.7857142857142857), np.float64(0.6893939393939394), np.float64(0.7078651685393258), np.float64(0.8008298755186722)]\n",
            "ID_TARGET: 225.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7313 | Fold Accuracies: [np.float64(0.6936619718309859), np.float64(0.7218045112781954), np.float64(0.7269503546099291), np.float64(0.7248062015503876), np.float64(0.7318840579710145)]\n",
            "ID_TARGET: 185.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7310 | Fold Accuracies: [np.float64(0.7013574660633484), np.float64(0.7074235807860262), np.float64(0.683982683982684), np.float64(0.7117903930131004), np.float64(0.7033898305084746)]\n",
            "ID_TARGET: 39.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 1.0000 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 272.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7795 | Fold Accuracies: [np.float64(0.7615062761506276), np.float64(0.8416666666666667), np.float64(0.7120622568093385), np.float64(0.7701149425287356), np.float64(0.7852112676056338)]\n",
            "ID_TARGET: 282.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7396 | Fold Accuracies: [np.float64(0.70703125), np.float64(0.7451737451737451), np.float64(0.72), np.float64(0.7595419847328244), np.float64(0.7385892116182573)]\n",
            "ID_TARGET: 90.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7747 | Fold Accuracies: [np.float64(0.75), np.float64(0.7701149425287356), np.float64(0.724), np.float64(0.7800829875518672), np.float64(0.7936507936507936)]\n",
            "ID_TARGET: 52.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7410 | Fold Accuracies: [np.float64(0.717391304347826), np.float64(0.7713004484304933), np.float64(0.6694560669456067), np.float64(0.7142857142857143), np.float64(0.7154471544715447)]\n",
            "ID_TARGET: 258.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7263 | Fold Accuracies: [np.float64(0.6978723404255319), np.float64(0.7521739130434782), np.float64(0.7193675889328063), np.float64(0.75390625), np.float64(0.6589147286821705)]\n",
            "ID_TARGET: 291.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7596 | Fold Accuracies: [np.float64(0.7553648068669528), np.float64(0.7683397683397684), np.float64(0.73992673992674), np.float64(0.7683823529411765), np.float64(0.7658730158730159)]\n",
            "ID_TARGET: 152.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7523 | Fold Accuracies: [np.float64(0.6958333333333333), np.float64(0.744), np.float64(0.7310606060606061), np.float64(0.6884057971014492), np.float64(0.7593360995850622)]\n",
            "ID_TARGET: 133.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7715 | Fold Accuracies: [np.float64(0.7732342007434945), np.float64(0.7410358565737052), np.float64(0.7944664031620553), np.float64(0.7083333333333334), np.float64(0.8023255813953488)]\n",
            "ID_TARGET: 29.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7074 | Fold Accuracies: [np.float64(0.6613545816733067), np.float64(0.7665198237885462), np.float64(0.6781609195402298), np.float64(0.7022900763358778), np.float64(0.6973180076628352)]\n",
            "ID_TARGET: 274.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7475 | Fold Accuracies: [np.float64(0.7407407407407407), np.float64(0.7697841726618705), np.float64(0.7335907335907336), np.float64(0.7275985663082437), np.float64(0.6923076923076923)]\n",
            "ID_TARGET: 106.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.9610 | Fold Accuracies: [np.float64(0.8051948051948052), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 173.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7626 | Fold Accuracies: [np.float64(0.7875457875457875), np.float64(0.752), np.float64(0.75), np.float64(0.7777777777777778), np.float64(0.7086614173228346)]\n",
            "ID_TARGET: 33.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7340 | Fold Accuracies: [np.float64(0.7676348547717843), np.float64(0.722007722007722), np.float64(0.6941176470588235), np.float64(0.7354085603112841), np.float64(0.7509293680297398)]\n",
            "ID_TARGET: 69.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7338 | Fold Accuracies: [np.float64(0.7434782608695653), np.float64(0.7257383966244726), np.float64(0.6846153846153846), np.float64(0.7358490566037735), np.float64(0.7477477477477478)]\n",
            "ID_TARGET: 17.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7002 | Fold Accuracies: [np.float64(0.7170542635658915), np.float64(0.7180451127819549), np.float64(0.6953125), np.float64(0.6796875), np.float64(0.667953667953668)]\n",
            "ID_TARGET: 189.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7320 | Fold Accuracies: [np.float64(0.7272727272727273), np.float64(0.6833976833976834), np.float64(0.7851239669421488), np.float64(0.7391304347826086), np.float64(0.725)]\n",
            "ID_TARGET: 284.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7287 | Fold Accuracies: [np.float64(0.6618181818181819), np.float64(0.7065637065637066), np.float64(0.7581967213114754), np.float64(0.7211895910780669), np.float64(0.7333333333333333)]\n",
            "ID_TARGET: 218.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7126 | Fold Accuracies: [np.float64(0.6844106463878327), np.float64(0.7019607843137254), np.float64(0.6703703703703704), np.float64(0.8016194331983806), np.float64(0.6798561151079137)]\n",
            "ID_TARGET: 183.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7483 | Fold Accuracies: [np.float64(0.7246376811594203), np.float64(0.7644628099173554), np.float64(0.7396694214876033), np.float64(0.6946564885496184), np.float64(0.8181818181818182)]\n",
            "ID_TARGET: 206.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7602 | Fold Accuracies: [np.float64(0.7091633466135459), np.float64(0.7279693486590039), np.float64(0.782608695652174), np.float64(0.7510729613733905), np.float64(0.767175572519084)]\n",
            "ID_TARGET: 93.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7047 | Fold Accuracies: [np.float64(0.6694560669456067), np.float64(0.6383763837638377), np.float64(0.7136752136752137), np.float64(0.6966292134831461), np.float64(0.7011494252873564)]\n",
            "ID_TARGET: 16.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7130 | Fold Accuracies: [np.float64(0.6902985074626866), np.float64(0.6774193548387096), np.float64(0.6779026217228464), np.float64(0.7330827067669173), np.float64(0.6974789915966386)]\n",
            "ID_TARGET: 246.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7454 | Fold Accuracies: [np.float64(0.6628352490421456), np.float64(0.7121212121212122), np.float64(0.7338403041825095), np.float64(0.7132075471698113), np.float64(0.7137254901960784)]\n",
            "ID_TARGET: 167.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.9602 | Fold Accuracies: [np.float64(1.0), np.float64(1.0), np.float64(0.8008474576271186), np.float64(1.0), np.float64(1.0)]\n",
            "ID_TARGET: 1.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7377 | Fold Accuracies: [np.float64(0.7719298245614035), np.float64(0.7478632478632479), np.float64(0.7246963562753036), np.float64(0.6944444444444444), np.float64(0.7261410788381742)]\n",
            "ID_TARGET: 289.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7539 | Fold Accuracies: [np.float64(0.7521367521367521), np.float64(0.7761194029850746), np.float64(0.765625), np.float64(0.7649253731343284), np.float64(0.7105263157894737)]\n",
            "ID_TARGET: 141.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7918 | Fold Accuracies: [np.float64(0.7916666666666666), np.float64(0.8051948051948052), np.float64(0.7931034482758621), np.float64(0.816793893129771), np.float64(0.7520325203252033)]\n",
            "ID_TARGET: 109.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7265 | Fold Accuracies: [np.float64(0.7), np.float64(0.7530364372469636), np.float64(0.6995884773662552), np.float64(0.6679841897233202), np.float64(0.7446043165467626)]\n",
            "ID_TARGET: 19.0 | Best Params: {'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150, 'reg_alpha': 0.3, 'reg_lambda': 1.0, 'subsample': 0.8} | Mean Accuracy: 0.7719 | Fold Accuracies: [np.float64(0.7765151515151515), np.float64(0.7704918032786885), np.float64(0.73046875), np.float64(0.8150943396226416), np.float64(0.767175572519084)]\n",
            "ID_TARGET: 28.0 | Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'reg_alpha': 0.2, 'reg_lambda': 1.5, 'subsample': 0.7} | Mean Accuracy: 0.7113 | Fold Accuracies: [np.float64(0.696969696969697), np.float64(0.6778242677824268), np.float64(0.7091633466135459), np.float64(0.7343173431734318), np.float64(0.690677966101695)]\n",
            "ID_TARGET: 251.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7186 | Fold Accuracies: [np.float64(0.6612903225806451), np.float64(0.6791044776119403), np.float64(0.725925925925926), np.float64(0.7073170731707317), np.float64(0.725)]\n",
            "ID_TARGET: 278.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7499 | Fold Accuracies: [np.float64(0.6587301587301587), np.float64(0.7509727626459144), np.float64(0.7219917012448133), np.float64(0.8095238095238095), np.float64(0.7467811158798283)]\n",
            "ID_TARGET: 76.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7491 | Fold Accuracies: [np.float64(0.6911196911196911), np.float64(0.7238805970149254), np.float64(0.7042801556420234), np.float64(0.7302158273381295), np.float64(0.7312252964426877)]\n",
            "ID_TARGET: 241.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7444 | Fold Accuracies: [np.float64(0.7051792828685259), np.float64(0.7522522522522522), np.float64(0.6652719665271967), np.float64(0.7860082304526749), np.float64(0.7166666666666667)]\n",
            "ID_TARGET: 214.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7816 | Fold Accuracies: [np.float64(0.7320754716981132), np.float64(0.6823529411764706), np.float64(0.7755905511811023), np.float64(0.7888888888888889), np.float64(0.7248062015503876)]\n",
            "ID_TARGET: 102.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7621 | Fold Accuracies: [np.float64(0.7862595419847328), np.float64(0.717391304347826), np.float64(0.7396694214876033), np.float64(0.8103448275862069), np.float64(0.7153846153846154)]\n",
            "ID_TARGET: 145.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.6891 | Fold Accuracies: [np.float64(0.6640926640926641), np.float64(0.6370370370370371), np.float64(0.6816326530612244), np.float64(0.6539923954372624), np.float64(0.6954732510288066)]\n",
            "ID_TARGET: 155.0 | Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6} | Mean Accuracy: 0.7950 | Fold Accuracies: [np.float64(0.7777777777777778), np.float64(0.8382352941176471), np.float64(0.7901234567901234), np.float64(0.7704280155642024), np.float64(0.7830882352941176)]\n",
            "\n",
            "Performing second-pass training with top 30 features...\n",
            "\n",
            "Second-pass LightGBM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "LightGBM Targets:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:   1%|          | 1/100 [00:00<01:21,  1.22it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:   2%|         | 2/100 [00:01<01:09,  1.41it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:   3%|         | 3/100 [00:01<00:57,  1.69it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:   4%|         | 4/100 [00:02<00:48,  2.00it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:   5%|         | 5/100 [00:02<00:43,  2.20it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:   6%|         | 6/100 [00:03<00:40,  2.34it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:   7%|         | 7/100 [00:03<00:39,  2.37it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:   8%|         | 8/100 [00:03<00:37,  2.45it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:   9%|         | 9/100 [00:04<00:39,  2.31it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  10%|         | 10/100 [00:04<00:36,  2.45it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  11%|         | 11/100 [00:05<00:37,  2.40it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  12%|        | 12/100 [00:05<00:37,  2.35it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  13%|        | 13/100 [00:05<00:37,  2.29it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  14%|        | 14/100 [00:06<00:36,  2.33it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  15%|        | 15/100 [00:06<00:37,  2.25it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  16%|        | 16/100 [00:07<00:35,  2.37it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  17%|        | 17/100 [00:07<00:34,  2.42it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  18%|        | 18/100 [00:08<00:35,  2.31it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  19%|        | 19/100 [00:08<00:34,  2.34it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  20%|        | 20/100 [00:08<00:34,  2.31it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  21%|        | 21/100 [00:09<00:32,  2.42it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  22%|       | 22/100 [00:09<00:31,  2.47it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  23%|       | 23/100 [00:10<00:33,  2.31it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  24%|       | 24/100 [00:10<00:33,  2.28it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  25%|       | 25/100 [00:11<00:31,  2.41it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  26%|       | 26/100 [00:11<00:30,  2.45it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  27%|       | 27/100 [00:11<00:31,  2.34it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  28%|       | 28/100 [00:12<00:33,  2.13it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  29%|       | 29/100 [00:13<00:34,  2.04it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  30%|       | 30/100 [00:13<00:36,  1.94it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  31%|       | 31/100 [00:14<00:38,  1.80it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  32%|      | 32/100 [00:14<00:39,  1.71it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  33%|      | 33/100 [00:15<00:38,  1.73it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  34%|      | 34/100 [00:15<00:34,  1.90it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  35%|      | 35/100 [00:16<00:31,  2.08it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  36%|      | 36/100 [00:16<00:29,  2.21it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  37%|      | 37/100 [00:16<00:26,  2.34it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  38%|      | 38/100 [00:17<00:27,  2.29it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  39%|      | 39/100 [00:17<00:27,  2.21it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  40%|      | 40/100 [00:18<00:26,  2.25it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  41%|      | 41/100 [00:18<00:25,  2.28it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  42%|     | 42/100 [00:19<00:25,  2.29it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  43%|     | 43/100 [00:19<00:24,  2.35it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  44%|     | 44/100 [00:19<00:22,  2.44it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  45%|     | 45/100 [00:20<00:22,  2.48it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  46%|     | 46/100 [00:20<00:21,  2.46it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  47%|     | 47/100 [00:21<00:21,  2.50it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  48%|     | 48/100 [00:21<00:21,  2.43it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  49%|     | 49/100 [00:22<00:21,  2.42it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  50%|     | 50/100 [00:22<00:20,  2.46it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  51%|     | 51/100 [00:22<00:19,  2.52it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  52%|    | 52/100 [00:23<00:18,  2.57it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  53%|    | 53/100 [00:23<00:17,  2.61it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  54%|    | 54/100 [00:23<00:17,  2.59it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  55%|    | 55/100 [00:24<00:16,  2.65it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  56%|    | 56/100 [00:24<00:17,  2.54it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  57%|    | 57/100 [00:25<00:17,  2.42it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  58%|    | 58/100 [00:25<00:19,  2.12it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  59%|    | 59/100 [00:26<00:19,  2.06it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  60%|    | 60/100 [00:26<00:20,  1.97it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  61%|    | 61/100 [00:27<00:21,  1.78it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  62%|   | 62/100 [00:28<00:23,  1.60it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  63%|   | 63/100 [00:28<00:22,  1.64it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  64%|   | 64/100 [00:29<00:19,  1.83it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  65%|   | 65/100 [00:29<00:18,  1.89it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  66%|   | 66/100 [00:30<00:17,  1.95it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  67%|   | 67/100 [00:30<00:16,  2.04it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  68%|   | 68/100 [00:31<00:14,  2.20it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  69%|   | 69/100 [00:31<00:13,  2.29it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  70%|   | 70/100 [00:31<00:12,  2.38it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  71%|   | 71/100 [00:32<00:12,  2.36it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  72%|  | 72/100 [00:32<00:11,  2.44it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  73%|  | 73/100 [00:33<00:10,  2.51it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  74%|  | 74/100 [00:33<00:10,  2.53it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  75%|  | 75/100 [00:33<00:10,  2.47it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  76%|  | 76/100 [00:34<00:10,  2.28it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  77%|  | 77/100 [00:34<00:09,  2.31it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  78%|  | 78/100 [00:35<00:09,  2.33it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  79%|  | 79/100 [00:35<00:09,  2.33it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  80%|  | 80/100 [00:36<00:08,  2.33it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  81%|  | 81/100 [00:36<00:08,  2.32it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  82%| | 82/100 [00:36<00:07,  2.33it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  83%| | 83/100 [00:37<00:07,  2.35it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  84%| | 84/100 [00:37<00:07,  2.28it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  85%| | 85/100 [00:38<00:06,  2.34it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  86%| | 86/100 [00:38<00:05,  2.41it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  87%| | 87/100 [00:39<00:05,  2.21it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  88%| | 88/100 [00:39<00:05,  2.10it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  89%| | 89/100 [00:40<00:05,  1.93it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  90%| | 90/100 [00:40<00:05,  1.93it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  91%| | 91/100 [00:41<00:04,  1.89it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  92%|| 92/100 [00:41<00:04,  1.78it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  93%|| 93/100 [00:42<00:03,  1.88it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  94%|| 94/100 [00:42<00:02,  2.02it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  95%|| 95/100 [00:43<00:02,  2.07it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  96%|| 96/100 [00:43<00:01,  2.14it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  97%|| 97/100 [00:44<00:01,  2.04it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  98%|| 98/100 [00:44<00:00,  2.12it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets:  99%|| 99/100 [00:45<00:00,  2.13it/s]\u001b[A\u001b[A/usr/local/lib/python3.11/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n",
            "\n",
            "\n",
            "LightGBM Targets: 100%|| 100/100 [00:45<00:00,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Second-pass XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "XGBoost Targets:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:   1%|          | 1/100 [00:00<00:58,  1.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:   2%|         | 2/100 [00:01<00:58,  1.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:   3%|         | 3/100 [00:01<00:57,  1.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:   4%|         | 4/100 [00:02<00:56,  1.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:   5%|         | 5/100 [00:02<00:54,  1.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:   6%|         | 6/100 [00:03<00:54,  1.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:   7%|         | 7/100 [00:04<00:52,  1.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:   8%|         | 8/100 [00:04<00:54,  1.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:   9%|         | 9/100 [00:05<00:53,  1.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  10%|         | 10/100 [00:05<00:52,  1.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  11%|         | 11/100 [00:06<00:52,  1.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  12%|        | 12/100 [00:07<01:01,  1.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  13%|        | 13/100 [00:08<01:07,  1.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  14%|        | 14/100 [00:09<01:14,  1.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  15%|        | 15/100 [00:10<01:10,  1.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  16%|        | 16/100 [00:10<01:06,  1.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  17%|        | 17/100 [00:11<01:03,  1.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  18%|        | 18/100 [00:12<00:58,  1.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  19%|        | 19/100 [00:12<00:57,  1.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  20%|        | 20/100 [00:13<00:54,  1.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  21%|        | 21/100 [00:14<00:51,  1.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  22%|       | 22/100 [00:14<00:50,  1.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  23%|       | 23/100 [00:15<00:50,  1.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  24%|       | 24/100 [00:15<00:49,  1.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  25%|       | 25/100 [00:16<00:47,  1.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  26%|       | 26/100 [00:17<00:47,  1.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  27%|       | 27/100 [00:17<00:47,  1.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  28%|       | 28/100 [00:18<00:45,  1.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  29%|       | 29/100 [00:19<00:43,  1.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  30%|       | 30/100 [00:19<00:42,  1.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  31%|       | 31/100 [00:20<00:43,  1.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  32%|      | 32/100 [00:21<00:46,  1.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  33%|      | 33/100 [00:21<00:48,  1.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  34%|      | 34/100 [00:22<00:49,  1.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  35%|      | 35/100 [00:23<00:50,  1.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  36%|      | 36/100 [00:24<00:44,  1.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  37%|      | 37/100 [00:24<00:43,  1.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  38%|      | 38/100 [00:25<00:39,  1.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  39%|      | 39/100 [00:25<00:39,  1.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  40%|      | 40/100 [00:26<00:38,  1.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  41%|      | 41/100 [00:27<00:37,  1.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  42%|     | 42/100 [00:27<00:35,  1.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  43%|     | 43/100 [00:28<00:32,  1.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  44%|     | 44/100 [00:28<00:32,  1.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  45%|     | 45/100 [00:29<00:32,  1.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  46%|     | 46/100 [00:30<00:33,  1.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  47%|     | 47/100 [00:30<00:32,  1.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  48%|     | 48/100 [00:31<00:32,  1.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  49%|     | 49/100 [00:31<00:30,  1.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  50%|     | 50/100 [00:32<00:30,  1.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  51%|     | 51/100 [00:33<00:28,  1.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  52%|    | 52/100 [00:33<00:30,  1.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  53%|    | 53/100 [00:34<00:33,  1.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  54%|    | 54/100 [00:35<00:34,  1.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  55%|    | 55/100 [00:36<00:37,  1.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  56%|    | 56/100 [00:37<00:33,  1.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  57%|    | 57/100 [00:37<00:29,  1.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  58%|    | 58/100 [00:38<00:26,  1.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  59%|    | 59/100 [00:38<00:25,  1.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  60%|    | 60/100 [00:39<00:25,  1.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  61%|    | 61/100 [00:40<00:26,  1.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  62%|   | 62/100 [00:40<00:24,  1.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  63%|   | 63/100 [00:41<00:23,  1.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  64%|   | 64/100 [00:41<00:22,  1.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  65%|   | 65/100 [00:42<00:21,  1.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  66%|   | 66/100 [00:43<00:20,  1.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  67%|   | 67/100 [00:43<00:20,  1.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  68%|   | 68/100 [00:44<00:19,  1.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  69%|   | 69/100 [00:45<00:19,  1.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  70%|   | 70/100 [00:45<00:18,  1.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  71%|   | 71/100 [00:46<00:18,  1.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  72%|  | 72/100 [00:47<00:19,  1.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  73%|  | 73/100 [00:48<00:19,  1.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  74%|  | 74/100 [00:48<00:20,  1.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  75%|  | 75/100 [00:49<00:21,  1.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  76%|  | 76/100 [00:50<00:18,  1.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  77%|  | 77/100 [00:51<00:16,  1.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  78%|  | 78/100 [00:51<00:14,  1.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  79%|  | 79/100 [00:52<00:13,  1.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  80%|  | 80/100 [00:53<00:13,  1.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  81%|  | 81/100 [00:53<00:12,  1.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  82%| | 82/100 [00:54<00:11,  1.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  83%| | 83/100 [00:54<00:10,  1.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  84%| | 84/100 [00:55<00:10,  1.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  85%| | 85/100 [00:56<00:09,  1.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  86%| | 86/100 [00:56<00:08,  1.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  87%| | 87/100 [00:57<00:08,  1.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  88%| | 88/100 [00:57<00:07,  1.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  89%| | 89/100 [00:58<00:06,  1.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  90%| | 90/100 [00:59<00:06,  1.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  91%| | 91/100 [00:59<00:05,  1.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  92%|| 92/100 [01:00<00:05,  1.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  93%|| 93/100 [01:01<00:05,  1.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  94%|| 94/100 [01:02<00:04,  1.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  95%|| 95/100 [01:03<00:04,  1.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  96%|| 96/100 [01:04<00:03,  1.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  97%|| 97/100 [01:04<00:02,  1.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  98%|| 98/100 [01:05<00:01,  1.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets:  99%|| 99/100 [01:06<00:00,  1.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "XGBoost Targets: 100%|| 100/100 [01:06<00:00,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performing third-pass training for low-performing targets...\n",
            "\n",
            "Third-pass LightGBM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "LightGBM Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 52488.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Third-pass XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "XGBoost Low-Performing Targets: 100%|| 11/11 [00:00<00:00, 100517.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved hyperparameter log to: /content/hyperparameters.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9527c674-16da-47d9-9b9e-31bfd8e63d2a\", \"hyperparameters.json\", 612437)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved predictions to: /content/predictions_ensemble.csv\n",
            "Output CSV shape: (114468, 2)\n",
            "Output CSV ID range: 0 to 114467\n",
            "Unique RET_TARGET values: [ 1 -1]\n",
            "Missing values: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_db762e4d-8600-4f56-8fe7-1d5716d74dd1\", \"predictions_ensemble.csv\", 965635)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation Results:\n",
            "LightGBM: 0.9045\n",
            "XGBoost: 0.7645\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFGGRY+y/9cm+QOlGLYbKz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}